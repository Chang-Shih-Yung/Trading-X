"""
ğŸ” EPL Decision History Tracking JSON é…ç½®é©—è­‰
=============================================

ç¬¬3çµ„ä»¶é…ç½®çµæ§‹åˆ†æå’Œé©—è­‰
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)

class EPLConfigValidator:
    """EPL æ±ºç­–æ­·å²è¿½è¹¤é…ç½®é©—è­‰å™¨"""
    
    def __init__(self):
        self.config_path = Path("/Users/henrychang/Desktop/Trading-X/X/backend/phase4_output_monitoring/3_epl_decision_history_tracking/epl_decision_history_tracking_config.json")
        self.python_path = Path("/Users/henrychang/Desktop/Trading-X/X/backend/phase4_output_monitoring/3_epl_decision_history_tracking/epl_decision_history_tracking.py")
        
    def load_and_analyze_config(self) -> Dict[str, Any]:
        """è¼‰å…¥ä¸¦åˆ†æé…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            return {
                "config_loaded": True,
                "config_data": config,
                "file_size": self.config_path.stat().st_size,
                "structure_analysis": self._analyze_config_structure(config)
            }
            
        except Exception as e:
            return {
                "config_loaded": False,
                "error": str(e),
                "file_exists": self.config_path.exists()
            }
    
    def _analyze_config_structure(self, config: Dict) -> Dict[str, Any]:
        """åˆ†æé…ç½®çµæ§‹"""
        analysis = {
            "root_keys": list(config.keys()),
            "structure_depth": self._calculate_depth(config),
            "total_config_items": self._count_config_items(config),
            "section_analysis": {}
        }
        
        # æª¢æŸ¥ä¸»è¦éƒ¨åˆ†
        if "PHASE4_EPL_DECISION_HISTORY_TRACKING" in config:
            epl_config = config["PHASE4_EPL_DECISION_HISTORY_TRACKING"]
            analysis["section_analysis"] = {
                "main_sections": list(epl_config.keys()),
                "decision_tracking": "decision_tracking_architecture" in epl_config,
                "historical_analytics": "historical_analytics" in epl_config,
                "performance_monitoring": "performance_monitoring" in epl_config,
                "data_management": "data_management" in epl_config
            }
        
        return analysis
    
    def _calculate_depth(self, obj, current_depth=0):
        """è¨ˆç®—é…ç½®æ·±åº¦"""
        if isinstance(obj, dict):
            if not obj:
                return current_depth
            return max(self._calculate_depth(v, current_depth + 1) for v in obj.values())
        elif isinstance(obj, list):
            if not obj:
                return current_depth
            return max(self._calculate_depth(item, current_depth + 1) for item in obj)
        else:
            return current_depth
    
    def _count_config_items(self, obj):
        """è¨ˆç®—é…ç½®é …ç›®æ•¸é‡"""
        if isinstance(obj, dict):
            return len(obj) + sum(self._count_config_items(v) for v in obj.values())
        elif isinstance(obj, list):
            return len(obj) + sum(self._count_config_items(item) for item in obj)
        else:
            return 1
    
    def validate_phase_integration(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰ Phase æ•´åˆ"""
        integration_score = 0
        max_score = 40
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        # Phase1 æ•´åˆæª¢æŸ¥ (10åˆ†)
        phase1_integration = 0
        if "decision_tracking_architecture" in epl_config:
            decision_arch = epl_config["decision_tracking_architecture"]
            if "signal_decision_correlation" in decision_arch:
                phase1_integration += 5
            if "signal_outcome_tracking" in decision_arch:
                phase1_integration += 5
        
        details["phase1_signal_correlation"] = f"{phase1_integration}/10"
        integration_score += phase1_integration
        
        # Phase2 æ•´åˆæª¢æŸ¥ (10åˆ†)
        phase2_integration = 0
        if "decision_tracking_architecture" in epl_config:
            decision_arch = epl_config["decision_tracking_architecture"]
            if "epl_decision_recording" in decision_arch:
                phase2_integration += 5
            if "context_preservation" in decision_arch:
                phase2_integration += 5
        
        details["phase2_epl_integration"] = f"{phase2_integration}/10"
        integration_score += phase2_integration
        
        # Phase3 æ•´åˆæª¢æŸ¥ (10åˆ†)
        phase3_integration = 0
        if "performance_monitoring" in epl_config:
            perf_config = epl_config["performance_monitoring"]
            if "execution_outcome_tracking" in perf_config:
                phase3_integration += 5
            if "decision_effectiveness" in perf_config:
                phase3_integration += 5
        
        details["phase3_execution_tracking"] = f"{phase3_integration}/10"
        integration_score += phase3_integration
        
        # Phase4 è‡ªèº«æ•´åˆæª¢æŸ¥ (10åˆ†)
        phase4_integration = 0
        if "historical_analytics" in epl_config:
            hist_config = epl_config["historical_analytics"]
            if "decision_pattern_analysis" in hist_config:
                phase4_integration += 3
            if "performance_trend_analysis" in hist_config:
                phase4_integration += 3
            if "success_rate_analytics" in hist_config:
                phase4_integration += 4
        
        details["phase4_analytics"] = f"{phase4_integration}/10"
        integration_score += phase4_integration
        
        return {
            "integration_score": integration_score,
            "max_score": max_score,
            "percentage": (integration_score / max_score) * 100,
            "details": details,
            "status": "excellent" if integration_score >= 32 else "good" if integration_score >= 24 else "needs_improvement"
        }
    
    def validate_data_structures(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰æ•¸æ“šçµæ§‹ç›¸å®¹æ€§"""
        compatibility_score = 0
        max_score = 30
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        # æ±ºç­–è¨˜éŒ„çµæ§‹ (10åˆ†)
        decision_structure = 0
        if "decision_tracking_architecture" in epl_config:
            arch = epl_config["decision_tracking_architecture"]
            if "decision_record_format" in arch:
                decision_structure += 5
            if "metadata_structure" in arch:
                decision_structure += 5
        
        details["decision_record_structure"] = f"{decision_structure}/10"
        compatibility_score += decision_structure
        
        # æ­·å²æ•¸æ“šç®¡ç† (10åˆ†)  
        history_management = 0
        if "data_management" in epl_config:
            data_mgmt = epl_config["data_management"]
            if "retention_policies" in data_mgmt:
                history_management += 5
            if "archival_strategies" in data_mgmt:
                history_management += 5
        
        details["history_data_management"] = f"{history_management}/10"
        compatibility_score += history_management
        
        # æŸ¥è©¢å’Œæª¢ç´¢ (10åˆ†)
        query_capabilities = 0
        if "historical_analytics" in epl_config:
            analytics = epl_config["historical_analytics"]
            if "query_optimization" in analytics:
                query_capabilities += 5
            if "search_capabilities" in analytics:
                query_capabilities += 5
        
        details["query_and_retrieval"] = f"{query_capabilities}/10"
        compatibility_score += query_capabilities
        
        return {
            "compatibility_score": compatibility_score,
            "max_score": max_score,
            "percentage": (compatibility_score / max_score) * 100,
            "details": details,
            "status": "excellent" if compatibility_score >= 24 else "good" if compatibility_score >= 18 else "needs_improvement"
        }
    
    def validate_monitoring_features(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰ç›£æ§åŠŸèƒ½"""
        monitoring_score = 0
        max_score = 30
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        # æ±ºç­–æ•ˆæœç›£æ§ (10åˆ†)
        effectiveness_monitoring = 0
        if "performance_monitoring" in epl_config:
            perf = epl_config["performance_monitoring"]
            if "decision_effectiveness" in perf:
                effectiveness_monitoring += 5
            if "success_rate_tracking" in perf:
                effectiveness_monitoring += 5
        
        details["decision_effectiveness"] = f"{effectiveness_monitoring}/10"
        monitoring_score += effectiveness_monitoring
        
        # æ¨¡å¼åˆ†æ (10åˆ†)
        pattern_analysis = 0
        if "historical_analytics" in epl_config:
            analytics = epl_config["historical_analytics"]
            if "decision_pattern_analysis" in analytics:
                pattern_analysis += 5
            if "trend_identification" in analytics:
                pattern_analysis += 5
        
        details["pattern_analysis"] = f"{pattern_analysis}/10"
        monitoring_score += pattern_analysis
        
        # å¯¦æ™‚è¿½è¹¤ (10åˆ†)
        realtime_tracking = 0
        if "decision_tracking_architecture" in epl_config:
            tracking = epl_config["decision_tracking_architecture"]
            if "real_time_recording" in tracking:
                realtime_tracking += 5
            if "immediate_feedback" in tracking:
                realtime_tracking += 5
        
        details["realtime_tracking"] = f"{realtime_tracking}/10"
        monitoring_score += realtime_tracking
        
        return {
            "monitoring_score": monitoring_score,
            "max_score": max_score,
            "percentage": (monitoring_score / max_score) * 100,
            "details": details,
            "status": "excellent" if monitoring_score >= 24 else "good" if monitoring_score >= 18 else "needs_improvement"
        }
    
    def generate_validation_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        print("ğŸ” é–‹å§‹ EPL Decision History Tracking JSON é…ç½®é©—è­‰")
        print("=" * 60)
        
        # è¼‰å…¥é…ç½®
        config_analysis = self.load_and_analyze_config()
        
        if not config_analysis.get("config_loaded"):
            return {
                "validation_status": "failed",
                "error": config_analysis.get("error"),
                "recommendations": ["æª¢æŸ¥é…ç½®æ–‡ä»¶è·¯å¾‘", "ä¿®å¾© JSON æ ¼å¼éŒ¯èª¤"]
            }
        
        config = config_analysis["config_data"]
        structure = config_analysis["structure_analysis"]
        
        print(f"âœ… é…ç½®æª”æ¡ˆè¼‰å…¥æˆåŠŸ ({config_analysis['file_size']} bytes)")
        print(f"ğŸ“Š é…ç½®çµæ§‹æ·±åº¦: {structure['structure_depth']}")
        print(f"ğŸ“‹ ç¸½é…ç½®é …ç›®: {structure['total_config_items']}")
        print(f"ğŸ”§ ä¸»è¦æ ¹éµ: {structure['root_keys']}")
        
        # å„é …é©—è­‰
        phase_integration = self.validate_phase_integration(config)
        data_compatibility = self.validate_data_structures(config)
        monitoring_features = self.validate_monitoring_features(config)
        
        # è¨ˆç®—ç¸½åˆ†
        total_score = (
            phase_integration["integration_score"] +
            data_compatibility["compatibility_score"] +
            monitoring_features["monitoring_score"]
        )
        max_total_score = (
            phase_integration["max_score"] +
            data_compatibility["max_score"] +
            monitoring_features["max_score"]
        )
        
        overall_percentage = (total_score / max_total_score) * 100
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "validation_timestamp": datetime.now().isoformat(),
            "config_file": str(self.config_path),
            "overall_score": {
                "total_points": f"{total_score}/{max_total_score}",
                "percentage": f"{overall_percentage:.1f}%",
                "grade": self._get_grade(overall_percentage)
            },
            "detailed_scores": {
                "phase_integration": phase_integration,
                "data_compatibility": data_compatibility,
                "monitoring_features": monitoring_features
            },
            "config_structure": structure,
            "recommendations": self._generate_recommendations(
                phase_integration, data_compatibility, monitoring_features
            )
        }
        
        # æ‰“å°è©³ç´°çµæœ
        self._print_detailed_results(report)
        
        return report
    
    def _get_grade(self, percentage: float) -> str:
        """ç²å–è©•ç´š"""
        if percentage >= 90:
            return "A+ (å„ªç§€)"
        elif percentage >= 80:
            return "A (è‰¯å¥½)"
        elif percentage >= 70:
            return "B (å¯æ¥å—)"
        elif percentage >= 60:
            return "C (éœ€æ”¹é€²)"
        else:
            return "D (éœ€é‡æ§‹)"
    
    def _generate_recommendations(self, phase_integration, data_compatibility, monitoring_features) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        recommendations = []
        
        if phase_integration["percentage"] < 80:
            recommendations.append("åŠ å¼· Phase é–“æ•´åˆé…ç½®")
        
        if data_compatibility["percentage"] < 80:
            recommendations.append("å„ªåŒ–æ•¸æ“šçµæ§‹ç›¸å®¹æ€§")
        
        if monitoring_features["percentage"] < 80:
            recommendations.append("å®Œå–„ç›£æ§åŠŸèƒ½é…ç½®")
        
        if not recommendations:
            recommendations.append("é…ç½®å“è³ªå„ªç§€ï¼Œå»ºè­°ç¶­æŒç¾ç‹€")
        
        return recommendations
    
    def _print_detailed_results(self, report: Dict):
        """æ‰“å°è©³ç´°çµæœ"""
        print(f"\nğŸ“Š ç¸½é«”è©•åˆ†: {report['overall_score']['percentage']} - {report['overall_score']['grade']}")
        
        print("\nğŸ“‹ è©³ç´°è©•åˆ†:")
        for category, details in report["detailed_scores"].items():
            percentage = details["percentage"]
            status_icon = "âœ…" if percentage >= 80 else "âš ï¸" if percentage >= 60 else "âŒ"
            print(f"  {status_icon} {category}: {percentage:.1f}% ({details['status']})")
            
            for detail_key, detail_value in details["details"].items():
                print(f"    - {detail_key}: {detail_value}")
        
        print("\nğŸ’¡ å»ºè­°äº‹é …:")
        for rec in report["recommendations"]:
            print(f"  â€¢ {rec}")

def main():
    """ä¸»å‡½æ•¸"""
    validator = EPLConfigValidator()
    report = validator.generate_validation_report()
    
    # å„²å­˜å ±å‘Š
    report_path = Path("epl_config_validation_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è©³ç´°å ±å‘Šå·²å„²å­˜è‡³: {report_path}")

if __name__ == "__main__":
    main()
