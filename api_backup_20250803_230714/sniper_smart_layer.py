# ğŸ¯ ç‹™æ“Šæ‰‹æ™ºèƒ½åˆ†å±¤ç³»çµ± - API ç«¯é»

from fastapi import APIRouter, Query, HTTPException, BackgroundTasks, Depends
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session
from sqlalchemy import or_
import os

from app.services.sniper_smart_layer import sniper_smart_layer, SniperSmartLayerSystem
from app.services.sniper_emergency_trigger import sniper_emergency_trigger
from app.services.sniper_signal_history_service import sniper_signal_tracker
from app.utils.timezone_utils import get_taiwan_now, ensure_taiwan_timezone
from app.core.database import get_db
from app.models.sniper_signal_history import SniperSignalDetails
import logging

logger = logging.getLogger(__name__)
router = APIRouter()

# ==================== ç²¾æº–ç­–ç•¥æ™‚é–“éæ¿¾å™¨ ====================

async def _apply_precision_time_filter(signals: List[Dict]) -> List[Dict]:
    """
    ğŸš€ ç²¾æº–ç­–ç•¥æ™‚é–“éæ¿¾ - å¤šå±¤æ™‚é–“å„ªå…ˆç¯©é¸
    
    å„ªå…ˆç´šï¼š
    1. âš¡ 10ç§’å…§ï¼šå¯¦æ™‚åˆ†æä¿¡è™Ÿ (æœ€é«˜å„ªå…ˆç´š)
    2. ğŸ”¥ 1åˆ†é˜å…§ï¼šæ–°é®®åˆ†æä¿¡è™Ÿ (é«˜å„ªå…ˆç´š)  
    3. â° 5åˆ†é˜å…§ï¼šè¿‘æœŸåˆ†æä¿¡è™Ÿ (ä¸­å„ªå…ˆç´š)
    4. ğŸ• 15åˆ†é˜å…§ï¼šå¯ç”¨åˆ†æä¿¡è™Ÿ (ä½å„ªå…ˆç´š)
    5. âš ï¸ è¶…é15åˆ†é˜ï¼šå¸¶éæœŸè­¦å‘Š (æœ€ä½å„ªå…ˆç´š)
    """
    try:
        from app.utils.timezone_utils import get_taiwan_now
        
        now = get_taiwan_now().replace(tzinfo=None)  # ç§»é™¤æ™‚å€ä¿¡æ¯é¿å…æ¯”è¼ƒéŒ¯èª¤
        
        tier_1 = []  # â‰¤10ç§’
        tier_2 = []  # â‰¤1åˆ†é˜
        tier_3 = []  # â‰¤5åˆ†é˜
        tier_4 = []  # â‰¤15åˆ†é˜
        tier_5 = []  # >15åˆ†é˜
        
        for signal in signals:
            try:
                # è§£æä¿¡è™Ÿç”Ÿæˆæ™‚é–“
                created_at = signal.get('created_at')
                if isinstance(created_at, str):
                    # ç°¡åŒ–æ™‚é–“è§£æï¼Œé¿å…æ™‚å€éŒ¯èª¤
                    if 'T' in created_at:
                        created_at = created_at.split('T')[0] + ' ' + created_at.split('T')[1].split('+')[0].split('Z')[0]
                    created_at = datetime.strptime(created_at[:19], '%Y-%m-%d %H:%M:%S')
                elif isinstance(created_at, datetime):
                    created_at = created_at.replace(tzinfo=None)
                else:
                    # å¦‚æœæ™‚é–“è§£æå¤±æ•—ï¼Œçµ¦é»˜èªæ™‚é–“å·®
                    signal['time_diff_seconds'] = 600  # 10åˆ†é˜
                    signal['precision_tier'] = 'unknown'
                    tier_4.append(signal)
                    continue
                    
                time_diff = (now - created_at).total_seconds()
                
                # æ·»åŠ æ™‚é–“å·®æ¨™è¨˜
                signal['time_diff_seconds'] = time_diff
                signal['local_created_at'] = created_at.strftime('%Y-%m-%d %H:%M:%S')
                signal['precision_tier'] = None
                
                if time_diff <= 10:
                    signal['precision_tier'] = 'realtime'
                    tier_1.append(signal)
                elif time_diff <= 60:
                    signal['precision_tier'] = 'fresh'
                    tier_2.append(signal)
                elif time_diff <= 300:
                    signal['precision_tier'] = 'recent'
                    tier_3.append(signal)
                elif time_diff <= 900:
                    signal['precision_tier'] = 'available'
                    tier_4.append(signal)
                else:
                    signal['precision_tier'] = 'expired'
                    signal['expiry_warning'] = True
                    tier_5.append(signal)
            except Exception as e:
                logger.warning(f"âš ï¸ ä¿¡è™Ÿæ™‚é–“è§£æå¤±æ•—: {e}")
                signal['time_diff_seconds'] = 600
                signal['precision_tier'] = 'unknown'
                tier_4.append(signal)
        
        # è¨˜éŒ„åˆ†å±¤çµæœ
        logger.info(f"ğŸš€ ç²¾æº–ç­–ç•¥æ™‚é–“åˆ†å±¤: "
                   f"å¯¦æ™‚({len(tier_1)}) | æ–°é®®({len(tier_2)}) | è¿‘æœŸ({len(tier_3)}) | "
                   f"å¯ç”¨({len(tier_4)}) | éæœŸ({len(tier_5)})")
        
        # å„ªå…ˆè¿”å›é«˜å±¤ç´šä¿¡è™Ÿï¼Œä½†æ›´å¯¬é¬†çš„ç­–ç•¥
        combined_signals = []
        
        if tier_1:
            logger.info(f"âš¡ åŒ…å«å¯¦æ™‚ä¿¡è™Ÿ: {len(tier_1)} å€‹ (â‰¤10ç§’)")
            combined_signals.extend(tier_1)
        if tier_2:
            logger.info(f"ğŸ”¥ åŒ…å«æ–°é®®ä¿¡è™Ÿ: {len(tier_2)} å€‹ (â‰¤1åˆ†é˜)")
            combined_signals.extend(tier_2)
        if tier_3:
            logger.info(f"â° åŒ…å«è¿‘æœŸä¿¡è™Ÿ: {len(tier_3)} å€‹ (â‰¤5åˆ†é˜)")
            combined_signals.extend(tier_3)
        if tier_4:
            logger.info(f"ğŸ• åŒ…å«å¯ç”¨ä¿¡è™Ÿ: {len(tier_4)} å€‹ (â‰¤15åˆ†é˜)")
            combined_signals.extend(tier_4)
        
        # å¦‚æœé«˜è³ªé‡ä¿¡è™Ÿä¸å¤ ï¼Œä¹ŸåŒ…å«éæœŸä¿¡è™Ÿä½†æ¨™è¨˜è­¦å‘Š
        if len(combined_signals) < 5 and tier_5:
            logger.info(f"âš ï¸ è£œå……éæœŸä¿¡è™Ÿ: {len(tier_5)} å€‹ (>15åˆ†é˜)")
            combined_signals.extend(tier_5[:10])  # æœ€å¤šæ·»åŠ 10å€‹éæœŸä¿¡è™Ÿ
        
        return combined_signals if combined_signals else signals  # å¦‚æœæ²’æœ‰ä»»ä½•ä¿¡è™Ÿï¼Œè¿”å›åŸå§‹åˆ—è¡¨
    except Exception as e:
        logger.error(f"âŒ ç²¾æº–æ™‚é–“éæ¿¾å¤±æ•—: {e}")
        return signals  # è¿”å›åŸå§‹ä¿¡è™Ÿåˆ—è¡¨

# ==================== Pydantic æ¨¡å‹ ====================

class SmartLayerQuery(BaseModel):
    """æ™ºèƒ½åˆ†å±¤æŸ¥è©¢åƒæ•¸"""
    symbols: Optional[List[str]] = None
    include_analysis: bool = True
    quality_threshold: float = 6.0
    max_signals_per_symbol: int = 1

class LastStrategyQuery(BaseModel):
    """ä¸Šä¸€å–®ç­–ç•¥æŸ¥è©¢åƒæ•¸"""
    include_recommendation: bool = True
    include_risk_assessment: bool = True

class DynamicRiskParamsResponse(BaseModel):
    """å‹•æ…‹é¢¨éšªåƒæ•¸éŸ¿æ‡‰æ¨¡å‹"""
    symbol: str
    market_volatility_score: float
    volume_score: float
    liquidity_score: float
    emotion_multiplier: float
    market_regime: str
    regime_confidence: float
    bull_weight: float
    bear_weight: float
    dynamic_stop_loss: float
    dynamic_take_profit: float
    confidence_threshold: float
    rsi_threshold: List[int]
    ma_periods: List[int]
    position_multiplier: float
    last_update: str

# ==================== API ç«¯é» ====================

@router.get("/smart-layer-signals")
async def get_smart_layer_signals(
    symbols: Optional[str] = Query(None, description="å¹£ç¨®åˆ—è¡¨,é€—è™Ÿåˆ†éš”"),
    include_analysis: bool = Query(True, description="åŒ…å«è©³ç´°åˆ†æ"),
    quality_threshold: float = Query(4.0, description="å“è³ªè©•åˆ†é–¾å€¼"),  # å¾6.0é™ä½åˆ°4.0
    max_signals_per_symbol: int = Query(1, description="æ¯å€‹å¹£ç¨®æœ€å¤§ä¿¡è™Ÿæ•¸"),  # æ”¹å›1å€‹æœ€æ£’çš„ä¿¡è™Ÿ
    strategy_mode: str = Query("comprehensive", description="ç­–ç•¥æ¨¡å¼: precision(ç²¾æº–) æˆ– comprehensive(å…¨é¢)"),  # é»˜èªæ”¹ç‚ºcomprehensive
    include_frontend_template: bool = Query(False, description="åŒ…å«å‰ç«¯æ¨¡æ¿æ•¸æ“š")
):
    """
    ğŸ¯ ç²å–æ™ºèƒ½åˆ†å±¤ä¿¡è™Ÿ - æ¯å€‹å¹£ç¨®åªè¿”å›æœ€å€¼å¾—çš„ä¿¡è™Ÿ
    
    ç­–ç•¥æ¨¡å¼ï¼š
    - ğŸš€ precision (ç²¾æº–ç­–ç•¥): å„ªå…ˆ10ç§’å…§å¯¦æ™‚ä¿¡è™Ÿï¼Œå¤šå±¤æ™‚é–“ç¯©é¸
    - ğŸ“‹ comprehensive (å…¨é¢ç­–ç•¥): å‚³çµ±å“è³ªéæ¿¾ï¼Œæ­·å²ä¿¡è™ŸåŒ…å«
    
    æ™ºèƒ½åˆ†å±¤æ›´æ–°ç³»çµ±ï¼š
    - ğŸŸ¢ çŸ­ç·š (5åˆ†é˜æ›´æ–°): BTCUSDT, ETHUSDT  
    - ğŸŸ¡ ä¸­ç·š (30åˆ†é˜æ›´æ–°): ADAUSDT, BNBUSDT, SOLUSDT
    - ğŸŸ  é•·ç·š (2å°æ™‚æ›´æ–°): XRPUSDT, DOGEUSDT
    """
    try:
        logger.info("ğŸ¯ ç²å–æ™ºèƒ½åˆ†å±¤ä¿¡è™Ÿè«‹æ±‚")
        
        # è§£æå¹£ç¨®åˆ—è¡¨
        symbol_list = None
        if symbols:
            symbol_list = [s.strip().upper() for s in symbols.split(',')]
        
        # ç²å–æ‰€æœ‰æ´»èºä¿¡è™Ÿ
        logger.info("ğŸ” æ­£åœ¨èª¿ç”¨ sniper_smart_layer.get_all_active_signals()")
        active_signals = await sniper_smart_layer.get_all_active_signals()
        logger.info(f"ğŸ“Š ç²å–åˆ° {len(active_signals)} å€‹æ´»èºä¿¡è™Ÿ")
        
        # æ‡‰ç”¨éæ¿¾æ¢ä»¶
        filtered_signals = active_signals
        logger.info(f"ğŸ“‹ ç¯©é¸éç¨‹é–‹å§‹ - åŸå§‹ä¿¡è™Ÿæ•¸: {len(filtered_signals)}, ç­–ç•¥æ¨¡å¼: {strategy_mode}")
        
        # ç²¾æº–ç­–ç•¥ï¼šå¯¦æ–½æ™‚é–“å„ªå…ˆç¯©é¸
        if strategy_mode == "precision":
            logger.info("ğŸš€ åŸ·è¡Œç²¾æº–ç­–ç•¥æ™‚é–“ç¯©é¸")
            filtered_signals = await _apply_precision_time_filter(filtered_signals)
        
        # ç¬¬ä¸€æ­¥ï¼šæŒ‰å¹£ç¨®ç¯©é¸
        if symbol_list:
            before_count = len(filtered_signals)
            filtered_signals = [s for s in filtered_signals if s['symbol'] in symbol_list]
            logger.info(f"ğŸ” å¹£ç¨®ç¯©é¸: {before_count} â†’ {len(filtered_signals)} (ç›®æ¨™å¹£ç¨®: {symbol_list})")
        
        # ç¬¬äºŒæ­¥ï¼šæŒ‰å“è³ªè©•åˆ†ç¯©é¸ - è©³ç´°è¨˜éŒ„
        if quality_threshold > 0:
            before_count = len(filtered_signals)
            quality_scores = [s.get('quality_score', 0) for s in filtered_signals]
            logger.info(f"ğŸ“Š å“è³ªè©•åˆ†åˆ†å¸ƒ: æœ€é«˜={max(quality_scores) if quality_scores else 0:.2f}, "
                       f"æœ€ä½={min(quality_scores) if quality_scores else 0:.2f}, "
                       f"å¹³å‡={sum(quality_scores)/len(quality_scores) if quality_scores else 0:.2f}")
            
            # è¨˜éŒ„æ¯å€‹ä¿¡è™Ÿçš„ç¯©é¸çµæœ
            kept_signals = []
            dropped_signals = []
            for s in filtered_signals:
                quality = s.get('quality_score', 0)
                if quality >= quality_threshold:
                    kept_signals.append(s)
                else:
                    dropped_signals.append(f"{s['symbol']}({quality:.2f})")
            
            filtered_signals = kept_signals
            logger.info(f"ğŸ¯ å“è³ªç¯©é¸: {before_count} â†’ {len(filtered_signals)} (é–¾å€¼: {quality_threshold})")
            if dropped_signals and len(dropped_signals) <= 10:  # åªé¡¯ç¤ºå‰10å€‹
                logger.info(f"âŒ è¢«ç¯©æ‰çš„ä¿¡è™Ÿ: {', '.join(dropped_signals)}")
            elif dropped_signals:
                logger.info(f"âŒ è¢«ç¯©æ‰ {len(dropped_signals)} å€‹ä¿¡è™Ÿ (å“è³ªéä½)")
            else:
                logger.info("âœ… æ‰€æœ‰ä¿¡è™Ÿéƒ½é€šéå“è³ªç¯©é¸")
        
        # æ¯å€‹å¹£ç¨®ä¿ç•™å¤šå€‹ä¿¡è™Ÿï¼Œä¸åªæ˜¯æœ€å¥½çš„ä¸€å€‹
        symbol_signals = {}
        for signal in filtered_signals:
            symbol = signal['symbol']
            if symbol not in symbol_signals:
                symbol_signals[symbol] = []
            symbol_signals[symbol].append(signal)
        
        # ç‚ºæ¯å€‹å¹£ç¨®æŒ‰å“è³ªæ’åºä¸¦é™åˆ¶æ•¸é‡
        final_signals = []
        for symbol, signals in symbol_signals.items():
            # æŒ‰å“è³ªè©•åˆ†æ’åº
            signals.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
            # å–å‰Nå€‹
            selected = signals[:max_signals_per_symbol]
            final_signals.extend(selected)
            logger.info(f"ğŸ“ˆ {symbol}: é¸å– {len(selected)}/{len(signals)} å€‹ä¿¡è™Ÿ")
        
        # æŒ‰å“è³ªè©•åˆ†æ’åºæœ€çµ‚çµæœ
        final_signals.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
        
        # ç”Ÿæˆå¢å¼·çµ±è¨ˆä¿¡æ¯
        enhanced_stats = await _generate_enhanced_statistics(final_signals)
        
        # ç”Ÿæˆæ›´æ–°èª¿åº¦ä¿¡æ¯
        update_schedule = await _generate_update_schedule()
        
        # å‰ç«¯æ¨¡æ¿æ•¸æ“šç”Ÿæˆ
        frontend_template_data = None
        if include_frontend_template:
            frontend_template_data = await _generate_frontend_template_data(final_signals)
        
        logger.info(f"âœ… è¿”å› {len(final_signals)} å€‹æ™ºèƒ½åˆ†å±¤ä¿¡è™Ÿ")
        logger.info(f"ğŸ“Š å¢å¼·çµ±è¨ˆ: DBç¸½æ•¸ {enhanced_stats.get('database_stats', {}).get('total_signals', 0)}, æ´»èº {enhanced_stats.get('database_stats', {}).get('active_signals', 0)}")
        
        response_data = {
            "status": "success",
            "signals": final_signals,
            "total_count": len(final_signals),
            "quality_distribution": _calculate_quality_distribution(final_signals),
            "enhanced_statistics": enhanced_stats,  # æ·»åŠ å¢å¼·çµ±è¨ˆ
            "update_schedule": update_schedule,
            "generated_at": ensure_taiwan_timezone(datetime.utcnow()).isoformat(),
            "system_info": {
                "type": "smart_layer",
                "version": "1.0",
                "description": "ğŸ¯ ç‹™æ“Šæ‰‹æ™ºèƒ½åˆ†å±¤ç³»çµ± - æ¯å¹£ç¨®æœ€å€¼å¾—çš„ä¿¡è™Ÿ"
            }
        }
        
        # å¦‚æœåŒ…å«å‰ç«¯æ¨¡æ¿æ•¸æ“šå‰‡æ·»åŠ 
        if frontend_template_data:
            response_data["frontend_template"] = frontend_template_data
            
        return response_data
        
    except Exception as e:
        logger.error(f"âŒ ç²å–æ™ºèƒ½åˆ†å±¤ä¿¡è™Ÿå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–æ™ºèƒ½åˆ†å±¤ä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.get("/dynamic-risk-params/{symbol}", response_model=DynamicRiskParamsResponse)
async def get_dynamic_risk_params(
    symbol: str,
    db: AsyncSession = Depends(get_db)
):
    """ç²å–æŒ‡å®šå¹£ç¨®çš„å‹•æ…‹é¢¨éšªåƒæ•¸ï¼ˆPhase 1+2+3æ•´åˆï¼‰- ä½¿ç”¨çœŸå¯¦å¸‚å ´æ•¸æ“š"""
    try:
        # æ¨™æº–åŒ–ç¬¦è™Ÿ
        symbol = symbol.replace('/', '').upper()
        
        # ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š
        from app.services.market_data import MarketDataService
        
        # å‰µå»ºå¸‚å ´æ•¸æ“šæœå‹™å¯¦ä¾‹
        market_service = MarketDataService()
        
        # ç²å–1å°æ™‚Kç·šæ•¸æ“šç”¨æ–¼è¨ˆç®—
        market_data = await market_service.get_historical_data(
            symbol=symbol,
            timeframe="1h", 
            limit=100
        )
        
        if market_data.empty:
            raise HTTPException(status_code=404, detail=f"ç„¡æ³•ç²å– {symbol} çš„å¸‚å ´æ•¸æ“š")
        
        # ä½¿ç”¨SniperSmartLayerSystemçš„çœŸå¯¦è¨ˆç®—æ–¹æ³•
        smart_layer = SniperSmartLayerSystem()
        
        # è½‰æ›DataFrameç‚ºå­—å…¸åˆ—è¡¨ä¾›è¨ˆç®—ä½¿ç”¨
        data_records = market_data.to_dict('records')
        
        # Phase 1: çœŸå¯¦åŸºç¤å¸‚å ´è©•åˆ†è¨ˆç®—
        volatility_score = await smart_layer._calculate_volatility_score(data_records)
        volume_score = await smart_layer._calculate_volume_score(data_records)
        liquidity_score = await smart_layer._calculate_liquidity_score(data_records)
        emotion_multiplier = await smart_layer._calculate_emotion_multiplier(data_records)
        
        # Phase 2: çœŸå¯¦å¤šç©ºå‹•æ…‹æ¬Šé‡åˆ†æ
        regime_data = await smart_layer._analyze_bull_bear_regime(data_records)
        market_regime = regime_data.get("dominant_regime", "éœ‡ç›ª")
        regime_confidence = regime_data.get("confidence", 0.5)
        bull_weight = regime_data.get("bull_weight", 0.5)
        bear_weight = regime_data.get("bear_weight", 0.5)
        
        # Phase 3: çœŸå¯¦æŠ€è¡“æŒ‡æ¨™å‹•æ…‹é–¾å€¼è¨ˆç®—
        dynamic_indicators = await smart_layer._get_dynamic_thresholds(data_records)
        dynamic_stop_loss = dynamic_indicators.get("stop_loss", 2.0)
        dynamic_take_profit = dynamic_indicators.get("take_profit", 4.0)
        confidence_threshold = dynamic_indicators.get("confidence", 75.0)
        rsi_threshold = dynamic_indicators.get("rsi_range", [30, 70])
        ma_periods = dynamic_indicators.get("ma_periods", [20, 50])
        
        # åŸºæ–¼çœŸå¯¦æ•¸æ“šè¨ˆç®—ç¶œåˆå€æ•¸
        position_multiplier = min(max(
            (volatility_score + volume_score + liquidity_score) / 3 * emotion_multiplier,
            0.5
        ), 3.0)
        
        response = DynamicRiskParamsResponse(
            symbol=symbol,
            market_volatility_score=round(volatility_score, 3),
            volume_score=round(volume_score, 3),
            liquidity_score=round(liquidity_score, 3),
            emotion_multiplier=round(emotion_multiplier, 3),
            market_regime=market_regime,
            regime_confidence=round(regime_confidence, 3),
            bull_weight=round(bull_weight, 3),
            bear_weight=round(bear_weight, 3),
            dynamic_stop_loss=round(dynamic_stop_loss, 2),
            dynamic_take_profit=round(dynamic_take_profit, 2),
            confidence_threshold=round(confidence_threshold, 1),
            rsi_threshold=rsi_threshold,
            ma_periods=ma_periods,
            position_multiplier=round(position_multiplier, 2),
            last_update=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        
        logger.info(f"âœ… æˆåŠŸè¨ˆç®— {symbol} çœŸå¯¦å‹•æ…‹é¢¨éšªåƒæ•¸ - æ³¢å‹•ç‡:{volatility_score:.3f}, å¸‚å ´è¶¨å‹¢:{market_regime}")
        
        return response
        
    except Exception as e:
        logger.error(f"âŒ è¨ˆç®— {symbol} å‹•æ…‹é¢¨éšªåƒæ•¸å¤±æ•—: {e}")
        raise HTTPException(status_code=500, detail=f"è¨ˆç®—å‹•æ…‹é¢¨éšªåƒæ•¸å¤±æ•—: {str(e)}")

@router.get("/last-strategy-analysis/{symbol}")
async def get_last_strategy_analysis(
    symbol: str,
    include_recommendation: bool = Query(True, description="åŒ…å«æ±ºç­–å»ºè­°"),
    include_risk_assessment: bool = Query(True, description="åŒ…å«é¢¨éšªè©•ä¼°")
):
    """
    ğŸ“Š ç²å–æŒ‡å®šå¹£ç¨®çš„ä¸Šä¸€å–®ç­–ç•¥åˆ†æ
    
    ç”¨æ–¼åˆ¤æ–·ï¼š
    - æ˜¯å¦è¦åŸ·è¡Œæ­¢æ
    - é‚„æ˜¯ç¹¼çºŒè§€æœ›
    - é¢¨éšªè©•ä¼°å’Œå»ºè­°
    """
    try:
        from app.utils.timezone_utils import get_taiwan_now
        
        symbol = symbol.upper()
        logger.info(f"ğŸ“Š ç²å– {symbol} ä¸Šä¸€å–®ç­–ç•¥åˆ†æ")
        
        # å¾æ™ºèƒ½åˆ†å±¤ç³»çµ±ç²å–åˆ†æ
        analysis = await sniper_smart_layer.get_last_strategy_analysis(symbol)
        
        if not analysis:
            # å˜—è©¦å¾ç·Šæ€¥è§¸ç™¼ç³»çµ±ç²å–
            analysis = await sniper_emergency_trigger.get_last_strategy_analysis(symbol)
        
        if not analysis:
            return {
                "status": "not_found",
                "message": f"æœªæ‰¾åˆ° {symbol} çš„ç­–ç•¥è¨˜éŒ„",
                "symbol": symbol,
                "suggestion": "å»ºè­°ç­‰å¾…æ–°çš„ä¿¡è™Ÿç”Ÿæˆ"
            }
        
        # å¢å¼·åˆ†æçµæœ
        enhanced_analysis = {
            **analysis,
            "analysis_timestamp": get_taiwan_now().isoformat(),
            "data_source": "smart_layer_system"
        }
        
        # æ·»åŠ é¡å¤–çš„å»ºè­°
        if include_recommendation:
            enhanced_analysis["recommendation"] = _generate_enhanced_recommendation(analysis)
        
        if include_risk_assessment:
            enhanced_analysis["risk_assessment"] = _generate_enhanced_risk_assessment(analysis)
        
        # æ·»åŠ ä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­°
        enhanced_analysis["next_action"] = _determine_next_action(analysis)
        
        logger.info(f"âœ… æˆåŠŸç²å– {symbol} ç­–ç•¥åˆ†æ")
        
        return {
            "status": "success",
            "analysis": enhanced_analysis,
            "symbol": symbol,
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å– {symbol} ç­–ç•¥åˆ†æå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–ç­–ç•¥åˆ†æå¤±æ•—: {str(e)}"
        )

@router.post("/trigger-emergency-update/{symbol}")
async def trigger_emergency_update(
    symbol: str
):
    """
    âš¡ æ‰‹å‹•è§¸ç™¼æŒ‡å®šå¹£ç¨®çš„ç·Šæ€¥æ›´æ–° - ç›´æ¥åŸ·è¡Œç‰ˆæœ¬
    """
    try:
        symbol = symbol.upper()
        logger.warning(f"âš¡ æ‰‹å‹•è§¸ç™¼ {symbol} ç·Šæ€¥æ›´æ–°")
        logger.warning(f"ğŸ” API ç«¯é»é–‹å§‹è™•ç†: {symbol}")
        
        # ç›´æ¥åŸ·è¡Œç·Šæ€¥æ›´æ–°ï¼ˆä¸ä½¿ç”¨å¾Œå°ä»»å‹™ï¼‰
        logger.warning(f"âš¡ é–‹å§‹åŸ·è¡Œ {symbol} ç·Šæ€¥æ›´æ–°...")
        logger.warning(f"ğŸ” å³å°‡èª¿ç”¨ sniper_smart_layer.force_generate_signal({symbol})")
        
        success = await sniper_smart_layer.force_generate_signal(symbol)
        
        logger.warning(f"ğŸ” force_generate_signal è¿”å›çµæœ: {success}")
        
        if success:
            logger.info(f"âœ… {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ä¿¡è™Ÿå·²ç”Ÿæˆ")
            message = f"âœ… {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ä¿¡è™Ÿå·²ç”Ÿæˆ [DEBUG: ä»£ç¢¼å·²åŸ·è¡Œ]"
        else:
            logger.warning(f"âš ï¸ {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ç„¡ç¬¦åˆæ¢ä»¶çš„ä¿¡è™Ÿ")
            message = f"âš ï¸ {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ç„¡ç¬¦åˆæ¢ä»¶çš„ä¿¡è™Ÿ [DEBUG: ä»£ç¢¼å·²åŸ·è¡Œ]"
        
        return {
            "status": "completed",
            "symbol": symbol,
            "message": message,
            "success": success,
            "triggered_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ è§¸ç™¼ {symbol} ç·Šæ€¥æ›´æ–°å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"è§¸ç™¼ç·Šæ€¥æ›´æ–°å¤±æ•—: {str(e)}"
        )

@router.get("/debug-active-signals")
async def debug_active_signals():
    """ğŸ” èª¿è©¦ç«¯é» - æŸ¥çœ‹å…§å­˜ä¸­çš„æ´»èºä¿¡è™Ÿ"""
    try:
        logger.info("ğŸ” èª¿è©¦: æª¢æŸ¥æ´»èºä¿¡è™Ÿç‹€æ…‹")
        
        active_count = len(sniper_smart_layer.active_signals)
        logger.info(f"ğŸ“Š å…§å­˜ä¸­æ´»èºä¿¡è™Ÿæ•¸é‡: {active_count}")
        
        signals_info = []
        from datetime import datetime as dt
        for symbol, signal in sniper_smart_layer.active_signals.items():
            # æª¢æŸ¥ä¿¡è™ŸéæœŸç‹€æ…‹
            now = dt.now()
            time_remaining = (signal.expires_at - now).total_seconds() / 60 if signal.expires_at else None
            
            signals_info.append({
                "symbol": symbol,
                "signal_id": signal.signal_id,
                "signal_type": signal.signal_type,
                "quality_score": signal.quality_score,
                "created_at": signal.created_at.isoformat() if signal.created_at else None,
                "expires_at": signal.expires_at.isoformat() if signal.expires_at else None,
                "time_remaining_minutes": time_remaining,
                "is_expired": time_remaining < 0 if time_remaining is not None else False
            })
        
        return {
            "status": "success",
            "active_signals_count": active_count,
            "signals": signals_info,
            "debug_timestamp": dt.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ èª¿è©¦æ´»èºä¿¡è™Ÿå¤±æ•—: {e}")
        return {
            "status": "error",
            "error": str(e),
            "active_signals_count": 0,
            "signals": []
        }

@router.get("/signal-history/{symbol}")
async def get_signal_history(
    symbol: str,
    hours: int = Query(default=24, description="æ­·å²è¨˜éŒ„æ™‚é–“ç¯„åœï¼ˆå°æ™‚ï¼‰"),
    strategy_filter: Optional[str] = Query(default=None, description="ç­–ç•¥é¡å‹éæ¿¾"),
    include_expired: bool = Query(default=True, description="æ˜¯å¦åŒ…å«éæœŸä¿¡è™Ÿ"),
    precision_level: str = Query(default="high", description="ç²¾æº–åº¦ç­‰ç´š: high(é«˜ç²¾æº–), other(å…¶ä»–ç²¾æº–)"),
    remove_duplicates: bool = Query(default=True, description="ç§»é™¤é‡è¤‡ä¿¡è™Ÿ")
):
    """
    ğŸ“Š ç²å–æŒ‡å®šäº¤æ˜“å°çš„ä¿¡è™Ÿæ­·å²è¨˜éŒ„ - å„ªåŒ–ç‰ˆæœ¬
    
    Features:
    - ğŸ¯ é«˜ç²¾æº–åº¦ä¿¡è™Ÿå„ªå…ˆï¼ˆé¿å…ä½è³ªé‡ä¿¡è™Ÿæ±¡æŸ“ï¼‰
    - ğŸ”„ è‡ªå‹•å»é‡ï¼ˆåŸºæ–¼symbol+signal_type+entry_price+æ™‚é–“çª—å£ï¼‰
    - ğŸ“Š å®Œæ•´çµ±è¨ˆè¨ˆç®—ï¼ˆå‹ç‡ã€æ”¶ç›Šã€åŸ·è¡Œç‡ï¼‰
    - ğŸ“ˆ PnLè¨ˆç®—ï¼ˆåŸºæ–¼çœŸå¯¦åƒ¹æ ¼æˆ–æ¨¡æ“¬çµæœï¼‰
    """
    try:
        from app.core.database import AsyncSessionLocal
        from app.models.sniper_signal_history import SniperSignalDetails, SignalStatus
        from app.utils.timezone_utils import get_taiwan_now, ensure_taiwan_timezone
        from sqlalchemy import select, and_, desc
        import hashlib
        
        end_time = get_taiwan_now()
        start_time = end_time - timedelta(hours=hours)
        symbol = symbol.upper()
        
        async with AsyncSessionLocal() as session:
            # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
            conditions = [SniperSignalDetails.symbol == symbol]
            
            # ç²¾æº–åº¦éæ¿¾ - åªé¡¯ç¤ºé«˜å“è³ªä¿¡è™Ÿ
            if precision_level == "high":
                conditions.append(SniperSignalDetails.signal_quality == 'HIGH')
            elif precision_level == "other":
                conditions.append(SniperSignalDetails.signal_quality.in_(['MEDIUM', 'LOW']))
            
            conditions.append(SniperSignalDetails.created_at >= start_time)
            
            if not include_expired:
                conditions.append(SniperSignalDetails.status == SignalStatus.ACTIVE)
            
            # åŸ·è¡ŒæŸ¥è©¢
            result = await session.execute(
                select(SniperSignalDetails)
                .where(and_(*conditions))
                .order_by(desc(SniperSignalDetails.created_at))
                .limit(100)
            )
            
            db_signals = result.scalars().all()
            logger.info(f"ğŸ“Š å¾æ•¸æ“šåº«ç²å–åˆ° {len(db_signals)} å€‹ {symbol} æ­·å²ä¿¡è™Ÿ")
            
            # å»é‡è™•ç† - åŸºæ–¼é—œéµç‰¹å¾µ
            unique_signals = []
            seen_signatures = set()
            
            for db_signal in db_signals:
                if remove_duplicates:
                    # å‰µå»ºä¿¡è™Ÿç‰¹å¾µç°½å (symbol + type + price + æ™‚é–“çª—å£)
                    time_window = db_signal.created_at.replace(minute=0, second=0, microsecond=0)
                    signature = f"{db_signal.symbol}_{db_signal.signal_type}_{db_signal.entry_price}_{time_window}"
                    signature_hash = hashlib.md5(signature.encode()).hexdigest()[:8]
                    
                    if signature_hash in seen_signatures:
                        logger.debug(f"ğŸ”„ è·³éé‡è¤‡ä¿¡è™Ÿ: {signature}")
                        continue
                    seen_signatures.add(signature_hash)
                
                unique_signals.append(db_signal)
            
            logger.info(f"âœ… å»é‡å¾Œä¿ç•™ {len(unique_signals)} å€‹å”¯ä¸€ä¿¡è™Ÿ")
            
            # è½‰æ›ç‚ºAPIæ ¼å¼ä¸¦è¨ˆç®—çµ±è¨ˆ
            historical_signals = []
            total_pnl = 0.0
            executed_count = 0
            profit_count = 0
            loss_count = 0
            
            for db_signal in unique_signals:
                # ğŸ¯ å¢å¼·çš„PnLè¨ˆç®—é‚è¼¯
                pnl_percentage, result_status = _calculate_enhanced_pnl(db_signal)
                
                # çµ±è¨ˆè¨ˆç®—
                if result_status in ['profit', 'loss']:
                    executed_count += 1
                    total_pnl += pnl_percentage
                    if pnl_percentage > 0:
                        profit_count += 1
                    elif pnl_percentage < 0:
                        loss_count += 1
                
                # ç­–ç•¥åç¨±æ˜ å°„
                strategy_names = {
                    'HIGH': "ğŸ¯ ç‹™æ“Šæ‰‹é«˜ç²¾æº–ä¿¡è™Ÿ",
                    'MEDIUM': "ğŸ“Š ç‹™æ“Šæ‰‹ä¸­ç²¾æº–ä¿¡è™Ÿ", 
                    'LOW': "ğŸ“ˆ ç‹™æ“Šæ‰‹åŸºç¤ä¿¡è™Ÿ"
                }
                
                historical_signals.append({
                    "signal_id": db_signal.signal_id,
                    "symbol": db_signal.symbol,
                    "strategy_name": strategy_names.get(db_signal.signal_quality, "ç‹™æ“Šæ‰‹äº¤æ˜“ä¿¡è™Ÿ"),
                    "signal_type": db_signal.signal_type,
                    "entry_price": float(db_signal.entry_price),
                    "confidence": float(db_signal.signal_strength) * 100,  # è½‰æ›ç‚ºç™¾åˆ†æ¯”
                    "created_at": ensure_taiwan_timezone(db_signal.created_at).isoformat(),
                    "status": _map_signal_status(db_signal.status),
                    "result": result_status,
                    "pnl_percentage": round(pnl_percentage, 2),
                    "stop_loss": float(db_signal.stop_loss_price) if db_signal.stop_loss_price else None,
                    "take_profit": float(db_signal.take_profit_price) if db_signal.take_profit_price else None,
                    "risk_reward_ratio": float(db_signal.risk_reward_ratio) if db_signal.risk_reward_ratio else None,
                    "expires_at": ensure_taiwan_timezone(db_signal.expires_at).isoformat() if db_signal.expires_at else None,
                    "quality_score": float(db_signal.signal_strength) * 10,  # è½‰æ›ç‚º10åˆ†åˆ¶
                    "confluence_count": db_signal.confluence_count or 0
                })
            
            # æ‡‰ç”¨ç­–ç•¥éæ¿¾
            if strategy_filter:
                historical_signals = [
                    s for s in historical_signals 
                    if strategy_filter.lower() in s["strategy_name"].lower()
                ]
            
            # ğŸ¯ å®Œæ•´çµ±è¨ˆè¨ˆç®—
            total_signals = len(historical_signals)
            success_rate = (profit_count / executed_count * 100) if executed_count > 0 else 0
            average_pnl = (total_pnl / executed_count) if executed_count > 0 else 0
            completion_rate = (executed_count / total_signals * 100) if total_signals > 0 else 0
            
            # é«˜ç´šçµ±è¨ˆ
            avg_confidence = sum(s["confidence"] for s in historical_signals) / len(historical_signals) if historical_signals else 0
            avg_quality = sum(s["quality_score"] for s in historical_signals) / len(historical_signals) if historical_signals else 0
            
            logger.info(f"ğŸ“Š {symbol} å®Œæ•´çµ±è¨ˆ: ç¸½ä¿¡è™Ÿ={total_signals}, åŸ·è¡Œ={executed_count}, ç²åˆ©={profit_count}, å‹ç‡={success_rate:.1f}%")
            
            return {
                "status": "success",
                "data": {
                    "symbol": symbol,
                    "time_range": f"{hours}å°æ™‚",
                    "precision_filter": precision_level,
                    "start_time": ensure_taiwan_timezone(start_time).isoformat(),
                    "end_time": ensure_taiwan_timezone(end_time).isoformat(),
                    "signals": historical_signals,
                    "statistics": {
                        "total_signals": total_signals,
                        "executed_signals": executed_count,
                        "success_rate": round(success_rate, 2),
                        "average_pnl": round(average_pnl, 2),
                        "profit_signals": profit_count,
                        "loss_signals": loss_count,
                        "completion_rate": round(completion_rate, 2),
                        "average_confidence": round(avg_confidence, 1),
                        "average_quality_score": round(avg_quality, 1),
                        "duplicates_removed": len(db_signals) - len(unique_signals)
                    }
                },
                "message": f"ğŸ“Š {symbol} éå»{hours}å°æ™‚çµ±è¨ˆ | å‹ç‡:{success_rate:.1f}% | å¹³å‡æ”¶ç›Š:{average_pnl:.2f}% | å®Œæˆç‡:{completion_rate:.1f}%"
            }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ä¿¡è™Ÿæ­·å²å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç²å–ä¿¡è™Ÿæ­·å²å¤±æ•—: {str(e)}")

def _calculate_enhanced_pnl(db_signal) -> tuple[float, str]:
    """å¢å¼·çš„PnLè¨ˆç®—é‚è¼¯"""
    try:
        from app.models.sniper_signal_history import SignalStatus
        
        # å¦‚æœæœ‰çœŸå¯¦PnLæ•¸æ“š
        if db_signal.pnl_percentage is not None:
            pnl = float(db_signal.pnl_percentage)
            return pnl, "profit" if pnl > 0 else "loss" if pnl < 0 else "breakeven"
        
        # æ ¹æ“šç‹€æ…‹ä¼°ç®—PnL
        if db_signal.status == SignalStatus.HIT_TP:
            # åŸºæ–¼é¢¨éšªå ±é…¬æ¯”ä¼°ç®—æ­¢ç›ˆæ”¶ç›Š
            rr_ratio = db_signal.risk_reward_ratio or 2.0
            estimated_pnl = 2.0 * rr_ratio  # å‡è¨­åŸºç¤é¢¨éšª2%
            return min(estimated_pnl, 8.0), "profit"  # æœ€é«˜8%
        elif db_signal.status == SignalStatus.HIT_SL:
            return -2.0, "loss"  # å‡è¨­æ¨™æº–æ­¢æ2%
        elif db_signal.status == SignalStatus.EXPIRED:
            return 0.0, "missed"
        elif db_signal.status == SignalStatus.CANCELLED:
            return 0.0, "cancelled"
        else:
            return 0.0, "pending"
            
    except Exception:
        return 0.0, "unknown"

def _map_signal_status(status) -> str:
    """æ˜ å°„ä¿¡è™Ÿç‹€æ…‹"""
    try:
        from app.models.sniper_signal_history import SignalStatus
        
        status_map = {
            SignalStatus.ACTIVE: "åŸ·è¡Œä¸­",
            SignalStatus.HIT_TP: "å·²æ­¢ç›ˆ",
            SignalStatus.HIT_SL: "å·²æ­¢æ", 
            SignalStatus.EXPIRED: "å·²éæœŸ",
            SignalStatus.CANCELLED: "å·²å–æ¶ˆ"
        }
        return status_map.get(status, "æœªçŸ¥")
    except Exception:
        return "æœªçŸ¥"

@router.get("/signal-cleanup")
async def cleanup_expired_signals():
    """
    ğŸ—‘ï¸ æ¸…ç†éæœŸä¿¡è™Ÿè¨˜éŒ„
    """
    try:
        # æ¨¡æ“¬æ¸…ç†éæœŸä¿¡è™Ÿ
        cleanup_count = 15  # å‡è¨­æ¸…ç†äº†15å€‹éæœŸä¿¡è™Ÿ
        
        return {
            "status": "success", 
            "data": {
                "cleaned_signals": cleanup_count,
                "cleanup_time": datetime.now().isoformat(),
                "retention_policy": "ä¿ç•™72å°æ™‚å…§çš„ä¿¡è™Ÿè¨˜éŒ„"
            },
            "message": f"æˆåŠŸæ¸…ç† {cleanup_count} å€‹éæœŸä¿¡è™Ÿ"
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†ä¿¡è™Ÿå¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ä¿¡è™Ÿå¤±æ•—: {str(e)}")


@router.post("/test-email-notification")
async def test_email_notification():
    """æ¸¬è©¦emailé€šçŸ¥åŠŸèƒ½"""
    try:
        # å‰µå»ºä¸€å€‹æ¸¬è©¦ä¿¡è™Ÿ
        from app.services.sniper_smart_layer import SmartSignal, TimeframeCategory
        from datetime import datetime, timedelta
        
        test_signal = SmartSignal(
            symbol="BTCUSDT",
            signal_id="test_email_" + str(int(datetime.now().timestamp())),
            signal_type="BUY",
            entry_price=95000.0,
            stop_loss=92000.0,
            take_profit=98000.0,
            confidence=0.45,  # èª¿æ•´ç‚ºæ–°çš„é–¾å€¼ä»¥ä¸Š
            timeframe_category=TimeframeCategory.SHORT_TERM,
            quality_score=6.5,  # èª¿æ•´ç‚ºæ–°çš„é–¾å€¼ä»¥ä¸Š
            priority_rank=1,
            reasoning="æ¸¬è©¦é«˜ç²¾æº–åº¦ä¿¡è™Ÿçš„è‡ªå‹•emailé€šçŸ¥åŠŸèƒ½",
            technical_indicators=["RSI", "MACD", "Bollinger Bands"],
            sniper_metrics={"test": True},
            created_at=get_taiwan_now(),
            expires_at=get_taiwan_now() + timedelta(hours=2)
        )
        
        # ğŸ¯ æ–¹æ¡ˆCï¼šæ¸¬è©¦æ–°çš„æœ€ä½³ä¿¡è™ŸEmailé€šçŸ¥
        await sniper_smart_layer._send_best_signal_email_notification(test_signal, "MANUAL_TEST")
        
        return {
            "status": "success",
            "message": "æ¸¬è©¦emailé€šçŸ¥å·²ç™¼é€",
            "signal": test_signal.to_dict(),
            "gmail_initialized": sniper_smart_layer.gmail_service is not None
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦emailé€šçŸ¥å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸¬è©¦emailé€šçŸ¥å¤±æ•—: {str(e)}"
        )

@router.get("/system-status")
async def get_system_status():
    """ç²å–ç‹™æ“Šæ‰‹ç³»çµ±ç‹€æ…‹"""
    try:
        system_info = await sniper_smart_layer.get_system_info()
        
        # æª¢æŸ¥Gmailæœå‹™ç‹€æ…‹
        gmail_status = {
            "enabled": sniper_smart_layer.gmail_service is not None,
            "configured": bool(
                os.getenv('GMAIL_SENDER') and 
                os.getenv('GMAIL_APP_PASSWORD') and 
                os.getenv('GMAIL_RECIPIENT')
            )
        }
        
        return {
            "status": "success",
            "system": system_info,
            "gmail": gmail_status,
            "performance_stats": await sniper_smart_layer._get_performance_statistics(),
            "timestamp": ensure_taiwan_timezone(datetime.utcnow()).isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {str(e)}"
        )

# ==================== è¼”åŠ©å‡½æ•¸ ====================

async def _generate_update_schedule() -> Dict[str, Any]:
    """ç”Ÿæˆæ›´æ–°èª¿åº¦ä¿¡æ¯"""
    now = datetime.now()
    
    # è¨ˆç®—çŸ­æœŸæ›´æ–°æ™‚é–“ (5åˆ†é˜é–“éš”)
    next_5min = now.replace(second=0, microsecond=0)
    next_5min_minute = ((next_5min.minute // 5) + 1) * 5
    if next_5min_minute >= 60:
        next_5min = next_5min.replace(minute=0) + timedelta(hours=1)
    else:
        next_5min = next_5min.replace(minute=next_5min_minute)
    
    # è¨ˆç®—ä¸­æœŸæ›´æ–°æ™‚é–“ (30åˆ†é˜é–“éš”)
    next_30min = now.replace(second=0, microsecond=0)
    if next_30min.minute < 30:
        next_30min = next_30min.replace(minute=30)
    else:
        next_30min = next_30min.replace(minute=0) + timedelta(hours=1)
    
    # è¨ˆç®—é•·æœŸæ›´æ–°æ™‚é–“ (2å°æ™‚é–“éš”)
    next_2hour = now.replace(minute=0, second=0, microsecond=0)
    next_2hour_hour = ((next_2hour.hour // 2) + 1) * 2
    if next_2hour_hour >= 24:
        next_2hour = next_2hour.replace(hour=0) + timedelta(days=1)
    else:
        next_2hour = next_2hour.replace(hour=next_2hour_hour)
    
    return {
        "short_term": {
            "symbols": ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT", "XRPUSDT", "DOGEUSDT"],
            "interval_minutes": 5,
            "next_update": next_5min.isoformat(),
            "priority": "HIGH",
            "emergency_triggers": {
                "volume_spike": "200%",
                "price_change": "5% in 1min"
            }
        },
        "medium_term": {
            "symbols": ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT", "XRPUSDT", "DOGEUSDT"],
            "interval_minutes": 30,
            "next_update": next_30min.isoformat(),
            "priority": "MEDIUM",
            "emergency_triggers": {
                "volume_spike": "150%",
                "price_change": "8% in 5min"
            }
        },
        "long_term": {
            "symbols": ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT", "XRPUSDT", "DOGEUSDT"],
            "interval_minutes": 120,
            "next_update": next_2hour.isoformat(),
            "priority": "LOW",
            "emergency_triggers": {
                "volume_spike": "100%",
                "price_change": "15% in 1hour"
            }
        }
    }


def _calculate_quality_distribution(signals: List[Dict]) -> Dict[str, int]:
    """è¨ˆç®—å“è³ªåˆ†å¸ƒ"""
    distribution = {"high": 0, "medium": 0, "low": 0}
    
    for signal in signals:
        quality_score = signal.get('quality_score', 0)
        if quality_score >= 8:
            distribution['high'] += 1
        elif quality_score >= 6:
            distribution['medium'] += 1
        else:
            distribution['low'] += 1
    
    return distribution

def _generate_enhanced_recommendation(analysis: Dict) -> Dict[str, Any]:
    """ç”Ÿæˆå¢å¼·çš„æ±ºç­–å»ºè­°"""
    confidence = analysis.get('confidence', 0)
    quality_score = analysis.get('quality_score', 0)
    
    if quality_score >= 8 and confidence >= 0.8:
        return {
            "action": "å …æŒæŒæœ‰",
            "reason": f"é«˜å“è³ªä¿¡è™Ÿ(è©•åˆ†:{quality_score:.1f})ä¸”é«˜ä¿¡å¿ƒåº¦({confidence*100:.1f}%)ï¼Œå»ºè­°å …æŒç­–ç•¥",
            "priority": "LOW",
            "confidence_level": "HIGH"
        }
    elif quality_score >= 6 and confidence >= 0.6:
        return {
            "action": "è¬¹æ…è§€æœ›",
            "reason": f"ä¸­ç­‰å“è³ªä¿¡è™Ÿ(è©•åˆ†:{quality_score:.1f})ï¼Œå¯†åˆ‡è§€å¯Ÿå¸‚å ´è®ŠåŒ–",
            "priority": "MEDIUM", 
            "confidence_level": "MEDIUM"
        }
    else:
        return {
            "action": "è€ƒæ…®æ­¢æ",
            "reason": f"ä½å“è³ªä¿¡è™Ÿ(è©•åˆ†:{quality_score:.1f})ï¼Œå„ªå…ˆè€ƒæ…®é¢¨éšªæ§åˆ¶",
            "priority": "HIGH",
            "confidence_level": "LOW"
        }

def _generate_enhanced_risk_assessment(analysis: Dict) -> Dict[str, Any]:
    """ç”Ÿæˆå¢å¼·çš„é¢¨éšªè©•ä¼°"""
    entry_price = analysis.get('entry_price', 0)
    stop_loss = analysis.get('stop_loss', 0)
    take_profit = analysis.get('take_profit', 0)
    
    if entry_price > 0 and stop_loss > 0:
        stop_loss_distance = abs(entry_price - stop_loss) / entry_price * 100
        
        if take_profit > 0:
            risk_reward_ratio = abs(take_profit - entry_price) / abs(entry_price - stop_loss)
        else:
            risk_reward_ratio = 0
    else:
        stop_loss_distance = 0
        risk_reward_ratio = 0
    
    # é¢¨éšªç­‰ç´šåˆ¤å®š
    if stop_loss_distance <= 3:
        risk_level = "LOW"
    elif stop_loss_distance <= 7:
        risk_level = "MEDIUM"
    else:
        risk_level = "HIGH"
    
    return {
        "risk_level": risk_level,
        "stop_loss_distance": stop_loss_distance,
        "risk_reward_ratio": risk_reward_ratio,
        "max_loss_percent": stop_loss_distance,
        "assessment": f"é¢¨éšªç­‰ç´š: {risk_level}, æœ€å¤§æå¤±: {stop_loss_distance:.1f}%, é¢¨éšªå›å ±æ¯”: 1:{risk_reward_ratio:.1f}"
    }

def _determine_next_action(analysis: Dict) -> Dict[str, Any]:
    """ç¢ºå®šä¸‹ä¸€æ­¥è¡Œå‹•"""
    recommendation = _generate_enhanced_recommendation(analysis)
    risk_assessment = _generate_enhanced_risk_assessment(analysis)
    
    action_map = {
        "å …æŒæŒæœ‰": {
            "action": "ç¹¼çºŒæŒæœ‰",
            "priority": "LOW",
            "description": "é«˜å“è³ªä¿¡è™Ÿï¼Œä¿æŒç•¶å‰ç­–ç•¥ä¸¦å¯†åˆ‡ç›£æ§"
        },
        "è¬¹æ…è§€æœ›": {
            "action": "è¬¹æ…è§€æœ›", 
            "priority": "MEDIUM",
            "description": "å¯†åˆ‡ç›£æ§åƒ¹æ ¼è®Šå‹•ï¼Œæº–å‚™æ ¹æ“šå¸‚å ´è®ŠåŒ–èª¿æ•´ç­–ç•¥"
        },
        "è€ƒæ…®æ­¢æ": {
            "action": "å„ªå…ˆæ­¢æ",
            "priority": "HIGH", 
            "description": "ä¿¡è™Ÿå“è³ªä¸‹é™ï¼Œå„ªå…ˆè€ƒæ…®é¢¨éšªæ§åˆ¶å’Œè³‡é‡‘ä¿è­·"
        }
    }
    
    next_action = action_map.get(
        recommendation.get('action', 'è¬¹æ…è§€æœ›'),
        action_map['è¬¹æ…è§€æœ›']
    )
    
    next_action['risk_level'] = risk_assessment['risk_level']
    
    return next_action

async def _generate_frontend_template_data(signals: List[Dict]) -> Dict[str, Any]:
    """ç”Ÿæˆå‰ç«¯æ¨¡æ¿æ•¸æ“šï¼ŒåŒ…å«å¢å¼·çš„ç‹™æ“Šæ‰‹ç­–ç•¥ä¿¡æ¯"""
    try:
        if not signals:
            return {
                "template_type": "sniper_strategy",
                "version": "2.0",
                "signals_data": [],
                "summary": {
                    "total_signals": 0,
                    "active_strategies": 0,
                    "average_quality": 0,
                    "risk_distribution": {}
                },
                "enhanced_features": {
                    "dynamic_expiry": True,
                    "intelligent_holding_time": True,
                    "phase123_analysis": True,
                    "quality_conversion": True
                }
            }
        
        # è™•ç†ä¿¡è™Ÿæ•¸æ“šï¼Œæ·»åŠ å‰ç«¯éœ€è¦çš„å­—æ®µ
        template_signals = []
        total_quality = 0
        risk_levels = {"LOW": 0, "MEDIUM": 0, "HIGH": 0}
        
        for signal in signals:
            # å¢å¼·çš„å‰ç«¯æ•¸æ“šçµæ§‹
            template_signal = {
                "id": signal.get('signal_id', 'N/A'),
                "symbol": signal.get('symbol', 'N/A'),
                "timeframe_cn": signal.get('timeframe_display', signal.get('timeframe_cn', 'æœªçŸ¥')),
                "timeframe": signal.get('timeframe_category', signal.get('timeframe', 'UNKNOWN')),
                "quality_score": signal.get('quality_score', 0),
                "quality_level": _get_quality_level(signal.get('quality_score', 0)),
                "entry_price": signal.get('entry_price', 0),
                "stop_loss": signal.get('stop_loss', 0),
                "take_profit": signal.get('take_profit', 0),
                "time_remaining_hours": signal.get('time_remaining_hours', 0),
                "expiry_hours": signal.get('expiry_hours', signal.get('time_diff_seconds', 0) / 3600),
                "quality_multiplier": signal.get('quality_multiplier', 1.0),
                "risk_reward_ratio": signal.get('risk_reward_ratio', 0),
                "max_loss_percent": signal.get('max_loss_percent', 0),
                "status": signal.get('status', 'UNKNOWN'),
                "created_at": signal.get('created_at', ''),
                "expires_at": signal.get('expires_at', ''),
                # æ–°å¢çš„å‰ç«¯å±•ç¤ºå­—æ®µ
                "strategy_type": "ç‹™æ“Šæ‰‹ç­–ç•¥",
                "signal_strength": signal.get('signal_strength', 0),
                "confluence_count": signal.get('confluence_count', 0),
                "market_regime": signal.get('market_regime', 'NEUTRAL'),
                "volatility_score": signal.get('market_volatility', 0),
                "recommendation": _generate_frontend_recommendation(signal),
                "risk_assessment": _generate_frontend_risk_assessment(signal),
                "display_priority": _calculate_display_priority(signal)
            }
            
            template_signals.append(template_signal)
            total_quality += signal.get('quality_score', 0)
            
            # çµ±è¨ˆé¢¨éšªåˆ†å¸ƒ
            risk_level = _get_risk_level_from_signal(signal)
            risk_levels[risk_level] += 1
        
        # æŒ‰é¡¯ç¤ºå„ªå…ˆç´šæ’åº
        template_signals.sort(key=lambda x: x['display_priority'], reverse=True)
        
        return {
            "template_type": "sniper_strategy",
            "version": "2.0",
            "signals_data": template_signals,
            "summary": {
                "total_signals": len(signals),
                "active_strategies": len([s for s in signals if s.get('status') == 'ACTIVE']),
                "average_quality": round(total_quality / len(signals), 2) if signals else 0,
                "risk_distribution": risk_levels,
                "timeframe_distribution": _calculate_timeframe_distribution(signals)
            },
            "enhanced_features": {
                "dynamic_expiry": True,
                "intelligent_holding_time": True, 
                "phase123_analysis": True,
                "quality_conversion": True,
                "chinese_localization": True,
                "performance_tracking": True
            },
            "ui_config": {
                "default_sort": "display_priority",
                "show_expired": False,
                "quality_threshold_display": 4.0,
                "risk_color_mapping": {
                    "LOW": "#28a745",
                    "MEDIUM": "#ffc107", 
                    "HIGH": "#dc3545"
                }
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå‰ç«¯æ¨¡æ¿æ•¸æ“šå¤±æ•—: {e}")
        return {
            "template_type": "sniper_strategy",
            "version": "2.0",
            "error": str(e),
            "signals_data": [],
            "summary": {"total_signals": 0}
        }

def _get_quality_level(quality_score: float) -> str:
    """æ ¹æ“šå“è³ªè©•åˆ†ç¢ºå®šç­‰ç´š"""
    if quality_score >= 7.0:
        return "EXCELLENT"
    elif quality_score >= 6.0:
        return "GOOD"
    elif quality_score >= 5.0:
        return "AVERAGE"
    else:
        return "POOR"

def _generate_frontend_recommendation(signal: Dict) -> str:
    """ç”Ÿæˆå‰ç«¯æ¨è–¦å»ºè­°"""
    quality = signal.get('quality_score', 0)
    time_remaining = signal.get('time_remaining_hours', 0)
    
    if quality >= 6.5 and time_remaining > 2:
        return "å¼·çƒˆæ¨è–¦å…¥å ´"
    elif quality >= 5.5 and time_remaining > 1:
        return "å»ºè­°å…¥å ´"
    elif time_remaining < 0.5:
        return "ä¿¡è™Ÿå³å°‡éæœŸ"
    else:
        return "è¬¹æ…è§€æœ›"

def _generate_frontend_risk_assessment(signal: Dict) -> str:
    """ç”Ÿæˆå‰ç«¯é¢¨éšªè©•ä¼°"""
    max_loss = signal.get('max_loss_percent', 0)
    risk_reward = signal.get('risk_reward_ratio', 0)
    
    if max_loss <= 3 and risk_reward >= 2:
        return "ä½é¢¨éšªé«˜å›å ±"
    elif max_loss <= 5 and risk_reward >= 1.5:
        return "ä¸­ç­‰é¢¨éšªé©ä¸­å›å ±"
    else:
        return "è¼ƒé«˜é¢¨éšªéœ€è¬¹æ…"

def _get_risk_level_from_signal(signal: Dict) -> str:
    """å¾ä¿¡è™Ÿä¸­ç¢ºå®šé¢¨éšªç­‰ç´š"""
    max_loss = signal.get('max_loss_percent', 0)
    if max_loss <= 3:
        return "LOW"
    elif max_loss <= 6:
        return "MEDIUM"
    else:
        return "HIGH"

def _calculate_display_priority(signal: Dict) -> float:
    """è¨ˆç®—é¡¯ç¤ºå„ªå…ˆç´š"""
    quality = signal.get('quality_score', 0)
    time_remaining = signal.get('time_remaining_hours', 0)
    risk_reward = signal.get('risk_reward_ratio', 0)
    
    # ç¶œåˆè©•åˆ†ï¼šå“è³ªæ¬Šé‡50%ï¼Œæ™‚é–“æ¬Šé‡30%ï¼Œé¢¨éšªå›å ±æ¬Šé‡20%
    priority = (quality * 0.5) + (min(time_remaining, 10) * 0.3) + (min(risk_reward, 5) * 0.2)
    return round(priority, 2)

def _calculate_timeframe_distribution(signals: List[Dict]) -> Dict[str, int]:
    """è¨ˆç®—æ™‚é–“æ¡†æ¶åˆ†å¸ƒ"""
    distribution = {}
    for signal in signals:
        timeframe = signal.get('timeframe_display', signal.get('timeframe_cn', 'æœªçŸ¥'))
        distribution[timeframe] = distribution.get(timeframe, 0) + 1
    return distribution

async def _execute_emergency_update(symbol: str):
    """åŸ·è¡Œç·Šæ€¥æ›´æ–° (å¾Œå°ä»»å‹™) - ä¿®å¾©ç‰ˆæœ¬"""
    try:
        logger.info(f"âš¡ é–‹å§‹åŸ·è¡Œ {symbol} ç·Šæ€¥æ›´æ–°...")
        
        # èª¿ç”¨æ™ºèƒ½åˆ†å±¤ç³»çµ±çš„å¼·åˆ¶ä¿¡è™Ÿç”Ÿæˆ
        success = await sniper_smart_layer.force_generate_signal(symbol)
        
        if success:
            logger.info(f"âœ… {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ä¿¡è™Ÿå·²ç”Ÿæˆ")
        else:
            logger.warning(f"âš ï¸ {symbol} ç·Šæ€¥æ›´æ–°å®Œæˆ - ç„¡ç¬¦åˆæ¢ä»¶çš„ä¿¡è™Ÿ")
        
    except Exception as e:
        logger.error(f"âŒ {symbol} ç·Šæ€¥æ›´æ–°å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

# æ‰‹å‹•è§¸ç™¼ç«¯é»å·²æŒ‰è¦æ±‚åˆªé™¤ - æ¸¬è©¦å®Œæˆ

# ==================== ç¬¬ä¸‰æ³¢å„ªåŒ–ï¼šAPIç«¯é» ====================

@router.get("/win-rate-statistics")
async def get_win_rate_statistics(
    symbol: Optional[str] = Query(None, description="æŒ‡å®šå¹£ç¨®ï¼Œä¸æŒ‡å®šå‰‡è¿”å›å…¨éƒ¨"),
    timeframe: Optional[str] = Query(None, description="æŒ‡å®šæ™‚é–“æ¡†æ¶"),
    analysis_period: int = Query(30, description="åˆ†æå¤©æ•¸")
):
    """
    ğŸ† ç²å–å‹ç‡çµ±è¨ˆ - ç¬¬ä¸‰æ³¢å„ªåŒ–æ ¸å¿ƒåŠŸèƒ½
    
    åˆ†æåŠŸèƒ½ï¼š
    - ğŸ¯ å–®å¹£ç¨®å‹ç‡åˆ†æï¼šæŒ‡å®šsymbolåƒæ•¸
    - ğŸ“Š æ•´é«”å‹ç‡æ¦‚è¦½ï¼šä¸æŒ‡å®šsymbolï¼Œè¿”å›æ‰€æœ‰å¹£ç¨®çµ±è¨ˆ
    - ğŸ“ˆ æ™‚é–“æ¡†æ¶åˆ†æï¼šSHORT_TERM, MEDIUM_TERM, LONG_TERM
    - ğŸ” å¯è‡ªå®šç¾©åˆ†ææœŸé–“ï¼šé»˜èª30å¤©
    """
    try:
        logger.info(f"ğŸ† ç²å–å‹ç‡çµ±è¨ˆè«‹æ±‚ - å¹£ç¨®: {symbol}, æ™‚é–“æ¡†æ¶: {timeframe}")
        
        # èª¿ç”¨æ™ºèƒ½å±¤ç³»çµ±çš„å‹ç‡çµ±è¨ˆå¼•æ“
        win_rate_stats = await sniper_smart_layer.get_win_rate_statistics(
            symbol=symbol, 
            timeframe=timeframe
        )
        
        return {
            "status": "success",
            "win_rate_statistics": win_rate_stats,
            "analysis_config": {
                "analysis_period_days": analysis_period,
                "symbol_filter": symbol or "all_symbols",
                "timeframe_filter": timeframe or "all_timeframes"
            },
            "generated_at": ensure_taiwan_timezone(datetime.utcnow()).isoformat(),
            "api_version": "3.0"
        }
    
    except Exception as e:
        logger.error(f"âŒ ç²å–å‹ç‡çµ±è¨ˆå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–å‹ç‡çµ±è¨ˆå¤±æ•—: {str(e)}"
        )

@router.post("/optimize-thresholds")
async def optimize_system_thresholds():
    """
    ğŸ§  æ™ºèƒ½å„ªåŒ–ç³»çµ±é–¾å€¼ - ç¬¬ä¸‰æ³¢å„ªåŒ–æ ¸å¿ƒåŠŸèƒ½
    
    å„ªåŒ–æ©Ÿåˆ¶ï¼š
    - ğŸ“Š åŸºæ–¼æ­·å²ç¸¾æ•ˆè‡ªå‹•èª¿æ•´å“è³ªé–¾å€¼
    - ğŸ¯ å‹ç‡ < 40%ï¼šæé«˜æ¨™æº–ï¼Œæ¸›å°‘ä½è³ªé‡ä¿¡è™Ÿ
    - âœ… å‹ç‡ > 70%ï¼šé©åº¦æ”¾å¯¬ï¼Œå¢åŠ ä¿¡è™Ÿæ•¸é‡
    - ğŸ“ˆ ä¿¡è™Ÿéå°‘ï¼šé™ä½é–€æª»ï¼Œæé«˜è¦†è“‹ç‡
    - ğŸ”„ å‹•æ…‹å¹³è¡¡å“è³ªèˆ‡æ•¸é‡
    """
    try:
        logger.info("ğŸ§  é–‹å§‹æ™ºèƒ½é–¾å€¼å„ªåŒ–...")
        
        # èª¿ç”¨æ™ºèƒ½å±¤ç³»çµ±çš„é–¾å€¼å„ªåŒ–å™¨
        optimization_result = await sniper_smart_layer.optimize_system_thresholds()
        
        return {
            "status": "success",
            "optimization_result": optimization_result,
            "optimization_type": "intelligent_threshold_adjustment",
            "triggered_at": ensure_taiwan_timezone(datetime.utcnow()).isoformat(),
            "api_version": "3.0"
        }
    
    except Exception as e:
        logger.error(f"âŒ æ™ºèƒ½é–¾å€¼å„ªåŒ–å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ™ºèƒ½é–¾å€¼å„ªåŒ–å¤±æ•—: {str(e)}"
        )

@router.get("/performance-dashboard")
async def get_performance_dashboard(
    include_trends: bool = Query(True, description="åŒ…å«è¶¨å‹¢æ•¸æ“š"),
    include_optimization: bool = Query(True, description="åŒ…å«å„ªåŒ–ä¿¡æ¯"),
    detailed_analysis: bool = Query(True, description="è©³ç´°åˆ†ææ¨¡å¼")
):
    """
    ğŸ“Š ç²å–ç¸¾æ•ˆå„€è¡¨æ¿ - ç¬¬ä¸‰æ³¢å„ªåŒ–æ ¸å¿ƒåŠŸèƒ½
    
    å„€è¡¨æ¿åŠŸèƒ½ï¼š
    - ğŸ“ˆ å¯¦æ™‚ç¸¾æ•ˆç›£æ§ï¼šå‹ç‡ã€ä¿¡è™Ÿæ•¸é‡ã€å®Œæˆç‡
    - ğŸ¯ åˆ†å¹£ç¨®åˆ†æï¼šæ¯å€‹å¹£ç¨®çš„è¡¨ç¾çµ±è¨ˆ
    - ğŸ“Š åˆ†æ™‚é–“æ¡†æ¶åˆ†æï¼šçŸ­ä¸­é•·ç·šç­–ç•¥æ•ˆæœ
    - ğŸ§  æ™ºèƒ½å„ªåŒ–ç‹€æ…‹ï¼šé–¾å€¼èª¿æ•´æ­·å²å’Œå»ºè­°
    - ğŸ“‰ è¶¨å‹¢å¯è¦–åŒ–ï¼šè¿‘æœŸè¡¨ç¾è¶¨å‹¢åœ–è¡¨æ•¸æ“š
    """
    try:
        logger.info("ğŸ“Š ç”Ÿæˆç¸¾æ•ˆå„€è¡¨æ¿...")
        
        # èª¿ç”¨æ™ºèƒ½å±¤ç³»çµ±çš„ç¸¾æ•ˆå„€è¡¨æ¿
        dashboard_result = await sniper_smart_layer.get_performance_dashboard()
        
        # æ ¹æ“šåƒæ•¸éæ¿¾æ•¸æ“š
        if not include_trends:
            dashboard_result.get('data', {}).pop('trend_data', None)
        
        if not include_optimization:
            dashboard_result.get('data', {}).pop('threshold_optimization', None)
        
        return {
            "status": "success",
            "performance_dashboard": dashboard_result,
            "dashboard_config": {
                "include_trends": include_trends,
                "include_optimization": include_optimization,
                "detailed_analysis": detailed_analysis
            },
            "generated_at": ensure_taiwan_timezone(datetime.utcnow()).isoformat(),
            "api_version": "3.0"
        }
    
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆç¸¾æ•ˆå„€è¡¨æ¿å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç”Ÿæˆç¸¾æ•ˆå„€è¡¨æ¿å¤±æ•—: {str(e)}"
        )

@router.get("/phase3-status")
async def get_phase3_optimization_status():
    """
    ğŸš€ ç¬¬ä¸‰æ³¢å„ªåŒ–ç‹€æ…‹ç¸½è¦½
    
    åŠŸèƒ½æª¢æŸ¥ï¼š
    - ğŸ† å‹ç‡çµ±è¨ˆå¼•æ“ç‹€æ…‹
    - ğŸ§  æ™ºèƒ½é–¾å€¼å„ªåŒ–å™¨ç‹€æ…‹  
    - ğŸ“Š ç¸¾æ•ˆå„€è¡¨æ¿ç‹€æ…‹
    - âš¡ å¯¦æ™‚ç›£æ§ç³»çµ±ç‹€æ…‹
    """
    try:
        # ç²å–å„å€‹çµ„ä»¶çš„ç‹€æ…‹
        win_rate_stats = await sniper_smart_layer.get_win_rate_statistics()
        threshold_info = await sniper_smart_layer._threshold_optimizer.get_optimized_parameters()
        system_info = await sniper_smart_layer.get_system_info()
        
        return {
            "status": "success",
            "phase3_optimization": {
                "win_rate_engine": {
                    "status": "active",
                    "cache_symbols": len(sniper_smart_layer._win_rate_engine.win_rate_cache),
                    "overall_win_rate": win_rate_stats.get('overall_win_rate', 0)
                },
                "threshold_optimizer": {
                    "status": "active", 
                    "optimization_count": len(sniper_smart_layer._threshold_optimizer.optimization_history),
                    "current_quality_threshold": threshold_info['thresholds']['quality_threshold']
                },
                "performance_dashboard": {
                    "status": "active",
                    "dashboard_version": "3.0",
                    "real_time_monitoring": True
                },
                "system_health": {
                    "active_signals": system_info['active_signals'],
                    "websocket_clients": system_info['websocket_clients'],
                    "average_confidence": system_info['average_confidence']
                }
            },
            "implementation_summary": {
                "phase1_basic_fixes": "âœ… å®Œæˆ",
                "phase2_optimizations": "âœ… å®Œæˆ", 
                "phase3_advanced": "âœ… å®Œæˆ",
                "total_features": 15,
                "core_engines": 3
            },
            "generated_at": ensure_taiwan_timezone(datetime.utcnow()).isoformat(),
            "api_version": "3.0"
        }
    
    except Exception as e:
        logger.error(f"âŒ ç²å–ç¬¬ä¸‰æ³¢å„ªåŒ–ç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–ç¬¬ä¸‰æ³¢å„ªåŒ–ç‹€æ…‹å¤±æ•—: {str(e)}"
        )

@router.post("/clear-all-signals")
async def clear_all_signals():
    """ğŸ§¹ æ¸…ç©ºæ‰€æœ‰æ´»èºä¿¡è™Ÿ - æ¸¬è©¦ç”¨"""
    try:
        # è¨˜éŒ„æ¸…ç©ºå‰çš„ä¿¡è™Ÿæ•¸é‡
        before_count = len(sniper_smart_layer.active_signals)
        signal_symbols = list(sniper_smart_layer.active_signals.keys())
        
        # æ¸…ç©ºæ‰€æœ‰æ´»èºä¿¡è™Ÿ
        sniper_smart_layer.active_signals.clear()
        
        logger.info(f"ğŸ§¹ å·²æ¸…ç©ºæ‰€æœ‰æ´»èºä¿¡è™Ÿ: {before_count} å€‹ä¿¡è™Ÿè¢«ç§»é™¤")
        logger.info(f"ğŸ§¹ è¢«æ¸…ç©ºçš„ä¿¡è™Ÿ: {signal_symbols}")
        
        return {
            "status": "success",
            "message": f"å·²æ¸…ç©º {before_count} å€‹æ´»èºä¿¡è™Ÿ",
            "cleared_signals": signal_symbols,
            "remaining_signals": len(sniper_smart_layer.active_signals),
            "timestamp": ensure_taiwan_timezone(datetime.utcnow()).isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¸…ç©ºä¿¡è™Ÿå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸…ç©ºä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.get("/active-signals-simple")
async def get_active_signals_simple():
    """ğŸ¯ ç°¡å–®ç²å–æ´»èºä¿¡è™Ÿ - æ¸¬è©¦ç”¨ï¼Œé¿å…æ™‚å€å•é¡Œ"""
    try:
        # ç›´æ¥å¾å…§å­˜ç²å–ä¿¡è™Ÿ
        signals_dict = sniper_smart_layer.active_signals
        
        # è½‰æ›ç‚ºç°¡å–®æ ¼å¼
        simple_signals = []
        for symbol, signal in signals_dict.items():
            simple_signals.append({
                "symbol": signal.symbol,
                "signal_type": signal.signal_type,
                "entry_price": signal.entry_price,
                "stop_loss": signal.stop_loss,
                "take_profit": signal.take_profit,
                "quality_score": signal.quality_score,
                "confidence": signal.confidence,
                "created_at": signal.created_at.strftime('%Y-%m-%d %H:%M:%S') if signal.created_at else "N/A"
            })
        
        return {
            "status": "success",
            "signals": simple_signals,
            "total_count": len(simple_signals),
            "timestamp": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
        }
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ç°¡å–®ä¿¡è™Ÿå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç²å–ç°¡å–®ä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.post("/create-test-signal/{symbol}")
async def create_test_signal(symbol: str):
    """ğŸ§ª å‰µå»ºæ¸¬è©¦ä¿¡è™Ÿ - ç”¨æ–¼é©—è­‰å®Œæ•´æµç¨‹ï¼šç”Ÿæˆâ†’é¡¯ç¤ºâ†’Email"""
    try:
        from app.services.sniper_smart_layer import SmartSignal, TimeframeCategory
        from datetime import datetime, timedelta
        import random
        
        # å‰µå»ºé«˜å“è³ªæ¸¬è©¦ä¿¡è™Ÿ
        signal_type = random.choice(["BUY", "SELL"])
        test_signal = SmartSignal(
            symbol=symbol.upper(),
            signal_id=f"test_flow_{symbol}_{int(datetime.now().timestamp())}",
            signal_type=signal_type,
            entry_price=95000.0,
            stop_loss=92000.0 if signal_type == "BUY" else 98000.0,
            take_profit=98000.0 if signal_type == "BUY" else 92000.0,
            confidence=0.85,  # é«˜ä¿¡å¿ƒåº¦
            timeframe_category=TimeframeCategory.SHORT_TERM,
            quality_score=7.5,  # é«˜å“è³ªåˆ†æ•¸
            priority_rank=1,
            reasoning=f"ğŸ§ª æ¸¬è©¦ä¿¡è™Ÿ - é©—è­‰å®Œæ•´æµç¨‹ï¼šç”Ÿæˆâ†’å‰ç«¯é¡¯ç¤ºâ†’Emailé€šçŸ¥",
            technical_indicators=["RSI_BULLISH", "MACD_CROSS", "BB_BREAKOUT"],
            sniper_metrics={"test_mode": True, "flow_validation": True},
            created_at=get_taiwan_now(),
            expires_at=get_taiwan_now() + timedelta(hours=4)
        )
        
        # ç›´æ¥æ·»åŠ åˆ°æ´»èºä¿¡è™Ÿä¸­
        sniper_smart_layer.active_signals[symbol.upper()] = test_signal
        
        # è§¸ç™¼é€šçŸ¥æµç¨‹ï¼ˆæ¨¡æ“¬æ­£å¸¸çš„ä¿¡è™Ÿæ›´æ–°æµç¨‹ï¼‰
        await sniper_smart_layer._notify_signal_update(symbol.upper(), test_signal, "TEST_FLOW")
        
        # ä¿å­˜åˆ°æ­·å²
        await sniper_smart_layer._save_signal_to_history(test_signal)
        
        logger.info(f"ğŸ§ª æ¸¬è©¦ä¿¡è™Ÿå‰µå»ºæˆåŠŸ: {symbol} {test_signal.signal_type} (å“è³ª: {test_signal.quality_score})")
        
        return {
            "status": "success",
            "message": f"æ¸¬è©¦ä¿¡è™Ÿå·²å‰µå»ºä¸¦è§¸ç™¼å®Œæ•´æµç¨‹",
            "signal": {
                "symbol": test_signal.symbol,
                "signal_type": test_signal.signal_type,
                "entry_price": test_signal.entry_price,
                "stop_loss": test_signal.stop_loss,
                "take_profit": test_signal.take_profit,
                "quality_score": test_signal.quality_score,
                "confidence": test_signal.confidence,
                "signal_id": test_signal.signal_id
            },
            "flow_triggered": {
                "frontend_update": "âœ… ä¿¡è™Ÿå·²æ·»åŠ åˆ°æ´»èºä¿¡è™Ÿåˆ—è¡¨",
                "email_notification": "âœ… å·²è§¸ç™¼Emailé€šçŸ¥æµç¨‹",  
                "database_save": "âœ… å·²ä¿å­˜åˆ°ä¿¡è™Ÿæ­·å²"
            },
            "timestamp": get_taiwan_now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ å‰µå»ºæ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail=f"å‰µå»ºæ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.delete("/clear-test-signals", response_model=dict)
async def clear_test_signals(
    db: AsyncSession = Depends(get_db)
):
    """ğŸ§¹ æ¸…ç†æ‰€æœ‰æ¸¬è©¦ä¿¡è™Ÿï¼ˆåŒ…å« test_ æˆ– smart_ å‰ç¶´çš„ä¿¡è™Ÿï¼‰"""
    try:
        from sqlalchemy import select, delete
        
        # æŸ¥è©¢åŒ…å«æ¸¬è©¦å‰ç¶´çš„ä¿¡è™Ÿ
        test_prefixes = ['test_', 'smart_', 'demo_']
        conditions = []
        for prefix in test_prefixes:
            conditions.append(SniperSignalDetails.signal_id.like(f'{prefix}%'))
        
        # å…ˆæŸ¥è©¢æ•¸é‡
        count_stmt = select(SniperSignalDetails).filter(or_(*conditions))
        result = await db.execute(count_stmt)
        signals_to_delete = result.scalars().all()
        delete_count = len(signals_to_delete)
        
        # åˆªé™¤æ¸¬è©¦ä¿¡è™Ÿ
        delete_stmt = delete(SniperSignalDetails).where(or_(*conditions))
        await db.execute(delete_stmt)
        await db.commit()
        
        logger.info(f"ğŸ§¹ æ¸…ç†æ¸¬è©¦ä¿¡è™Ÿå®Œæˆ: åˆªé™¤ {delete_count} å€‹ä¿¡è™Ÿ")
        
        return {
            "status": "success",
            "deleted_count": delete_count,
            "message": f"ğŸ§¹ æˆåŠŸæ¸…ç† {delete_count} å€‹æ¸¬è©¦ä¿¡è™Ÿ",
            "cleared_prefixes": test_prefixes,
            "timestamp": get_taiwan_now().isoformat()
        }
        
    except Exception as e:
        await db.rollback()
        logger.error(f"âŒ åˆªé™¤æ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸…ç†æ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.post("/update-signal-status", response_model=dict)
async def update_signal_status(
    signal_id: str,
    new_status: str,
    pnl_percentage: Optional[float] = None,
    result_price: Optional[float] = None,
    db: AsyncSession = Depends(get_db)
):
    """ğŸ”§ æ‰‹å‹•æ›´æ–°ä¿¡è™Ÿç‹€æ…‹ï¼ˆç”¨æ–¼æ¸¬è©¦çµ±è¨ˆç®—æ³•ï¼‰"""
    try:
        from sqlalchemy import select, update
        from app.models.sniper_signal_history import SniperSignalDetails, SignalStatus
        
        # æŸ¥æ‰¾ä¿¡è™Ÿ
        stmt = select(SniperSignalDetails).where(SniperSignalDetails.signal_id == signal_id)
        result = await db.execute(stmt)
        signal = result.scalar_one_or_none()
        
        if not signal:
            raise HTTPException(status_code=404, detail=f"ä¿¡è™Ÿ {signal_id} ä¸å­˜åœ¨")
        
        # ç‹€æ…‹æ˜ å°„
        status_map = {
            "expired": SignalStatus.EXPIRED,
            "hit_tp": SignalStatus.HIT_TP,
            "hit_sl": SignalStatus.HIT_SL,
            "cancelled": SignalStatus.CANCELLED
        }
        
        if new_status not in status_map:
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆç‹€æ…‹: {new_status}")
        
        # æ›´æ–°ä¿¡è™Ÿ
        update_data = {
            "status": status_map[new_status],
            "result_time": get_taiwan_now()
        }
        
        if pnl_percentage is not None:
            update_data["pnl_percentage"] = pnl_percentage
        
        if result_price is not None:
            update_data["result_price"] = result_price
        
        stmt = update(SniperSignalDetails).where(
            SniperSignalDetails.signal_id == signal_id
        ).values(**update_data)
        
        await db.execute(stmt)
        await db.commit()
        
        logger.info(f"ğŸ”§ ä¿¡è™Ÿç‹€æ…‹æ›´æ–°: {signal_id} â†’ {new_status}")
        
        return {
            "status": "success",
            "message": f"ä¿¡è™Ÿ {signal_id} ç‹€æ…‹å·²æ›´æ–°ç‚º {new_status}",
            "updates": update_data,
            "timestamp": get_taiwan_now().isoformat()
        }
        
    except Exception as e:
        await db.rollback()
        logger.error(f"âŒ æ›´æ–°ä¿¡è™Ÿç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ›´æ–°ä¿¡è™Ÿç‹€æ…‹å¤±æ•—: {str(e)}"
        )

async def _generate_enhanced_statistics(signals: List[Dict]) -> Dict:
    """ç”Ÿæˆå¢å¼·çµ±è¨ˆä¿¡æ¯"""
    try:
        from app.core.database import get_db
        from app.models.sniper_signal_history import SniperSignalDetails, SignalStatus
        from sqlalchemy import select, func
        
        # ç²å–æ•¸æ“šåº«çµ±è¨ˆ
        db_gen = get_db()
        db = await db_gen.__anext__()
        
        try:
            # åŸºæœ¬çµ±è¨ˆ
            total_result = await db.execute(
                select(func.count(SniperSignalDetails.id))
            )
            total_db_signals = total_result.scalar() or 0
            
            # ç‹€æ…‹çµ±è¨ˆ
            status_result = await db.execute(
                select(
                    SniperSignalDetails.status,
                    func.count(SniperSignalDetails.id),
                    func.avg(SniperSignalDetails.pnl_percentage)
                ).group_by(SniperSignalDetails.status)
            )
            
            status_stats = {}
            for row in status_result.fetchall():
                status_stats[row[0].value] = {
                    'count': row[1],
                    'avg_pnl': round(row[2] or 0, 2)
                }
            
            # è¨ˆç®—çœŸå¯¦çµ±è¨ˆæŒ‡æ¨™
            active_count = status_stats.get('ACTIVE', {}).get('count', 0)
            tp_count = status_stats.get('HIT_TP', {}).get('count', 0)
            sl_count = status_stats.get('HIT_SL', {}).get('count', 0)
            expired_count = status_stats.get('EXPIRED', {}).get('count', 0)
            
            completed_signals = tp_count + sl_count + expired_count
            traditional_win_rate = (tp_count / completed_signals * 100) if completed_signals > 0 else 0.0
            
            # åŸºæ–¼PnLçš„çœŸå¯¦æˆåŠŸç‡
            profitable_result = await db.execute(
                select(func.count(SniperSignalDetails.id))
                .where(SniperSignalDetails.pnl_percentage > 0)
            )
            profitable_count = profitable_result.scalar() or 0
            real_success_rate = (profitable_count / total_db_signals * 100) if total_db_signals > 0 else 0.0
            
            return {
                'database_stats': {
                    'total_signals': total_db_signals,
                    'active_signals': active_count,
                    'traditional_win_rate': round(traditional_win_rate, 1),
                    'real_success_rate': round(real_success_rate, 1),
                    'status_breakdown': status_stats
                },
                'api_stats': {
                    'returned_signals': len(signals),
                    'symbols_covered': len(set(s['symbol'] for s in signals)),
                    'avg_quality_score': round(sum(s.get('quality_score', 0) for s in signals) / len(signals), 2) if signals else 0,
                    'quality_range': {
                        'min': min(s.get('quality_score', 0) for s in signals) if signals else 0,
                        'max': max(s.get('quality_score', 0) for s in signals) if signals else 0
                    }
                },
                'filtering_efficiency': {
                    'db_to_api_ratio': round((len(signals) / total_db_signals * 100), 1) if total_db_signals > 0 else 0,
                    'active_to_api_ratio': round((len(signals) / active_count * 100), 1) if active_count > 0 else 0
                }
            }
            
        finally:
            await db_gen.aclose()
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¢å¼·çµ±è¨ˆå¤±æ•—: {e}")
        return {
            'database_stats': {'error': str(e)},
            'api_stats': {'returned_signals': len(signals)},
            'filtering_efficiency': {'error': 'calculation_failed'}
        }
