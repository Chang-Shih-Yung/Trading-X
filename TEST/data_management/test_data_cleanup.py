#!/usr/bin/env python3
"""
æ•¸æ“šç®¡ç†èˆ‡æ¸…ç†æ¸¬è©¦è…³æœ¬
æ¸¬è©¦7å¤©æ•¸æ“šæ¸…ç†é€±æœŸå’Œæ•¸æ“šå­˜å„²ç®¡ç†åŠŸèƒ½
"""

import asyncio
import requests
import json
import sqlite3
import os
from datetime import datetime, timedelta
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

BASE_URL = "http://localhost:8000"
DB_PATH = "/Users/henrychang/Desktop/Trading-X/tradingx.db"

class DataManagementTester:
    """æ•¸æ“šç®¡ç†æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.base_url = BASE_URL
        self.db_path = DB_PATH
        
    async def test_data_storage_and_retrieval(self):
        """æ¸¬è©¦æ•¸æ“šå­˜å„²å’Œæª¢ç´¢"""
        logger.info("ğŸ§ª æ¸¬è©¦æ•¸æ“šå­˜å„²å’Œæª¢ç´¢...")
        
        try:
            # 1. æª¢æŸ¥æ•¸æ“šåº«é€£æ¥
            if not self._check_database_connection():
                logger.error("âŒ ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šåº«")
                return False
            
            # 2. å•Ÿå‹•ä¿¡è™Ÿå¼•æ“ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
            logger.info("å•Ÿå‹•ä¿¡è™Ÿå¼•æ“ç”Ÿæˆæ¸¬è©¦æ•¸æ“š...")
            start_result = self._make_request("POST", "/api/v1/realtime-signals/start")
            if not start_result.get("success"):
                logger.error("âŒ ä¿¡è™Ÿå¼•æ“å•Ÿå‹•å¤±æ•—")
                return False
            
            # 3. ç­‰å¾…æ•¸æ“šç”Ÿæˆ
            await asyncio.sleep(10)
            
            # 4. ç”Ÿæˆä¸€äº›æ¸¬è©¦ä¿¡è™Ÿ
            for i in range(5):
                test_result = self._make_request("POST", "/api/v1/realtime-signals/signals/test", {
                    "symbol": "BTCUSDT" if i % 2 == 0 else "ETHUSDT"
                })
                if test_result.get("success"):
                    logger.info(f"ç”Ÿæˆæ¸¬è©¦ä¿¡è™Ÿ {i+1}/5")
                await asyncio.sleep(2)
            
            # 5. æª¢æŸ¥æ•¸æ“šå­˜å„²
            stored_data = self._check_stored_data()
            if stored_data:
                logger.info("âœ… æ•¸æ“šå­˜å„²æ­£å¸¸")
                logger.info(f"   å­˜å„²çš„ä¿¡è™Ÿæ•¸é‡: {stored_data.get('signal_count', 0)}")
                logger.info(f"   å­˜å„²çš„å¸‚å ´æ•¸æ“šé‡: {stored_data.get('market_data_count', 0)}")
            else:
                logger.warning("âš ï¸ æ•¸æ“šå­˜å„²æª¢æŸ¥å¤±æ•—")
                return False
            
            # 6. æ¸¬è©¦æ•¸æ“šæª¢ç´¢
            recent_signals = self._make_request("GET", "/api/v1/realtime-signals/signals/recent?hours=1")
            if recent_signals.get("success"):
                signal_count = recent_signals.get("data", {}).get("count", 0)
                logger.info(f"âœ… æ•¸æ“šæª¢ç´¢æ­£å¸¸ï¼Œæœ€è¿‘1å°æ™‚ä¿¡è™Ÿæ•¸: {signal_count}")
            else:
                logger.error("âŒ æ•¸æ“šæª¢ç´¢å¤±æ•—")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šå­˜å„²æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    async def test_7_day_cleanup_cycle(self):
        """æ¸¬è©¦7å¤©æ•¸æ“šæ¸…ç†é€±æœŸ"""
        logger.info("ğŸ§ª æ¸¬è©¦7å¤©æ•¸æ“šæ¸…ç†é€±æœŸ...")
        
        try:
            # 1. æª¢æŸ¥ç¾æœ‰æ•¸æ“š
            initial_data = self._check_stored_data()
            logger.info(f"åˆå§‹æ•¸æ“šé‡: ä¿¡è™Ÿ {initial_data.get('signal_count', 0)}, å¸‚å ´æ•¸æ“š {initial_data.get('market_data_count', 0)}")
            
            # 2. å‰µå»ºæ¨¡æ“¬èˆŠæ•¸æ“šï¼ˆè¶…é7å¤©ï¼‰
            if not self._create_old_test_data():
                logger.error("âŒ å‰µå»ºæ¸¬è©¦èˆŠæ•¸æ“šå¤±æ•—")
                return False
            
            # 3. æª¢æŸ¥æ’å…¥èˆŠæ•¸æ“šå¾Œçš„æ•¸æ“šé‡
            after_insert_data = self._check_stored_data()
            logger.info(f"æ’å…¥èˆŠæ•¸æ“šå¾Œ: ä¿¡è™Ÿ {after_insert_data.get('signal_count', 0)}, å¸‚å ´æ•¸æ“š {after_insert_data.get('market_data_count', 0)}")
            
            # 4. è§¸ç™¼æ¸…ç†æ“ä½œ
            logger.info("è§¸ç™¼æ•¸æ“šæ¸…ç†...")
            cleanup_result = self._make_request("POST", "/api/v1/realtime-signals/cleanup")
            
            if cleanup_result.get("success"):
                cleaned_info = cleanup_result.get("data", {})
                logger.info(f"âœ… æ¸…ç†å®Œæˆ:")
                logger.info(f"   æ¸…ç†çš„ä¿¡è™Ÿæ•¸: {cleaned_info.get('signals_cleaned', 0)}")
                logger.info(f"   æ¸…ç†çš„å¸‚å ´æ•¸æ“š: {cleaned_info.get('market_data_cleaned', 0)}")
            else:
                logger.error("âŒ æ•¸æ“šæ¸…ç†å¤±æ•—")
                return False
            
            # 5. æª¢æŸ¥æ¸…ç†å¾Œçš„æ•¸æ“šé‡
            after_cleanup_data = self._check_stored_data()
            logger.info(f"æ¸…ç†å¾Œæ•¸æ“šé‡: ä¿¡è™Ÿ {after_cleanup_data.get('signal_count', 0)}, å¸‚å ´æ•¸æ“š {after_cleanup_data.get('market_data_count', 0)}")
            
            # 6. é©—è­‰æ¸…ç†æ•ˆæœ
            signals_cleaned = after_insert_data.get('signal_count', 0) - after_cleanup_data.get('signal_count', 0)
            if signals_cleaned > 0:
                logger.info(f"âœ… æ•¸æ“šæ¸…ç†æ•ˆæœé©—è­‰é€šéï¼Œæ¸…ç†äº† {signals_cleaned} å€‹èˆŠä¿¡è™Ÿ")
                return True
            else:
                logger.warning("âš ï¸ æœªæª¢æ¸¬åˆ°æ•¸æ“šæ¸…ç†æ•ˆæœ")
                return False
            
        except Exception as e:
            logger.error(f"âŒ 7å¤©æ¸…ç†é€±æœŸæ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    async def test_database_integrity(self):
        """æ¸¬è©¦æ•¸æ“šåº«å®Œæ•´æ€§"""
        logger.info("ğŸ§ª æ¸¬è©¦æ•¸æ“šåº«å®Œæ•´æ€§...")
        
        try:
            # 1. æª¢æŸ¥æ•¸æ“šåº«çµæ§‹
            if not self._check_database_schema():
                logger.error("âŒ æ•¸æ“šåº«çµæ§‹æª¢æŸ¥å¤±æ•—")
                return False
            
            # 2. æª¢æŸ¥ç´¢å¼•
            if not self._check_database_indexes():
                logger.warning("âš ï¸ æ•¸æ“šåº«ç´¢å¼•æª¢æŸ¥ç•°å¸¸")
            
            # 3. æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§
            if not self._check_data_consistency():
                logger.error("âŒ æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—")
                return False
            
            # 4. æª¢æŸ¥å¤–éµç´„æŸ
            if not self._check_foreign_key_constraints():
                logger.warning("âš ï¸ å¤–éµç´„æŸæª¢æŸ¥ç•°å¸¸")
            
            logger.info("âœ… æ•¸æ“šåº«å®Œæ•´æ€§æª¢æŸ¥é€šé")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šåº«å®Œæ•´æ€§æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    async def test_storage_efficiency(self):
        """æ¸¬è©¦å­˜å„²æ•ˆç‡"""
        logger.info("ğŸ§ª æ¸¬è©¦å­˜å„²æ•ˆç‡...")
        
        try:
            # 1. æª¢æŸ¥æ•¸æ“šåº«å¤§å°
            initial_size = self._get_database_size()
            logger.info(f"åˆå§‹æ•¸æ“šåº«å¤§å°: {initial_size:.2f} MB")
            
            # 2. ç”Ÿæˆå¤§é‡æ¸¬è©¦æ•¸æ“š
            logger.info("ç”Ÿæˆæ¸¬è©¦æ•¸æ“š...")
            for i in range(20):
                test_result = self._make_request("POST", "/api/v1/realtime-signals/signals/test")
                if i % 5 == 0:
                    logger.info(f"ç”Ÿæˆé€²åº¦: {i+1}/20")
                await asyncio.sleep(0.5)
            
            # 3. æª¢æŸ¥æ•¸æ“šå¢é•·
            after_generation_size = self._get_database_size()
            size_increase = after_generation_size - initial_size
            logger.info(f"ç”Ÿæˆæ•¸æ“šå¾Œå¤§å°: {after_generation_size:.2f} MB (å¢é•· {size_increase:.2f} MB)")
            
            # 4. åŸ·è¡Œæ•¸æ“šåº«å„ªåŒ–
            self._optimize_database()
            
            # 5. æª¢æŸ¥å„ªåŒ–å¾Œå¤§å°
            after_optimization_size = self._get_database_size()
            optimization_savings = after_generation_size - after_optimization_size
            logger.info(f"å„ªåŒ–å¾Œå¤§å°: {after_optimization_size:.2f} MB (ç¯€çœ {optimization_savings:.2f} MB)")
            
            # 6. è©•ä¼°å­˜å„²æ•ˆç‡
            if size_increase < 10:  # 20å€‹ä¿¡è™Ÿå¢é•·å°‘æ–¼10MBèªç‚ºæ•ˆç‡è‰¯å¥½
                logger.info("âœ… å­˜å„²æ•ˆç‡è‰¯å¥½")
                return True
            elif size_increase < 20:
                logger.info("âš ï¸ å­˜å„²æ•ˆç‡å¯æ¥å—")
                return True
            else:
                logger.warning("âŒ å­˜å„²æ•ˆç‡éœ€è¦æ”¹å–„")
                return False
            
        except Exception as e:
            logger.error(f"âŒ å­˜å„²æ•ˆç‡æ¸¬è©¦å¤±æ•—: {e}")
            return False
    
    def _check_database_connection(self):
        """æª¢æŸ¥æ•¸æ“šåº«é€£æ¥"""
        try:
            if not os.path.exists(self.db_path):
                logger.warning(f"æ•¸æ“šåº«æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
                return False
            
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT 1")
                return True
                
        except Exception as e:
            logger.error(f"æ•¸æ“šåº«é€£æ¥å¤±æ•—: {e}")
            return False
    
    def _check_stored_data(self):
        """æª¢æŸ¥å­˜å„²çš„æ•¸æ“š"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æª¢æŸ¥ä¿¡è™Ÿè¡¨
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]
                
                result = {}
                
                # æª¢æŸ¥å¸¸è¦‹çš„è¡¨
                if 'trading_signals' in tables:
                    cursor.execute("SELECT COUNT(*) FROM trading_signals")
                    result['signal_count'] = cursor.fetchone()[0]
                
                if 'market_data' in tables:
                    cursor.execute("SELECT COUNT(*) FROM market_data")
                    result['market_data_count'] = cursor.fetchone()[0]
                
                return result
                
        except Exception as e:
            logger.error(f"æª¢æŸ¥å­˜å„²æ•¸æ“šå¤±æ•—: {e}")
            return None
    
    def _create_old_test_data(self):
        """å‰µå»ºæ¨¡æ“¬èˆŠæ•¸æ“š"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # å‰µå»ºèˆŠçš„ä¿¡è™Ÿæ•¸æ“šï¼ˆ8å¤©å‰ï¼‰
                old_date = datetime.now() - timedelta(days=8)
                old_timestamp = old_date.isoformat()
                
                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨ trading_signals è¡¨
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='trading_signals'")
                if not cursor.fetchone():
                    # å‰µå»ºæ¸¬è©¦è¡¨
                    cursor.execute("""
                        CREATE TABLE IF NOT EXISTS trading_signals (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            symbol TEXT NOT NULL,
                            signal_type TEXT NOT NULL,
                            confidence REAL NOT NULL,
                            timestamp TEXT NOT NULL,
                            created_at TEXT NOT NULL
                        )
                    """)
                
                # æ’å…¥èˆŠæ•¸æ“š
                for i in range(10):
                    cursor.execute("""
                        INSERT INTO trading_signals 
                        (symbol, signal_type, confidence, timestamp, created_at)
                        VALUES (?, ?, ?, ?, ?)
                    """, (
                        "BTCUSDT" if i % 2 == 0 else "ETHUSDT",
                        "buy" if i % 3 == 0 else "sell",
                        0.7 + (i % 3) * 0.1,
                        old_timestamp,
                        old_timestamp
                    ))
                
                conn.commit()
                logger.info("âœ… å‰µå»ºäº†10å€‹æ¸¬è©¦èˆŠæ•¸æ“š")
                return True
                
        except Exception as e:
            logger.error(f"å‰µå»ºèˆŠæ¸¬è©¦æ•¸æ“šå¤±æ•—: {e}")
            return False
    
    def _check_database_schema(self):
        """æª¢æŸ¥æ•¸æ“šåº«çµæ§‹"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ç²å–æ‰€æœ‰è¡¨
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]
                
                logger.info(f"æ•¸æ“šåº«è¡¨: {tables}")
                
                # æª¢æŸ¥é—œéµè¡¨çš„çµæ§‹
                for table in tables:
                    if table.startswith('sqlite_'):
                        continue
                        
                    cursor.execute(f"PRAGMA table_info({table})")
                    columns = cursor.fetchall()
                    logger.info(f"è¡¨ {table} çš„åˆ—: {[col[1] for col in columns]}")
                
                return True
                
        except Exception as e:
            logger.error(f"æ•¸æ“šåº«çµæ§‹æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_database_indexes(self):
        """æª¢æŸ¥æ•¸æ“šåº«ç´¢å¼•"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("SELECT name, tbl_name FROM sqlite_master WHERE type='index'")
                indexes = cursor.fetchall()
                
                logger.info(f"æ•¸æ“šåº«ç´¢å¼•: {len(indexes)} å€‹")
                for index_name, table_name in indexes:
                    if not index_name.startswith('sqlite_'):
                        logger.info(f"  {table_name}.{index_name}")
                
                return True
                
        except Exception as e:
            logger.error(f"æ•¸æ“šåº«ç´¢å¼•æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_data_consistency(self):
        """æª¢æŸ¥æ•¸æ“šä¸€è‡´æ€§"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # æª¢æŸ¥æ˜¯å¦æœ‰é‡è¤‡æ•¸æ“š
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
                tables = [row[0] for row in cursor.fetchall()]
                
                for table in tables:
                    if table.startswith('sqlite_'):
                        continue
                    
                    # æª¢æŸ¥NULLå€¼
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    total_rows = cursor.fetchone()[0]
                    
                    if total_rows > 0:
                        logger.info(f"è¡¨ {table}: {total_rows} è¡Œæ•¸æ“š")
                
                return True
                
        except Exception as e:
            logger.error(f"æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _check_foreign_key_constraints(self):
        """æª¢æŸ¥å¤–éµç´„æŸ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                cursor.execute("PRAGMA foreign_key_check")
                violations = cursor.fetchall()
                
                if violations:
                    logger.warning(f"ç™¼ç¾ {len(violations)} å€‹å¤–éµç´„æŸé•è¦")
                    return False
                else:
                    logger.info("âœ… å¤–éµç´„æŸæª¢æŸ¥é€šé")
                    return True
                
        except Exception as e:
            logger.error(f"å¤–éµç´„æŸæª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    def _get_database_size(self):
        """ç²å–æ•¸æ“šåº«å¤§å°ï¼ˆMBï¼‰"""
        try:
            size_bytes = os.path.getsize(self.db_path)
            return size_bytes / (1024 * 1024)  # è½‰æ›ç‚º MB
        except Exception as e:
            logger.error(f"ç²å–æ•¸æ“šåº«å¤§å°å¤±æ•—: {e}")
            return 0
    
    def _optimize_database(self):
        """å„ªåŒ–æ•¸æ“šåº«"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # åŸ·è¡Œ VACUUM æ¸…ç†
                cursor.execute("VACUUM")
                
                # åˆ†æçµ±è¨ˆä¿¡æ¯
                cursor.execute("ANALYZE")
                
                logger.info("âœ… æ•¸æ“šåº«å„ªåŒ–å®Œæˆ")
                
        except Exception as e:
            logger.error(f"æ•¸æ“šåº«å„ªåŒ–å¤±æ•—: {e}")
    
    def _make_request(self, method: str, endpoint: str, data: dict = None):
        """ç™¼é€ HTTP è«‹æ±‚"""
        url = f"{self.base_url}{endpoint}"
        
        try:
            if method == "GET":
                response = requests.get(url, timeout=30)
            elif method == "POST":
                response = requests.post(url, json=data, timeout=30)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„æ–¹æ³•: {method}")
            
            response.raise_for_status()
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"HTTP è«‹æ±‚å¤±æ•— {method} {endpoint}: {e}")
            return {"success": False, "error": str(e)}

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("ğŸš€ é–‹å§‹æ•¸æ“šç®¡ç†èˆ‡æ¸…ç†æ¸¬è©¦...")
    
    tester = DataManagementTester()
    test_results = []
    
    # æ¸¬è©¦é …ç›®
    tests = [
        ("æ•¸æ“šå­˜å„²å’Œæª¢ç´¢", tester.test_data_storage_and_retrieval),
        ("7å¤©æ•¸æ“šæ¸…ç†é€±æœŸ", tester.test_7_day_cleanup_cycle),
        ("æ•¸æ“šåº«å®Œæ•´æ€§", tester.test_database_integrity),
        ("å­˜å„²æ•ˆç‡", tester.test_storage_efficiency),
    ]
    
    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ åŸ·è¡Œæ¸¬è©¦: {test_name}")
        try:
            result = await test_func()
            test_results.append((test_name, result))
            
            if result:
                logger.info(f"âœ… {test_name} - é€šé")
            else:
                logger.error(f"âŒ {test_name} - å¤±æ•—")
                
            # æ¸¬è©¦é–“éš”
            await asyncio.sleep(2)
            
        except Exception as e:
            logger.error(f"âŒ {test_name} - ç•°å¸¸: {e}")
            test_results.append((test_name, False))
    
    # æ¸¬è©¦ç¸½çµ
    logger.info("\nğŸ“Š æ¸¬è©¦çµæœç¸½çµ:")
    passed = sum(1 for _, result in test_results if result)
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—"
        logger.info(f"  {test_name}: {status}")
    
    logger.info(f"\nğŸ¯ ç¸½è¨ˆ: {passed}/{total} é …æ¸¬è©¦é€šé")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æ•¸æ“šç®¡ç†æ¸¬è©¦é€šéï¼æ•¸æ“šç®¡ç†åŠŸèƒ½æ­£å¸¸")
        return True
    else:
        logger.warning("âš ï¸ éƒ¨åˆ†æ•¸æ“šç®¡ç†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç›¸é—œåŠŸèƒ½")
        return False

if __name__ == "__main__":
    # é‹è¡Œæ¸¬è©¦
    success = asyncio.run(main())
    exit(0 if success else 1)
