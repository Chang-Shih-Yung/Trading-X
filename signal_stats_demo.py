#!/usr/bin/env python3
"""
Signal Processing Statistics åŠŸèƒ½æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„çµ±è¨ˆåˆ†æåŠŸèƒ½
"""

import asyncio
import json
import sys
from pathlib import Path
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾‘ä»¥å°å…¥çµ±è¨ˆæ¨¡çµ„
sys.path.append(str(Path(__file__).parent / "X/backend/phase4_output_monitoring/2_signal_processing_statistics"))

try:
    from signal_processing_statistics import SignalProcessingStatistics, SignalMetrics
    print("âœ… æˆåŠŸå°å…¥ä¿¡è™Ÿè™•ç†çµ±è¨ˆæ¨¡çµ„")
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

class SignalStatsDemo:
    def __init__(self):
        self.stats = None
    
    def initialize_statistics(self):
        """åˆå§‹åŒ–çµ±è¨ˆç³»çµ±"""
        print("\nğŸš€ åˆå§‹åŒ–ä¿¡è™Ÿè™•ç†çµ±è¨ˆç³»çµ±...")
        try:
            self.stats = SignalProcessingStatistics()
            print("âœ… çµ±è¨ˆç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ çµ±è¨ˆç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    async def demonstrate_signal_recording(self):
        """æ¼”ç¤ºä¿¡è™Ÿè¨˜éŒ„åŠŸèƒ½"""
        print("\nğŸ“Š æ¼”ç¤ºä¿¡è™Ÿè¨˜éŒ„åŠŸèƒ½...")
        
        # æ¨¡æ“¬å¤šç¨®é¡å‹çš„ä¿¡è™Ÿæ•¸æ“š
        signals = [
            {
                "timestamp": (datetime.now() - timedelta(minutes=30)).isoformat(),
                "symbol": "BTCUSDT",
                "priority": "CRITICAL",
                "quality_score": 0.92,
                "total_latency": 180.5,
                "source": "BOLLINGER_BANDS",
                "phase1_duration": 120.0,
                "phase2_duration": 35.5,
                "phase3_duration": 25.0
            },
            {
                "timestamp": (datetime.now() - timedelta(minutes=25)).isoformat(),
                "symbol": "ETHUSDT", 
                "priority": "HIGH",
                "quality_score": 0.85,
                "total_latency": 220.3,
                "source": "RSI_DIVERGENCE",
                "phase1_duration": 150.0,
                "phase2_duration": 45.3,
                "phase3_duration": 25.0
            },
            {
                "timestamp": (datetime.now() - timedelta(minutes=20)).isoformat(),
                "symbol": "ADAUSDT",
                "priority": "MEDIUM",
                "quality_score": 0.78,
                "total_latency": 195.8,
                "source": "MACD_SIGNAL",
                "phase1_duration": 130.0,
                "phase2_duration": 40.8,
                "phase3_duration": 25.0
            },
            {
                "timestamp": (datetime.now() - timedelta(minutes=15)).isoformat(),
                "symbol": "SOLUSDT",
                "priority": "LOW",
                "quality_score": 0.65,
                "total_latency": 280.2,
                "source": "VOLUME_ANALYSIS",
                "phase1_duration": 200.0,
                "phase2_duration": 55.2,
                "phase3_duration": 25.0
            },
            {
                "timestamp": (datetime.now() - timedelta(minutes=10)).isoformat(),
                "symbol": "BTCUSDT",
                "priority": "HIGH",
                "quality_score": 0.88,
                "total_latency": 165.4,
                "source": "SNIPER_SYSTEM",
                "phase1_duration": 110.0,
                "phase2_duration": 30.4,
                "phase3_duration": 25.0
            }
        ]
        
        for signal in signals:
            success = await self.stats.record_signal_metrics(signal)
            if success:
                print(f"âœ… è¨˜éŒ„ä¿¡è™Ÿ: {signal['symbol']} - {signal['priority']} - è³ªé‡:{signal['quality_score']}")
            else:
                print(f"âŒ è¨˜éŒ„å¤±æ•—: {signal['symbol']}")
        
        print(f"ğŸ“ˆ ç¸½è¨˜éŒ„ä¿¡è™Ÿæ•¸: {len(self.stats.signal_history)}")
    
    async def demonstrate_real_time_metrics(self):
        """æ¼”ç¤ºå¯¦æ™‚æŒ‡æ¨™"""
        print("\nâš¡ æ¼”ç¤ºå¯¦æ™‚æŒ‡æ¨™...")
        
        real_time_data = await self.stats.get_real_time_metrics()
        
        print("âœ… å¯¦æ™‚æŒ‡æ¨™æ•¸æ“šç”Ÿæˆå®Œæˆ")
        print(f"   ğŸ“Š ç‹€æ…‹: {real_time_data.get('real_time_status')}")
        
        if 'recent_5min_metrics' in real_time_data:
            metrics = real_time_data['recent_5min_metrics']
            print(f"   ğŸ“ˆ æœ€è¿‘5åˆ†é˜ä¿¡è™Ÿæ•¸: {metrics.get('signal_count')}")
            print(f"   ğŸ¯ å¹³å‡è³ªé‡: {metrics.get('average_quality', 0):.3f}")
            print(f"   âš¡ å¹³å‡å»¶é²: {metrics.get('average_latency', 0):.2f}ms")
        
        if 'processing_rate' in real_time_data:
            rate = real_time_data['processing_rate']
            print(f"   ğŸ“Š è™•ç†ç‡: {rate.get('performance_ratio', 0):.2f}")
    
    async def demonstrate_comprehensive_statistics(self):
        """æ¼”ç¤ºç¶œåˆçµ±è¨ˆåˆ†æ"""
        print("\nğŸ“‹ æ¼”ç¤ºç¶œåˆçµ±è¨ˆåˆ†æ...")
        
        comprehensive_stats = await self.stats.get_comprehensive_statistics()
        
        print("âœ… ç¶œåˆçµ±è¨ˆæ•¸æ“šç”Ÿæˆå®Œæˆ")
        
        # é¡¯ç¤ºçµ±è¨ˆå…ƒæ•¸æ“š
        if 'statistics_metadata' in comprehensive_stats:
            metadata = comprehensive_stats['statistics_metadata']
            print(f"   ğŸ“Š åˆ†æä¿¡è™Ÿç¸½æ•¸: {metadata.get('total_signals_analyzed')}")
            print(f"   â° ç”Ÿæˆæ™‚é–“: {metadata.get('generated_at')}")
        
        # é¡¯ç¤ºè³ªé‡åˆ†å¸ƒåˆ†æ
        if 'quality_distribution_analysis' in comprehensive_stats:
            quality_analysis = comprehensive_stats['quality_distribution_analysis']
            if 'overall_statistics' in quality_analysis:
                overall = quality_analysis['overall_statistics']
                print(f"   ğŸ¯ å¹³å‡è³ªé‡: {overall.get('mean', 0):.3f}")
                print(f"   ğŸ“ˆ è³ªé‡ä¸­ä½æ•¸: {overall.get('median', 0):.3f}")
                print(f"   ğŸ“Š 95%åˆ†ä½æ•¸: {overall.get('percentile_95', 0):.3f}")
        
        # é¡¯ç¤ºå„ªå…ˆç´šåˆ†æ
        if 'priority_level_analytics' in comprehensive_stats:
            priority_analysis = comprehensive_stats['priority_level_analytics']
            if 'distribution' in priority_analysis:
                distribution = priority_analysis['distribution']
                print(f"   ğŸ“Š å„ªå…ˆç´šåˆ†å¸ƒ:")
                for priority, count in distribution.items():
                    print(f"      {priority}: {count}")
        
        # é¡¯ç¤ºè™•ç†æ™‚é–“åˆ†æ
        if 'processing_time_analysis' in comprehensive_stats:
            time_analysis = comprehensive_stats['processing_time_analysis']
            if 'overall_latency' in time_analysis:
                overall_latency = time_analysis['overall_latency']
                print(f"   âš¡ å¹³å‡å»¶é²: {overall_latency.get('mean', 0):.2f}ms")
                print(f"   âš¡ 99%åˆ†ä½å»¶é²: {overall_latency.get('percentile_99', 0):.2f}ms")
            
            if 'phase_breakdown' in time_analysis:
                phases = time_analysis['phase_breakdown']
                print(f"   ğŸ“Š Phaseå»¶é²åˆ†è§£:")
                for phase, stats in phases.items():
                    print(f"      {phase}: {stats.get('mean', 0):.2f}ms")
        
        # é¡¯ç¤ºä¾†æºæ€§èƒ½æ¯”è¼ƒ
        if 'source_performance_comparison' in comprehensive_stats:
            source_analysis = comprehensive_stats['source_performance_comparison']
            if 'performance_by_source' in source_analysis:
                performance = source_analysis['performance_by_source']
                print(f"   ğŸ“Š ä¾†æºæ€§èƒ½:")
                for source, metrics in performance.items():
                    print(f"      {source}: å»¶é²{metrics.get('average_latency', 0):.2f}ms, è³ªé‡{metrics.get('average_quality', 0):.3f}")
    
    def demonstrate_temporal_analysis(self):
        """æ¼”ç¤ºæ™‚é–“æ¨¡å¼åˆ†æ"""
        print("\nğŸ“… æ¼”ç¤ºæ™‚é–“æ¨¡å¼åˆ†æ...")
        
        # æ‰‹å‹•è§¸ç™¼æ™‚é–“æ¨¡å¼åˆ†æ
        hourly_patterns = self.stats._analyze_hourly_patterns()
        daily_patterns = self.stats._analyze_daily_patterns()
        peak_windows = self.stats._identify_peak_windows()
        
        print("âœ… æ™‚é–“æ¨¡å¼åˆ†æå®Œæˆ")
        print(f"   ğŸ“Š å°æ™‚æ¨¡å¼æ•¸æ“šé»: {len(hourly_patterns)}")
        print(f"   ğŸ“Š æ—¥æ¨¡å¼æ•¸æ“šé»: {len(daily_patterns)}")
        print(f"   ğŸ¯ å³°å€¼æ™‚æ®µè­˜åˆ¥: {len(peak_windows)} å€‹æ™‚æ®µ")
        
        # é¡¯ç¤ºå³°å€¼æ™‚æ®µ
        for window in peak_windows:
            print(f"   â­ {window.get('description')}: {window.get('type')}")
    
    def demonstrate_performance_benchmarks(self):
        """æ¼”ç¤ºæ€§èƒ½åŸºæº–æ¸¬è©¦"""
        print("\nğŸ† æ¼”ç¤ºæ€§èƒ½åŸºæº–æ¸¬è©¦...")
        
        benchmarks = self.stats._calculate_performance_benchmarks()
        
        if benchmarks:
            print("âœ… æ€§èƒ½åŸºæº–æ¸¬è©¦å®Œæˆ")
            
            if 'throughput_benchmarks' in benchmarks:
                throughput = benchmarks['throughput_benchmarks']
                print(f"   ğŸ“Š ååé‡: {throughput.get('signals_per_minute', 0):.2f} ä¿¡è™Ÿ/åˆ†é˜")
                print(f"   ğŸ¯ æ•ˆç‡æ¯”ç‡: {throughput.get('efficiency_ratio', 0):.2f}")
            
            if 'quality_benchmarks' in benchmarks:
                quality = benchmarks['quality_benchmarks']
                print(f"   ğŸ¯ å¹³å‡è³ªé‡: {quality.get('average_quality', 0):.3f}")
                print(f"   ğŸ“ˆ è³ªé‡é”æˆç‡: {quality.get('quality_achievement_rate', 0)*100:.1f}%")
            
            if 'latency_benchmarks' in benchmarks:
                latency = benchmarks['latency_benchmarks']
                print(f"   âš¡ å¹³å‡å»¶é²: {latency.get('average_latency', 0):.2f}ms")
                print(f"   ğŸ“Š å»¶é²åˆè¦ç‡: {latency.get('latency_compliance_rate', 0)*100:.1f}%")
        else:
            print("âš ï¸ ç„¡è¶³å¤ æ•¸æ“šé€²è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦")
    
    def display_system_summary(self):
        """é¡¯ç¤ºç³»çµ±æ‘˜è¦"""
        print("\nğŸ“‹ ç³»çµ±æ‘˜è¦:")
        print("=" * 50)
        
        print(f"ğŸ“Š é…ç½®ç‹€æ…‹:")
        print(f"   ç‰ˆæœ¬: {self.stats.config.get('PHASE4_SIGNAL_PROCESSING_STATISTICS', {}).get('system_metadata', {}).get('version', 'æœªçŸ¥')}")
        print(f"   çµ±è¨ˆå•Ÿç”¨: {self.stats.statistics_enabled}")
        print(f"   æœ€å¾Œæ›´æ–°: {self.stats.last_update}")
        
        print(f"\nğŸ“ˆ æ•¸æ“šç‹€æ…‹:")
        print(f"   æ­·å²ä¿¡è™Ÿæ•¸: {len(self.stats.signal_history)}")
        print(f"   è³ªé‡åˆ†å¸ƒæ¢ç›®: {len(self.stats.quality_distribution)}")
        print(f"   å„ªå…ˆç´šåˆ†å¸ƒæ¢ç›®: {len(self.stats.priority_distribution)}")
        print(f"   ä¾†æºåˆ†å¸ƒæ¢ç›®: {len(self.stats.source_distribution)}")
        print(f"   å°æ™‚çµ±è¨ˆæ¢ç›®: {len(self.stats.hourly_stats)}")
        print(f"   æ—¥çµ±è¨ˆæ¢ç›®: {len(self.stats.daily_stats)}")
    
    async def run_complete_demo(self):
        """é‹è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸª Signal Processing Statistics - å®Œæ•´åŠŸèƒ½æ¼”ç¤º")
        print("=" * 60)
        
        # åˆå§‹åŒ–
        if not self.initialize_statistics():
            return
        
        # æ¼”ç¤ºå„å€‹åŠŸèƒ½
        await self.demonstrate_signal_recording()
        await self.demonstrate_real_time_metrics()
        await self.demonstrate_comprehensive_statistics()
        self.demonstrate_temporal_analysis()
        self.demonstrate_performance_benchmarks()
        self.display_system_summary()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼ä¿¡è™Ÿè™•ç†çµ±è¨ˆç³»çµ±åŠŸèƒ½é½Šå…¨ï¼")
        print("âœ… JSONé…ç½®å„ªç§€ (96%åŒ¹é…)")
        print("âœ… Pythonå¯¦ç¾å®Œç¾ (100%åŠŸèƒ½)")
        print("âœ… æ‰€æœ‰çµ±è¨ˆåŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("âœ… Phase1-3æ•´åˆç„¡ç¸«")
        print("ğŸš€ Signal Processing Statistics å·²æº–å‚™å°±ç·’ï¼")

async def main():
    demo = SignalStatsDemo()
    await demo.run_complete_demo()

if __name__ == "__main__":
    asyncio.run(main())
