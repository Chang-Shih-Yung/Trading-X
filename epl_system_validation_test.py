#!/usr/bin/env python3
"""
ğŸ” EPLå‰è™•ç†ç³»çµ±å®Œæ•´æ€§é©—è­‰æ¸¬è©¦
==============================

é©—è­‰EPLå‰è™•ç†ç³»çµ±æ˜¯å¦100%åŒ¹é…JSONè¦ç¯„
"""

import sys
import time
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir / "X" / "backend" / "phase2_pre_evaluation" / "epl_pre_processing_system"))

try:
    from epl_pre_processing_system import (
        # JSONæ ¸å¿ƒä¾è³´æª¢æŸ¥
        IntelligentDeduplicationEngine,  # JSON: intelligent_deduplication_analysis_engine
        ContextualCorrelationAnalyzer,   # JSON: contextual_correlation_analyzer
        LightweightQualityControlGate,   # JSON: lightweight_quality_control_gate
        EnhancedPreEvaluationLayer,      # JSON: ä¸»æ§åˆ¶å™¨
        
        # JSONæ•¸æ“šçµæ§‹æª¢æŸ¥
        SignalCandidate,                 # JSON: è¼¸å…¥æ•¸æ“šæ ¼å¼
        PreEvaluationResult,             # JSON: è¼¸å‡ºæ•¸æ“šæ ¼å¼
        
        # JSONæšèˆ‰æª¢æŸ¥
        DeduplicationResult,
        CorrelationAnalysisResult,
        QualityControlResult,
        
        # JSONå…¨å±€å¯¦ä¾‹
        enhanced_pre_evaluation_layer
    )
    print("âœ… æ‰€æœ‰JSONè¦ç¯„è¦æ±‚çš„é¡å’Œæšèˆ‰éƒ½å·²æ­£ç¢ºå¯¦ç¾")
except ImportError as e:
    print(f"âŒ å°å…¥å¤±æ•—: {e}")
    sys.exit(1)

def test_json_specification_compliance():
    """æ¸¬è©¦JSONè¦ç¯„åˆè¦æ€§"""
    print("\nğŸ” é–‹å§‹JSONè¦ç¯„åˆè¦æ€§æ¸¬è©¦...")
    
    results = []
    
    # 1. æ¸¬è©¦æ™ºèƒ½å»é‡å¼•æ“
    print("1ï¸âƒ£ æ¸¬è©¦æ™ºèƒ½å»é‡å¼•æ“...")
    dedup_engine = IntelligentDeduplicationEngine()
    
    # æª¢æŸ¥JSONé…ç½®åƒæ•¸
    assert dedup_engine.similarity_threshold == 0.85, "ç›¸ä¼¼åº¦é–¾å€¼æ‡‰ç‚º0.85"
    assert dedup_engine.time_overlap_minutes == 15, "æ™‚é–“é‡ç–Šæ‡‰ç‚º15åˆ†é˜"
    assert dedup_engine.confidence_diff_threshold == 0.03, "ä¿¡å¿ƒåº¦å·®ç•°é–¾å€¼æ‡‰ç‚º0.03"
    
    # æª¢æŸ¥JSONæºå…±è­˜é©—è­‰åƒæ•¸
    assert dedup_engine.source_overlap_score_threshold == 0.72, "æºé‡ç–Šåˆ†æ•¸é–¾å€¼éŒ¯èª¤"
    assert dedup_engine.model_diversity_score_threshold == 0.8, "æ¨¡å‹å¤šæ¨£æ€§é–¾å€¼éŒ¯èª¤"
    assert dedup_engine.action_bias_score_threshold == 0.85, "è¡Œå‹•åå·®é–¾å€¼éŒ¯èª¤"
    
    results.append("âœ… æ™ºèƒ½å»é‡å¼•æ“é…ç½®æ­£ç¢º")
    
    # 2. æ¸¬è©¦ä¸Šä¸‹æ–‡é—œè¯åˆ†æå™¨
    print("2ï¸âƒ£ æ¸¬è©¦ä¸Šä¸‹æ–‡é—œè¯åˆ†æå™¨...")
    corr_analyzer = ContextualCorrelationAnalyzer()
    
    # æª¢æŸ¥JSONé…ç½®åƒæ•¸
    assert corr_analyzer.direction_conflict_threshold == 0.15, "æ–¹å‘è¡çªé–¾å€¼éŒ¯èª¤"
    assert corr_analyzer.confidence_improvement_threshold == 0.08, "ä¿¡å¿ƒåº¦æ”¹å–„é–¾å€¼éŒ¯èª¤"
    
    results.append("âœ… ä¸Šä¸‹æ–‡é—œè¯åˆ†æå™¨é…ç½®æ­£ç¢º")
    
    # 3. æ¸¬è©¦è¼•é‡å“è³ªæ§åˆ¶é–€æª»
    print("3ï¸âƒ£ æ¸¬è©¦è¼•é‡å“è³ªæ§åˆ¶é–€æª»...")
    quality_gate = LightweightQualityControlGate()
    
    # æª¢æŸ¥JSONé…ç½®åƒæ•¸
    assert quality_gate.strength_threshold == 70.0, "å¼·åº¦é–¾å€¼éŒ¯èª¤"
    assert quality_gate.liquidity_threshold == 0.6, "æµå‹•æ€§é–¾å€¼éŒ¯èª¤"
    assert quality_gate.risk_score_threshold == 0.3, "é¢¨éšªåˆ†æ•¸é–¾å€¼éŒ¯èª¤"
    
    # æª¢æŸ¥JSONå¾®ç•°å¸¸åƒæ•¸
    assert quality_gate.signal_volatility_jump_threshold == 0.3, "ä¿¡è™Ÿæ³¢å‹•æ€§è·³èºé–¾å€¼éŒ¯èª¤"
    assert quality_gate.confidence_drop_rate_threshold == 0.1, "ä¿¡å¿ƒåº¦ä¸‹é™ç‡é–¾å€¼éŒ¯èª¤"
    
    # æª¢æŸ¥JSONæ•´åˆè©•åˆ†æ¬Šé‡
    expected_weights = {"strength": 0.3, "confidence": 0.25, "quality": 0.2, "risk": 0.15, "timing": 0.1}
    assert quality_gate.scoring_weights == expected_weights, "æ•´åˆè©•åˆ†æ¬Šé‡éŒ¯èª¤"
    
    results.append("âœ… è¼•é‡å“è³ªæ§åˆ¶é–€æª»é…ç½®æ­£ç¢º")
    
    # 4. æ¸¬è©¦ä¸»æ§åˆ¶å™¨
    print("4ï¸âƒ£ æ¸¬è©¦å¢å¼·å‰è™•ç†å±¤ä¸»æ§åˆ¶å™¨...")
    epl_layer = EnhancedPreEvaluationLayer()
    
    # æª¢æŸ¥JSONæ™ºèƒ½è·¯ç”±é…ç½®
    express_config = epl_layer.routing_config["express_lane"]
    assert express_config["data_completeness_threshold"] == 0.9, "å¿«é€Ÿé€šé“æ•¸æ“šå®Œæ•´æ€§é–¾å€¼éŒ¯èª¤"
    assert express_config["signal_clarity_threshold"] == 0.8, "å¿«é€Ÿé€šé“ä¿¡è™Ÿæ¸…æ™°åº¦é–¾å€¼éŒ¯èª¤"
    assert express_config["confidence_threshold"] == 0.75, "å¿«é€Ÿé€šé“ä¿¡å¿ƒåº¦é–¾å€¼éŒ¯èª¤"
    assert express_config["micro_anomaly_threshold"] == 0.2, "å¿«é€Ÿé€šé“å¾®ç•°å¸¸é–¾å€¼éŒ¯èª¤"
    assert express_config["market_stress_threshold"] == 0.7, "å¿«é€Ÿé€šé“å¸‚å ´å£“åŠ›é–¾å€¼éŒ¯èª¤"
    
    results.append("âœ… å¢å¼·å‰è™•ç†å±¤ä¸»æ§åˆ¶å™¨é…ç½®æ­£ç¢º")
    
    # 5. æ¸¬è©¦æšèˆ‰å€¼
    print("5ï¸âƒ£ æ¸¬è©¦æšèˆ‰å€¼...")
    
    # DeduplicationResultæšèˆ‰
    expected_dedup = ["â­ ç¨ç‰¹", "âŒ å¿½ç•¥", "âš ï¸ å»¶é²è§€å¯Ÿ", "âœ… é€šé"]
    actual_dedup = [item.value for item in DeduplicationResult]
    assert set(actual_dedup) == set(expected_dedup), f"å»é‡çµæœæšèˆ‰å€¼éŒ¯èª¤: {actual_dedup}"
    
    # CorrelationAnalysisResultæšèˆ‰
    expected_corr = ["â• å¼·åŒ–å€™é¸", "ğŸ” æ›¿æ›å€™é¸", "âœ… ç¨ç«‹æ–°å–®"]
    actual_corr = [item.value for item in CorrelationAnalysisResult]
    assert set(actual_corr) == set(expected_corr), f"é—œè¯åˆ†æçµæœæšèˆ‰å€¼éŒ¯èª¤: {actual_corr}"
    
    # QualityControlResultæšèˆ‰
    expected_quality = ["ğŸŒŸ å„ªç§€", "âœ… é€šé", "âŒ ä¿¡è™Ÿå¼·åº¦ä¸è¶³", "âŒ æµå‹•æ€§ä¸è¶³", "âŒ é¢¨éšªè©•ä¼°æœªé€šé"]
    actual_quality = [item.value for item in QualityControlResult]
    assert set(actual_quality) == set(expected_quality), f"å“è³ªæ§åˆ¶çµæœæšèˆ‰å€¼éŒ¯èª¤: {actual_quality}"
    
    results.append("âœ… æ‰€æœ‰æšèˆ‰å€¼æ­£ç¢º")
    
    # 6. æ¸¬è©¦æ•¸æ“šçµæ§‹
    print("6ï¸âƒ£ æ¸¬è©¦æ•¸æ“šçµæ§‹...")
    
    # æ¸¬è©¦SignalCandidateçµæ§‹
    test_candidate = SignalCandidate(
        id="test_001",
        symbol="BTCUSDT",
        signal_strength=75.0,
        confidence=0.85,
        direction="long",
        timestamp=datetime.now(),
        source="phase1a",
        data_completeness=0.95,
        signal_clarity=0.88,
        dynamic_params={"adaptation_timestamp": datetime.now(), "volatility_jump": 0.1},
        market_environment={"volatility": 0.02, "liquidity_score": 0.8, "momentum": 0.1},
        technical_snapshot={"rsi": 65, "macd_signal": 0.5, "bollinger_position": 0.6}
    )
    
    assert hasattr(test_candidate, 'id'), "SignalCandidateç¼ºå°‘idå­—æ®µ"
    assert hasattr(test_candidate, 'dynamic_params'), "SignalCandidateç¼ºå°‘dynamic_paramså­—æ®µ"
    assert hasattr(test_candidate, 'market_environment'), "SignalCandidateç¼ºå°‘market_environmentå­—æ®µ"
    
    results.append("âœ… SignalCandidateæ•¸æ“šçµæ§‹æ­£ç¢º")
    
    print("\nğŸ¯ JSONè¦ç¯„åˆè¦æ€§æ¸¬è©¦çµæœ:")
    for result in results:
        print(f"  {result}")
    
    return True

async def test_complete_processing_flow():
    """æ¸¬è©¦å®Œæ•´è™•ç†æµç¨‹"""
    print("\nğŸ”„ é–‹å§‹å®Œæ•´è™•ç†æµç¨‹æ¸¬è©¦...")
    
    # å‰µå»ºæ¸¬è©¦ä¿¡è™Ÿå€™é¸è€…
    test_candidate = SignalCandidate(
        id="flow_test_001",
        symbol="BTCUSDT",
        signal_strength=78.5,
        confidence=0.82,
        direction="long",
        timestamp=datetime.now(),
        source="phase1abc_dynamic",
        data_completeness=0.93,
        signal_clarity=0.85,
        dynamic_params={
            "adaptation_timestamp": datetime.now(),
            "volatility_jump": 0.05,
            "confidence_drop_rate": 0.02
        },
        market_environment={
            "volatility": 0.025,
            "liquidity_score": 0.75,
            "momentum": 0.15
        },
        technical_snapshot={
            "rsi": 62,
            "macd_signal": 0.3,
            "bollinger_position": 0.55
        }
    )
    
    # æ¸¬è©¦ä¸»è™•ç†æµç¨‹
    start_time = time.time()
    result = await enhanced_pre_evaluation_layer.process_signal_candidate(test_candidate)
    processing_time = (time.time() - start_time) * 1000
    
    print(f"ğŸ“Š è™•ç†çµæœ:")
    print(f"  å€™é¸è€…ID: {result.candidate.id}")
    print(f"  å»é‡çµæœ: {result.deduplication_result.value}")
    print(f"  é—œè¯çµæœ: {result.correlation_result.value}")
    print(f"  å“è³ªçµæœ: {result.quality_result.value}")
    print(f"  é€šéEPL: {'âœ…' if result.pass_to_epl else 'âŒ'}")
    print(f"  è™•ç†æ™‚é–“: {processing_time:.2f}ms")
    print(f"  ç›¸ä¼¼åº¦åˆ†æ•¸: {result.similarity_score}")
    
    # é©—è­‰JSONæ€§èƒ½ç›®æ¨™
    json_targets = {
        "express_lane": 3.0,  # 3ms
        "standard_lane": 15.0,  # 15ms
        "deep_lane": 40.0   # 40ms
    }
    
    print(f"\nğŸ¯ æ€§èƒ½é©—è­‰:")
    if processing_time <= json_targets["express_lane"]:
        print(f"  âœ… é”åˆ°å¿«é€Ÿé€šé“ç›®æ¨™: {processing_time:.2f}ms <= {json_targets['express_lane']}ms")
    elif processing_time <= json_targets["standard_lane"]:
        print(f"  âœ… é”åˆ°æ¨™æº–é€šé“ç›®æ¨™: {processing_time:.2f}ms <= {json_targets['standard_lane']}ms")
    elif processing_time <= json_targets["deep_lane"]:
        print(f"  âœ… é”åˆ°æ·±åº¦åˆ†æç›®æ¨™: {processing_time:.2f}ms <= {json_targets['deep_lane']}ms")
    else:
        print(f"  âš ï¸ è¶…å‡ºæ€§èƒ½ç›®æ¨™: {processing_time:.2f}ms > {json_targets['deep_lane']}ms")
    
    # ç²å–è™•ç†çµ±è¨ˆ
    stats = enhanced_pre_evaluation_layer.get_processing_stats()
    print(f"\nğŸ“ˆ è™•ç†çµ±è¨ˆ:")
    print(f"  ç¸½è™•ç†æ•¸: {stats['total_processed']}")
    print(f"  é€šéæ•¸: {stats['passed_to_epl']}")
    print(f"  é€šéç‡: {stats['pass_rate']:.1f}%")
    print(f"  å¿«é€Ÿé€šé“æ¯”ä¾‹: {stats['express_lane_ratio']:.1f}%")
    print(f"  æ¨™æº–é€šé“æ¯”ä¾‹: {stats['standard_lane_ratio']:.1f}%")
    print(f"  æ·±åº¦åˆ†ææ¯”ä¾‹: {stats['deep_lane_ratio']:.1f}%")
    
    return result.pass_to_epl

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸš€ EPLå‰è™•ç†ç³»çµ±å®Œæ•´æ€§é©—è­‰é–‹å§‹...")
    
    try:
        # 1. JSONè¦ç¯„åˆè¦æ€§æ¸¬è©¦
        compliance_success = test_json_specification_compliance()
        
        # 2. å®Œæ•´æµç¨‹æ¸¬è©¦
        import asyncio
        flow_success = asyncio.run(test_complete_processing_flow())
        
        if compliance_success and flow_success:
            print("\nğŸ‰ EPLå‰è™•ç†ç³»çµ±100%é€šéå®Œæ•´æ€§é©—è­‰ï¼")
            print("âœ… JSONè¦ç¯„å®Œå…¨åŒ¹é…")
            print("âœ… è™•ç†æµç¨‹æ­£å¸¸é‹è¡Œ")
            print("âœ… æ€§èƒ½ç›®æ¨™é”æˆ")
            return True
        else:
            print("\nâš ï¸ é©—è­‰æœªå®Œå…¨é€šéï¼Œéœ€è¦é€²ä¸€æ­¥æª¢æŸ¥")
            return False
            
    except Exception as e:
        print(f"\nâŒ é©—è­‰éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
