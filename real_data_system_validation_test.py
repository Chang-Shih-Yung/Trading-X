"""
ğŸ¯ Real Data Signal Quality Engine - ç³»çµ±é©—è­‰æ¸¬è©¦
é©—è­‰é‡å¯«å¾Œçš„ç³»çµ±æ˜¯å¦å®Œå…¨ç¬¦åˆ JSON è¦ç¯„ä¸¦æ­£å¸¸é‹ä½œ
"""

import asyncio
import time
from datetime import datetime
import sys
import os
sys.path.append('/Users/henrychang/Desktop/Trading-X/X/backend/phase2_pre_evaluation/real_data_signal_quality_engine')

from real_data_signal_quality_engine import (
    EnhancedRealDataQualityMonitoringEngine,
    SystemLoadMetrics,
    QualityStatus,
    enhanced_real_data_quality_engine
)

class RealDataSystemValidationTest:
    """Real Data ä¿¡è™Ÿè³ªé‡å¼•æ“ç³»çµ±é©—è­‰æ¸¬è©¦"""
    
    def __init__(self):
        self.engine = enhanced_real_data_quality_engine
        self.test_results = {
            "json_compliance": {},
            "processing_performance": {},
            "functionality_tests": {},
            "overall_score": 0.0
        }
    
    async def test_json_compliance(self):
        """æ¸¬è©¦ JSON è¦ç¯„ç¬¦åˆåº¦"""
        print("ğŸ” æ¸¬è©¦ JSON è¦ç¯„ç¬¦åˆåº¦...")
        
        # 1. ç‰ˆæœ¬å’Œè§’è‰²é©—è­‰
        assert self.engine.version == "2.1.0", f"ç‰ˆæœ¬ä¸ç¬¦ï¼šæœŸæœ› 2.1.0ï¼Œå¯¦éš› {self.engine.version}"
        assert self.engine.module_type == "enhanced_quality_monitoring_engine", f"æ¨¡çµ„é¡å‹ä¸ç¬¦"
        assert self.engine.role == "parallel_monitoring_not_blocking_main_flow", f"è§’è‰²ä¸ç¬¦"
        
        # 2. å¢å¼·ç›£æ§èƒ½åŠ›é©—è­‰
        assert hasattr(self.engine, 'system_load_monitor'), "ç¼ºå°‘ç³»çµ±è² è¼‰ç›£æ§å™¨"
        assert hasattr(self.engine, 'micro_anomaly_detector'), "ç¼ºå°‘å¾®ç•°å¸¸æª¢æ¸¬å™¨"
        assert hasattr(self.engine, 'delayed_observation_tracker'), "ç¼ºå°‘å»¶é²è§€å¯Ÿè¿½è¹¤å™¨"
        assert hasattr(self.engine, 'dynamic_threshold_monitor'), "ç¼ºå°‘å‹•æ…‹é–¾å€¼ç›£æ§å™¨"
        
        # 3. è™•ç†å±¤é©—è­‰
        expected_layers = ["layer_0", "layer_1", "layer_2"]
        for layer in expected_layers:
            assert layer in self.engine.layer_processing_times, f"ç¼ºå°‘è™•ç†å±¤ï¼š{layer}"
        
        # 4. è™•ç†æ™‚é–“é…ç½®é©—è­‰
        assert self.engine.layer_processing_times["layer_0"] == 15, "Layer 0 è™•ç†æ™‚é–“é…ç½®éŒ¯èª¤"
        assert self.engine.layer_processing_times["layer_1"] == 10, "Layer 1 è™•ç†æ™‚é–“é…ç½®éŒ¯èª¤"
        assert self.engine.layer_processing_times["layer_2"] == 12, "Layer 2 è™•ç†æ™‚é–“é…ç½®éŒ¯èª¤"
        
        # 5. ä¸Šæ¸¸ä¸‹æ¸¸æ¨¡çµ„é€£æ¥é»é©—è­‰
        upstream_attrs = ["unified_signal_candidate_pool"]
        downstream_attrs = ["monitoring_dashboard", "alert_notification_system", "system_load_balancer"]
        
        for attr in upstream_attrs + downstream_attrs:
            assert hasattr(self.engine, attr), f"ç¼ºå°‘æ¨¡çµ„é€£æ¥é»ï¼š{attr}"
        
        self.test_results["json_compliance"] = {
            "version_compliance": True,
            "enhanced_capabilities": True,
            "processing_layers": True,
            "module_connections": True,
            "score": 100.0
        }
        
        print("âœ… JSON è¦ç¯„ç¬¦åˆåº¦æ¸¬è©¦é€šé")
    
    async def test_processing_performance(self):
        """æ¸¬è©¦è™•ç†æ€§èƒ½ç¬¦åˆåº¦"""
        print("ğŸ” æ¸¬è©¦è™•ç†æ€§èƒ½ç¬¦åˆåº¦...")
        
        # å‰µå»ºæ¸¬è©¦ä¿¡è™Ÿå€™é¸è€…
        test_candidates = [
            {
                "signal_id": f"test_signal_{i}",
                "source_module": "test_module",
                "signal_strength": 0.8,
                "confidence_score": 0.7,
                "data_completeness": 0.9
            } for i in range(10)
        ]
        
        # æ¸¬è©¦ä¸‰å±¤è™•ç†æ™‚é–“
        start_time = time.time()
        
        # Layer 0 æ¸¬è©¦
        layer0_start = time.time()
        validated_candidates = await self.engine.layer_0_signal_intake(test_candidates)
        layer0_time = (time.time() - layer0_start) * 1000
        
        # Layer 1 æ¸¬è©¦
        layer1_start = time.time()
        classified_signals = await self.engine.layer_1_priority_classification(validated_candidates)
        layer1_time = (time.time() - layer1_start) * 1000
        
        # Layer 2 æ¸¬è©¦
        layer2_start = time.time()
        quality_controlled = await self.engine.layer_2_quality_control(classified_signals)
        layer2_time = (time.time() - layer2_start) * 1000
        
        total_time = (time.time() - start_time) * 1000
        
        # æ€§èƒ½é©—è­‰
        layer0_pass = layer0_time <= 15  # 15ms ç›®æ¨™
        layer1_pass = layer1_time <= 10  # 10ms ç›®æ¨™
        layer2_pass = layer2_time <= 12  # 12ms ç›®æ¨™
        total_pass = total_time <= 40    # 40ms ç¸½ç›®æ¨™
        
        self.test_results["processing_performance"] = {
            "layer_0_time_ms": round(layer0_time, 2),
            "layer_1_time_ms": round(layer1_time, 2),
            "layer_2_time_ms": round(layer2_time, 2),
            "total_time_ms": round(total_time, 2),
            "layer_0_pass": layer0_pass,
            "layer_1_pass": layer1_pass,
            "layer_2_pass": layer2_pass,
            "total_pass": total_pass,
            "score": (sum([layer0_pass, layer1_pass, layer2_pass, total_pass]) / 4) * 100
        }
        
        print(f"âœ… è™•ç†æ€§èƒ½æ¸¬è©¦å®Œæˆï¼šç¸½æ™‚é–“ {total_time:.2f}ms (ç›®æ¨™: 40ms)")
    
    async def test_functionality(self):
        """æ¸¬è©¦åŠŸèƒ½å®Œæ•´æ€§"""
        print("ğŸ” æ¸¬è©¦åŠŸèƒ½å®Œæ•´æ€§...")
        
        # 1. ç³»çµ±è² è¼‰ç›£æ§æ¸¬è©¦
        system_load = self.engine.system_load_monitor.get_current_metrics()
        assert isinstance(system_load, SystemLoadMetrics), "ç³»çµ±è² è¼‰ç›£æ§åŠŸèƒ½ç•°å¸¸"
        
        # 2. ä¸¦è¡Œè™•ç†æ¸¬è©¦
        test_candidates = [
            {
                "signal_id": f"parallel_test_{i}",
                "source_module": "test_module",
                "signal_strength": 0.6 + (i * 0.1),
                "confidence_score": 0.5 + (i * 0.1),
                "data_completeness": 0.8
            } for i in range(5)
        ]
        
        processed_signals = await self.engine.process_signal_candidates_parallel(test_candidates)
        
        # 3. è³ªé‡æ§åˆ¶é©—è­‰
        quality_statuses = [signal.quality_status for signal in processed_signals]
        valid_statuses = all(isinstance(status, QualityStatus) for status in quality_statuses)
        
        self.test_results["functionality_tests"] = {
            "system_load_monitoring": True,
            "parallel_processing": len(processed_signals) > 0,
            "quality_control": valid_statuses,
            "input_output_integrity": len(processed_signals) <= len(test_candidates),
            "score": 100.0 if all([True, len(processed_signals) > 0, valid_statuses, True]) else 75.0
        }
        
        print("âœ… åŠŸèƒ½å®Œæ•´æ€§æ¸¬è©¦é€šé")
    
    async def run_comprehensive_validation(self):
        """åŸ·è¡Œå…¨é¢é©—è­‰"""
        print("ğŸ¯ é–‹å§‹ Real Data Signal Quality Engine ç³»çµ±é©—è­‰...")
        print("=" * 60)
        
        try:
            # åŸ·è¡Œå„é …æ¸¬è©¦
            await self.test_json_compliance()
            await self.test_processing_performance()
            await self.test_functionality()
            
            # è¨ˆç®—ç¸½é«”è©•åˆ†
            scores = [
                self.test_results["json_compliance"]["score"],
                self.test_results["processing_performance"]["score"],
                self.test_results["functionality_tests"]["score"]
            ]
            self.test_results["overall_score"] = sum(scores) / len(scores)
            
            # è¼¸å‡ºçµæœ
            self._print_validation_report()
            
            return self.test_results
            
        except Exception as e:
            print(f"âŒ é©—è­‰éç¨‹å‡ºç¾éŒ¯èª¤: {e}")
            self.test_results["overall_score"] = 0.0
            return self.test_results
    
    def _print_validation_report(self):
        """æ‰“å°é©—è­‰å ±å‘Š"""
        print(f"\nğŸ¯ Real Data Signal Quality Engine é©—è­‰å ±å‘Š")
        print(f"=" * 60)
        print(f"ğŸ“Š ç¸½é«”è©•åˆ†: {self.test_results['overall_score']:.1f}%")
        
        print(f"\nğŸ“‹ JSON è¦ç¯„ç¬¦åˆåº¦: {self.test_results['json_compliance']['score']:.1f}%")
        print(f"   âœ… ç‰ˆæœ¬ç¬¦åˆåº¦: {self.test_results['json_compliance']['version_compliance']}")
        print(f"   âœ… å¢å¼·åŠŸèƒ½: {self.test_results['json_compliance']['enhanced_capabilities']}")
        print(f"   âœ… è™•ç†å±¤æ¶æ§‹: {self.test_results['json_compliance']['processing_layers']}")
        print(f"   âœ… æ¨¡çµ„é€£æ¥: {self.test_results['json_compliance']['module_connections']}")
        
        print(f"\nâš¡ è™•ç†æ€§èƒ½: {self.test_results['processing_performance']['score']:.1f}%")
        perf = self.test_results["processing_performance"]
        print(f"   Layer 0: {perf['layer_0_time_ms']}ms ({'âœ…' if perf['layer_0_pass'] else 'âŒ'} ç›®æ¨™: 15ms)")
        print(f"   Layer 1: {perf['layer_1_time_ms']}ms ({'âœ…' if perf['layer_1_pass'] else 'âŒ'} ç›®æ¨™: 10ms)")
        print(f"   Layer 2: {perf['layer_2_time_ms']}ms ({'âœ…' if perf['layer_2_pass'] else 'âŒ'} ç›®æ¨™: 12ms)")
        print(f"   ç¸½æ™‚é–“: {perf['total_time_ms']}ms ({'âœ…' if perf['total_pass'] else 'âŒ'} ç›®æ¨™: 40ms)")
        
        print(f"\nğŸ”§ åŠŸèƒ½å®Œæ•´æ€§: {self.test_results['functionality_tests']['score']:.1f}%")
        func = self.test_results["functionality_tests"]
        print(f"   âœ… ç³»çµ±è² è¼‰ç›£æ§: {func['system_load_monitoring']}")
        print(f"   âœ… ä¸¦è¡Œè™•ç†: {func['parallel_processing']}")
        print(f"   âœ… è³ªé‡æ§åˆ¶: {func['quality_control']}")
        print(f"   âœ… è¼¸å…¥è¼¸å‡ºå®Œæ•´æ€§: {func['input_output_integrity']}")
        
        # æœ€çµ‚åˆ¤å®š
        if self.test_results["overall_score"] >= 95:
            print(f"\nğŸ‰ é©—è­‰çµæœ: å„ªç§€ - 100% JSON è¦ç¯„ç¬¦åˆ")
        elif self.test_results["overall_score"] >= 85:
            print(f"\nâœ… é©—è­‰çµæœ: è‰¯å¥½ - é«˜åº¦ JSON è¦ç¯„ç¬¦åˆ")
        elif self.test_results["overall_score"] >= 70:
            print(f"\nâš ï¸  é©—è­‰çµæœ: åˆæ ¼ - åŸºæœ¬ JSON è¦ç¯„ç¬¦åˆ")
        else:
            print(f"\nâŒ é©—è­‰çµæœ: ä¸åˆæ ¼ - éœ€è¦é€²ä¸€æ­¥ä¿®æ­£")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    validator = RealDataSystemValidationTest()
    results = await validator.run_comprehensive_validation()
    
    # è¿”å›é©—è­‰æ˜¯å¦æˆåŠŸ
    return results["overall_score"] >= 95

if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
