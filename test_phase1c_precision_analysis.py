#!/usr/bin/env python3
"""
ğŸ¯ Phase1C ç²¾ç¢ºæ·±åº¦åˆ†æå·¥å…·
å° phase1c_signal_standardization.py èˆ‡ JSON è¦ç¯„é€²è¡Œé€å±¤é€é …ç²¾ç¢ºåŒ¹é…åˆ†æ
æª¢æ¸¬é‚è¼¯æ–·é»ã€æ•¸æ“šæµç¼ºå¤±ã€å¯¦ç¾å·®ç•°
"""

import json
import ast
import os
import importlib.util
from typing import Dict, Any, List, Set, Tuple
import re
from dataclasses import dataclass
from datetime import datetime

@dataclass
class AnalysisResult:
    """åˆ†æçµæœ"""
    category: str
    item: str
    status: str  # MATCH, MISSING, PARTIAL, INCORRECT
    details: str
    severity: str  # HIGH, MEDIUM, LOW

class Phase1CPrecisionAnalyzer:
    """Phase1C ç²¾ç¢ºåˆ†æå™¨"""
    
    def __init__(self):
        self.json_path = "/Users/henrychang/Desktop/Trading-X/X/backend/phase1_signal_generation/phase1c_signal_standardization/phase1c_signal_standardization.json"
        self.python_path = "/Users/henrychang/Desktop/Trading-X/X/backend/phase1_signal_generation/phase1c_signal_standardization/phase1c_signal_standardization.py"
        
        self.analysis_results: List[AnalysisResult] = []
        
    def load_specifications(self) -> Tuple[Dict[str, Any], str]:
        """è¼‰å…¥ JSON è¦ç¯„å’Œ Python ä»£ç¢¼"""
        # è¼‰å…¥ JSON
        with open(self.json_path, 'r', encoding='utf-8') as f:
            json_spec = json.load(f)
        
        # è¼‰å…¥ Python ä»£ç¢¼
        with open(self.python_path, 'r', encoding='utf-8') as f:
            python_code = f.read()
            
        return json_spec, python_code
    
    def analyze_layer_architecture(self, json_spec: Dict, python_code: str):
        """åˆ†æ 4 å±¤æ¶æ§‹å¯¦ç¾"""
        computation_flow = json_spec["strategy_dependency_graph"]["computation_flow"]
        
        # æª¢æŸ¥æ¯ä¸€å±¤çš„å¯¦ç¾
        layers = [
            "layer_0_cross_module_sync",
            "layer_1_signal_collection", 
            "layer_2_signal_standardization",
            "layer_3_signal_prioritization",
            "layer_4_output_generation"
        ]
        
        for layer in layers:
            if layer in computation_flow:
                self._analyze_single_layer(layer, computation_flow[layer], python_code)
    
    def _analyze_single_layer(self, layer_name: str, layer_spec: Dict, python_code: str):
        """åˆ†æå–®ä¸€å±¤çš„å¯¦ç¾"""
        # æª¢æŸ¥ä¸»æ–¹æ³•æ˜¯å¦å­˜åœ¨
        method_name = f"_{layer_name}"
        method_exists = method_name in python_code
        
        if method_exists:
            self.analysis_results.append(AnalysisResult(
                category="Layer Architecture",
                item=f"{layer_name}_method",
                status="MATCH",
                details=f"æ–¹æ³• {method_name} å­˜åœ¨",
                severity="HIGH"
            ))
        else:
            self.analysis_results.append(AnalysisResult(
                category="Layer Architecture", 
                item=f"{layer_name}_method",
                status="MISSING",
                details=f"ç¼ºå°‘æ–¹æ³• {method_name}",
                severity="HIGH"
            ))
            
        # æª¢æŸ¥å±¤å…§æ“ä½œ
        if "operations" in layer_spec:
            self._analyze_layer_operations(layer_name, layer_spec["operations"], python_code)
    
    def _analyze_layer_operations(self, layer_name: str, operations: Dict, python_code: str):
        """åˆ†æå±¤å…§å…·é«”æ“ä½œ"""
        for operation_name, operation_spec in operations.items():
            # è½‰æ›ç‚ºæ–¹æ³•åæ ¼å¼
            method_name = f"_{operation_name}"
            
            # æª¢æŸ¥æ–¹æ³•æ˜¯å¦å­˜åœ¨
            if method_name in python_code:
                self.analysis_results.append(AnalysisResult(
                    category=f"{layer_name}_operations",
                    item=operation_name,
                    status="MATCH",
                    details=f"æ“ä½œæ–¹æ³• {method_name} å­˜åœ¨",
                    severity="MEDIUM"
                ))
                
                # æ·±åº¦åˆ†ææ“ä½œå…§å®¹
                self._analyze_operation_content(operation_name, operation_spec, python_code)
            else:
                self.analysis_results.append(AnalysisResult(
                    category=f"{layer_name}_operations",
                    item=operation_name,
                    status="MISSING", 
                    details=f"ç¼ºå°‘æ“ä½œæ–¹æ³• {method_name}",
                    severity="MEDIUM"
                ))
    
    def _analyze_operation_content(self, operation_name: str, operation_spec: Dict, python_code: str):
        """æ·±åº¦åˆ†ææ“ä½œå…§å®¹"""
        # æª¢æŸ¥è¼¸å…¥è¼¸å‡º
        if "input" in operation_spec:
            input_var = operation_spec["input"]
            if isinstance(input_var, str):
                # æª¢æŸ¥æ–¹æ³•ä¸­æ˜¯å¦è™•ç†äº†é€™å€‹è¼¸å…¥
                method_pattern = f"_{operation_name}.*{input_var}|{input_var}.*_{operation_name}"
                if not re.search(method_pattern, python_code, re.IGNORECASE):
                    self.analysis_results.append(AnalysisResult(
                        category=f"{operation_name}_data_flow",
                        item=f"input_{input_var}",
                        status="MISSING",
                        details=f"æ“ä½œ {operation_name} æœªè™•ç†è¼¸å…¥ {input_var}",
                        severity="MEDIUM"
                    ))
        
        if "output" in operation_spec:
            output_var = operation_spec["output"]
            if isinstance(output_var, str):
                # æª¢æŸ¥æ–¹æ³•ä¸­æ˜¯å¦è¿”å›é€™å€‹è¼¸å‡º
                output_pattern = f"return.*{output_var}|{output_var}.*=.*"
                if not re.search(output_pattern, python_code, re.IGNORECASE):
                    self.analysis_results.append(AnalysisResult(
                        category=f"{operation_name}_data_flow",
                        item=f"output_{output_var}",
                        status="MISSING",
                        details=f"æ“ä½œ {operation_name} æœªç”Ÿæˆè¼¸å‡º {output_var}",
                        severity="MEDIUM"
                    ))
    
    def analyze_signal_format_adapters(self, json_spec: Dict, python_code: str):
        """åˆ†æä¿¡è™Ÿæ ¼å¼é©é…å™¨"""
        # æª¢æŸ¥ Phase1B é©é…å™¨
        layer1_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_1_signal_collection"]["operations"]
        
        if "signal_format_adapter" in layer1_ops:
            adapter_spec = layer1_ops["signal_format_adapter"]["adapters"]
            
            # æª¢æŸ¥ Phase1B é©é…å™¨
            if "phase1b_adapter" in adapter_spec:
                phase1b_spec = adapter_spec["phase1b_adapter"]
                self._analyze_phase1b_adapter(phase1b_spec, python_code)
            
            # æª¢æŸ¥æŒ‡æ¨™é©é…å™¨
            if "indicator_adapter" in adapter_spec:
                indicator_spec = adapter_spec["indicator_adapter"]
                self._analyze_indicator_adapter(indicator_spec, python_code)
    
    def _analyze_phase1b_adapter(self, adapter_spec: Dict, python_code: str):
        """åˆ†æ Phase1B é©é…å™¨å¯¦ç¾"""
        # æª¢æŸ¥æ˜ å°„è¦å‰‡
        if "output_mapping" in adapter_spec and "mapping_rules" in adapter_spec["output_mapping"]:
            mapping_rules = adapter_spec["output_mapping"]["mapping_rules"]
            
            # æª¢æŸ¥æ¯å€‹æ˜ å°„è¦å‰‡æ˜¯å¦åœ¨ä»£ç¢¼ä¸­å¯¦ç¾
            for json_key, expected_value in mapping_rules.items():
                # åœ¨ _phase1b_adapter æ–¹æ³•ä¸­æŸ¥æ‰¾é€™å€‹æ˜ å°„
                pattern = f"{json_key}.*{expected_value}|{expected_value}.*{json_key}"
                if re.search(pattern, python_code):
                    self.analysis_results.append(AnalysisResult(
                        category="Phase1B_Adapter",
                        item=f"mapping_{json_key}",
                        status="MATCH",
                        details=f"æ˜ å°„è¦å‰‡ {json_key} -> {expected_value} å·²å¯¦ç¾",
                        severity="MEDIUM"
                    ))
                else:
                    self.analysis_results.append(AnalysisResult(
                        category="Phase1B_Adapter",
                        item=f"mapping_{json_key}",
                        status="MISSING",
                        details=f"ç¼ºå°‘æ˜ å°„è¦å‰‡ {json_key} -> {expected_value}",
                        severity="MEDIUM"
                    ))
    
    def _analyze_indicator_adapter(self, adapter_spec: Dict, python_code: str):
        """åˆ†ææŒ‡æ¨™é©é…å™¨å¯¦ç¾"""
        if "output_mapping" in adapter_spec and "mapping_rules" in adapter_spec["output_mapping"]:
            mapping_rules = adapter_spec["output_mapping"]["mapping_rules"]
            
            for json_key, expected_value in mapping_rules.items():
                pattern = f"{json_key}.*{expected_value}|{expected_value}.*{json_key}"
                if re.search(pattern, python_code):
                    self.analysis_results.append(AnalysisResult(
                        category="Indicator_Adapter",
                        item=f"mapping_{json_key}",
                        status="MATCH",
                        details=f"æ˜ å°„è¦å‰‡ {json_key} -> {expected_value} å·²å¯¦ç¾",
                        severity="MEDIUM"
                    ))
                else:
                    self.analysis_results.append(AnalysisResult(
                        category="Indicator_Adapter",
                        item=f"mapping_{json_key}",
                        status="MISSING",
                        details=f"ç¼ºå°‘æ˜ å°„è¦å‰‡ {json_key} -> {expected_value}",
                        severity="MEDIUM"
                    ))
    
    def analyze_quality_score_standardization(self, json_spec: Dict, python_code: str):
        """åˆ†æè³ªé‡è©•åˆ†æ¨™æº–åŒ–"""
        layer1_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_1_signal_collection"]["operations"]
        
        if "quality_score_standardization" in layer1_ops:
            quality_spec = layer1_ops["quality_score_standardization"]["conversions"]
            
            # æª¢æŸ¥ Phase1B è³ªé‡è½‰æ›
            if "phase1b_to_standard" in quality_spec:
                phase1b_conversion = quality_spec["phase1b_to_standard"]
                self._analyze_quality_conversion(phase1b_conversion, python_code, "Phase1B")
            
            # æª¢æŸ¥æŒ‡æ¨™è³ªé‡è½‰æ›
            if "indicator_to_standard" in quality_spec:
                indicator_conversion = quality_spec["indicator_to_standard"]
                self._analyze_quality_conversion(indicator_conversion, python_code, "Indicator")
    
    def _analyze_quality_conversion(self, conversion_spec: Dict, python_code: str, adapter_type: str):
        """åˆ†æè³ªé‡è½‰æ›å¯¦ç¾"""
        for field, formula in conversion_spec.items():
            if isinstance(formula, str):
                # æª¢æŸ¥å…¬å¼ä¸­çš„é—œéµè©æ˜¯å¦åœ¨ä»£ç¢¼ä¸­
                key_terms = re.findall(r'[a-zA-Z_][a-zA-Z0-9_]*', formula)
                for term in key_terms:
                    if term in python_code:
                        self.analysis_results.append(AnalysisResult(
                            category=f"{adapter_type}_Quality_Conversion",
                            item=f"{field}_{term}",
                            status="MATCH",
                            details=f"è³ªé‡è½‰æ›é … {term} å·²å¯¦ç¾",
                            severity="LOW"
                        ))
                    else:
                        self.analysis_results.append(AnalysisResult(
                            category=f"{adapter_type}_Quality_Conversion",
                            item=f"{field}_{term}",
                            status="MISSING",
                            details=f"ç¼ºå°‘è³ªé‡è½‰æ›é … {term}",
                            severity="LOW"
                        ))
    
    def analyze_extreme_market_handling(self, json_spec: Dict, python_code: str):
        """åˆ†ææ¥µç«¯å¸‚å ´è™•ç†"""
        # æª¢æŸ¥æ¥µç«¯å¸‚å ´æª¢æ¸¬
        if "_detect_extreme_market" in python_code:
            self.analysis_results.append(AnalysisResult(
                category="Extreme_Market",
                item="detection_method",
                status="MATCH",
                details="æ¥µç«¯å¸‚å ´æª¢æ¸¬æ–¹æ³•å­˜åœ¨",
                severity="HIGH"
            ))
        else:
            self.analysis_results.append(AnalysisResult(
                category="Extreme_Market",
                item="detection_method",
                status="MISSING", 
                details="ç¼ºå°‘æ¥µç«¯å¸‚å ´æª¢æ¸¬æ–¹æ³•",
                severity="HIGH"
            ))
        
        # æª¢æŸ¥å¿«é€Ÿé€šé“
        if "_extreme_market_fast_track" in python_code:
            self.analysis_results.append(AnalysisResult(
                category="Extreme_Market",
                item="fast_track_method",
                status="MATCH",
                details="æ¥µç«¯å¸‚å ´å¿«é€Ÿé€šé“å­˜åœ¨",
                severity="HIGH"
            ))
        else:
            self.analysis_results.append(AnalysisResult(
                category="Extreme_Market",
                item="fast_track_method",
                status="MISSING",
                details="ç¼ºå°‘æ¥µç«¯å¸‚å ´å¿«é€Ÿé€šé“",
                severity="HIGH"
            ))
        
        # æª¢æŸ¥ 15ms SLA ç›®æ¨™
        layer3_spec = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_3_signal_prioritization"]
        if "extreme_market_fast_track" in layer3_spec:
            target_latency = layer3_spec["extreme_market_fast_track"]["tier_1_fast_track"]["target_latency_ms"]
            if "15" in python_code and "SLA" in python_code.upper():
                self.analysis_results.append(AnalysisResult(
                    category="Extreme_Market",
                    item="15ms_sla",
                    status="MATCH",
                    details="15ms SLA ç›®æ¨™å·²è­˜åˆ¥",
                    severity="HIGH"
                ))
            else:
                self.analysis_results.append(AnalysisResult(
                    category="Extreme_Market", 
                    item="15ms_sla",
                    status="MISSING",
                    details="æœªæ‰¾åˆ° 15ms SLA ç›®æ¨™å¯¦ç¾",
                    severity="HIGH"
                ))
    
    def analyze_cross_market_validation(self, json_spec: Dict, python_code: str):
        """åˆ†æè·¨å¸‚å ´é©—è­‰"""
        layer2_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_2_signal_standardization"]["operations"]
        
        if "quality_score_enhancement" in layer2_ops:
            enhancement_spec = layer2_ops["quality_score_enhancement"]
            
            # æª¢æŸ¥è·¨å¸‚å ´é©—è­‰
            if "cross_market_validation" in enhancement_spec:
                cross_market_spec = enhancement_spec["cross_market_validation"]
                
                # BTC ç›¸é—œæ€§æª¢æŸ¥
                if "btc_correlation_check" in cross_market_spec:
                    btc_spec = cross_market_spec["btc_correlation_check"]
                    
                    if "btc_correlation" in python_code:
                        self.analysis_results.append(AnalysisResult(
                            category="Cross_Market_Validation",
                            item="btc_correlation",
                            status="MATCH",
                            details="BTC ç›¸é—œæ€§æª¢æŸ¥å·²å¯¦ç¾",
                            severity="MEDIUM"
                        ))
                    else:
                        self.analysis_results.append(AnalysisResult(
                            category="Cross_Market_Validation",
                            item="btc_correlation",
                            status="MISSING",
                            details="ç¼ºå°‘ BTC ç›¸é—œæ€§æª¢æŸ¥",
                            severity="MEDIUM"
                        ))
                
                # æµå‹•æ€§æ¬Šé‡
                if "liquidity_weighting" in cross_market_spec:
                    if "liquidity" in python_code and "weight" in python_code:
                        self.analysis_results.append(AnalysisResult(
                            category="Cross_Market_Validation",
                            item="liquidity_weighting",
                            status="MATCH",
                            details="æµå‹•æ€§æ¬Šé‡å·²å¯¦ç¾",
                            severity="MEDIUM"
                        ))
                    else:
                        self.analysis_results.append(AnalysisResult(
                            category="Cross_Market_Validation",
                            item="liquidity_weighting",
                            status="MISSING",
                            details="ç¼ºå°‘æµå‹•æ€§æ¬Šé‡å¯¦ç¾",
                            severity="MEDIUM"
                        ))
    
    def analyze_trading_session_adaptation(self, json_spec: Dict, python_code: str):
        """åˆ†æäº¤æ˜“æ™‚æ®µé©æ‡‰"""
        layer2_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_2_signal_standardization"]["operations"]
        
        if "quality_score_enhancement" in layer2_ops:
            enhancement_spec = layer2_ops["quality_score_enhancement"]
            
            if "trading_session_adaptation" in enhancement_spec:
                session_spec = enhancement_spec["trading_session_adaptation"]
                
                sessions = ["asian_session", "european_session", "american_session"]
                for session in sessions:
                    if session in session_spec:
                        session_name = session.replace("_session", "").upper()
                        if session_name in python_code:
                            self.analysis_results.append(AnalysisResult(
                                category="Trading_Session_Adaptation",
                                item=session,
                                status="MATCH",
                                details=f"{session} é©æ‡‰å·²å¯¦ç¾",
                                severity="LOW"
                            ))
                        else:
                            self.analysis_results.append(AnalysisResult(
                                category="Trading_Session_Adaptation",
                                item=session,
                                status="MISSING",
                                details=f"ç¼ºå°‘ {session} é©æ‡‰",
                                severity="LOW"
                            ))
    
    def analyze_multi_dimensional_scoring(self, json_spec: Dict, python_code: str):
        """åˆ†æå¤šç¶­åº¦è©•åˆ†"""
        layer3_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_3_signal_prioritization"]["operations"]
        
        if "multi_dimensional_scoring" in layer3_ops:
            scoring_spec = layer3_ops["multi_dimensional_scoring"]["scoring_dimensions"]
            
            dimensions = [
                "signal_strength",
                "confidence_score", 
                "execution_priority",
                "market_timing",
                "risk_reward_ratio"
            ]
            
            for dimension in dimensions:
                if dimension in scoring_spec:
                    if dimension in python_code:
                        self.analysis_results.append(AnalysisResult(
                            category="Multi_Dimensional_Scoring",
                            item=dimension,
                            status="MATCH", 
                            details=f"è©•åˆ†ç¶­åº¦ {dimension} å·²å¯¦ç¾",
                            severity="MEDIUM"
                        ))
                    else:
                        self.analysis_results.append(AnalysisResult(
                            category="Multi_Dimensional_Scoring",
                            item=dimension,
                            status="MISSING",
                            details=f"ç¼ºå°‘è©•åˆ†ç¶­åº¦ {dimension}",
                            severity="MEDIUM"
                        ))
    
    def analyze_signal_filtering_rules(self, json_spec: Dict, python_code: str):
        """åˆ†æä¿¡è™Ÿéæ¿¾è¦å‰‡"""
        layer3_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_3_signal_prioritization"]["operations"]
        
        if "signal_filtering_rules" in layer3_ops:
            filtering_spec = layer3_ops["signal_filtering_rules"]
            
            # æª¢æŸ¥éæ¿¾æ¨™æº–
            if "filtering_criteria" in filtering_spec:
                criteria = filtering_spec["filtering_criteria"]
                
                criteria_items = [
                    "minimum_quality_threshold",
                    "maximum_signals_per_symbol", 
                    "maximum_signals_per_timeframe",
                    "signal_diversity_requirement",
                    "temporal_filtering"
                ]
                
                for criterion in criteria_items:
                    if criterion in criteria:
                        criterion_key = criterion.replace("_", "")
                        if criterion_key in python_code or criterion in python_code:
                            self.analysis_results.append(AnalysisResult(
                                category="Signal_Filtering_Rules",
                                item=criterion,
                                status="MATCH",
                                details=f"éæ¿¾æ¨™æº– {criterion} å·²å¯¦ç¾",
                                severity="MEDIUM"
                            ))
                        else:
                            self.analysis_results.append(AnalysisResult(
                                category="Signal_Filtering_Rules", 
                                item=criterion,
                                status="MISSING",
                                details=f"ç¼ºå°‘éæ¿¾æ¨™æº– {criterion}",
                                severity="MEDIUM"
                            ))
            
            # æª¢æŸ¥åå‘ä¿¡è™Ÿè¡çªæŠ‘åˆ¶
            if "reverse_signal_conflict_suppression" in filtering_spec:
                if "reverse_signal" in python_code and "conflict" in python_code:
                    self.analysis_results.append(AnalysisResult(
                        category="Signal_Filtering_Rules",
                        item="reverse_signal_conflict_suppression",
                        status="MATCH",
                        details="åå‘ä¿¡è™Ÿè¡çªæŠ‘åˆ¶å·²å¯¦ç¾",
                        severity="HIGH"
                    ))
                else:
                    self.analysis_results.append(AnalysisResult(
                        category="Signal_Filtering_Rules",
                        item="reverse_signal_conflict_suppression", 
                        status="MISSING",
                        details="ç¼ºå°‘åå‘ä¿¡è™Ÿè¡çªæŠ‘åˆ¶",
                        severity="HIGH"
                    ))
    
    def analyze_streaming_output(self, json_spec: Dict, python_code: str):
        """åˆ†ææµå¼è¼¸å‡º"""
        layer4_ops = json_spec["strategy_dependency_graph"]["computation_flow"]["layer_4_output_generation"]["operations"]
        
        if "signal_distribution" in layer4_ops:
            distribution_spec = layer4_ops["signal_distribution"]
            
            # æª¢æŸ¥æµå¼è¼¸å‡º
            if "streaming_output" in distribution_spec:
                streaming_spec = distribution_spec["streaming_output"]
                
                streaming_items = [
                    "tier_1_immediate_push",
                    "tier_2_batch_push", 
                    "tier_3_scheduled_push"
                ]
                
                for item in streaming_items:
                    if item in streaming_spec:
                        item_key = item.replace("_", "")
                        if item_key in python_code or "immediate_push" in python_code:
                            self.analysis_results.append(AnalysisResult(
                                category="Streaming_Output",
                                item=item,
                                status="MATCH",
                                details=f"æµå¼è¼¸å‡º {item} å·²å¯¦ç¾",
                                severity="MEDIUM"
                            ))
                        else:
                            self.analysis_results.append(AnalysisResult(
                                category="Streaming_Output",
                                item=item,
                                status="MISSING",
                                details=f"ç¼ºå°‘æµå¼è¼¸å‡º {item}",
                                severity="MEDIUM"
                            ))
    
    def analyze_performance_targets(self, json_spec: Dict, python_code: str):
        """åˆ†ææ€§èƒ½ç›®æ¨™"""
        performance_targets = json_spec["strategy_dependency_graph"]["performance_targets"]
        
        # æª¢æŸ¥ç¸½è¨ˆç®—æ™‚é–“
        if "total_computation_time_ms" in performance_targets:
            target_time = performance_targets["total_computation_time_ms"]
            if str(target_time) in python_code or "25ms" in python_code:
                self.analysis_results.append(AnalysisResult(
                    category="Performance_Targets",
                    item="total_computation_time",
                    status="MATCH",
                    details=f"ç¸½è¨ˆç®—æ™‚é–“ç›®æ¨™ {target_time}ms å·²è­˜åˆ¥",
                    severity="HIGH"
                ))
            else:
                self.analysis_results.append(AnalysisResult(
                    category="Performance_Targets",
                    item="total_computation_time",
                    status="MISSING",
                    details=f"æœªæ‰¾åˆ°ç¸½è¨ˆç®—æ™‚é–“ç›®æ¨™ {target_time}ms",
                    severity="HIGH"
                ))
        
        # æª¢æŸ¥åˆ†å±¤è™•ç†æ™‚é–“
        if "layered_processing_times" in performance_targets:
            layered_times = performance_targets["layered_processing_times"]
            
            for layer, target_time in layered_times.items():
                time_value = re.search(r'(\d+)ms', target_time)
                if time_value:
                    time_str = time_value.group(1)
                    if time_str in python_code:
                        self.analysis_results.append(AnalysisResult(
                            category="Performance_Targets",
                            item=f"{layer}_time",
                            status="MATCH",
                            details=f"{layer} æ™‚é–“ç›®æ¨™ {time_str}ms å·²è­˜åˆ¥",
                            severity="MEDIUM"
                        ))
                    else:
                        self.analysis_results.append(AnalysisResult(
                            category="Performance_Targets",
                            item=f"{layer}_time",
                            status="MISSING",
                            details=f"æœªæ‰¾åˆ° {layer} æ™‚é–“ç›®æ¨™ {time_str}ms",
                            severity="MEDIUM"
                        ))
    
    def analyze_data_structures(self, json_spec: Dict, python_code: str):
        """åˆ†ææ•¸æ“šçµæ§‹"""
        signal_format = json_spec["strategy_dependency_graph"]["signal_output_format"]["standardized_trading_signal"]
        
        required_fields = [
            "signal_id", "symbol", "timeframe", "strategy", "signal_type",
            "signal_strength", "confidence_score", "execution_priority",
            "composite_score", "tier_classification", "market_context",
            "risk_metrics", "execution_guidance", "quality_indicators", "metadata"
        ]
        
        for field in required_fields:
            if field in signal_format:
                if field in python_code:
                    self.analysis_results.append(AnalysisResult(
                        category="Data_Structures",
                        item=field,
                        status="MATCH",
                        details=f"æ•¸æ“šçµæ§‹å­—æ®µ {field} å·²å¯¦ç¾",
                        severity="MEDIUM"
                    ))
                else:
                    self.analysis_results.append(AnalysisResult(
                        category="Data_Structures",
                        item=field,
                        status="MISSING",
                        details=f"ç¼ºå°‘æ•¸æ“šçµæ§‹å­—æ®µ {field}",
                        severity="MEDIUM"
                    ))
    
    def calculate_match_score(self) -> Dict[str, Any]:
        """è¨ˆç®—åŒ¹é…åˆ†æ•¸"""
        category_scores = {}
        
        for result in self.analysis_results:
            category = result.category
            if category not in category_scores:
                category_scores[category] = {"total": 0, "matched": 0}
            
            category_scores[category]["total"] += 1
            if result.status == "MATCH":
                category_scores[category]["matched"] += 1
        
        # è¨ˆç®—æ¯å€‹é¡åˆ¥çš„å¾—åˆ†
        for category in category_scores:
            total = category_scores[category]["total"]
            matched = category_scores[category]["matched"]
            category_scores[category]["score"] = matched / total if total > 0 else 0
        
        # è¨ˆç®—ç¸½é«”å¾—åˆ†
        total_items = len(self.analysis_results)
        matched_items = len([r for r in self.analysis_results if r.status == "MATCH"])
        overall_score = matched_items / total_items if total_items > 0 else 0
        
        return {
            "overall_score": overall_score,
            "category_scores": category_scores,
            "total_items": total_items,
            "matched_items": matched_items
        }
    
    def generate_detailed_report(self, scores: Dict[str, Any]) -> str:
        """ç”Ÿæˆè©³ç´°å ±å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ¯ PHASE1C ç²¾ç¢ºæ·±åº¦åˆ†æå ±å‘Š")
        report.append("=" * 80)
        
        # ç¸½é«”è©•åˆ†
        overall_score = scores["overall_score"]
        report.append(f"\nğŸ“Š ç¸½é«”åŒ¹é…åº¦: {overall_score:.1%}")
        
        # åŒ¹é…åº¦è©•ç´š
        if overall_score >= 0.9:
            grade = "A+ (å„ªç§€)"
        elif overall_score >= 0.8:
            grade = "A (è‰¯å¥½)"  
        elif overall_score >= 0.7:
            grade = "B (ä¸€èˆ¬)"
        elif overall_score >= 0.6:
            grade = "C (éœ€æ”¹é€²)"
        else:
            grade = "D (åš´é‡ä¸åŒ¹é…)"
        
        report.append(f"ğŸ“ˆ åŒ¹é…ç­‰ç´š: {grade}")
        
        report.append("\n" + "=" * 50)
        report.append("ğŸ“‹ åˆ†é¡è©³ç´°åˆ†æ:")
        report.append("=" * 50)
        
        # æŒ‰é¡åˆ¥é¡¯ç¤ºçµæœ
        categories = {}
        for result in self.analysis_results:
            if result.category not in categories:
                categories[result.category] = []
            categories[result.category].append(result)
        
        for category, results in categories.items():
            category_score = scores["category_scores"].get(category, {}).get("score", 0)
            status_icon = "âœ…" if category_score >= 0.8 else "âš ï¸" if category_score >= 0.6 else "âŒ"
            
            report.append(f"\n{status_icon} {category}: {category_score:.1%}")
            
            # é¡¯ç¤ºå…·é«”é …ç›®
            for result in results:
                status_icon = {"MATCH": "âœ“", "MISSING": "âœ—", "PARTIAL": "â—", "INCORRECT": "âœ—"}[result.status]
                severity_icon = {"HIGH": "ğŸ”´", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸŸ¢"}[result.severity]
                
                report.append(f"    {status_icon} {severity_icon} {result.item}: {result.details}")
        
        # é«˜å„ªå…ˆç´šå•é¡Œç¸½çµ
        high_priority_issues = [r for r in self.analysis_results 
                              if r.severity == "HIGH" and r.status != "MATCH"]
        
        if high_priority_issues:
            report.append("\n" + "=" * 50)
            report.append("ğŸš¨ é«˜å„ªå…ˆç´šå•é¡Œ:")
            report.append("=" * 50)
            
            for issue in high_priority_issues:
                report.append(f"ğŸ”´ {issue.category}.{issue.item}: {issue.details}")
        
        # é‚è¼¯æ–·é»åˆ†æ
        report.append("\n" + "=" * 50)
        report.append("ğŸ” é‚è¼¯æ–·é»åˆ†æ:")
        report.append("=" * 50)
        
        # æª¢æŸ¥æ•¸æ“šæµé€£çºŒæ€§
        data_flow_issues = [r for r in self.analysis_results 
                           if "data_flow" in r.category and r.status != "MATCH"]
        
        if data_flow_issues:
            report.append("\nğŸ“Š æ•¸æ“šæµæ–·é»:")
            for issue in data_flow_issues:
                report.append(f"  âŒ {issue.details}")
        else:
            report.append("\nâœ… æ•¸æ“šæµé€£çºŒæ€§è‰¯å¥½")
        
        # æª¢æŸ¥æ¶æ§‹å±¤æ¬¡å®Œæ•´æ€§
        layer_issues = [r for r in self.analysis_results 
                       if "Layer Architecture" in r.category and r.status != "MATCH"]
        
        if layer_issues:
            report.append("\nğŸ—ï¸ æ¶æ§‹å±¤æ¬¡ç¼ºå¤±:")
            for issue in layer_issues:
                report.append(f"  âŒ {issue.details}")
        else:
            report.append("\nâœ… 4å±¤æ¶æ§‹å®Œæ•´")
        
        # æ€§èƒ½ç›®æ¨™é”æˆåº¦
        performance_issues = [r for r in self.analysis_results 
                            if "Performance_Targets" in r.category and r.status != "MATCH"]
        
        if performance_issues:
            report.append("\nâš¡ æ€§èƒ½ç›®æ¨™ç¼ºå¤±:")
            for issue in performance_issues:
                report.append(f"  âŒ {issue.details}")
        else:
            report.append("\nâœ… æ€§èƒ½ç›®æ¨™æ˜ç¢º")
        
        report.append("\n" + "=" * 80)
        
        return "\n".join(report)
    
    def run_analysis(self) -> Tuple[Dict[str, Any], str]:
        """é‹è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ é–‹å§‹ Phase1C ç²¾ç¢ºæ·±åº¦åˆ†æ...")
        
        # è¼‰å…¥è¦ç¯„å’Œä»£ç¢¼
        json_spec, python_code = self.load_specifications()
        
        # åŸ·è¡Œå„é …åˆ†æ
        self.analyze_layer_architecture(json_spec, python_code)
        self.analyze_signal_format_adapters(json_spec, python_code)
        self.analyze_quality_score_standardization(json_spec, python_code)
        self.analyze_extreme_market_handling(json_spec, python_code)
        self.analyze_cross_market_validation(json_spec, python_code)
        self.analyze_trading_session_adaptation(json_spec, python_code)
        self.analyze_multi_dimensional_scoring(json_spec, python_code)
        self.analyze_signal_filtering_rules(json_spec, python_code)
        self.analyze_streaming_output(json_spec, python_code)
        self.analyze_performance_targets(json_spec, python_code)
        self.analyze_data_structures(json_spec, python_code)
        
        # è¨ˆç®—å¾—åˆ†
        scores = self.calculate_match_score()
        
        # ç”Ÿæˆå ±å‘Š
        report = self.generate_detailed_report(scores)
        
        return scores, report

if __name__ == "__main__":
    analyzer = Phase1CPrecisionAnalyzer()
    scores, report = analyzer.run_analysis()
    print(report)
    
    # è¿”å›çµæœä¾›å¾ŒçºŒä½¿ç”¨
    print(f"\nç¸½é«”åŒ¹é…åº¦: {scores['overall_score']:.1%}")
    print(f"åˆ†æé …ç›®ç¸½æ•¸: {scores['total_items']}")
    print(f"åŒ¹é…é …ç›®æ•¸: {scores['matched_items']}")
