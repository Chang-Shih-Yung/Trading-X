"""
ğŸ” EPL Decision History Tracking JSON é…ç½®é©—è­‰ (å®Œæ•´ç‰ˆ)
=====================================================

åŸºæ–¼å®Œæ•´é…ç½®çµæ§‹çš„æº–ç¢ºé©—è­‰
"""

import json
import logging
from pathlib import Path
from typing import Dict, Any, List
from datetime import datetime

logger = logging.getLogger(__name__)

class EPLConfigValidatorFinal:
    """EPL æ±ºç­–æ­·å²è¿½è¹¤é…ç½®é©—è­‰å™¨ (æœ€çµ‚ç‰ˆ)"""
    
    def __init__(self):
        self.config_path = Path("/Users/henrychang/Desktop/Trading-X/X/backend/phase4_output_monitoring/3_epl_decision_history_tracking/epl_decision_history_tracking_config.json")
        
    def load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"è¼‰å…¥é…ç½®å¤±æ•—: {e}")
            return {}
    
    def validate_phase_integration(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰ Phase æ•´åˆ (åŸºæ–¼å¯¦éš›çµæ§‹)"""
        integration_score = 0
        max_score = 40
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        decision_arch = epl_config.get("decision_tracking_architecture", {})
        
        # Phase1 ä¿¡è™Ÿè¿½è¹¤ (10åˆ†)
        phase1_score = 0
        decision_lifecycle = decision_arch.get("decision_lifecycle_monitoring", {})
        if "decision_creation" in decision_lifecycle:
            creation = decision_lifecycle["decision_creation"]
            if "input_data_capture" in creation:
                input_data = creation["input_data_capture"]
                if "original_signal_candidate" in input_data:
                    phase1_score += 5
                if "pre_evaluation_result" in input_data:
                    phase1_score += 5
        
        details["phase1_signal_integration"] = f"{phase1_score}/10"
        integration_score += phase1_score
        
        # Phase2 é è©•ä¼°æ•´åˆ (10åˆ†)
        phase2_score = 0
        if "decision_creation" in decision_lifecycle:
            creation = decision_lifecycle["decision_creation"]
            if "decision_engine_process" in creation:
                phase2_score += 5
            if "decision_output_capture" in creation:
                phase2_score += 5
        
        details["phase2_decision_engine"] = f"{phase2_score}/10"
        integration_score += phase2_score
        
        # Phase3 åŸ·è¡Œè¿½è¹¤ (10åˆ†)
        phase3_score = 0
        if "decision_execution_tracking" in decision_lifecycle:
            execution = decision_lifecycle["decision_execution_tracking"]
            if "execution_initiation" in execution:
                phase3_score += 5
            if "execution_monitoring" in execution:
                phase3_score += 5
        
        details["phase3_execution_tracking"] = f"{phase3_score}/10"
        integration_score += phase3_score
        
        # Phase4 æˆæ•ˆæ¸¬é‡ (10åˆ†)
        phase4_score = 0
        if "outcome_measurement" in decision_lifecycle:
            outcome = decision_lifecycle["outcome_measurement"]
            if "immediate_outcomes" in outcome:
                phase4_score += 5
            if "extended_outcomes" in outcome:
                phase4_score += 5
        
        details["phase4_outcome_measurement"] = f"{phase4_score}/10"
        integration_score += phase4_score
        
        return {
            "integration_score": integration_score,
            "max_score": max_score,
            "percentage": (integration_score / max_score) * 100,
            "details": details,
            "status": "excellent" if integration_score >= 32 else "good" if integration_score >= 24 else "needs_improvement"
        }
    
    def validate_data_structures(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰æ•¸æ“šçµæ§‹ç›¸å®¹æ€§"""
        compatibility_score = 0
        max_score = 30
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        # æ±ºç­–é¡å‹åˆ†æ (10åˆ†)
        decision_analytics = 0
        if "decision_type_analytics" in epl_config.get("decision_tracking_architecture", {}):
            analytics = epl_config["decision_tracking_architecture"]["decision_type_analytics"]
            if "replacement_decision_tracking" in analytics:
                decision_analytics += 3
            if "strengthening_decision_tracking" in analytics:
                decision_analytics += 3
            if "new_position_decision_tracking" in analytics:
                decision_analytics += 2
            if "ignore_decision_tracking" in analytics:
                decision_analytics += 2
        
        details["decision_analytics_structure"] = f"{decision_analytics}/10"
        compatibility_score += decision_analytics
        
        # æ•¸æ“šå­˜å„²å’Œæª¢ç´¢ (10åˆ†)
        data_storage = 0
        storage_config = epl_config.get("data_storage_and_retrieval", {})
        if "decision_data_storage" in storage_config:
            storage = storage_config["decision_data_storage"]
            if "raw_decision_data" in storage:
                data_storage += 5
            if "aggregated_analytics" in storage:
                data_storage += 5
        
        details["data_storage_structure"] = f"{data_storage}/10"
        compatibility_score += data_storage
        
        # API æ¥å£ (10åˆ†)
        api_score = 0
        api_config = epl_config.get("api_interfaces", {})
        if "decision_tracking_api" in api_config:
            api_score += 4
        if "performance_analytics_api" in api_config:
            api_score += 3
        if "learning_data_api" in api_config:
            api_score += 3
        
        details["api_interfaces"] = f"{api_score}/10"
        compatibility_score += api_score
        
        return {
            "compatibility_score": compatibility_score,
            "max_score": max_score,
            "percentage": (compatibility_score / max_score) * 100,
            "details": details,
            "status": "excellent" if compatibility_score >= 24 else "good" if compatibility_score >= 18 else "needs_improvement"
        }
    
    def validate_monitoring_features(self, config: Dict) -> Dict[str, Any]:
        """é©—è­‰ç›£æ§åŠŸèƒ½"""
        monitoring_score = 0
        max_score = 30
        details = {}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        # å­¸ç¿’å’Œå„ªåŒ– (10åˆ†)
        learning_score = 0
        learning_config = epl_config.get("learning_and_optimization", {})
        if "pattern_recognition" in learning_config:
            learning_score += 4
        if "adaptive_learning" in learning_config:
            learning_score += 3
        if "feedback_integration" in learning_config:
            learning_score += 3
        
        details["learning_optimization"] = f"{learning_score}/10"
        monitoring_score += learning_score
        
        # å ±å‘Šå’Œåˆ†æ (10åˆ†)
        reporting_score = 0
        reporting_config = epl_config.get("reporting_and_analytics", {})
        if "real_time_dashboards" in reporting_config:
            reporting_score += 5
        if "historical_analysis" in reporting_config:
            reporting_score += 5
        
        details["reporting_analytics"] = f"{reporting_score}/10"
        monitoring_score += reporting_score
        
        # å„ªå…ˆç´šåˆ†é¡åˆ†æ (10åˆ†)
        priority_score = 0
        decision_arch = epl_config.get("decision_tracking_architecture", {})
        if "priority_classification_analytics" in decision_arch:
            priority_analytics = decision_arch["priority_classification_analytics"]
            if "critical_priority_tracking" in priority_analytics:
                priority_score += 5
            if "priority_calibration" in priority_analytics:
                priority_score += 5
        
        details["priority_classification"] = f"{priority_score}/10"
        monitoring_score += priority_score
        
        return {
            "monitoring_score": monitoring_score,
            "max_score": max_score,
            "percentage": (monitoring_score / max_score) * 100,
            "details": details,
            "status": "excellent" if monitoring_score >= 24 else "good" if monitoring_score >= 18 else "needs_improvement"
        }
    
    def generate_validation_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆé©—è­‰å ±å‘Š"""
        print("ğŸ” EPL Decision History Tracking JSON é…ç½®é©—è­‰ (å®Œæ•´ç‰ˆ)")
        print("=" * 70)
        
        # è¼‰å…¥é…ç½®
        config = self.load_config()
        if not config:
            return {"validation_status": "failed", "error": "ç„¡æ³•è¼‰å…¥é…ç½®"}
        
        epl_config = config.get("PHASE4_EPL_DECISION_HISTORY_TRACKING", {})
        
        print(f"âœ… é…ç½®è¼‰å…¥æˆåŠŸ")
        print(f"ğŸ“Š ä¸»è¦çµ„ä»¶: {list(epl_config.keys())}")
        print(f"ğŸ“ ç³»çµ±ç‰ˆæœ¬: {epl_config.get('system_metadata', {}).get('version', 'N/A')}")
        
        # å„é …é©—è­‰
        phase_integration = self.validate_phase_integration(config)
        data_compatibility = self.validate_data_structures(config)
        monitoring_features = self.validate_monitoring_features(config)
        
        # è¨ˆç®—ç¸½åˆ†
        total_score = (
            phase_integration["integration_score"] +
            data_compatibility["compatibility_score"] +
            monitoring_features["monitoring_score"]
        )
        max_total_score = (
            phase_integration["max_score"] +
            data_compatibility["max_score"] +
            monitoring_features["max_score"]
        )
        
        overall_percentage = (total_score / max_total_score) * 100
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            "validation_timestamp": datetime.now().isoformat(),
            "overall_score": {
                "total_points": f"{total_score}/{max_total_score}",
                "percentage": f"{overall_percentage:.1f}%",
                "grade": self._get_grade(overall_percentage)
            },
            "detailed_scores": {
                "phase_integration": phase_integration,
                "data_compatibility": data_compatibility,
                "monitoring_features": monitoring_features
            },
            "recommendations": self._generate_recommendations(overall_percentage)
        }
        
        # æ‰“å°çµæœ
        self._print_results(report)
        
        return report
    
    def _get_grade(self, percentage: float) -> str:
        """ç²å–è©•ç´š"""
        if percentage >= 95:
            return "A+ (å®Œç¾)"
        elif percentage >= 85:
            return "A (å„ªç§€)"
        elif percentage >= 75:
            return "B+ (è‰¯å¥½)"
        elif percentage >= 65:
            return "B (å¯æ¥å—)"
        elif percentage >= 55:
            return "C (éœ€æ”¹é€²)"
        else:
            return "D (éœ€é‡æ§‹)"
    
    def _generate_recommendations(self, overall_percentage) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        if overall_percentage >= 90:
            return ["é…ç½®å“è³ªå„ªç§€ï¼Œå»ºè­°ç¶­æŒç¾ç‹€ä¸¦ç¹¼çºŒä¸‹ä¸€çµ„ä»¶"]
        elif overall_percentage >= 80:
            return ["é…ç½®è‰¯å¥½ï¼Œå¯é€²è¡Œå°å¹…å„ªåŒ–", "å»ºè­°ç¹¼çºŒä¸‹ä¸€çµ„ä»¶é©—è­‰"]
        elif overall_percentage >= 70:
            return ["é…ç½®å¯æ¥å—ï¼Œå»ºè­°é€²è¡Œé©åº¦å„ªåŒ–", "é‡é»é—œæ³¨ä½åˆ†é …ç›®"]
        else:
            return ["é…ç½®éœ€è¦é‡å¤§æ”¹é€²", "å»ºè­°å„ªåŒ–å¾Œå†ç¹¼çºŒ", "é‡æ§‹ä½åˆ†çµ„ä»¶"]
    
    def _print_results(self, report: Dict):
        """æ‰“å°çµæœ"""
        print(f"\nğŸ“Š ç¸½é«”è©•åˆ†: {report['overall_score']['percentage']} - {report['overall_score']['grade']}")
        
        print("\nğŸ“‹ è©³ç´°è©•åˆ†:")
        for category, details in report["detailed_scores"].items():
            percentage = details["percentage"]
            status_icon = "âœ…" if percentage >= 80 else "âš ï¸" if percentage >= 60 else "âŒ"
            print(f"  {status_icon} {category}: {percentage:.1f}% ({details['status']})")
            
            for detail_key, detail_value in details["details"].items():
                print(f"    - {detail_key}: {detail_value}")
        
        print("\nğŸ’¡ å»ºè­°:")
        for rec in report["recommendations"]:
            print(f"  â€¢ {rec}")

def main():
    """ä¸»å‡½æ•¸"""
    validator = EPLConfigValidatorFinal()
    report = validator.generate_validation_report()
    
    print(f"\nğŸ¯ EPL Decision History Tracking JSON é©—è­‰å®Œæˆ")
    print(f"ğŸ“Š æœ€çµ‚è©•åˆ†: {report['overall_score']['percentage']}")

if __name__ == "__main__":
    main()
