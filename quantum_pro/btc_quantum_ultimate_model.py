#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BTC é‡å­çµ‚æ¥µæ¨¡å‹ - æ•´åˆåˆ° Trading X é‡å­ç³»çµ±
========================================

é€™å€‹æ¨¡çµ„æ•´åˆäº†æ‚¨æä¾›çš„ BTC_Quantum_Ultimate_Model.py çš„æ ¸å¿ƒé‡å­é›»è·¯åŠŸèƒ½ï¼Œ
ä¸¦èˆ‡ç¾æœ‰çš„ Trading X é‡å­ç³»çµ±å®Œç¾æ•´åˆã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- é‡å­ç‰¹å¾µç·¨ç¢¼ (angle, amplitude, multi-scale)
- é‡å­é›»è·¯åƒæ•¸åŒ– ansatz
- æ™‚é–“æ¼”åŒ–èˆ‡ Hamiltonian æ˜ å°„
- å™ªè²æ¨¡å‹èˆ‡çœŸæ©Ÿæ”¯æ´
- è®Šåˆ†è¨“ç·´å™¨ (SPSA, COBYLA)
- å›æ¸¬æ¨¡çµ„

æ•´åˆç‰¹æ€§ï¼š
- èˆ‡ regime_hmm_quantum.py çš„å³æ™‚æ•¸æ“šæµæ•´åˆ
- èˆ‡ quantum_decision_optimizer.py çš„æ±ºç­–å¼•æ“æ•´åˆ
- æ”¯æ´ Trading X ä¿¡è™Ÿè¼¸å‡ºæ ¼å¼

ä½œè€…: Trading X Quantum Team
ç‰ˆæœ¬: 1.0 - Trading X æ•´åˆç‰ˆ
"""

import datetime
from datetime import timedelta
import json
import logging
import math
import os
import pickle
import sys
import time
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ğŸ”® é‡å­ç´šå€å¡Šéˆæ­·å²æ•¸æ“šæ’·å–å™¨ - å¾çœŸå¯¦å‰µä¸–é–‹å§‹
from blockchain_unlimited_extractor import QuantumBlockchainExtractor, ProductionConfig

# Qiskit é‡å­è¨ˆç®—
try:
    from qiskit import ClassicalRegister, QuantumCircuit, transpile
    from qiskit.circuit import ParameterVector
    try:
        from qiskit import Aer
    except ImportError:
        try:
            from qiskit_aer import Aer
        except ImportError:
            Aer = None
    
    try:
        from qiskit.providers.aer.noise import (
            NoiseModel,
            depolarizing_error,
            thermal_relaxation_error,
        )
    except ImportError:
        try:
            from qiskit_aer.noise import (
                NoiseModel,
                depolarizing_error,
                thermal_relaxation_error,
            )
        except ImportError:
            NoiseModel = None
            depolarizing_error = None
            thermal_relaxation_error = None
    
    QISKIT_AVAILABLE = True
    QUANTUM_LIBS_AVAILABLE = True
except ImportError:
    QISKIT_AVAILABLE = False
    QUANTUM_LIBS_AVAILABLE = False
    print("âš ï¸ Qiskit æœªå®‰è£ï¼Œé‡å­é›»è·¯åŠŸèƒ½å°‡è¢«ç¦ç”¨")

# Progress bar
try:
    from tqdm import tqdm
except ImportError:
    # Fallback é€²åº¦æ¢
    def tqdm(iterable, **kwargs):
        return iterable

# Trading X æ•´åˆ
try:
    import os

    # æ•´åˆ X è³‡æ–™å¤¾çš„å€å¡Šéˆä¸»æ± æ•¸æ“šæº
    import sys

    # from .quantum_decision_optimizer import ProductionQuantumConfig  # å·²åˆªé™¤
    from .regime_hmm_quantum import TradingXä¿¡è™Ÿ, å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨
    sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'X'))
    from binance_data_connector import BinanceDataConnector
    TRADING_X_AVAILABLE = True
except ImportError:
    try:
        import os

        # æ•´åˆ X è³‡æ–™å¤¾çš„å€å¡Šéˆä¸»æ± æ•¸æ“šæº
        import sys

        # from quantum_decision_optimizer import ProductionQuantumConfig  # å·²åˆªé™¤
        from regime_hmm_quantum import TradingXä¿¡è™Ÿ, å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'X'))
        from binance_data_connector import BinanceDataConnector
        TRADING_X_AVAILABLE = True
    except ImportError:
        print("âš ï¸ Trading X æ¨¡çµ„æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç¨ç«‹æ¨¡å¼")
        å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨ = None
        TradingXä¿¡è™Ÿ = None
        # ProductionQuantumConfig = None  # å·²åˆªé™¤
        BinanceDataConnector = None
        TRADING_X_AVAILABLE = False

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')
logger = logging.getLogger('BTCQuantumUltimate')

# ---------------------------
# CONFIG: é‡å­æ¨¡å‹é…ç½®
# ---------------------------
QUANTUM_CONFIG = {
    'N_FEATURE_QUBITS': 6,
    'N_READOUT': 3,  # bear/side/bull
    'N_ANSATZ_LAYERS': 3,
    'ENCODING': 'multi-scale',  # 'angle' | 'amplitude' | 'multi-scale'
    'USE_STATEVECTOR': False,
    'SHOTS': 2048,
    'SPSA_ITER': 120,
    'SPSA_SETTINGS': {'a': 0.4, 'c': 0.15, 'A': 20, 'alpha': 0.602, 'gamma': 0.101},
    'NOISE_MODEL': True,
    'DEPOLARIZING_PROB': 0.002,
    'THERMAL_PARAMS': {'T1': 50e3, 'T2': 70e3, 'time': 50},
    'LOOKBACK': 30,
    'AHEAD': 3,
    'BULL_THRESHOLD': 0.02,
    'BEAR_THRESHOLD': -0.02,
    # ä¸ƒå¤§å¹£ç¨®å€å¡Šéˆä¸»æ± é…ç½®
    'BLOCKCHAIN_SYMBOLS': ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
}

# ---------------------------
# é‡å­é›»è·¯å»ºæ§‹å‡½æ•¸
# ---------------------------

def angle_encoding(qc, qubit_indices: List[int], features: np.ndarray, scale=1.0):
    """è§’åº¦ç·¨ç¢¼é‡å­ç‰¹å¾µï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    for i, q in enumerate(qubit_indices):
        if i < len(features):
            angle = float(features[i]) * scale
            qc.ry(angle, q)

def amplitude_encoding(qc, qubit_indices: List[int], features: np.ndarray):
    """æŒ¯å¹…ç·¨ç¢¼é‡å­ç‰¹å¾µï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    
    vec = np.zeros(2 ** len(qubit_indices))
    vec[:min(len(features), len(vec))] = features[:len(vec)]
    norm = np.linalg.norm(vec)
    if norm > 1e-12:
        vec = vec / norm
    qc.initialize(vec, qubit_indices)

def multi_scale_encoding(qc, qubit_indices: List[int], features: np.ndarray):
    """å¤šå°ºåº¦ç·¨ç¢¼é‡å­ç‰¹å¾µï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    
    n_qubits = len(qubit_indices)
    if n_qubits < 2:
        angle_encoding(qc, qubit_indices, features)
        return
    
    # åˆ†çµ„ç·¨ç¢¼ï¼šçŸ­æœŸã€ä¸­æœŸã€é•·æœŸç‰¹å¾µ
    group_size = n_qubits // 3
    for i, start_idx in enumerate([0, group_size, 2 * group_size]):
        end_idx = start_idx + group_size if i < 2 else n_qubits
        group_qubits = qubit_indices[start_idx:end_idx]
        group_features = features[i * len(group_qubits):(i + 1) * len(group_qubits)]
        
        if len(group_features) > 0:
            angle_encoding(qc, group_qubits, group_features, scale=0.5 * (i + 1))

def entangle_chain(qc, qubits: List[int]):
    """éˆå¼ç³¾çºï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    for i in range(len(qubits) - 1):
        qc.cx(qubits[i], qubits[i + 1])

def entangle_star(qc, qubits: List[int]):
    """æ˜Ÿå½¢ç³¾çºï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    if len(qubits) < 2:
        return
    center = qubits[0]
    for q in qubits[1:]:
        qc.cx(center, q)

def build_param_ansatz(n_qubits: int, n_layers: int, prefix='theta') -> Tuple[Any, Any]:
    """æ§‹å»ºåƒæ•¸åŒ– ansatzï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE:
        return None, None
    
    pcount = n_layers * n_qubits * 2
    params = ParameterVector(prefix, length=pcount)
    qc = QuantumCircuit(n_qubits)
    
    idx = 0
    for layer in range(n_layers):
        # å–®é‡å­ä½æ—‹è½‰
        for q in range(n_qubits):
            qc.ry(params[idx], q)
            idx += 1
            qc.rz(params[idx], q)
            idx += 1
        
        # ç³¾çºå±¤
        if layer < n_layers - 1:
            entangle_chain(qc, list(range(n_qubits)))
    
    return qc, params

def apply_zz_interaction(qc, q1: int, q2: int, theta: float):
    """æ‡‰ç”¨ ZZ ç›¸äº’ä½œç”¨ï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    qc.cx(q1, q2)
    qc.rz(2 * theta, q2)
    qc.cx(q1, q2)

def apply_time_evolution(qc, feature_qubits: List[int], h: np.ndarray, J: np.ndarray, dt: float, trotter_steps: int = 1):
    """æ‡‰ç”¨æ™‚é–“æ¼”åŒ–ï¼ˆå…¼å®¹ Qiskit ä¸å¯ç”¨æƒ…æ³ï¼‰"""
    if not QUANTUM_LIBS_AVAILABLE or qc is None:
        return
    n = len(feature_qubits)
    
    for _ in range(trotter_steps):
        # å–®é«”é …æ¼”åŒ–
        for i in range(n):
            if i < len(h):
                qc.rz(2 * h[i] * dt, feature_qubits[i])
        
        # ç›¸äº’ä½œç”¨é …æ¼”åŒ–
        for i in range(n):
            for j in range(i + 1, min(n, len(h))):
                if abs(J[i, j]) > 1e-12:
                    apply_zz_interaction(qc, feature_qubits[i], feature_qubits[j], J[i, j] * dt)

# ---------------------------
# ç‰¹å¾µåˆ° Hamiltonian æ˜ å°„
# ---------------------------

def feature_to_hJ_advanced(feature_vec: np.ndarray, n_qubits: int, mapping_mode: str = 'hybrid') -> Tuple[np.ndarray, np.ndarray]:
    """é€²éšç‰¹å¾µåˆ° Hamiltonian æ˜ å°„"""
    v = np.zeros(n_qubits)
    v[:min(len(feature_vec), n_qubits)] = feature_vec[:n_qubits]
    
    # æ­£è¦åŒ–
    norm = np.linalg.norm(v)
    if norm > 1e-12:
        v = v / norm
    
    # h: ç·šæ€§ + éç·šæ€§è®Šæ›
    h = 0.6 * v + 0.4 * np.tanh(v)
    
    # J: å¤šå°ºåº¦å¤–ç© + è·é›¢è¡°æ¸›
    J = np.outer(v, v) * 0.25
    
    # è·é›¢è¡°æ¸›ï¼ˆé‡å­ä½ç´¢å¼•ä½œç‚ºé »ç‡å¸¶ï¼‰
    for i in range(n_qubits):
        for j in range(n_qubits):
            dist = abs(i - j)
            J[i, j] *= math.exp(-0.5 * dist)
    
    np.fill_diagonal(J, 0.0)
    return h, J

# ---------------------------
# é‡å­æ¸¬é‡èˆ‡è©•ä¼°
# ---------------------------

def statevector_expectation_z(statevector: np.ndarray, n_qubits: int, target: int) -> float:
    """è¨ˆç®— Z ç®—å­æœŸæœ›å€¼"""
    exp = 0.0
    dim = len(statevector)
    
    for k in range(dim):
        amp = statevector[k]
        prob = np.abs(amp) ** 2
        bit = (k >> (n_qubits - 1 - target)) & 1
        exp += prob * (1.0 if bit == 0 else -1.0)
    
    return exp

def softmax(x: np.ndarray) -> np.ndarray:
    """è»Ÿæœ€å¤§åŒ–å‡½æ•¸"""
    ex = np.exp(x - np.max(x))
    return ex / (np.sum(ex) + 1e-12)

# ---------------------------
# é‡å­é›»è·¯è©•ä¼°ä¸»å‡½æ•¸
# ---------------------------

def evaluate_quantum_circuit(theta: np.ndarray, feature_vec: np.ndarray, h: np.ndarray, J: np.ndarray, 
                            n_feature_qubits: int, n_readout: int, n_ansatz_layers: int, 
                            encoding: str, use_statevector: bool, shots: int, 
                            noise_model = None, quantum_backend = None) -> Tuple[np.ndarray, np.ndarray]:
    """è©•ä¼°çœŸå¯¦é‡å­é›»è·¯ - å¼·åˆ¶ä½¿ç”¨é‡å­å¾Œç«¯"""
    
    if not QUANTUM_LIBS_AVAILABLE:
        raise RuntimeError("âŒ é‡å­è¨ˆç®—åº«æœªå®‰è£ - æ­¤ç³»çµ±éœ€è¦çœŸå¯¦é‡å­è¨ˆç®—èƒ½åŠ›")
    
    if quantum_backend is None:
        raise RuntimeError("âŒ æœªæŒ‡å®šé‡å­å¾Œç«¯ - å¿…é ˆä½¿ç”¨çœŸå¯¦é‡å­ç¡¬é«”æˆ–é«˜ä¿çœŸåº¦å™ªè²æ¨¡æ“¬å™¨")
    
    try:
        total_qubits = n_feature_qubits + n_readout
        feat_idx = list(range(n_feature_qubits))
        read_idx = list(range(n_feature_qubits, total_qubits))
        
        qc = QuantumCircuit(total_qubits)
        
        # ç‰¹å¾µç·¨ç¢¼
        if encoding == 'angle':
            f = np.zeros(n_feature_qubits)
            f[:len(feature_vec)] = feature_vec[:n_feature_qubits]
            angle_encoding(qc, feat_idx, f, scale=1.0)
        elif encoding == 'amplitude':
            amplitude_encoding(qc, feat_idx, feature_vec)
        elif encoding == 'multi-scale':
            multi_scale_encoding(qc, feat_idx, feature_vec)
        
        # æ™‚é–“æ¼”åŒ–
        if len(h) >= n_feature_qubits and J.shape[0] >= n_feature_qubits:
            apply_time_evolution(qc, feat_idx, h[:n_feature_qubits], J[:n_feature_qubits, :n_feature_qubits], dt=0.1)
        
        # åƒæ•¸åŒ– ansatz
        ansatz, params = build_param_ansatz(n_readout, n_ansatz_layers)
        if ansatz is not None and params is not None:
            try:
                # æ–°ç‰ˆ Qiskit çš„åƒæ•¸ç¶å®šæ–¹å¼
                param_dict = {params[i]: theta[i] if i < len(theta) else 0.0 for i in range(len(params))}
                
                # æª¢æŸ¥æ˜¯å¦æœ‰ assign_parameters æ–¹æ³•ï¼ˆæ–°ç‰ˆï¼‰
                if hasattr(ansatz, 'assign_parameters'):
                    bound_ansatz = ansatz.assign_parameters(param_dict)
                elif hasattr(ansatz, 'bind_parameters'):
                    bound_ansatz = ansatz.bind_parameters(param_dict)
                else:
                    # å¦‚æœéƒ½æ²’æœ‰ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ ansatz
                    bound_ansatz = ansatz
                
                # å°‡ ansatz æ·»åŠ åˆ°ä¸»é›»è·¯
                if hasattr(qc, 'compose'):
                    qc = qc.compose(bound_ansatz, qubits=list(range(n_readout)))
                else:
                    # èˆŠç‰ˆæœ¬çš„æ·»åŠ æ–¹å¼
                    qc += bound_ansatz
                    
            except Exception as e:
                logger.warning(f"åƒæ•¸ç¶å®šå¤±æ•—ï¼Œä½¿ç”¨é»˜èª ansatz: {e}")
                # ç°¡å–®çš„é»˜èª ansatz
                for q in range(n_readout):
                    qc.ry(0.1, q)
                    qc.rz(0.1, q)
        
        # æ¸¬é‡
        if use_statevector:
            # é«˜ä¿çœŸåº¦ç‹€æ…‹å‘é‡è¨ˆç®—
            if not hasattr(quantum_backend, 'name') or 'statevector' not in str(quantum_backend.name):
                raise RuntimeError("âŒ ç‹€æ…‹å‘é‡æ¨¡å¼éœ€è¦æ”¯æ´ç‹€æ…‹å‘é‡çš„é‡å­å¾Œç«¯")
            
            transpiled_qc = transpile(qc, quantum_backend, optimization_level=3)
            job = quantum_backend.run(transpiled_qc, shots=1)
            result = job.result()
            statevector = result.get_statevector()
            
            expectations = []
            for i in range(n_readout):
                exp_val = statevector_expectation_z(statevector, total_qubits, n_feature_qubits + i)
                expectations.append(exp_val)
            
            return np.array(expectations), np.array([1.0])
        else:
            # çœŸå¯¦é‡å­æ¸¬é‡ï¼ˆåŒ…å«å™ªè²ï¼‰
            qc.add_register(ClassicalRegister(n_readout))
            for i, q in enumerate(read_idx):
                qc.measure(q, i)
            
            # é‡å­é›»è·¯å„ªåŒ–ç·¨è­¯
            transpiled_qc = transpile(qc, quantum_backend, optimization_level=3)
            
            # åŸ·è¡ŒçœŸå¯¦é‡å­è¨ˆç®—
            if noise_model:
                job = quantum_backend.run(transpiled_qc, shots=shots, noise_model=noise_model)
            else:
                job = quantum_backend.run(transpiled_qc, shots=shots)
            
            result = job.result()
            counts = result.get_counts()
            
            # è™•ç†çœŸå¯¦é‡å­æ¸¬é‡çµæœ
            expectations = np.zeros(n_readout)
            total_shots = sum(counts.values())
            
            if total_shots == 0:
                raise RuntimeError("âŒ é‡å­æ¸¬é‡å¤±æ•— - æœªç²å¾—æœ‰æ•ˆæ¸¬é‡çµæœ")
            
            for bitstring, count in counts.items():
                prob = count / total_shots
                for i in range(min(n_readout, len(bitstring))):
                    bit = int(bitstring[-(i+1)])  # å¾å³åˆ°å·¦è®€å–
                    expectations[i] += prob * (1.0 if bit == 0 else -1.0)
            
            return expectations, np.array([total_shots])
    
    except Exception as e:
        logger.error(f"âŒ çœŸå¯¦é‡å­é›»è·¯åŸ·è¡Œå¤±æ•—: {e}")
        raise RuntimeError(f"é‡å­è¨ˆç®—åŸ·è¡Œå¤±æ•—: {e}")

# ---------------------------
# çœŸå¯¦é‡å­å¾Œç«¯ç®¡ç†å™¨
# ---------------------------

class QuantumBackendManager:
    """çœŸå¯¦é‡å­å¾Œç«¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.backends = {}
        self.current_backend = None
        self.error_mitigation_enabled = True
        
    def initialize_ibm_quantum(self, token: str = None):
        """åˆå§‹åŒ– IBM Quantum å¾Œç«¯"""
        try:
            from qiskit import IBMQ
            
            if token:
                IBMQ.save_account(token, overwrite=True)
            
            provider = IBMQ.load_account()
            
            # ç²å–å¯ç”¨çš„çœŸå¯¦é‡å­è¨­å‚™
            quantum_backends = provider.backends(
                filters=lambda x: x.configuration().n_qubits >= 5 and 
                                x.status().operational == True
            )
            
            if not quantum_backends:
                # å¦‚æœæ²’æœ‰å¯ç”¨çš„çœŸå¯¦è¨­å‚™ï¼Œä½¿ç”¨æœ€é«˜ä¿çœŸåº¦çš„æ¨¡æ“¬å™¨
                backend = provider.get_backend('ibmq_qasm_simulator')
                logger.warning("âš ï¸ æœªæ‰¾åˆ°å¯ç”¨çš„çœŸå¯¦é‡å­è¨­å‚™ï¼Œä½¿ç”¨é«˜ä¿çœŸåº¦æ¨¡æ“¬å™¨")
            else:
                # é¸æ“‡é‡å­ä½æ•¸æœ€å¤šä¸”éšŠåˆ—æœ€çŸ­çš„è¨­å‚™
                backend = min(quantum_backends, key=lambda x: x.status().pending_jobs)
                logger.info(f"âœ… å·²é€£æ¥åˆ°çœŸå¯¦é‡å­è¨­å‚™: {backend.name}")
            
            self.backends['ibm'] = backend
            self.current_backend = backend
            return backend
            
        except Exception as e:
            logger.error(f"âŒ IBM Quantum åˆå§‹åŒ–å¤±æ•—: {e}")
            raise RuntimeError(f"ç„¡æ³•åˆå§‹åŒ– IBM Quantum å¾Œç«¯: {e}")
    
    def initialize_local_high_fidelity(self):
        """åˆå§‹åŒ–æœ¬åœ°é«˜ä¿çœŸåº¦é‡å­æ¨¡æ“¬å™¨"""
        if not QUANTUM_LIBS_AVAILABLE or Aer is None:
            raise RuntimeError("âŒ Qiskit Aer æœªå®‰è£")
        
        # ä½¿ç”¨å¸¶å™ªè²çš„é«˜ä¿çœŸåº¦æ¨¡æ“¬å™¨
        backend = Aer.get_backend('qasm_simulator')
        
        # é…ç½®çœŸå¯¦çš„é‡å­å™ªè²æ¨¡å‹
        noise_model = self._create_realistic_noise_model()
        
        self.backends['local_hf'] = backend
        self.current_backend = backend
        self.noise_model = noise_model
        
        logger.info("âœ… å·²åˆå§‹åŒ–æœ¬åœ°é«˜ä¿çœŸåº¦é‡å­æ¨¡æ“¬å™¨ï¼ˆå«çœŸå¯¦å™ªè²æ¨¡å‹ï¼‰")
        return backend
    
    def _create_realistic_noise_model(self):
        """å‰µå»ºçœŸå¯¦çš„é‡å­å™ªè²æ¨¡å‹"""
        if not NoiseModel:
            return None
        
        noise_model = NoiseModel()
        
        # åŸºæ–¼çœŸå¯¦é‡å­è¨­å‚™çš„éŒ¯èª¤ç‡
        # å–®é‡å­ä½éŒ¯èª¤ - ä½¿ç”¨è¤‡åˆéŒ¯èª¤æ¨¡å‹
        error_1q = depolarizing_error(0.001, 1)  # 0.1% éŒ¯èª¤ç‡
        
        # é›™é‡å­ä½éŒ¯èª¤
        error_2q = depolarizing_error(0.01, 2)   # 1% éŒ¯èª¤ç‡
        
        # ç†±å¼›è±«éŒ¯èª¤ - èˆ‡å»æ¥µåŒ–éŒ¯èª¤æ•´åˆï¼Œé¿å…é‡è¤‡
        if thermal_relaxation_error:
            try:
                thermal_error = thermal_relaxation_error(
                    t1=50e3,  # T1 æ™‚é–“ 50å¾®ç§’
                    t2=70e3,  # T2 æ™‚é–“ 70å¾®ç§’  
                    time=50   # é–€æ™‚é–“ 50ç´ç§’
                )
                # å°‡ç†±å¼›è±«éŒ¯èª¤èˆ‡å»æ¥µåŒ–éŒ¯èª¤çµ„åˆ
                combined_error_1q = error_1q.compose(thermal_error)
                noise_model.add_all_qubit_quantum_error(combined_error_1q, ['u1', 'u2', 'u3'])
            except Exception:
                # å¦‚æœçµ„åˆå¤±æ•—ï¼Œåªä½¿ç”¨å»æ¥µåŒ–éŒ¯èª¤
                noise_model.add_all_qubit_quantum_error(error_1q, ['u1', 'u2', 'u3'])
        else:
            # åªæ·»åŠ å»æ¥µåŒ–éŒ¯èª¤
            noise_model.add_all_qubit_quantum_error(error_1q, ['u1', 'u2', 'u3'])
        
        # æ·»åŠ é›™é‡å­ä½éŒ¯èª¤
        noise_model.add_all_qubit_quantum_error(error_2q, ['cx'])
        
        return noise_model
    
    def get_current_backend(self):
        """ç²å–ç•¶å‰é‡å­å¾Œç«¯"""
        if self.current_backend is None:
            raise RuntimeError("âŒ æœªåˆå§‹åŒ–ä»»ä½•é‡å­å¾Œç«¯")
        return self.current_backend
    
    def enable_error_mitigation(self):
        """å•Ÿç”¨é‡å­éŒ¯èª¤ç·©è§£"""
        self.error_mitigation_enabled = True
        logger.info("âœ… å·²å•Ÿç”¨é‡å­éŒ¯èª¤ç·©è§£")
    
    def apply_error_mitigation(self, circuit, backend, shots: int):
        """æ‡‰ç”¨é‡å­éŒ¯èª¤ç·©è§£æŠ€è¡“"""
        if not self.error_mitigation_enabled:
            return circuit, shots
        
        # é›¶å™ªè²å¤–æ¨ï¼ˆZero Noise Extrapolationï¼‰
        noise_factors = [1.0, 1.5, 2.0]  # å™ªè²æ”¾å¤§å› å­
        extrapolated_circuits = []
        
        for factor in noise_factors:
            # å‰µå»ºå™ªè²æ”¾å¤§çš„é›»è·¯
            mitigated_circuit = self._amplify_noise(circuit, factor)
            extrapolated_circuits.append(mitigated_circuit)
        
        # è®€å‡ºéŒ¯èª¤ç·©è§£
        calibration_circuits = self._create_readout_calibration_circuits(backend)
        
        return extrapolated_circuits, shots, calibration_circuits
    
    def _amplify_noise(self, circuit, factor: float):
        """å™ªè²æ”¾å¤§ç”¨æ–¼é›¶å™ªè²å¤–æ¨"""
        # é€šéæ’å…¥é¡å¤–çš„å–®ä½é–€ä¾†æ”¾å¤§å™ªè²
        amplified_circuit = circuit.copy()
        
        if factor > 1.0:
            # åœ¨æ¯å€‹é–€å¾Œæ’å…¥æ†ç­‰é–€å°ä¾†æ”¾å¤§å™ªè²
            identity_pairs = int((factor - 1.0) * 2)
            for _ in range(identity_pairs):
                for qubit in range(circuit.num_qubits):
                    amplified_circuit.x(qubit)
                    amplified_circuit.x(qubit)  # Xâ€ X = I
        
        return amplified_circuit
    
    def _create_readout_calibration_circuits(self, backend):
        """å‰µå»ºè®€å‡ºæ ¡æº–é›»è·¯"""
        calibration_circuits = []
        n_qubits = min(backend.configuration().n_qubits, 10)  # é™åˆ¶é‡å­ä½æ•¸
        
        # |0âŸ© ç‹€æ…‹æ ¡æº–
        qc_0 = QuantumCircuit(n_qubits, n_qubits)
        qc_0.measure_all()
        calibration_circuits.append(qc_0)
        
        # |1âŸ© ç‹€æ…‹æ ¡æº–
        qc_1 = QuantumCircuit(n_qubits, n_qubits)
        for i in range(n_qubits):
            qc_1.x(i)
        qc_1.measure_all()
        calibration_circuits.append(qc_1)
        
        return calibration_circuits

# å…¨å±€é‡å­å¾Œç«¯ç®¡ç†å™¨å¯¦ä¾‹
quantum_backend_manager = QuantumBackendManager()

# ---------------------------
# é‡å­å„ªå‹¢é©—è­‰å™¨
# ---------------------------

class QuantumAdvantageValidator:
    """é‡å­å„ªå‹¢é©—è­‰å™¨ - é©—è­‰é‡å­è¨ˆç®—ç›¸å°æ–¼å¤å…¸è¨ˆç®—çš„å„ªå‹¢"""
    
    def __init__(self):
        self.benchmark_results = {}
        
    def validate_quantum_advantage(self, X_sample: np.ndarray, quantum_backend) -> float:
        """é©—è­‰é‡å­å„ªå‹¢
        
        Returns:
            float: é‡å­å„ªå‹¢åˆ†æ•¸ (0-1, è¶Šé«˜è¡¨ç¤ºé‡å­å„ªå‹¢è¶Šæ˜é¡¯)
        """
        logger.info("ğŸ”¬ é–‹å§‹é‡å­å„ªå‹¢é©—è­‰...")
        
        try:
            # 1. é‡å­ç›¸å¹²æ€§æ¸¬è©¦
            coherence_score = self._test_quantum_coherence(quantum_backend)
            
            # 2. é‡å­ç³¾çºæ¸¬è©¦
            entanglement_score = self._test_quantum_entanglement(quantum_backend)
            
            # 3. é‡å­ä¸¦è¡Œæ€§æ¸¬è©¦
            parallelism_score = self._test_quantum_parallelism(X_sample, quantum_backend)
            
            # 4. ç¶œåˆé‡å­å„ªå‹¢åˆ†æ•¸
            quantum_advantage_score = (
                0.3 * coherence_score + 
                0.4 * entanglement_score + 
                0.3 * parallelism_score
            )
            
            self.benchmark_results = {
                'coherence_score': coherence_score,
                'entanglement_score': entanglement_score,
                'parallelism_score': parallelism_score,
                'total_score': quantum_advantage_score,
                'backend_name': getattr(quantum_backend, 'name', str(quantum_backend))
            }
            
            logger.info(f"âœ… é‡å­å„ªå‹¢é©—è­‰å®Œæˆ:")
            logger.info(f"   ç›¸å¹²æ€§åˆ†æ•¸: {coherence_score:.3f}")
            logger.info(f"   ç³¾çºåˆ†æ•¸: {entanglement_score:.3f}")
            logger.info(f"   ä¸¦è¡Œæ€§åˆ†æ•¸: {parallelism_score:.3f}")
            logger.info(f"   ç¸½é«”é‡å­å„ªå‹¢: {quantum_advantage_score:.3f}")
            
            return quantum_advantage_score
            
        except Exception as e:
            logger.error(f"âŒ é‡å­å„ªå‹¢é©—è­‰å¤±æ•—: {e}")
            return 0.0
    
    def _test_quantum_coherence(self, backend) -> float:
        """æ¸¬è©¦é‡å­ç›¸å¹²æ€§"""
        try:
            # å‰µå»º GHZ æ…‹æ¸¬è©¦ç›¸å¹²æ€§
            n_qubits = min(3, backend.configuration().n_qubits)
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # å‰µå»º GHZ æ…‹: (|000âŸ© + |111âŸ©)/âˆš2
            qc.h(0)
            for i in range(1, n_qubits):
                qc.cx(0, i)
            
            qc.measure_all()
            
            # åŸ·è¡Œå¤šæ¬¡æ¸¬é‡
            job = backend.run(qc, shots=1000)
            result = job.result()
            counts = result.get_counts()
            
            # è¨ˆç®—ç›¸å¹²æ€§åˆ†æ•¸
            total_shots = sum(counts.values())
            coherent_states = counts.get('0' * n_qubits, 0) + counts.get('1' * n_qubits, 0)
            coherence_score = coherent_states / total_shots
            
            return coherence_score
            
        except Exception as e:
            logger.error(f"ç›¸å¹²æ€§æ¸¬è©¦å¤±æ•—: {e}")
            return 0.0
    
    def _test_quantum_entanglement(self, backend) -> float:
        """æ¸¬è©¦é‡å­ç³¾çº"""
        try:
            # Bell æ…‹ç³¾çºæ¸¬è©¦
            qc = QuantumCircuit(2, 2)
            
            # å‰µå»º Bell æ…‹: (|00âŸ© + |11âŸ©)/âˆš2
            qc.h(0)
            qc.cx(0, 1)
            qc.measure_all()
            
            job = backend.run(qc, shots=1000)
            result = job.result()
            counts = result.get_counts()
            
            # è¨ˆç®—ç³¾çºåˆ†æ•¸ï¼ˆBell æ…‹æ‡‰è©²åªæœ‰ |00âŸ© å’Œ |11âŸ©ï¼‰
            total_shots = sum(counts.values())
            entangled_states = counts.get('00', 0) + counts.get('11', 0)
            entanglement_score = entangled_states / total_shots
            
            return entanglement_score
            
        except Exception as e:
            logger.error(f"ç³¾çºæ¸¬è©¦å¤±æ•—: {e}")
            return 0.0
    
    def _test_quantum_parallelism(self, X_sample: np.ndarray, backend) -> float:
        """æ¸¬è©¦é‡å­ä¸¦è¡Œæ€§ï¼ˆä½¿ç”¨ Grover's-like ç®—æ³•ï¼‰"""
        try:
            # ç°¡åŒ–çš„é‡å­ä¸¦è¡Œæ€§æ¸¬è©¦
            n_qubits = min(4, backend.configuration().n_qubits, len(X_sample))
            qc = QuantumCircuit(n_qubits, n_qubits)
            
            # å‰µå»ºå‡å‹»ç–ŠåŠ æ…‹
            for i in range(n_qubits):
                qc.h(i)
            
            # æ‡‰ç”¨ç›¸ä½ç¿»è½‰ï¼ˆæ¨¡æ“¬é‡å­ä¸¦è¡Œæœç´¢ï¼‰
            # åŸºæ–¼è¼¸å…¥æ•¸æ“šçš„ç‰¹å®šæ¨¡å¼
            target_pattern = np.mean(X_sample[:n_qubits]) > 0
            if target_pattern:
                qc.cz(0, 1) if n_qubits > 1 else qc.z(0)
            
            # åæ¼”é—œæ–¼å¹³å‡å€¼
            for i in range(n_qubits):
                qc.h(i)
                qc.x(i)
            
            if n_qubits > 1:
                qc.cz(0, 1)
            
            for i in range(n_qubits):
                qc.x(i)
                qc.h(i)
            
            qc.measure_all()
            
            job = backend.run(qc, shots=1000)
            result = job.result()
            counts = result.get_counts()
            
            # è©•ä¼°æœç´¢æ•ˆæœ
            max_count = max(counts.values()) if counts else 0
            total_shots = sum(counts.values()) if counts else 1
            parallelism_score = max_count / total_shots
            
            return parallelism_score
            
        except Exception as e:
            logger.error(f"ä¸¦è¡Œæ€§æ¸¬è©¦å¤±æ•—: {e}")
            return 0.0

# ---------------------------
# BTC é‡å­çµ‚æ¥µæ¨¡å‹é¡
# ---------------------------

class BTCQuantumUltimateModel:
    """BTC é‡å­çµ‚æ¥µæ¨¡å‹ - çœŸå¯¦é‡å­è¨ˆç®—ç‰ˆæœ¬"""
    
    def __init__(self, config: Dict[str, Any] = None, quantum_backend_type: str = 'ibm'):
        self.config = config or QUANTUM_CONFIG.copy()
        self.scaler = StandardScaler()
        self.pca = None
        self.theta = None
        self.training_history = []
        self.is_fitted = False
        
        # çœŸå¯¦é‡å­å¾Œç«¯åˆå§‹åŒ–
        self.quantum_backend_manager = quantum_backend_manager
        self.quantum_backend = None
        self._initialize_quantum_backend(quantum_backend_type)
        
        # Trading X æ•´åˆ
        self.data_collector = None
        self.signal_history = []
        
        # ğŸ”® é‡å­ç´šå€å¡Šéˆæ•¸æ“šæ’·å–å™¨
        self.quantum_extractor = None  # å°‡åœ¨éœ€è¦æ™‚åˆå§‹åŒ–
        
        # å‚³çµ±å€å¡Šéˆä¸»æ± æ•¸æ“šé€£æ¥å™¨ï¼ˆå‚™ç”¨ï¼‰
        self.blockchain_connector = None
        if TRADING_X_AVAILABLE and BinanceDataConnector:
            self.blockchain_connector = BinanceDataConnector()
        
        # é‡å­å„ªå‹¢é©—è­‰å™¨
        self.quantum_advantage_validator = QuantumAdvantageValidator()
        
        logger.info(f"ğŸ”® BTC é‡å­çµ‚æ¥µæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ˆçœŸå¯¦é‡å­ç‰ˆæœ¬ï¼‰")
        logger.info(f"   ç‰¹å¾µé‡å­ä½: {self.config['N_FEATURE_QUBITS']}")
        logger.info(f"   ç·¨ç¢¼æ–¹å¼: {self.config['ENCODING']}")
        logger.info(f"   é‡å­å¾Œç«¯: {getattr(self.quantum_backend, 'name', 'qasm_simulator') if self.quantum_backend else 'æœªåˆå§‹åŒ–'}")
        logger.info(f"   éŒ¯èª¤ç·©è§£: {'âœ… å·²å•Ÿç”¨' if self.quantum_backend_manager.error_mitigation_enabled else 'âŒ æœªå•Ÿç”¨'}")
        if self.blockchain_connector:
            logger.info(f"   æ”¯æ´å¹£ç¨®: {', '.join(self.config['BLOCKCHAIN_SYMBOLS'])}")
    
    def _initialize_quantum_backend(self, backend_type: str):
        """åˆå§‹åŒ–çœŸå¯¦é‡å­å¾Œç«¯"""
        try:
            if backend_type == 'ibm':
                # å˜—è©¦å¾ç’°å¢ƒè®Šæ•¸ç²å– IBM Quantum token
                import os
                ibm_token = os.getenv('IBM_QUANTUM_TOKEN')
                if ibm_token:
                    self.quantum_backend = self.quantum_backend_manager.initialize_ibm_quantum(ibm_token)
                else:
                    logger.warning("âš ï¸ IBM_QUANTUM_TOKEN ç’°å¢ƒè®Šæ•¸æœªè¨­ç½®ï¼Œå˜—è©¦æœ¬åœ°é«˜ä¿çœŸåº¦æ¨¡æ“¬å™¨")
                    self.quantum_backend = self.quantum_backend_manager.initialize_local_high_fidelity()
            else:
                self.quantum_backend = self.quantum_backend_manager.initialize_local_high_fidelity()
            
            # å•Ÿç”¨é‡å­éŒ¯èª¤ç·©è§£
            self.quantum_backend_manager.enable_error_mitigation()
            
        except Exception as e:
            logger.error(f"âŒ é‡å­å¾Œç«¯åˆå§‹åŒ–å¤±æ•—: {e}")
            raise RuntimeError(f"ç„¡æ³•åˆå§‹åŒ–é‡å­å¾Œç«¯: {e}")
    
    async def _initialize_quantum_extractor(self):
        """åˆå§‹åŒ–é‡å­ç´šæ•¸æ“šæ’·å–å™¨"""
        if self.quantum_extractor is None:
            self.quantum_extractor = QuantumBlockchainExtractor()
            await self.quantum_extractor.initialize()
            logger.info("âœ… é‡å­ç´šå€å¡Šéˆæ•¸æ“šæ’·å–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def generate_unlimited_market_data(self, symbol: str, timeframe: str = '1d', days_back: int = None) -> pd.DataFrame:
        """
        ğŸ”® å¾é‡å­ç´šæ•¸æ“šæ’·å–å™¨ç²å–ç„¡é™åˆ¶æ­·å²æ•¸æ“š
        æ”¯æ´å¾å‰µä¸–æ—¥æœŸé–‹å§‹çš„å®Œæ•´æ­·å²æ•¸æ“š
        """
        await self._initialize_quantum_extractor()
        
        try:
            # ä½¿ç”¨é‡å­ç´šæ’·å–å™¨ç²å–å®Œæ•´æ­·å²æ•¸æ“š
            config = ProductionConfig()
            end_time = datetime.now()
            
            if days_back:
                start_time = end_time - timedelta(days=days_back)
            else:
                # ä½¿ç”¨çœŸå¯¦å‰µä¸–æ—¥æœŸ
                genesis_dates = config.REAL_GENESIS_DATES
                symbol_key = symbol.replace('USDT', '').upper()
                if symbol_key in genesis_dates:
                    start_time = genesis_dates[symbol_key]
                    logger.info(f"ğŸš€ ä½¿ç”¨çœŸå¯¦å‰µä¸–æ—¥æœŸ: {symbol} å¾ {start_time.strftime('%Y-%m-%d')} é–‹å§‹")
                else:
                    # é»˜èªä½¿ç”¨ BSC éƒ¨ç½²æ—¥æœŸ
                    start_time = config.BSC_DEPLOYMENT_DATES.get(symbol_key, end_time - timedelta(days=365))
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ° {symbol} çš„å‰µä¸–æ—¥æœŸï¼Œä½¿ç”¨ BSC éƒ¨ç½²æ—¥æœŸ")
            
            # ä½¿ç”¨é‡å­ç´šæ•¸æ“šæ’·å–å™¨
            market_data = await self.quantum_extractor.extract_unlimited_historical_data(
                symbol=symbol,
                start_date=start_time,
                end_date=end_time,
                interval=timeframe
            )
            
            if market_data is not None and not market_data.empty:
                logger.info(f"âœ… é‡å­ç´šæ•¸æ“šç²å–æˆåŠŸ: {symbol}")
                logger.info(f"   æ•¸æ“šç¯„åœ: {market_data.index[0]} è‡³ {market_data.index[-1]}")
                logger.info(f"   ç¸½å¤©æ•¸: {len(market_data)} æ¢è¨˜éŒ„")
                return market_data
            else:
                logger.warning(f"âš ï¸ é‡å­ç´šæ•¸æ“šæ’·å–å™¨ç„¡æ•¸æ“šï¼Œå›é€€è‡³å‚³çµ±æ–¹æ³•")
                return await self._fallback_to_traditional_data(symbol, timeframe, days_back or 1000)
                
        except Exception as e:
            logger.error(f"âŒ é‡å­ç´šæ•¸æ“šç²å–å¤±æ•—: {e}")
            logger.info("ğŸ”„ å›é€€è‡³å‚³çµ±å€å¡Šéˆæ•¸æ“šæº...")
            return await self._fallback_to_traditional_data(symbol, timeframe, days_back or 1000)
    
    async def _fallback_to_traditional_data(self, symbol: str, timeframe: str, limit: int) -> pd.DataFrame:
        """å›é€€è‡³å‚³çµ±å€å¡Šéˆæ•¸æ“šæº"""
        if not self.blockchain_connector:
            raise RuntimeError("âŒ ç„¡å¯ç”¨æ•¸æ“šæº - é‡å­ç´šæ’·å–å™¨å’Œå‚³çµ±é€£æ¥å™¨éƒ½ä¸å¯ç”¨")
        
        try:
            market_data = self.blockchain_connector.get_historical_klines(
                symbol=symbol,
                interval=timeframe,
                limit=limit
            )
            
            df = pd.DataFrame(market_data, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['close'] = df['close'].astype(float)
            df.set_index('timestamp', inplace=True)
            
            logger.info(f"âœ… å‚³çµ±æ•¸æ“šç²å–æˆåŠŸ: {symbol} - {len(df)} æ¢è¨˜éŒ„")
            return df[['close']].rename(columns={'close': 'price'})
            
        except Exception as e:
            logger.error(f"âŒ å‚³çµ±æ•¸æ“šç²å–å¤±æ•—: {e}")
            raise RuntimeError(f"æ‰€æœ‰æ•¸æ“šæºéƒ½ç„¡æ³•ç²å–æ•¸æ“š: {e}")
    
    def generate_realistic_market_data(self, symbol: str, timeframe: str = '1m', limit: int = 1000) -> pd.DataFrame:
        """
        ğŸ”® ç”ŸæˆçœŸå¯¦å¸‚å ´æ•¸æ“š - å„ªå…ˆä½¿ç”¨é‡å­ç´šæ’·å–å™¨
        
        æ­¤æ–¹æ³•ä¿æŒåŒæ­¥æ¥å£å…¼å®¹æ€§ï¼Œå…§éƒ¨èª¿ç”¨ç•°æ­¥é‡å­ç´šæ’·å–å™¨
        """
        import asyncio
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°
        try:
            loop = asyncio.get_running_loop()
            # å¦‚æœæœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºä»»å‹™
            task = loop.create_task(self.generate_unlimited_market_data(symbol, timeframe, limit))
            return asyncio.run_coroutine_threadsafe(task, loop).result()
        except RuntimeError:
            # æ²’æœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°ï¼Œç›´æ¥é‹è¡Œ
            return asyncio.run(self.generate_unlimited_market_data(symbol, timeframe, limit))
    
    def generate_realistic_market_data_legacy(self, symbol: str, timeframe: str = '1m', limit: int = 1000) -> pd.DataFrame:
        """å¾çœŸå¯¦å€å¡Šéˆæ•¸æ“šæºç”Ÿæˆå¸‚å ´æ•¸æ“šï¼ˆå‚³çµ±æ–¹æ³• - å·²æ£„ç”¨ï¼‰"""
        if not self.blockchain_connector:
            raise RuntimeError("âŒ å€å¡Šéˆæ•¸æ“šé€£æ¥å™¨æœªåˆå§‹åŒ– - æ­¤ç³»çµ±ä¸ä½¿ç”¨åˆæˆæ•¸æ“š")
        
        try:
            # å¾çœŸå¯¦å¹£å®‰æ•¸æ“šæºç²å–æ•¸æ“š
            market_data = self.blockchain_connector.get_historical_klines(
                symbol=symbol,
                interval=timeframe,
                limit=limit
            )
            
            df = pd.DataFrame(market_data, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_asset_volume', 'number_of_trades',
                'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
            ])
            
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['close'] = df['close'].astype(float)
            
            logger.info(f"âœ… å·²ç²å– {symbol} çœŸå¯¦å¸‚å ´æ•¸æ“š: {len(df)} æ¢è¨˜éŒ„")
            return df[['timestamp', 'close']]
            
        except Exception as e:
            logger.error(f"âŒ ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“šå¤±æ•—: {e}")
            raise RuntimeError(f"ç„¡æ³•ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š: {e}")
    
    def prepare_features_and_labels(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """æº–å‚™ç‰¹å¾µå’Œæ¨™ç±¤"""
        df = df.copy()
        df['logret'] = np.log(df['close']).diff()
        df['ret_ahead'] = df['close'].shift(-self.config['AHEAD']) / df['close'] - 1.0
        
        # å¤šå°ºåº¦ç‰¹å¾µ
        scales = [5, 20, 60]
        feat_list = []
        
        for i in range(len(df)):
            if i < max(scales) or i + self.config['AHEAD'] >= len(df):
                feat_list.append(None)
                continue
            
            features = []
            for s in scales:
                window = df['logret'].iloc[i-s+1:i+1].values
                features.extend([
                    np.nan_to_num(window[-1]),  # æœ€å¾Œæ”¶ç›Šç‡
                    np.nan_to_num(np.std(window)),  # æ³¢å‹•ç‡
                    np.nan_to_num(np.mean(window)),  # å¹³å‡æ”¶ç›Šç‡
                    np.nan_to_num(pd.Series(window).skew()),  # ååº¦
                    np.nan_to_num(pd.Series(window).kurt())   # å³°åº¦
                ])
            
            # é¡å¤–æŠ€è¡“æŒ‡æ¨™
            short = df['logret'].iloc[i-5+1:i+1].values
            med = df['logret'].iloc[i-20+1:i+1].values
            features.append(np.nan_to_num(np.std(short) / (np.std(med) + 1e-8)))
            
            # å ä½ç¬¦ï¼ˆå¯ç”±ç”¨æˆ¶å¡«å…¥å¯¦éš›æŒ‡æ¨™ï¼‰
            features.extend([0.0, 0.0])  # è¨‚å–®ç°¿å¤±è¡¡ã€è³‡é‡‘è²»ç‡
            
            feat_list.append(features)
        
        df['features'] = feat_list
        
        # ç”Ÿæˆæ¨™ç±¤
        labels = []
        for r in df['ret_ahead'].values:
            if np.isnan(r):
                labels.append(None)
                continue
            
            if r >= self.config['BULL_THRESHOLD']:
                labels.append(2)  # ç‰›å¸‚
            elif r <= self.config['BEAR_THRESHOLD']:
                labels.append(0)  # ç†Šå¸‚
            else:
                labels.append(1)  # éœ‡ç›ª
        
        df['label'] = labels
        
        # æ¸…ç†æ•¸æ“š
        df_clean = df.dropna(subset=['features', 'label']).reset_index(drop=True)
        X = np.vstack(df_clean['features'].values)
        y = df_clean['label'].values.astype(int)
        
        return X, y
    
    def preprocess_features(self, X: np.ndarray, fit: bool = True) -> np.ndarray:
        """é è™•ç†ç‰¹å¾µ"""
        if fit:
            X_scaled = self.scaler.fit_transform(X)
            self.pca = PCA(n_components=self.config['N_FEATURE_QUBITS'])
            X_reduced = self.pca.fit_transform(X_scaled)
        else:
            X_scaled = self.scaler.transform(X)
            X_reduced = self.pca.transform(X_scaled)
        
        return X_reduced
    
    def fit(self, X: np.ndarray, y: np.ndarray, verbose: bool = True):
        """è¨“ç·´çœŸå¯¦é‡å­æ¨¡å‹"""
        logger.info("ğŸš€ é–‹å§‹è¨“ç·´ BTC é‡å­çµ‚æ¥µæ¨¡å‹ï¼ˆçœŸå¯¦é‡å­è¨ˆç®—ï¼‰...")
        
        if self.quantum_backend is None:
            raise RuntimeError("âŒ é‡å­å¾Œç«¯æœªåˆå§‹åŒ–")
        
        # é©—è­‰é‡å­å„ªå‹¢
        quantum_advantage_score = self.quantum_advantage_validator.validate_quantum_advantage(
            X[:100], self.quantum_backend  # ä½¿ç”¨å‰100å€‹æ¨£æœ¬é€²è¡Œé©—è­‰
        )
        
        if quantum_advantage_score < 0.1:
            logger.warning(f"âš ï¸ é‡å­å„ªå‹¢è¼ƒä½ (score: {quantum_advantage_score:.3f})ï¼Œä½†ç¹¼çºŒä½¿ç”¨é‡å­è¨ˆç®—")
        
        # é è™•ç†ç‰¹å¾µ
        X_processed = self.preprocess_features(X, fit=True)
        
        # åˆå§‹åŒ–é‡å­åƒæ•¸ï¼ˆä½¿ç”¨é‡å­éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨è€Œéå½éš¨æ©Ÿï¼‰
        n_params = self.config['N_ANSATZ_LAYERS'] * self.config['N_READOUT'] * 2
        self.theta = self._generate_quantum_random_parameters(n_params)
        
        # çœŸå¯¦é‡å­ SPSA è¨“ç·´
        spsa_settings = self.config['SPSA_SETTINGS']
        
        def objective_function(theta_trial):
            total_loss = 0.0
            n_samples = min(50, len(X_processed))  # é™åˆ¶æ¨£æœ¬æ•¸é‡ä»¥æ¸›å°‘é‡å­è¨ˆç®—è² è¼‰
            
            for i in range(n_samples):
                feature_vec = X_processed[i]
                true_label = y[i]
                
                # è¨ˆç®— Hamiltonian
                h, J = feature_to_hJ_advanced(feature_vec, self.config['N_FEATURE_QUBITS'])
                
                # çœŸå¯¦é‡å­é›»è·¯è©•ä¼°
                try:
                    expectations, shots_info = evaluate_quantum_circuit(
                        theta_trial, feature_vec, h, J,
                        self.config['N_FEATURE_QUBITS'], self.config['N_READOUT'], 
                        self.config['N_ANSATZ_LAYERS'], self.config['ENCODING'],
                        self.config['USE_STATEVECTOR'], self.config['SHOTS'],
                        getattr(self.quantum_backend_manager, 'noise_model', None),
                        self.quantum_backend
                    )
                    
                    # è¨ˆç®—äº¤å‰ç†µæå¤±
                    probabilities = softmax(expectations)
                    true_prob = np.zeros(self.config['N_READOUT'])
                    true_prob[true_label] = 1.0
                    
                    loss = -np.sum(true_prob * np.log(probabilities + 1e-12))
                    total_loss += loss
                    
                except Exception as e:
                    logger.error(f"é‡å­é›»è·¯è©•ä¼°å¤±æ•—: {e}")
                    total_loss += 10.0  # æ‡²ç½°å¤±æ•—çš„é‡å­è¨ˆç®—
            
            return total_loss / n_samples
        
        # çœŸå¯¦é‡å­ SPSA å„ªåŒ–å¾ªç’°
        best_theta = self.theta.copy()
        best_loss = float('inf')
        
        a = spsa_settings['a']
        c = spsa_settings['c'] 
        A = spsa_settings['A']
        alpha = spsa_settings['alpha']
        gamma = spsa_settings['gamma']
        
        logger.info("ğŸ”® é–‹å§‹çœŸå¯¦é‡å­ SPSA è¨“ç·´ - è‡ªå‹•æ”¶æ–‚æ¨¡å¼")
        logger.info("âš¡ é‡å­ç³»çµ±å°‡è‡ªå‹•é‹è¡Œç›´åˆ°æ”¶æ–‚ï¼Œç„¡äººç‚ºé™åˆ¶ï¼")
        
        # è‡ªå‹•æ”¶æ–‚åƒæ•¸
        convergence_threshold = 1e-6  # æ”¶æ–‚é–¾å€¼
        patience = 50  # é€£çºŒå¤šå°‘æ¬¡ç„¡æ”¹å–„å¾Œåœæ­¢
        min_iterations = 20  # æœ€å°‘è¿­ä»£æ¬¡æ•¸
        max_iterations = 10000  # é˜²æ­¢ç„¡é™å¾ªç’°çš„ä¸Šé™
        
        no_improvement_count = 0
        previous_loss = float('inf')
        iteration = 0
        
        logger.info("â³ è¨“ç·´ç‹€æ…‹: é‡å­åƒæ•¸è‡ªå‹•å„ªåŒ–ä¸­...")
        
        # è‡ªå‹•æ”¶æ–‚å¾ªç’°
        while True:
            # SPSA åƒæ•¸æ›´æ–°
            ak = a / (A + iteration + 1) ** alpha
            ck = c / (iteration + 1) ** gamma
            
            # ä½¿ç”¨é‡å­éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨ç”Ÿæˆæ“¾å‹•
            delta = self._generate_quantum_bernoulli(len(self.theta))
            
            # å‰å‘å’Œå¾Œå‘è©•ä¼°
            theta_plus = self.theta + ck * delta
            theta_minus = self.theta - ck * delta
            
            try:
                loss_plus = objective_function(theta_plus)
                loss_minus = objective_function(theta_minus)
                
                # SPSA æ¢¯åº¦ä¼°è¨ˆ
                grad_estimate = (loss_plus - loss_minus) / (2 * ck * delta)
                
                # åƒæ•¸æ›´æ–°
                self.theta = self.theta - ak * grad_estimate
                
                # è¨˜éŒ„æœ€ä½³åƒæ•¸
                current_loss = objective_function(self.theta)
                improvement = previous_loss - current_loss
                
                if current_loss < best_loss:
                    best_loss = current_loss
                    best_theta = self.theta.copy()
                    no_improvement_count = 0  # é‡ç½®è¨ˆæ•¸
                else:
                    no_improvement_count += 1
                
                self.training_history.append({
                    'iteration': iteration,
                    'loss': current_loss,
                    'improvement': improvement,
                    'quantum_backend': getattr(self.quantum_backend, 'name', 'qasm_simulator'),
                    'quantum_advantage_score': quantum_advantage_score
                })
                
                # æ”¶æ–‚åˆ¤æ–·
                convergence_rate = abs(improvement) if previous_loss != float('inf') else float('inf')
                
                # å¯¦æ™‚é€²åº¦é¡¯ç¤º
                if verbose and iteration % 10 == 0:
                    logger.info(f"ğŸ”® è¿­ä»£ {iteration}: æå¤± = {current_loss:.8f}")
                    logger.info(f"ğŸ“ˆ æœ€ä½³æå¤± = {best_loss:.8f}, æ”¹å–„é‡ = {improvement:.8f}")
                    logger.info(f"ğŸ“Š æ”¶æ–‚ç‡: {convergence_rate:.10f}, é–¾å€¼: {convergence_threshold}")
                    logger.info(f"â±ï¸ ç„¡æ”¹å–„æ¬¡æ•¸: {no_improvement_count}/{patience}")
                
                # è‡ªå‹•æ”¶æ–‚æ¢ä»¶æª¢æŸ¥
                if iteration >= min_iterations:
                    if convergence_rate < convergence_threshold:
                        logger.info(f"âœ… æ”¶æ–‚é”æˆï¼æ”¶æ–‚ç‡ {convergence_rate:.10f} < é–¾å€¼ {convergence_threshold}")
                        logger.info(f"ğŸ¯ åœ¨ç¬¬ {iteration} æ¬¡è¿­ä»£é”åˆ°æ”¶æ–‚")
                        break
                    
                    if no_improvement_count >= patience:
                        logger.info(f"â¸ï¸ æ—©åœè§¸ç™¼ï¼é€£çºŒ {patience} æ¬¡ç„¡æ”¹å–„")
                        logger.info(f"ğŸ¯ åœ¨ç¬¬ {iteration} æ¬¡è¿­ä»£è§¸ç™¼æ—©åœ")
                        break
                
                if iteration >= max_iterations:
                    logger.info(f"â° é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸ {max_iterations}")
                    logger.info(f"ğŸ¯ å¼·åˆ¶åœæ­¢è¨“ç·´")
                    break
                
                previous_loss = current_loss
                iteration += 1
                
            except Exception as e:
                logger.error(f"âŒ SPSA è¿­ä»£ {iteration} å¤±æ•—: {e}")
                iteration += 1
                if iteration >= max_iterations:
                    logger.warning(f"âš ï¸ é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸ï¼Œåœæ­¢è¨“ç·´")
                    break
                continue        # ä½¿ç”¨æœ€ä½³åƒæ•¸
        self.theta = best_theta
        self.is_fitted = True
        
        logger.info(f"âœ… çœŸå¯¦é‡å­è¨“ç·´å®Œæˆ! æœ€çµ‚æå¤±: {best_loss:.4f}")
        logger.info(f"   é‡å­å„ªå‹¢åˆ†æ•¸: {quantum_advantage_score:.3f}")
        logger.info(f"   ä½¿ç”¨å¾Œç«¯: {getattr(self.quantum_backend, 'name', 'qasm_simulator')}")
    
    def _generate_quantum_random_parameters(self, n_params: int) -> np.ndarray:
        """ä½¿ç”¨é‡å­éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨ç”Ÿæˆåƒæ•¸"""
        try:
            # å‰µå»ºé‡å­éš¨æ©Ÿæ•¸ç”Ÿæˆé›»è·¯
            qrng_circuit = QuantumCircuit(min(n_params, 10), min(n_params, 10))
            
            # ä½¿ç”¨ Hadamard é–€å‰µå»ºå‡å‹»ç–ŠåŠ æ…‹
            for i in range(min(n_params, 10)):
                qrng_circuit.h(i)
            qrng_circuit.measure_all()
            
            # åœ¨é‡å­å¾Œç«¯åŸ·è¡Œ
            job = self.quantum_backend.run(qrng_circuit, shots=n_params * 10)
            result = job.result()
            counts = result.get_counts()
            
            # å¾é‡å­æ¸¬é‡çµæœæå–éš¨æ©Ÿæ•¸
            random_bits = []
            for bitstring, count in counts.items():
                for _ in range(count):
                    random_bits.extend([int(b) for b in bitstring])
            
            # è½‰æ›ç‚ºåƒæ•¸ç¯„åœ [-Ï€, Ï€]
            quantum_params = []
            for i in range(n_params):
                if i < len(random_bits):
                    # ä½¿ç”¨é‡å­éš¨æ©Ÿä½ç”Ÿæˆåƒæ•¸
                    bit_value = random_bits[i % len(random_bits)]
                    param = (bit_value - 0.5) * 2 * math.pi * 0.1  # å°çš„åˆå§‹ç¯„åœ
                else:
                    param = 0.1 * (2 * (i % 2) - 1)  # ç°¡å–®çš„ç¢ºå®šæ€§åˆå§‹åŒ–
                quantum_params.append(param)
            
            logger.info(f"âœ… å·²ç”Ÿæˆ {n_params} å€‹é‡å­éš¨æ©Ÿåƒæ•¸")
            return np.array(quantum_params)
            
        except Exception as e:
            logger.error(f"é‡å­éš¨æ©Ÿæ•¸ç”Ÿæˆå¤±æ•—: {e}")
            # ä½¿ç”¨ç³»çµ±ç†µä½œç‚ºå‚™ä»½ï¼ˆä¸æ˜¯å½éš¨æ©Ÿæ•¸ï¼‰
            import os
            entropy_bytes = os.urandom(n_params * 4)  # ç³»çµ±ç†µ
            entropy_ints = [int.from_bytes(entropy_bytes[i:i+4], 'big') for i in range(0, len(entropy_bytes), 4)]
            return np.array([(x / (2**32)) * 0.2 - 0.1 for x in entropy_ints[:n_params]])
    
    def _generate_quantum_bernoulli(self, n: int) -> np.ndarray:
        """ä½¿ç”¨é‡å­è¨ˆç®—ç”Ÿæˆ Bernoulli éš¨æ©Ÿè®Šæ•¸"""
        try:
            qrng_circuit = QuantumCircuit(1, 1)
            qrng_circuit.h(0)  # å‰µå»º |+âŸ© æ…‹
            qrng_circuit.measure(0, 0)
            
            bernoulli_values = []
            for _ in range(n):
                job = self.quantum_backend.run(qrng_circuit, shots=1)
                result = job.result()
                counts = result.get_counts()
                
                # å¾æ¸¬é‡çµæœæå– Â±1
                if '0' in counts:
                    bernoulli_values.append(1.0)
                else:
                    bernoulli_values.append(-1.0)
            
            return np.array(bernoulli_values)
            
        except Exception as e:
            logger.error(f"é‡å­ Bernoulli ç”Ÿæˆå¤±æ•—: {e}")
            # ä½¿ç”¨ç³»çµ±ç†µä½œç‚ºå‚™ä»½
            import os
            entropy_bytes = os.urandom(n)
            return np.array([1.0 if b & 1 else -1.0 for b in entropy_bytes])
        
        def objective_function(theta_trial):
            total_loss = 0.0
            n_samples = min(50, len(X_processed))  # é™åˆ¶æ¨£æœ¬æ•¸é‡ä»¥åŠ é€Ÿè¨“ç·´
            
            for i in range(n_samples):
                feature_vec = X_processed[i]
                true_label = y[i]
                
                # è¨ˆç®— Hamiltonian
                h, J = feature_to_hJ_advanced(feature_vec, self.config['N_FEATURE_QUBITS'])
                
                # è©•ä¼°é‡å­é›»è·¯
                expectations, _ = evaluate_quantum_circuit(
                    theta_trial, feature_vec, h, J,
                    self.config['N_FEATURE_QUBITS'], self.config['N_READOUT'],
                    self.config['N_ANSATZ_LAYERS'], self.config['ENCODING'],
                    self.config['USE_STATEVECTOR'], self.config['SHOTS']
                )
                
                # è¨ˆç®—æå¤±
                probs = softmax(expectations)
                true_prob = probs[true_label] if true_label < len(probs) else probs[0]
                total_loss -= np.log(true_prob + 1e-12)
            
            return total_loss / n_samples
        
        # SPSA å„ªåŒ–
        best_loss = float('inf')
        best_theta = self.theta.copy()
        
        iterator = tqdm(range(self.config['SPSA_ITER'])) if verbose else range(self.config['SPSA_ITER'])
        
        for k in iterator:
            # SPSA åƒæ•¸
            a_k = spsa_settings['a'] / (k + spsa_settings['A']) ** spsa_settings['alpha']
            c_k = spsa_settings['c'] / (k + 1) ** spsa_settings['gamma']
            
            # éš¨æ©Ÿæ“¾å‹•
            delta = np.random.choice([-1, 1], size=len(self.theta))
            
            # æ­£å‘å’Œè² å‘è©•ä¼°
            theta_plus = self.theta + c_k * delta
            theta_minus = self.theta - c_k * delta
            
            loss_plus = objective_function(theta_plus)
            loss_minus = objective_function(theta_minus)
            
            # æ¢¯åº¦ä¼°è¨ˆ
            gradient = (loss_plus - loss_minus) / (2 * c_k) * delta
            
            # åƒæ•¸æ›´æ–°
            self.theta -= a_k * gradient
            
            # è¨˜éŒ„æœ€ä½³åƒæ•¸
            current_loss = objective_function(self.theta)
            if current_loss < best_loss:
                best_loss = current_loss
                best_theta = self.theta.copy()
            
            # è¨˜éŒ„è¨“ç·´æ­·å²
            self.training_history.append({
                'iteration': k,
                'loss': current_loss,
                'best_loss': best_loss
            })
            
            if verbose and k % 10 == 0:
                logger.info(f"   è¿­ä»£ {k}: æå¤± = {current_loss:.4f}, æœ€ä½³æå¤± = {best_loss:.4f}")
        
        self.theta = best_theta
        self.is_fitted = True
        
        logger.info(f"âœ… è¨“ç·´å®Œæˆï¼Œæœ€çµ‚æå¤±: {best_loss:.4f}")
    
    def predict(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """çœŸå¯¦é‡å­é æ¸¬"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨ fit() æ–¹æ³•")
        
        if self.quantum_backend is None:
            raise RuntimeError("âŒ é‡å­å¾Œç«¯æœªåˆå§‹åŒ–")
        
        X_processed = self.preprocess_features(X, fit=False)
        predictions = []
        probabilities = []
        
        logger.info(f"ğŸ”® é–‹å§‹çœŸå¯¦é‡å­é æ¸¬ ({len(X_processed)} å€‹æ¨£æœ¬)...")
        
        for i in tqdm(range(len(X_processed)), desc="é‡å­é æ¸¬"):
            try:
                feature_vec = X_processed[i]
                h, J = feature_to_hJ_advanced(feature_vec, self.config['N_FEATURE_QUBITS'])
                
                expectations, _ = evaluate_quantum_circuit(
                    self.theta, feature_vec, h, J,
                    self.config['N_FEATURE_QUBITS'], self.config['N_READOUT'],
                    self.config['N_ANSATZ_LAYERS'], self.config['ENCODING'],
                    self.config['USE_STATEVECTOR'], self.config['SHOTS'],
                    getattr(self.quantum_backend_manager, 'noise_model', None),
                    self.quantum_backend
                )
                
                probs = softmax(expectations)
                pred = np.argmax(probs)
                
                predictions.append(pred)
                probabilities.append(probs)
                
            except Exception as e:
                logger.error(f"é‡å­é æ¸¬ç¬¬ {i} å€‹æ¨£æœ¬å¤±æ•—: {e}")
                # ä½¿ç”¨è¬¹æ…çš„é»˜èªé æ¸¬ï¼ˆéœ‡ç›ªå¸‚å ´ï¼‰
                predictions.append(1)
                probabilities.append(np.array([0.25, 0.5, 0.25]))
        
        return np.array(predictions), np.array(probabilities)
    
    def predict_single(self, feature_vec: np.ndarray) -> Tuple[int, np.ndarray]:
        """å–®ä¸€çœŸå¯¦é‡å­é æ¸¬"""
        if not self.is_fitted:
            raise ValueError("æ¨¡å‹å°šæœªè¨“ç·´ï¼Œè«‹å…ˆèª¿ç”¨ fit() æ–¹æ³•")
        
        if self.quantum_backend is None:
            raise RuntimeError("âŒ é‡å­å¾Œç«¯æœªåˆå§‹åŒ–")
        
        try:
            # é‡æ§‹ç‚ºäºŒç¶­æ•¸çµ„é€²è¡Œé è™•ç†
            X_single = feature_vec.reshape(1, -1)
            X_processed = self.preprocess_features(X_single, fit=False)
            
            h, J = feature_to_hJ_advanced(X_processed[0], self.config['N_FEATURE_QUBITS'])
            
            expectations, _ = evaluate_quantum_circuit(
                self.theta, X_processed[0], h, J,
                self.config['N_FEATURE_QUBITS'], self.config['N_READOUT'],
                self.config['N_ANSATZ_LAYERS'], self.config['ENCODING'],
                self.config['USE_STATEVECTOR'], self.config['SHOTS'],
                getattr(self.quantum_backend_manager, 'noise_model', None),
                self.quantum_backend
            )
            
            probs = softmax(expectations)
            pred = np.argmax(probs)
            
            return pred, probs
            
        except Exception as e:
            logger.error(f"é‡å­å–®ä¸€é æ¸¬å¤±æ•—: {e}")
            raise RuntimeError(f"é‡å­é æ¸¬å¤±æ•—: {e}")
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'config': self.config,
            'theta': self.theta,
            'scaler': self.scaler,
            'pca': self.pca,
            'training_history': self.training_history,
            'is_fitted': self.is_fitted
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
        
        logger.info(f"âœ… æ¨¡å‹å·²ä¿å­˜è‡³: {filepath}")
    
    def load_model(self, filepath: str):
        """è¼‰å…¥æ¨¡å‹"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.config = model_data['config']
        self.theta = model_data['theta']
        self.scaler = model_data['scaler']
        self.pca = model_data['pca']
        self.training_history = model_data['training_history']
        self.is_fitted = model_data['is_fitted']
        
        logger.info(f"âœ… æ¨¡å‹å·²è¼‰å…¥è‡ª: {filepath}")
    
    def integrate_with_trading_x(self, symbols: List[str] = None):
        """èˆ‡ Trading X ç³»çµ±æ•´åˆ"""
        if å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨ is None:
            logger.warning("Trading X æ¨¡çµ„æœªæ‰¾åˆ°ï¼Œç„¡æ³•æ•´åˆå³æ™‚æ•¸æ“š")
            return False
        
        symbols = symbols or ['BTCUSDT']
        self.data_collector = å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨(symbols)
        
        logger.info(f"âœ… å·²æ•´åˆ Trading X ç³»çµ±ï¼Œç›£æ§äº¤æ˜“å°: {', '.join(symbols)}")
        return True
    
    async def get_blockchain_market_data(self, symbol: str = 'BTCUSDT') -> Optional[Dict[str, Any]]:
        """å¾å€å¡Šéˆä¸»æ± ç²å–å³æ™‚å¸‚å ´æ•¸æ“š"""
        if not self.blockchain_connector:
            logger.warning("å€å¡Šéˆä¸»æ± é€£æ¥å™¨æœªåˆå§‹åŒ–")
            return None
        
        try:
            # ä½¿ç”¨ X è³‡æ–™å¤¾çš„å€å¡Šéˆä¸»æ± æ–¹æ³•
            async with self.blockchain_connector as connector:
                market_data = await connector.get_comprehensive_market_data(symbol)
                
                if market_data and market_data.get('data_quality') != 'failed':
                    logger.debug(f"ğŸ“Š ç²å– {symbol} å€å¡Šéˆæ•¸æ“šæˆåŠŸï¼Œå®Œæ•´æ€§: {market_data.get('data_completeness', 0):.2%}")
                    return market_data
                else:
                    logger.warning(f"âš ï¸ {symbol} å€å¡Šéˆæ•¸æ“šç²å–å¤±æ•—æˆ–å“è³ªä¸ä½³")
                    return None
                    
        except Exception as e:
            logger.error(f"âŒ å€å¡Šéˆä¸»æ± æ•¸æ“šç²å–ç•°å¸¸: {e}")
            return None
    
    async def extract_features_from_blockchain_data(self, market_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """å¾å€å¡Šéˆæ•¸æ“šæå–é‡å­ç‰¹å¾µ"""
        if not market_data or market_data.get('data_quality') == 'failed':
            return None
        
        try:
            features = []
            
            # åƒ¹æ ¼ç‰¹å¾µ
            current_price = market_data.get('current_price', 0)
            price_series = market_data.get('price_series', [])
            
            if price_series and len(price_series) >= 5:
                # è¨ˆç®—æ”¶ç›Šç‡åºåˆ—
                returns = []
                for i in range(1, len(price_series)):
                    ret = (price_series[i] - price_series[i-1]) / price_series[i-1]
                    returns.append(ret)
                
                # å¤šå°ºåº¦ç‰¹å¾µè¨ˆç®—
                scales = [5, 20, min(60, len(returns))]
                for scale in scales:
                    if scale <= len(returns):
                        window = returns[-scale:]
                        features.extend([
                            np.nan_to_num(window[-1]),  # æœ€æ–°æ”¶ç›Šç‡
                            np.nan_to_num(np.std(window)),  # æ³¢å‹•ç‡
                            np.nan_to_num(np.mean(window)),  # å¹³å‡æ”¶ç›Šç‡
                            np.nan_to_num(pd.Series(window).skew()),  # ååº¦
                            np.nan_to_num(pd.Series(window).kurt())   # å³°åº¦
                        ])
                    else:
                        features.extend([0.0, 0.0, 0.0, 0.0, 0.0])
            else:
                features.extend([0.0] * 15)  # 3 scales Ã— 5 features
            
            # æˆäº¤é‡ç‰¹å¾µ
            volume_analysis = market_data.get('volume_analysis', {})
            features.append(volume_analysis.get('volume_trend', 0.0))
            
            # è¨‚å–®ç°¿ç‰¹å¾µ
            order_book = market_data.get('order_book', {})
            if order_book and 'bids' in order_book and 'asks' in order_book:
                bids = order_book['bids']
                asks = order_book['asks']
                if bids and asks:
                    bid_volume = sum(float(bid[1]) for bid in bids[:5])
                    ask_volume = sum(float(ask[1]) for ask in asks[:5])
                    total_volume = bid_volume + ask_volume
                    orderbook_imbalance = (bid_volume - ask_volume) / total_volume if total_volume > 0 else 0
                    features.append(orderbook_imbalance)
                else:
                    features.append(0.0)
            else:
                features.append(0.0)
            
            # è³‡é‡‘è²»ç‡ç‰¹å¾µ
            funding_rate = market_data.get('funding_rate', {})
            if funding_rate and 'fundingRate' in funding_rate:
                features.append(float(funding_rate['fundingRate']))
            else:
                features.append(0.0)
            
            return np.array(features)
            
        except Exception as e:
            logger.error(f"ç‰¹å¾µæå–å¤±æ•—: {e}")
            return None
    
    async def generate_trading_signal(self, symbol: str = 'BTCUSDT'):
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿï¼ˆæ•´åˆå€å¡Šéˆä¸»æ± æ•¸æ“šï¼‰"""
        try:
            # å„ªå…ˆä½¿ç”¨å€å¡Šéˆä¸»æ± æ•¸æ“š
            market_data = await self.get_blockchain_market_data(symbol)
            
            if market_data:
                # å¾å€å¡Šéˆæ•¸æ“šæå–ç‰¹å¾µ
                features = await self.extract_features_from_blockchain_data(market_data)
                
                if features is not None:
                    # é‡å­é æ¸¬
                    pred, probs = self.predict_single(features)
                    
                    # è½‰æ›ç‚º Trading X ä¿¡è™Ÿ
                    signal_map = {0: 'BEAR', 1: 'SIDE', 2: 'BULL'}
                    signal_strength = float(np.max(probs))
                    confidence = signal_strength * market_data.get('data_completeness', 1.0)
                    
                    if TradingXä¿¡è™Ÿ:
                        signal = TradingXä¿¡è™Ÿ(
                            äº¤æ˜“å°=symbol,
                            ä¿¡è™Ÿ=signal_map[pred],
                            ä¿¡è™Ÿå¼·åº¦=signal_strength,
                            ä¿¡å¿ƒåº¦=confidence,
                            é æœŸæ”¶ç›Š=float(probs[2] - probs[0]),  # bull_prob - bear_prob
                            é¢¨éšªè©•ä¼°=1.0 - confidence,
                            æ™‚é–“æˆ³=market_data.get('timestamp', datetime.now()),
                            æ•¸æ“šæº='BTC_Quantum_Ultimate_Model_Blockchain'
                        )
                        
                        self.signal_history.append(signal)
                        logger.info(f"ğŸ”® {symbol} é‡å­ä¿¡è™Ÿ: {signal.ä¿¡è™Ÿ} (å¼·åº¦: {signal_strength:.3f}, ä¿¡å¿ƒ: {confidence:.3f})")
                        return signal
            
            # å›é€€åˆ° Trading X æ•¸æ“šæ”¶é›†å™¨
            if self.data_collector:
                observation = self.data_collector.ç²å–å³æ™‚è§€æ¸¬(symbol)
                if observation is None:
                    logger.warning(f"âš ï¸ ç„¡æ³•ç²å– {symbol} çš„å³æ™‚è§€æ¸¬æ•¸æ“š")
                    return None
                
                # æ§‹å»ºç‰¹å¾µå‘é‡
                features = np.array([
                    observation.æ”¶ç›Šç‡,
                    observation.å·²å¯¦ç¾æ³¢å‹•ç‡,
                    observation.å‹•é‡æ–œç‡,
                    observation.è²·è³£åƒ¹å·®,
                    observation.è¨‚å–®ç°¿å£“åŠ›,
                    observation.ä¸»å‹•è²·å…¥æ¯”ç‡,
                    observation.è³‡é‡‘è²»ç‡ or 0.0,
                    0.0  # å ä½ç¬¦
                ])
                
                # é‡å­é æ¸¬
                pred, probs = self.predict_single(features)
                
                # è½‰æ›ç‚º Trading X ä¿¡è™Ÿ
                signal_map = {0: 'BEAR', 1: 'SIDE', 2: 'BULL'}
                signal_strength = float(np.max(probs))
                
                if TradingXä¿¡è™Ÿ:
                    signal = TradingXä¿¡è™Ÿ(
                        äº¤æ˜“å°=symbol,
                        ä¿¡è™Ÿ=signal_map[pred],
                        ä¿¡è™Ÿå¼·åº¦=signal_strength,
                        ä¿¡å¿ƒåº¦=signal_strength,
                        é æœŸæ”¶ç›Š=float(probs[2] - probs[0]),  # bull_prob - bear_prob
                        é¢¨éšªè©•ä¼°=1.0 - signal_strength,
                        æ™‚é–“æˆ³=observation.æ™‚é–“æˆ³,
                        æ•¸æ“šæº='BTC_Quantum_Ultimate_Model_TradingX'
                    )
                    
                    self.signal_history.append(signal)
                    return signal
            
            logger.warning(f"âš ï¸ ç„¡æ³•ç‚º {symbol} ç”Ÿæˆé‡å­ä¿¡è™Ÿï¼šç„¡å¯ç”¨æ•¸æ“šæº")
            return None
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ {symbol} äº¤æ˜“ä¿¡è™Ÿå¤±æ•—: {e}")
            return None

# ---------------------------
# å·¥å» å‡½æ•¸
# ---------------------------

def create_btc_quantum_model(config: Dict[str, Any] = None, quantum_backend_type: str = 'local_hf') -> BTCQuantumUltimateModel:
    """å‰µå»º BTC é‡å­çµ‚æ¥µæ¨¡å‹ï¼ˆçœŸå¯¦é‡å­ç‰ˆæœ¬ï¼‰"""
    return BTCQuantumUltimateModel(config, quantum_backend_type)

def production_quantum_demo():
    """ç”Ÿç”¢ç´šé‡å­æ¼”ç¤ºï¼ˆç„¡æ¸¬è©¦æ•¸æ“šï¼‰"""
    logger.info("ğŸš€ BTC é‡å­çµ‚æ¥µæ¨¡å‹ç”Ÿç”¢ç´šæ¼”ç¤ºï¼ˆçœŸå¯¦é‡å­è¨ˆç®—ï¼‰")
    
    try:
        # å‰µå»ºçœŸå¯¦é‡å­æ¨¡å‹
        model = create_btc_quantum_model(quantum_backend_type='local_hf')
        
        # ä½¿ç”¨çœŸå¯¦å¸‚å ´æ•¸æ“šï¼ˆéåˆæˆæ•¸æ“šï¼‰
        if model.blockchain_connector:
            logger.info("ğŸ“Š å¾çœŸå¯¦å€å¡Šéˆæ•¸æ“šæºç²å– BTC æ•¸æ“š...")
            df = model.generate_realistic_market_data('BTCUSDT', '1h', 1000)
        else:
            logger.error("âŒ ç„¡æ³•ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š - éœ€è¦å€å¡Šéˆæ•¸æ“šé€£æ¥å™¨")
            return None
        
        X, y = model.prepare_features_and_labels(df)
        logger.info(f"ğŸ“Š çœŸå¯¦æ•¸æ“šå½¢ç‹€: X={X.shape}, y={y.shape}")
        
        # æ•¸æ“šåˆ†å¸ƒæª¢æŸ¥
        unique, counts = np.unique(y, return_counts=True)
        logger.info(f"ğŸ“ˆ å¸‚å ´åˆ¶åº¦åˆ†å¸ƒ: {dict(zip(['BEAR', 'SIDE', 'BULL'], counts))}")
        
        # ç”Ÿç”¢ç´šé‡å­è¨“ç·´ï¼ˆæ¸›å°‘è¿­ä»£ä»¥ç¯€çœé‡å­è³‡æºï¼‰
        production_config = QUANTUM_CONFIG.copy()
        production_config['SPSA_ITER'] = 50  # ç”Ÿç”¢ç´šè¿­ä»£æ•¸
        production_config['SHOTS'] = 4096    # é«˜ç²¾åº¦ shots
        
        model.config.update(production_config)
        
        # è¨“ç·´æ¨¡å‹
        logger.info("ğŸ”® é–‹å§‹ç”Ÿç”¢ç´šé‡å­è¨“ç·´...")
        model.fit(X[:200], y[:200], verbose=True)  # ä½¿ç”¨è¼ƒå°æ•¸æ“šé›†ç¯€çœè¨ˆç®—è³‡æº
        
        # æ¸¬è©¦é æ¸¬
        logger.info("ğŸ¯ æ¸¬è©¦é‡å­é æ¸¬...")
        test_predictions, test_probs = model.predict(X[200:210])  # 10å€‹æ¸¬è©¦æ¨£æœ¬
        
        logger.info(f"âœ… é‡å­é æ¸¬å®Œæˆ:")
        for i, (pred, prob) in enumerate(zip(test_predictions, test_probs)):
            true_label = y[200 + i]
            market_state = ['BEAR', 'SIDE', 'BULL'][pred]
            confidence = np.max(prob)
            correct = "âœ…" if pred == true_label else "âŒ"
            logger.info(f"   æ¨£æœ¬ {i+1}: {market_state} (ä¿¡å¿ƒåº¦: {confidence:.3f}) {correct}")
        
        # è¨ˆç®—æº–ç¢ºç‡
        accuracy = np.mean(test_predictions == y[200:210])
        logger.info(f"ğŸ¯ é‡å­æ¨¡å‹æº–ç¢ºç‡: {accuracy:.3f}")
        
        # é‡å­å„ªå‹¢å ±å‘Š
        if hasattr(model, 'quantum_advantage_validator'):
            advantage_score = model.quantum_advantage_validator.benchmark_results.get('total_score', 0.0)
            logger.info(f"âš¡ é‡å­å„ªå‹¢åˆ†æ•¸: {advantage_score:.3f}")
        
        return model
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿç”¢ç´šé‡å­æ¼”ç¤ºå¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    """çœŸå¯¦é‡å­è¨ˆç®—ä¸»ç¨‹åºï¼ˆç„¡æ¸¬è©¦æ¨¡å¼ï¼‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='BTC é‡å­çµ‚æ¥µæ¨¡å‹ - çœŸå¯¦é‡å­è¨ˆç®—ç‰ˆæœ¬')
    parser.add_argument('--backend', choices=['ibm', 'local_hf'], default='local_hf',
                        help='é‡å­å¾Œç«¯é¡å‹ (ibm: IBM Quantum, local_hf: æœ¬åœ°é«˜ä¿çœŸåº¦)')
    parser.add_argument('--symbol', default='BTCUSDT', help='äº¤æ˜“å°ç¬¦è™Ÿ')
    parser.add_argument('--demo', action='store_true', help='é‹è¡Œç”Ÿç”¢ç´šæ¼”ç¤º')
    
    args = parser.parse_args()
    
    if args.demo:
        production_quantum_demo()
    else:
        logger.info("ğŸ”® BTC é‡å­çµ‚æ¥µæ¨¡å‹å·²å°±ç·’")
        logger.info("   ä½¿ç”¨ --demo åƒæ•¸é‹è¡Œç”Ÿç”¢ç´šæ¼”ç¤º")
        logger.info("   ä½¿ç”¨ --backend ibm é€£æ¥ IBM Quantum ç¡¬é«”")
        logger.info("   ç¢ºä¿è¨­ç½® IBM_QUANTUM_TOKEN ç’°å¢ƒè®Šæ•¸")
