# regime_hmm_quantum.py  
# é‡å­å¸‚å ´åˆ¶åº¦åµæ¸¬å¼•æ“ - ç”Ÿç”¢ç´šç‰ˆæœ¬
#
# é‡å­å¸‚å ´åˆ¶åº¦åµæ¸¬å¼•æ“ - ç”Ÿç”¢ç´šç‰ˆæœ¬
# æ ¸å¿ƒæ¦‚å¿µ: å¸‚å ´å¦‚é‡å­ç–ŠåŠ ï¼Œåœ¨ä¸ç¢ºå®šæ€§ä¸­å§‹çµ‚ç«™åœ¨çµ±è¨ˆå„ªå‹¢æœ€å¤§çš„ä¸€é‚Š
#
# æ–°å¢é‡å­å„ªå‹¢ç‰¹æ€§:
# âœ“ é‡å­ä¿¡è™Ÿæ€§åƒ¹æ¯”ç¯©é¸å™¨ (QuantumSignalSelector)
# âœ“ å³æ™‚æµè³‡æ–™é©é… (Online EM / Incremental Update)
# âœ“ è·¨å¹£ç¨®è€¦åˆåµæ¸¬ (Multi-asset Coupled HMM)
# âœ“ éå¹³ç©©æª¢æ¸¬å™¨ (Regime Shift Detector)
# âœ“ å¸‚å ´çªè®Šè§¸ç™¼å™¨ (æ³¢å‡½æ•¸å¼·åˆ¶åç¸®)
# âœ“ å³æ™‚å¹£å®‰ API æ•´åˆ (OrderBook/Trade å³æ™‚æ›´æ–°)
# âœ“ è³‡é‡‘è²»ç‡èˆ‡æœªå¹³å€‰é‡æ•´åˆ
# âœ“ Trading X æµæ°´ç·šç›´æ¥ä¿¡è™Ÿè¼¸å‡º
#
# åŸæœ‰ç”Ÿç”¢ç´šç‰¹æ€§:
# - å‘é‡åŒ– forward/backward è¨ˆç®—
# - è½‰ç§»çŸ©é™£å¿«å– (A_cache, logA_cache)
# - Per-row åŠ æ¬Š multinomial-logit M-step (L-BFGS)
# - åŠ æ¬Š Student-t nu æ•¸å€¼ä¼°è¨ˆ
# - Viterbi & smoothed posterior è¼¸å‡º  
# - ç³»çµ±åŒ–é‡æ¡æ¨£ç²’å­æ¿¾æ³¢
# - ç”Ÿç”¢ç´šæ•¸å€¼ç©©å®šæ€§
#
# Trading X é‡å­ä¸»æ± : BTC/ETH/ADA/SOL/XRP/DOGE/BNB
# Dependencies: numpy, scipy, ccxt, websockets

import math
import time
import warnings
import asyncio
import logging
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from scipy.optimize import minimize
from scipy.special import digamma, logsumexp
from scipy import stats

# æ–°å¢ï¼šå³æ™‚ API æ•´åˆ
try:
    import ccxt
    import websockets
    import json
    from datetime import datetime, timedelta
    from collections import deque, defaultdict
    import pickle
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LogisticRegression
    from sklearn.metrics import accuracy_score, mean_squared_error
    from sklearn.preprocessing import StandardScaler
    from sklearn.decomposition import PCA
    
    # ğŸ”® Qiskit é‡å­è¨ˆç®—ä¾è³´ - BTC_Quantum_Ultimate_Model æ•´åˆ
    from qiskit import QuantumCircuit, Aer, transpile
    from qiskit.circuit import ParameterVector
    from qiskit.providers.aer.noise import NoiseModel, depolarizing_error, thermal_relaxation_error
    from qiskit import ClassicalRegister
    
    QUANTUM_LIBS_AVAILABLE = True
    
except ImportError as e:
    logger.warning(f"é‡å­æˆ–ç§‘å­¸è¨ˆç®—åº«æœªå®‰è£: {e}")
    QUANTUM_LIBS_AVAILABLE = False
    from sklearn.preprocessing import StandardScaler
    BINANCE_API_AVAILABLE = True
except ImportError:
    BINANCE_API_AVAILABLE = False
    print("âš ï¸  å¹£å®‰ API æ¨¡çµ„æœªå®‰è£ï¼Œéƒ¨åˆ†åŠŸèƒ½å°‡è¢«ç¦ç”¨")

warnings.filterwarnings("ignore", category=RuntimeWarning)

# è¨­ç½®æ—¥èªŒ
logger = logging.getLogger(__name__)

# --------------------------
# æ ¸å¿ƒ PDF è¨ˆç®—å‡½æ•¸ (å‘é‡åŒ–)
# --------------------------

# --------------------------
# å³æ™‚å¹£å®‰ API æ•¸æ“šæ•´åˆå™¨
# --------------------------

@dataclass
class å³æ™‚å¸‚å ´è§€æ¸¬:
    """å³æ™‚å¸‚å ´è§€æ¸¬æ•¸æ“šçµæ§‹"""
    æ™‚é–“æˆ³: datetime
    äº¤æ˜“å°: str
    åƒ¹æ ¼: float
    æˆäº¤é‡: float
    
    # æŠ€è¡“æŒ‡æ¨™
    æ”¶ç›Šç‡: float
    å·²å¯¦ç¾æ³¢å‹•ç‡: float
    å‹•é‡æ–œç‡: float
    
    # è¨‚å–®ç°¿æ•¸æ“š
    æœ€ä½³è²·åƒ¹: float
    æœ€ä½³è³£åƒ¹: float
    è²·è³£åƒ¹å·®: float
    è¨‚å–®ç°¿å£“åŠ›: float  # (è²·é‡ - è³£é‡) / (è²·é‡ + è³£é‡)
    
    # äº¤æ˜“æµæ•¸æ“š
    ä¸»å‹•è²·å…¥æ¯”ç‡: float
    å¤§å–®æµå…¥ç‡: float
    
    # è¡ç”Ÿå“æ•¸æ“š
    è³‡é‡‘è²»ç‡: Optional[float] = None
    æœªå¹³å€‰é‡: Optional[float] = None
    éš±å«æ³¢å‹•ç‡: Optional[float] = None
    
    # åˆ¶åº¦ä¿¡è™Ÿ
    RSI_14: float = 50.0
    å¸ƒæ—å¸¶ä½ç½®: float = 0.5

# --------------------------
# Trading X ä¿¡è™Ÿæ•¸æ“šçµæ§‹
# --------------------------

@dataclass 
class TradingXä¿¡è™Ÿ:
    """Trading X ç³»çµ±ä¿¡è™Ÿæ ¼å¼"""
    æ™‚é–“æˆ³: datetime
    äº¤æ˜“å°: str
    ä¿¡è™Ÿé¡å‹: str  # 'LONG', 'SHORT', 'NEUTRAL'
    ä¿¡å¿ƒåº¦: float  # 0-1
    åˆ¶åº¦: int      # 0-5
    æœŸæœ›æ”¶ç›Š: float
    é¢¨éšªè©•ä¼°: float
    é¢¨éšªå ±é…¬æ¯”: float
    é€²å ´åƒ¹æ ¼: float
    æ­¢æåƒ¹æ ¼: Optional[float] = None
    æ­¢ç›ˆåƒ¹æ ¼: Optional[float] = None
    æŒå€‰å»ºè­°: float = 0.0  # å»ºè­°å€‰ä½å¤§å°
    
    # é‡å­åˆ†æçµæœ
    åˆ¶åº¦æ¦‚ç‡åˆ†å¸ƒ: List[float] = None
    é‡å­è©•åˆ†: float = 0.0
    å¸‚å ´åˆ¶åº¦åç¨±: str = "æœªçŸ¥"
    
    # é¡å¤–ä¿¡æ¯
    æŠ€è¡“æŒ‡æ¨™: Dict[str, float] = None
    å¸‚å ´å¾®è§€çµæ§‹: Dict[str, float] = None

# --------------------------
# å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨
# --------------------------

class å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨:
    """
    å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨
    
    åŠŸèƒ½:
    - WebSocket å³æ™‚åƒ¹æ ¼æµ
    - è¨‚å–®ç°¿æ·±åº¦æ›´æ–°
    - äº¤æ˜“æµåˆ†æ
    - è³‡é‡‘è²»ç‡ç›£æ§
    - æœªå¹³å€‰é‡è¿½è¹¤
    """
    
    def __init__(self, äº¤æ˜“å°åˆ—è¡¨: List[str]):
        self.äº¤æ˜“å°åˆ—è¡¨ = äº¤æ˜“å°åˆ—è¡¨
        self.å³æ™‚æ•¸æ“š = {}
        self.è¨‚å–®ç°¿æ•¸æ“š = {}
        self.äº¤æ˜“æµæ•¸æ“š = {}
        self.é‹è¡Œä¸­ = False
        
        # éŒ¯èª¤æ§åˆ¶æ©Ÿåˆ¶
        self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸ = {}
        self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸ = 10  # æœ€å¤§é‡è©¦æ¬¡æ•¸
        self.éŒ¯èª¤å»¶é² = 5  # éŒ¯èª¤å¾Œå»¶é²ç§’æ•¸
        
        # WebSocket é€£æ¥ç®¡ç†
        self.websocket_tasks = []  # å­˜å„² WebSocket ä»»å‹™
        self.force_stop = False    # å¼·åˆ¶åœæ­¢æ¨™èªŒ
        
        # ğŸ”¥ å‹•æ…‹æ¬Šé‡èåˆå™¨åˆå§‹åŒ–
        self.å‹•æ…‹æ¬Šé‡èåˆå™¨ = DynamicWeightFusion(
            lookback_periods=50,
            learning_rate=0.1,
            volatility_threshold=0.02,
            confidence_alpha=0.95
        )
        
        # ğŸš€ é‡å­çµ‚æ¥µèåˆå¼•æ“åˆå§‹åŒ–
        self.é‡å­çµ‚æ¥µå¼•æ“ = QuantumUltimateFusionEngine(äº¤æ˜“å°åˆ—è¡¨)
        
        # é‡å­ä¿¡è™Ÿæ­·å²è¿½è¹¤
        self.é‡å­ä¿¡è™Ÿæ­·å² = deque(maxlen=100)
        self.åˆ¶åº¦ä¿¡è™Ÿæ­·å² = deque(maxlen=100)
        self.å¸‚å ´å›å ±æ­·å² = deque(maxlen=100)
        
        # èåˆä¿¡è™Ÿè¼¸å‡ºç·©å­˜
        self.æœ€æ–°èåˆä¿¡è™Ÿ = {}  # æ¯å€‹äº¤æ˜“å°çš„æœ€æ–°ä¿¡è™Ÿ
        
        # åˆå§‹åŒ–å¹£å®‰ REST API
        if BINANCE_API_AVAILABLE:
            self.å¹£å®‰API = ccxt.binance({
                'sandbox': False,
                'enableRateLimit': True,
                'options': {'defaultType': 'spot'}
            })
        else:
            self.å¹£å®‰API = None
            logger.warning("å¹£å®‰ API ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š")
    
    async def å•Ÿå‹•æ•¸æ“šæ”¶é›†(self):
        """å•Ÿå‹•æ‰€æœ‰æ•¸æ“šæ”¶é›†ä»»å‹™"""
        if not BINANCE_API_AVAILABLE:
            logger.warning("å¹£å®‰ API æ¨¡çµ„ä¸å¯ç”¨ï¼Œè·³éå•Ÿå‹•")
            return
        
        self.é‹è¡Œä¸­ = True
        self.force_stop = False
        logger.info("ğŸš€ å•Ÿå‹•å³æ™‚æ•¸æ“šæ”¶é›†å™¨...")
        
        try:
            # å‰µå»ºä¸¦å„²å­˜ WebSocket ä»»å‹™
            self.websocket_tasks = [
                asyncio.create_task(self._åƒ¹æ ¼æµWebSocket()),
                asyncio.create_task(self._è¨‚å–®ç°¿WebSocket()),
                asyncio.create_task(self._äº¤æ˜“æµWebSocket()),
                asyncio.create_task(self._è³‡é‡‘è²»ç‡æ›´æ–°å™¨()),
                asyncio.create_task(self._æœªå¹³å€‰é‡æ›´æ–°å™¨())
            ]
            
            # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆæˆ–è¢«å–æ¶ˆ
            await asyncio.gather(*self.websocket_tasks, return_exceptions=True)
            
        except Exception as e:
            logger.error(f"âŒ æ•¸æ“šæ”¶é›†å•Ÿå‹•å¤±æ•—: {e}")
        finally:
            logger.info("ğŸ›‘ æ•¸æ“šæ”¶é›†å·²åœæ­¢")
    
    async def åœæ­¢æ•¸æ“šæ”¶é›†(self):
        """åœæ­¢æ‰€æœ‰æ•¸æ“šæ”¶é›†"""
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢æ•¸æ“šæ”¶é›†...")
        
        # è¨­ç½®åœæ­¢æ¨™èªŒ
        self.é‹è¡Œä¸­ = False
        self.force_stop = True
        
        # å¼·åˆ¶å–æ¶ˆæ‰€æœ‰ WebSocket ä»»å‹™
        if self.websocket_tasks:
            logger.info(f"ğŸ”„ å¼·åˆ¶å–æ¶ˆ {len(self.websocket_tasks)} å€‹ WebSocket ä»»å‹™...")
            for task in self.websocket_tasks:
                if not task.done():
                    task.cancel()
            
            # ç¸®çŸ­ç­‰å¾…æ™‚é–“ï¼Œå¿«é€Ÿå–æ¶ˆ
            try:
                await asyncio.wait_for(
                    asyncio.gather(*self.websocket_tasks, return_exceptions=True),
                    timeout=1.0  # æ¸›å°‘åˆ°1ç§’
                )
            except asyncio.TimeoutError:
                logger.warning("âš¡ ä»»å‹™å–æ¶ˆè¶…æ™‚ï¼Œå¼·åˆ¶æ¸…ç†")
                # å¼·åˆ¶æ¸…ç†æ²’æœ‰å®Œæˆçš„ä»»å‹™
                for task in self.websocket_tasks:
                    if not task.done():
                        try:
                            task.cancel()
                        except:
                            pass
        
        # æ¸…ç©ºä»»å‹™åˆ—è¡¨
        self.websocket_tasks = []
        
        # å–æ¶ˆæ‰€æœ‰event loopä¸­çš„ä»»å‹™
        try:
            loop = asyncio.get_running_loop()
            pending_tasks = [task for task in asyncio.all_tasks(loop) 
                           if not task.done() and task != asyncio.current_task()]
            
            if pending_tasks:
                logger.info(f"ğŸ”„ å–æ¶ˆ {len(pending_tasks)} å€‹å…¶ä»–ä»»å‹™...")
                for task in pending_tasks:
                    task.cancel()
                
                # å¿«é€Ÿç­‰å¾…
                try:
                    await asyncio.wait_for(
                        asyncio.gather(*pending_tasks, return_exceptions=True),
                        timeout=0.5  # åªç­‰0.5ç§’
                    )
                except:
                    pass  # å¿½ç•¥ä»»ä½•éŒ¯èª¤
        except Exception as e:
            logger.debug(f"æ¸…ç†ä»»å‹™æ™‚å‡ºéŒ¯: {e}")
        
        logger.info("âœ… æ•¸æ“šæ”¶é›†å·²åœæ­¢")
    
    async def _åƒ¹æ ¼æµWebSocket(self):
        """å³æ™‚åƒ¹æ ¼æµ WebSocket"""
        é€£æ¥åç¨± = "åƒ¹æ ¼æµWebSocket"
        self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0
        
        while self.é‹è¡Œä¸­ and not self.force_stop and self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] < self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
            try:
                streams = [f"{symbol.lower()}@ticker" for symbol in self.äº¤æ˜“å°åˆ—è¡¨]
                ws_url = f"wss://stream.binance.com:9443/stream?streams={'/'.join(streams)}"
                
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as websocket:
                    logger.info(f"âœ… {é€£æ¥åç¨±} å·²é€£æ¥: {len(streams)} å€‹äº¤æ˜“å°")
                    self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0  # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
                    
                    while self.é‹è¡Œä¸­ and not self.force_stop:
                        try:
                            # æ·»åŠ è¶…æ™‚ï¼Œè®“åœæ­¢ä¿¡è™Ÿèƒ½æ›´å¿«éŸ¿æ‡‰
                            æ¶ˆæ¯ = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                            æ•¸æ“š = json.loads(æ¶ˆæ¯)
                            
                            # è™•ç†å¤šstreamæ ¼å¼ï¼š{"stream": "btcusdt@ticker", "data": {...}}
                            if 'data' in æ•¸æ“š:
                                stream_data = æ•¸æ“š['data']
                                await self._è™•ç†åƒ¹æ ¼æ›´æ–°(stream_data)
                            else:
                                # ç›´æ¥æ ¼å¼ï¼ˆå–®ä¸€streamï¼‰
                                await self._è™•ç†åƒ¹æ ¼æ›´æ–°(æ•¸æ“š)
                        
                        except asyncio.TimeoutError:
                            # è¶…æ™‚æ˜¯æ­£å¸¸çš„ï¼Œç”¨æ–¼æª¢æŸ¥åœæ­¢ä¿¡è™Ÿ
                            if self.force_stop or not self.é‹è¡Œä¸­:
                                logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ")
                                break
                            continue
                        
                        except websockets.exceptions.ConnectionClosed:
                            logger.warning(f"{é€£æ¥åç¨±} é€£æ¥ä¸­æ–·ï¼Œæº–å‚™é‡é€£...")
                            break
                        except json.JSONDecodeError as e:
                            logger.warning(f"{é€£æ¥åç¨±} JSON è§£æéŒ¯èª¤: {e}")
                            continue
                        except Exception as e:
                            logger.error(f"{é€£æ¥åç¨±} è™•ç†éŒ¯èª¤: {e}")
                            await asyncio.sleep(1)
            
            except Exception as e:
                self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] += 1
                logger.error(f"{é€£æ¥åç¨±} å•Ÿå‹•å¤±æ•— ({self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±]}/{self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸}): {e}")
                
                if self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] >= self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
                    logger.critical(f"âŒ {é€£æ¥åç¨±} éŒ¯èª¤æ¬¡æ•¸è¶…é™ï¼Œåœæ­¢é‡é€£")
                    break
                
                if not self.force_stop:
                    await asyncio.sleep(self.éŒ¯èª¤å»¶é²)
        
        logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} å·²åœæ­¢")
    
    async def _è¨‚å–®ç°¿WebSocket(self):
        """å³æ™‚è¨‚å–®ç°¿æ·±åº¦ WebSocket"""
        é€£æ¥åç¨± = "è¨‚å–®ç°¿WebSocket"
        self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0
        
        while self.é‹è¡Œä¸­ and not self.force_stop and self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] < self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
            try:
                streams = [f"{symbol.lower()}@depth20@100ms" for symbol in self.äº¤æ˜“å°åˆ—è¡¨]
                ws_url = f"wss://stream.binance.com:9443/stream?streams={'/'.join(streams)}"
                
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as websocket:
                    logger.info(f"âœ… {é€£æ¥åç¨±} å·²é€£æ¥")
                    self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0  # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
                    
                    while self.é‹è¡Œä¸­ and not self.force_stop:
                        try:
                            # æ·»åŠ è¶…æ™‚ï¼Œè®“åœæ­¢ä¿¡è™Ÿèƒ½æ›´å¿«éŸ¿æ‡‰
                            æ¶ˆæ¯ = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                            æ•¸æ“š = json.loads(æ¶ˆæ¯)
                            
                            # è™•ç†å¤šstreamæ ¼å¼ï¼š{"stream": "btcusdt@depth20@100ms", "data": {...}}
                            if 'data' in æ•¸æ“š:
                                stream_data = æ•¸æ“š['data']
                                stream_name = æ•¸æ“š.get('stream', '')
                                await self._è™•ç†è¨‚å–®ç°¿æ›´æ–°(stream_data, stream_name)
                            else:
                                # ç›´æ¥æ ¼å¼ï¼ˆå–®ä¸€streamï¼‰
                                await self._è™•ç†è¨‚å–®ç°¿æ›´æ–°(æ•¸æ“š)
                        
                        except asyncio.TimeoutError:
                            # è¶…æ™‚æ˜¯æ­£å¸¸çš„ï¼Œç”¨æ–¼æª¢æŸ¥åœæ­¢ä¿¡è™Ÿ
                            if self.force_stop or not self.é‹è¡Œä¸­:
                                logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ")
                                break
                            continue
                        
                        except websockets.exceptions.ConnectionClosed:
                            logger.warning(f"{é€£æ¥åç¨±} é€£æ¥ä¸­æ–·ï¼Œæº–å‚™é‡é€£...")
                            break
                        except json.JSONDecodeError as e:
                            logger.warning(f"{é€£æ¥åç¨±} JSON è§£æéŒ¯èª¤: {e}")
                            continue
                        except Exception as e:
                            logger.error(f"{é€£æ¥åç¨±} è™•ç†éŒ¯èª¤: {e}")
                            await asyncio.sleep(1)
            
            except Exception as e:
                self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] += 1
                logger.error(f"{é€£æ¥åç¨±} å•Ÿå‹•å¤±æ•— ({self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±]}/{self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸}): {e}")
                
                if self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] >= self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
                    logger.critical(f"âŒ {é€£æ¥åç¨±} éŒ¯èª¤æ¬¡æ•¸è¶…é™ï¼Œåœæ­¢é‡é€£")
                    break
                
                if not self.force_stop:
                    await asyncio.sleep(self.éŒ¯èª¤å»¶é²)
        
        logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} å·²åœæ­¢")
    
    async def _äº¤æ˜“æµWebSocket(self):
        """å³æ™‚äº¤æ˜“æµ WebSocket"""
        é€£æ¥åç¨± = "äº¤æ˜“æµWebSocket"
        self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0
        
        while self.é‹è¡Œä¸­ and self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] < self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
            try:
                streams = [f"{symbol.lower()}@aggTrade" for symbol in self.äº¤æ˜“å°åˆ—è¡¨]
                ws_url = f"wss://stream.binance.com:9443/stream?streams={'/'.join(streams)}"
                
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as websocket:
                    logger.info(f"âœ… {é€£æ¥åç¨±} å·²é€£æ¥")
                    self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] = 0  # é‡ç½®éŒ¯èª¤è¨ˆæ•¸
                    
                    while self.é‹è¡Œä¸­ and not self.force_stop:
                        try:
                            # æ·»åŠ è¶…æ™‚ï¼Œè®“åœæ­¢ä¿¡è™Ÿèƒ½æ›´å¿«éŸ¿æ‡‰
                            æ¶ˆæ¯ = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                            æ•¸æ“š = json.loads(æ¶ˆæ¯)
                            
                            # è™•ç†å¤šstreamæ ¼å¼ï¼š{"stream": "btcusdt@aggTrade", "data": {...}}
                            if 'data' in æ•¸æ“š:
                                stream_data = æ•¸æ“š['data']
                                stream_name = æ•¸æ“š.get('stream', '')
                                await self._è™•ç†äº¤æ˜“æµæ›´æ–°(stream_data, stream_name)
                            else:
                                # ç›´æ¥æ ¼å¼ï¼ˆå–®ä¸€streamï¼‰
                                await self._è™•ç†äº¤æ˜“æµæ›´æ–°(æ•¸æ“š)
                        
                        except asyncio.TimeoutError:
                            # è¶…æ™‚æ˜¯æ­£å¸¸çš„ï¼Œç”¨æ–¼æª¢æŸ¥åœæ­¢ä¿¡è™Ÿ
                            if self.force_stop or not self.é‹è¡Œä¸­:
                                logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ")
                                break
                            continue
                        
                        except websockets.exceptions.ConnectionClosed:
                            logger.warning(f"{é€£æ¥åç¨±} é€£æ¥ä¸­æ–·ï¼Œæº–å‚™é‡é€£...")
                            break
                        except json.JSONDecodeError as e:
                            logger.warning(f"{é€£æ¥åç¨±} JSON è§£æéŒ¯èª¤: {e}")
                            continue
                        except Exception as e:
                            logger.error(f"{é€£æ¥åç¨±} è™•ç†éŒ¯èª¤: {e}")
                            await asyncio.sleep(1)
            
            except Exception as e:
                self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] += 1
                logger.error(f"{é€£æ¥åç¨±} å•Ÿå‹•å¤±æ•— ({self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±]}/{self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸}): {e}")
                
                if self.é€£æ¥éŒ¯èª¤è¨ˆæ•¸[é€£æ¥åç¨±] >= self.æœ€å¤§éŒ¯èª¤æ¬¡æ•¸:
                    logger.critical(f"âŒ {é€£æ¥åç¨±} éŒ¯èª¤æ¬¡æ•¸è¶…é™ï¼Œåœæ­¢é‡é€£")
                    break
                
                await asyncio.sleep(self.éŒ¯èª¤å»¶é²)
        
        logger.info(f"ğŸ›‘ {é€£æ¥åç¨±} å·²åœæ­¢")
    
    async def _è™•ç†åƒ¹æ ¼æ›´æ–°(self, æ•¸æ“š: dict):
        """è™•ç†å³æ™‚åƒ¹æ ¼æ›´æ–°"""
        try:
            # æª¢æŸ¥æ•¸æ“šçµæ§‹
            if 's' not in æ•¸æ“š:
                logger.warning(f"åƒ¹æ ¼æ•¸æ“šç¼ºå°‘äº¤æ˜“å°æ¨™è­˜: {list(æ•¸æ“š.keys())}")
                return
                
            äº¤æ˜“å° = æ•¸æ“š['s']
            if äº¤æ˜“å° not in self.äº¤æ˜“å°åˆ—è¡¨:
                return
            
            # æª¢æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['c', 'P', 'p', 'h', 'l']
            missing_fields = [field for field in required_fields if field not in æ•¸æ“š]
            if missing_fields:
                logger.warning(f"åƒ¹æ ¼æ•¸æ“šç¼ºå°‘å­—æ®µ {missing_fields}: {äº¤æ˜“å°}")
                return
            
            ç•¶å‰åƒ¹æ ¼ = float(æ•¸æ“š['c'])
            åƒ¹æ ¼è®ŠåŒ– = float(æ•¸æ“š['P'])
            
            # è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            æ”¶ç›Šç‡ = åƒ¹æ ¼è®ŠåŒ– / 100  # è½‰æ›ç‚ºå°æ•¸
            å‹•é‡æ–œç‡ = float(æ•¸æ“š['p']) / ç•¶å‰åƒ¹æ ¼
            
            # ä¼°ç®—å·²å¯¦ç¾æ³¢å‹•ç‡
            é«˜åƒ¹ = float(æ•¸æ“š['h'])
            ä½åƒ¹ = float(æ•¸æ“š['l'])
            å·²å¯¦ç¾æ³¢å‹•ç‡ = (é«˜åƒ¹ - ä½åƒ¹) / ç•¶å‰åƒ¹æ ¼
            
            # æ›´æ–°å³æ™‚æ•¸æ“š
            if äº¤æ˜“å° not in self.å³æ™‚æ•¸æ“š:
                self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°] = {}
                
            self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°].update({
                'æ™‚é–“æˆ³': datetime.now(),
                'åƒ¹æ ¼': ç•¶å‰åƒ¹æ ¼,
                'æ”¶ç›Šç‡': æ”¶ç›Šç‡,
                'å·²å¯¦ç¾æ³¢å‹•ç‡': å·²å¯¦ç¾æ³¢å‹•ç‡,
                'å‹•é‡æ–œç‡': å‹•é‡æ–œç‡,
                'æˆäº¤é‡': float(æ•¸æ“š.get('v', 0)),  # ä½¿ç”¨ get é¿å… KeyError
                '24hè®ŠåŒ–': åƒ¹æ ¼è®ŠåŒ–
            })
                
        except KeyError as e:
            logger.error(f"è™•ç†åƒ¹æ ¼æ›´æ–°å¤±æ•—ï¼Œç¼ºå°‘å­—æ®µ: {e}")
        except (ValueError, TypeError) as e:
            logger.error(f"è™•ç†åƒ¹æ ¼æ›´æ–°å¤±æ•—ï¼Œæ•¸æ“šæ ¼å¼éŒ¯èª¤: {e}")
        except Exception as e:
            logger.error(f"è™•ç†åƒ¹æ ¼æ›´æ–°å¤±æ•—: {e}")
            logger.debug(f"åƒ¹æ ¼åŸå§‹æ•¸æ“š: {æ•¸æ“š}")
    
    async def _è™•ç†è¨‚å–®ç°¿æ›´æ–°(self, æ•¸æ“š: dict, stream_name: str = None):
        """è™•ç†å³æ™‚è¨‚å–®ç°¿æ›´æ–°"""
        try:
            # æª¢æŸ¥æ•¸æ“šçµæ§‹ - å°æ–¼è¨‚å–®ç°¿ï¼Œéœ€è¦å¾stream_nameæå–äº¤æ˜“å°
            äº¤æ˜“å° = None
            if 's' in æ•¸æ“š:
                äº¤æ˜“å° = æ•¸æ“š['s']
            elif stream_name:
                # å¾streamåç¨±æå–äº¤æ˜“å°: "btcusdt@depth20@100ms" -> "BTCUSDT"
                äº¤æ˜“å° = stream_name.split('@')[0].upper()
            
            if not äº¤æ˜“å°:
                logger.warning(f"è¨‚å–®ç°¿æ•¸æ“šç„¡æ³•ç¢ºå®šäº¤æ˜“å°: {list(æ•¸æ“š.keys())}")
                return
            
            if äº¤æ˜“å° not in self.äº¤æ˜“å°åˆ—è¡¨:
                return
            
            # æª¢æŸ¥å¿…è¦çš„å­—æ®µ
            if 'bids' not in æ•¸æ“š or 'asks' not in æ•¸æ“š:
                logger.warning(f"è¨‚å–®ç°¿æ•¸æ“šç¼ºå°‘è²·è³£ç›¤: {äº¤æ˜“å°}")
                return
            
            è²·å–® = [(float(åƒ¹æ ¼), float(æ•¸é‡)) for åƒ¹æ ¼, æ•¸é‡ in æ•¸æ“š['bids'][:10] if len([åƒ¹æ ¼, æ•¸é‡]) == 2]
            è³£å–® = [(float(åƒ¹æ ¼), float(æ•¸é‡)) for åƒ¹æ ¼, æ•¸é‡ in æ•¸æ“š['asks'][:10] if len([åƒ¹æ ¼, æ•¸é‡]) == 2]
            
            if è²·å–® and è³£å–®:
                æœ€ä½³è²·åƒ¹ = è²·å–®[0][0]
                æœ€ä½³è³£åƒ¹ = è³£å–®[0][0]
                è²·è³£åƒ¹å·® = (æœ€ä½³è³£åƒ¹ - æœ€ä½³è²·åƒ¹) / æœ€ä½³è³£åƒ¹
                
                # è¨ˆç®—è¨‚å–®ç°¿å£“åŠ›
                ç¸½è²·é‡ = sum(æ•¸é‡ for _, æ•¸é‡ in è²·å–®)
                ç¸½è³£é‡ = sum(æ•¸é‡ for _, æ•¸é‡ in è³£å–®)
                è¨‚å–®ç°¿å£“åŠ› = (ç¸½è²·é‡ - ç¸½è³£é‡) / (ç¸½è²·é‡ + ç¸½è³£é‡) if (ç¸½è²·é‡ + ç¸½è³£é‡) > 0 else 0
                
                # æ›´æ–°è¨‚å–®ç°¿æ•¸æ“š
                self.è¨‚å–®ç°¿æ•¸æ“š[äº¤æ˜“å°] = {
                    'æ™‚é–“æˆ³': datetime.now(),
                    'æœ€ä½³è²·åƒ¹': æœ€ä½³è²·åƒ¹,
                    'æœ€ä½³è³£åƒ¹': æœ€ä½³è³£åƒ¹,
                    'è²·è³£åƒ¹å·®': è²·è³£åƒ¹å·®,
                    'è¨‚å–®ç°¿å£“åŠ›': è¨‚å–®ç°¿å£“åŠ›,
                    'è²·å–®æ·±åº¦': è²·å–®,
                    'è³£å–®æ·±åº¦': è³£å–®
                }
            
        except KeyError as e:
            logger.error(f"è™•ç†è¨‚å–®ç°¿æ›´æ–°å¤±æ•—ï¼Œç¼ºå°‘å­—æ®µ: {e}")
        except (ValueError, TypeError) as e:
            logger.error(f"è™•ç†è¨‚å–®ç°¿æ›´æ–°å¤±æ•—ï¼Œæ•¸æ“šæ ¼å¼éŒ¯èª¤: {e}")
        except Exception as e:
            logger.error(f"è™•ç†è¨‚å–®ç°¿æ›´æ–°å¤±æ•—: {e}")
            # è¨˜éŒ„åŸå§‹æ•¸æ“šç”¨æ–¼èª¿è©¦
            logger.debug(f"è¨‚å–®ç°¿åŸå§‹æ•¸æ“š: {æ•¸æ“š}")
            logger.error(f"è™•ç†è¨‚å–®ç°¿æ›´æ–°å¤±æ•—: {e}")
    
    async def _è™•ç†äº¤æ˜“æµæ›´æ–°(self, æ•¸æ“š: dict, stream_name: str = None):
        """è™•ç†å³æ™‚äº¤æ˜“æµæ›´æ–°"""
        try:
            # æª¢æŸ¥æ•¸æ“šçµæ§‹ - å°æ–¼äº¤æ˜“æµï¼Œéœ€è¦å¾stream_nameæå–äº¤æ˜“å°
            äº¤æ˜“å° = None
            if 's' in æ•¸æ“š:
                äº¤æ˜“å° = æ•¸æ“š['s']
            elif stream_name:
                # å¾streamåç¨±æå–äº¤æ˜“å°: "btcusdt@aggTrade" -> "BTCUSDT"
                äº¤æ˜“å° = stream_name.split('@')[0].upper()
            
            if not äº¤æ˜“å°:
                logger.warning(f"äº¤æ˜“æµæ•¸æ“šç„¡æ³•ç¢ºå®šäº¤æ˜“å°: {list(æ•¸æ“š.keys())}")
                return
                
            if äº¤æ˜“å° not in self.äº¤æ˜“å°åˆ—è¡¨:
                return
            
            # æª¢æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['m', 'q']
            missing_fields = [field for field in required_fields if field not in æ•¸æ“š]
            if missing_fields:
                logger.warning(f"äº¤æ˜“æµæ•¸æ“šç¼ºå°‘å­—æ®µ {missing_fields}: {äº¤æ˜“å°}")
                return
                
            æ˜¯å¦ä¸»å‹•è²·å…¥ = æ•¸æ“š['m']  # True è¡¨ç¤ºä¸»å‹•è³£å‡ºï¼ŒFalse è¡¨ç¤ºä¸»å‹•è²·å…¥
            äº¤æ˜“é‡ = float(æ•¸æ“š['q'])
            
            # ç´¯ç©äº¤æ˜“æµçµ±è¨ˆ
            if äº¤æ˜“å° not in self.äº¤æ˜“æµæ•¸æ“š:
                self.äº¤æ˜“æµæ•¸æ“š[äº¤æ˜“å°] = {
                    'ä¸»å‹•è²·å…¥é‡': 0,
                    'ä¸»å‹•è³£å‡ºé‡': 0,
                    'ç¸½äº¤æ˜“æ¬¡æ•¸': 0,
                    'æ™‚é–“æˆ³': datetime.now()
                }
            
            äº¤æ˜“æµ = self.äº¤æ˜“æµæ•¸æ“š[äº¤æ˜“å°]
            
            if not æ˜¯å¦ä¸»å‹•è²·å…¥:  # ä¸»å‹•è²·å…¥
                äº¤æ˜“æµ['ä¸»å‹•è²·å…¥é‡'] += äº¤æ˜“é‡
            else:  # ä¸»å‹•è³£å‡º
                äº¤æ˜“æµ['ä¸»å‹•è³£å‡ºé‡'] += äº¤æ˜“é‡
            
            äº¤æ˜“æµ['ç¸½äº¤æ˜“æ¬¡æ•¸'] += 1
            äº¤æ˜“æµ['æ™‚é–“æˆ³'] = datetime.now()
            
            # è¨ˆç®—ä¸»å‹•è²·å…¥æ¯”ç‡
            ç¸½äº¤æ˜“é‡ = äº¤æ˜“æµ['ä¸»å‹•è²·å…¥é‡'] + äº¤æ˜“æµ['ä¸»å‹•è³£å‡ºé‡']
            if ç¸½äº¤æ˜“é‡ > 0:
                äº¤æ˜“æµ['ä¸»å‹•è²·å…¥æ¯”ç‡'] = äº¤æ˜“æµ['ä¸»å‹•è²·å…¥é‡'] / ç¸½äº¤æ˜“é‡
            else:
                äº¤æ˜“æµ['ä¸»å‹•è²·å…¥æ¯”ç‡'] = 0.5
                
        except KeyError as e:
            logger.error(f"è™•ç†äº¤æ˜“æµæ›´æ–°å¤±æ•—ï¼Œç¼ºå°‘å­—æ®µ: {e}")
        except (ValueError, TypeError) as e:
            logger.error(f"è™•ç†äº¤æ˜“æµæ›´æ–°å¤±æ•—ï¼Œæ•¸æ“šæ ¼å¼éŒ¯èª¤: {e}")
        except Exception as e:
            logger.error(f"è™•ç†äº¤æ˜“æµæ›´æ–°å¤±æ•—: {e}")
            logger.debug(f"äº¤æ˜“æµåŸå§‹æ•¸æ“š: {æ•¸æ“š}")
    
    async def _è³‡é‡‘è²»ç‡æ›´æ–°å™¨(self):
        """å®šæœŸæ›´æ–°è³‡é‡‘è²»ç‡ - åƒ…é©ç”¨æ–¼æœŸè²¨äº¤æ˜“"""
        while self.é‹è¡Œä¸­:
            try:
                # æª¢æŸ¥æ˜¯å¦æ”¯æ´æœŸè²¨API
                if not hasattr(self.å¹£å®‰API, 'fetch_funding_rate'):
                    logger.info("ğŸ“Š ç¾è²¨äº¤æ˜“æ¨¡å¼ï¼šè·³éè³‡é‡‘è²»ç‡æ›´æ–°")
                    break
                
                if self.å¹£å®‰API:
                    for äº¤æ˜“å° in self.äº¤æ˜“å°åˆ—è¡¨:
                        try:
                            # ä½¿ç”¨æ¨™æº–çš„fetchæ–¹æ³•ç²å–è³‡é‡‘è²»ç‡
                            è³‡é‡‘è²»ç‡æ•¸æ“š = self.å¹£å®‰API.fetch_funding_rate(äº¤æ˜“å°)
                            
                            if äº¤æ˜“å° not in self.å³æ™‚æ•¸æ“š:
                                self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°] = {}
                            
                            self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°]['è³‡é‡‘è²»ç‡'] = float(è³‡é‡‘è²»ç‡æ•¸æ“š['funding_rate'])
                            self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°]['ä¸‹æ¬¡è³‡é‡‘æ™‚é–“'] = int(è³‡é‡‘è²»ç‡æ•¸æ“š['funding_timestamp'])
                            
                        except Exception as e:
                            logger.debug(f"è·³é {äº¤æ˜“å°} è³‡é‡‘è²»ç‡ï¼ˆç¾è²¨äº¤æ˜“ï¼‰")
                
                await asyncio.sleep(300)  # æ¯5åˆ†é˜æ›´æ–°ä¸€æ¬¡
                
            except Exception as e:
                logger.debug(f"è³‡é‡‘è²»ç‡æ›´æ–°å™¨å·²åœç”¨ï¼ˆç¾è²¨æ¨¡å¼ï¼‰")
                break
    
    async def _æœªå¹³å€‰é‡æ›´æ–°å™¨(self):
        """å®šæœŸæ›´æ–°æœªå¹³å€‰é‡ - åƒ…é©ç”¨æ–¼æœŸè²¨äº¤æ˜“"""
        while self.é‹è¡Œä¸­:
            try:
                # æª¢æŸ¥æ˜¯å¦æ”¯æ´æœŸè²¨API
                if not hasattr(self.å¹£å®‰API, 'fetch_open_interest'):
                    logger.info("ğŸ“Š ç¾è²¨äº¤æ˜“æ¨¡å¼ï¼šè·³éæœªå¹³å€‰é‡æ›´æ–°")
                    break
                    
                if self.å¹£å®‰API:
                    for äº¤æ˜“å° in self.äº¤æ˜“å°åˆ—è¡¨:
                        try:
                            # ä½¿ç”¨æ¨™æº–çš„fetchæ–¹æ³•ç²å–æœªå¹³å€‰é‡
                            æœªå¹³å€‰æ•¸æ“š = self.å¹£å®‰API.fetch_open_interest(äº¤æ˜“å°)
                            
                            if äº¤æ˜“å° not in self.å³æ™‚æ•¸æ“š:
                                self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°] = {}
                            
                            self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°]['æœªå¹³å€‰é‡'] = float(æœªå¹³å€‰æ•¸æ“š['open_interest'])
                            
                        except Exception as e:
                            logger.debug(f"è·³é {äº¤æ˜“å°} æœªå¹³å€‰é‡ï¼ˆç¾è²¨äº¤æ˜“ï¼‰")
                
                await asyncio.sleep(300)  # æ¯5åˆ†é˜æ›´æ–°ä¸€æ¬¡
                
            except Exception as e:
                logger.debug(f"æœªå¹³å€‰é‡æ›´æ–°å™¨å·²åœç”¨ï¼ˆç¾è²¨æ¨¡å¼ï¼‰")
                break
    
    def ç²å–å³æ™‚è§€æ¸¬(self, äº¤æ˜“å°: str) -> Optional[å³æ™‚å¸‚å ´è§€æ¸¬]:
        """ç²å–æŒ‡å®šäº¤æ˜“å°çš„å³æ™‚å¸‚å ´è§€æ¸¬"""
        try:
            if äº¤æ˜“å° not in self.å³æ™‚æ•¸æ“š:
                return None
            
            åƒ¹æ ¼æ•¸æ“š = self.å³æ™‚æ•¸æ“š[äº¤æ˜“å°]
            è¨‚å–®ç°¿ = self.è¨‚å–®ç°¿æ•¸æ“š.get(äº¤æ˜“å°, {})
            äº¤æ˜“æµ = self.äº¤æ˜“æµæ•¸æ“š.get(äº¤æ˜“å°, {})
            
            return å³æ™‚å¸‚å ´è§€æ¸¬(
                æ™‚é–“æˆ³=åƒ¹æ ¼æ•¸æ“š.get('æ™‚é–“æˆ³', datetime.now()),
                äº¤æ˜“å°=äº¤æ˜“å°,
                åƒ¹æ ¼=åƒ¹æ ¼æ•¸æ“š.get('åƒ¹æ ¼', 0),
                æˆäº¤é‡=åƒ¹æ ¼æ•¸æ“š.get('æˆäº¤é‡', 0),
                æ”¶ç›Šç‡=åƒ¹æ ¼æ•¸æ“š.get('æ”¶ç›Šç‡', 0),
                å·²å¯¦ç¾æ³¢å‹•ç‡=åƒ¹æ ¼æ•¸æ“š.get('å·²å¯¦ç¾æ³¢å‹•ç‡', 0.01),
                å‹•é‡æ–œç‡=åƒ¹æ ¼æ•¸æ“š.get('å‹•é‡æ–œç‡', 0),
                æœ€ä½³è²·åƒ¹=è¨‚å–®ç°¿.get('æœ€ä½³è²·åƒ¹', 0),
                æœ€ä½³è³£åƒ¹=è¨‚å–®ç°¿.get('æœ€ä½³è³£åƒ¹', 0),
                è²·è³£åƒ¹å·®=è¨‚å–®ç°¿.get('è²·è³£åƒ¹å·®', 0.001),
                è¨‚å–®ç°¿å£“åŠ›=è¨‚å–®ç°¿.get('è¨‚å–®ç°¿å£“åŠ›', 0),
                ä¸»å‹•è²·å…¥æ¯”ç‡=äº¤æ˜“æµ.get('ä¸»å‹•è²·å…¥æ¯”ç‡', 0.5),
                å¤§å–®æµå…¥ç‡=0.0,  # éœ€è¦é¡å¤–è¨ˆç®—
                è³‡é‡‘è²»ç‡=åƒ¹æ ¼æ•¸æ“š.get('è³‡é‡‘è²»ç‡'),
                æœªå¹³å€‰é‡=åƒ¹æ ¼æ•¸æ“š.get('æœªå¹³å€‰é‡')
            )
            
        except Exception as e:
            logger.error(f"ç²å– {äº¤æ˜“å°} å³æ™‚è§€æ¸¬å¤±æ•—: {e}")
            return None
    
    def ç”Ÿæˆé‡å­çµ‚æ¥µä¿¡è™Ÿ(self, äº¤æ˜“å°: str) -> Optional[TradingXä¿¡è™Ÿ]:
        """
        ğŸ¯ ç”Ÿæˆé‡å­çµ‚æ¥µèåˆäº¤æ˜“ä¿¡è™Ÿ
        
        æ•´åˆHMMåˆ¶åº¦è­˜åˆ¥ + é‡å­è®Šåˆ†é æ¸¬ + å‹•æ…‹æ¬Šé‡èåˆ
        """
        try:
            # ç²å–å³æ™‚å¸‚å ´è§€æ¸¬
            è§€æ¸¬ = self.ç²å–å³æ™‚è§€æ¸¬(äº¤æ˜“å°)
            if è§€æ¸¬ is None:
                return None
            
            # ä½¿ç”¨é‡å­çµ‚æ¥µèåˆå¼•æ“ç”Ÿæˆä¿¡è™Ÿ
            èåˆä¿¡è™Ÿ = self.é‡å­çµ‚æ¥µå¼•æ“.generate_ultimate_signal(è§€æ¸¬)
            
            # ç·©å­˜æœ€æ–°ä¿¡è™Ÿ
            self.æœ€æ–°èåˆä¿¡è™Ÿ[äº¤æ˜“å°] = èåˆä¿¡è™Ÿ
            
            return èåˆä¿¡è™Ÿ
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆ {äº¤æ˜“å°} é‡å­çµ‚æ¥µä¿¡è™Ÿå¤±æ•—: {e}")
            return None
    
    def ç²å–æ‰€æœ‰äº¤æ˜“å°ä¿¡è™Ÿ(self) -> Dict[str, TradingXä¿¡è™Ÿ]:
        """ç²å–æ‰€æœ‰äº¤æ˜“å°çš„æœ€æ–°é‡å­çµ‚æ¥µä¿¡è™Ÿ"""
        
        all_signals = {}
        
        for äº¤æ˜“å° in self.äº¤æ˜“å°åˆ—è¡¨:
            try:
                signal = self.ç”Ÿæˆé‡å­çµ‚æ¥µä¿¡è™Ÿ(äº¤æ˜“å°)
                if signal:
                    all_signals[äº¤æ˜“å°] = signal
            except Exception as e:
                logger.error(f"ç²å– {äº¤æ˜“å°} ä¿¡è™Ÿå¤±æ•—: {e}")
        
        return all_signals
    
    def ç²å–å‹•æ…‹æ¬Šé‡ç‹€æ…‹(self) -> Dict[str, Any]:
        """ç²å–å‹•æ…‹æ¬Šé‡èåˆå™¨çš„ç•¶å‰ç‹€æ…‹"""
        
        return self.å‹•æ…‹æ¬Šé‡èåˆå™¨.get_performance_summary()
    
    def è¨“ç·´æ¬Šé‡é æ¸¬æ¨¡å‹(self):
        """è¨“ç·´å‹•æ…‹æ¬Šé‡é æ¸¬æ¨¡å‹"""
        
        try:
            self.å‹•æ…‹æ¬Šé‡èåˆå™¨.train_weight_predictor()
            logger.info("âœ… å‹•æ…‹æ¬Šé‡é æ¸¬æ¨¡å‹è¨“ç·´å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¬Šé‡é æ¸¬æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
    
    def è¨“ç·´é‡å­æ¨¡å‹(self, symbol: str = None, max_iterations: int = 30):
        """
        ğŸ”® è¨“ç·´é‡å­è®Šåˆ†æ¨¡å‹ - BTC_Quantum_Ultimate SPSAè¨“ç·´
        
        åƒæ•¸:
        - symbol: æŒ‡å®šäº¤æ˜“å°ï¼ŒNoneç‚ºè¨“ç·´æ‰€æœ‰
        - max_iterations: æœ€å¤§SPSAè¿­ä»£æ¬¡æ•¸
        """
        if not QUANTUM_LIBS_AVAILABLE:
            logger.warning("é‡å­åº«ä¸å¯ç”¨ï¼Œè·³éé‡å­æ¨¡å‹è¨“ç·´")
            return
        
        symbols_to_train = [symbol] if symbol else self.äº¤æ˜“å°åˆ—è¡¨
        
        for train_symbol in symbols_to_train:
            logger.info(f"ğŸ”® é–‹å§‹è¨“ç·´ {train_symbol} çš„é‡å­è®Šåˆ†æ¨¡å‹...")
            
            # æ”¶é›†è¨“ç·´æ•¸æ“š
            feature_data = []
            labels = []
            
            # å¾æ­·å²ä¿¡è™Ÿä¸­æå–ç‰¹å¾µå’Œæ¨™ç±¤
            if len(self.é‡å­çµ‚æ¥µå¼•æ“.feature_history[train_symbol]) >= 20:
                features_list = list(self.é‡å­çµ‚æ¥µå¼•æ“.feature_history[train_symbol])
                
                # æ§‹é€ æ¨™ç±¤ï¼ˆåŸºæ–¼æœªä¾†åƒ¹æ ¼è®ŠåŒ–ï¼‰
                price_history = list(self.é‡å­çµ‚æ¥µå¼•æ“.price_history[train_symbol])
                
                for i in range(len(features_list) - 5):  # ç•™5å€‹æ™‚é–“æ­¥ç”¨æ–¼é æ¸¬
                    if i + 3 < len(price_history):  # ç¢ºä¿æœ‰æœªä¾†åƒ¹æ ¼
                        feature = features_list[i]
                        
                        # è¨ˆç®—æœªä¾†3æœŸçš„æ”¶ç›Šç‡
                        current_price = price_history[i]['price']
                        future_price = price_history[min(i + 3, len(price_history) - 1)]['price']
                        future_return = (future_price - current_price) / current_price
                        
                        # æ¨™ç±¤åŒ–ï¼š0=bear(-2%), 1=neutral, 2=bull(+2%)
                        if future_return > 0.02:
                            label = 2  # bull
                        elif future_return < -0.02:
                            label = 0  # bear
                        else:
                            label = 1  # neutral
                        
                        feature_data.append(feature)
                        labels.append(label)
                
                if len(feature_data) >= 10:
                    # åŸ·è¡ŒSPSAè¨“ç·´
                    best_theta, best_loss = self.é‡å­çµ‚æ¥µå¼•æ“.spsa_optimize_symbol(
                        train_symbol, feature_data, labels, max_iterations
                    )
                    
                    logger.info(f"âœ… {train_symbol} é‡å­æ¨¡å‹è¨“ç·´å®Œæˆï¼Œæå¤±: {best_loss:.6f}")
                else:
                    logger.warning(f"âš ï¸ {train_symbol} è¨“ç·´æ•¸æ“šä¸è¶³ ({len(feature_data)} < 10)")
            else:
                logger.warning(f"âš ï¸ {train_symbol} ç‰¹å¾µæ­·å²ä¸è¶³ï¼Œè·³éè¨“ç·´")
        
        logger.info("ğŸš€ é‡å­æ¨¡å‹æ‰¹é‡è¨“ç·´å®Œæˆ")

    async def åœæ­¢æ•¸æ“šæ”¶é›†(self):
        """åœæ­¢æ‰€æœ‰æ•¸æ“šæ”¶é›†"""
        self.é‹è¡Œä¸­ = False
        logger.info("ğŸ“´ å³æ™‚æ•¸æ“šæ”¶é›†å·²åœæ­¢")

# --------------------------
# Trading X ä¿¡è™Ÿè¼¸å‡ºå™¨
# --------------------------

class TradingXä¿¡è™Ÿè¼¸å‡ºå™¨:
    """
    Trading X ç³»çµ±ä¿¡è™Ÿè¼¸å‡ºå™¨
    
    å°‡é‡å­åˆ†æçµæœè½‰æ›ç‚º Trading X ç³»çµ±å¯ç”¨çš„ä¿¡è™Ÿæ ¼å¼
    """
    
    def __init__(self):
        self.åˆ¶åº¦åç¨±æ˜ å°„ = {
            0: "ç‰›å¸‚åˆ¶åº¦",
            1: "ç†Šå¸‚åˆ¶åº¦", 
            2: "é«˜æ³¢å‹•åˆ¶åº¦",
            3: "ä½æ³¢å‹•åˆ¶åº¦",
            4: "æ©«ç›¤åˆ¶åº¦",
            5: "å´©ç›¤åˆ¶åº¦"
        }
        
        self.é¢¨éšªä¿‚æ•¸ = {
            0: 1.2,  # ç‰›å¸‚
            1: 1.5,  # ç†Šå¸‚  
            2: 2.0,  # é«˜æ³¢å‹•
            3: 0.8,  # ä½æ³¢å‹•
            4: 1.0,  # æ©«ç›¤
            5: 3.0   # å´©ç›¤
        }
    
    def ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ(self, 
                     è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬,
                     é‡å­æ±ºç­–: 'QuantumSignalDecision',
                     åˆ¶åº¦æ¦‚ç‡: np.ndarray) -> TradingXä¿¡è™Ÿ:
        """
        å°‡é‡å­æ±ºç­–è½‰æ›ç‚º Trading X ä¿¡è™Ÿ
        
        Args:
            è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬
            é‡å­æ±ºç­–: é‡å­ä¿¡è™Ÿæ±ºç­–
            åˆ¶åº¦æ¦‚ç‡: åˆ¶åº¦æ¦‚ç‡åˆ†å¸ƒ
            
        Returns:
            TradingXä¿¡è™Ÿ: æ¨™æº–åŒ–çš„äº¤æ˜“ä¿¡è™Ÿ
        """
        
        # ç¢ºå®šä¿¡è™Ÿé¡å‹
        ä¿¡è™Ÿé¡å‹ = é‡å­æ±ºç­–.action
        if ä¿¡è™Ÿé¡å‹ not in ['LONG', 'SHORT', 'NEUTRAL']:
            ä¿¡è™Ÿé¡å‹ = 'NEUTRAL'
        
        # è¨ˆç®—æœŸæœ›æ”¶ç›Š
        æœŸæœ›æ”¶ç›Š = self._è¨ˆç®—æœŸæœ›æ”¶ç›Š(è§€æ¸¬, é‡å­æ±ºç­–, åˆ¶åº¦æ¦‚ç‡)
        
        # è¨ˆç®—é¢¨éšªè©•ä¼°
        é¢¨éšªè©•ä¼° = self._è¨ˆç®—é¢¨éšªè©•ä¼°(è§€æ¸¬, é‡å­æ±ºç­–)
        
        # è¨ˆç®—æ­¢ææ­¢ç›ˆ
        æ­¢æåƒ¹æ ¼, æ­¢ç›ˆåƒ¹æ ¼ = self._è¨ˆç®—æ­¢ææ­¢ç›ˆ(è§€æ¸¬, ä¿¡è™Ÿé¡å‹, é¢¨éšªè©•ä¼°)
        
        # è¨ˆç®—å»ºè­°å€‰ä½
        æŒå€‰å»ºè­° = self._è¨ˆç®—å»ºè­°å€‰ä½(é‡å­æ±ºç­–, é¢¨éšªè©•ä¼°)
        
        return TradingXä¿¡è™Ÿ(
            æ™‚é–“æˆ³=è§€æ¸¬.æ™‚é–“æˆ³,
            äº¤æ˜“å°=è§€æ¸¬.äº¤æ˜“å°,
            ä¿¡è™Ÿé¡å‹=ä¿¡è™Ÿé¡å‹,
            ä¿¡å¿ƒåº¦=é‡å­æ±ºç­–.confidence,
            åˆ¶åº¦=é‡å­æ±ºç­–.best_regime,
            æœŸæœ›æ”¶ç›Š=æœŸæœ›æ”¶ç›Š,
            é¢¨éšªè©•ä¼°=é¢¨éšªè©•ä¼°,
            é¢¨éšªå ±é…¬æ¯”=é‡å­æ±ºç­–.risk_reward_ratio,
            é€²å ´åƒ¹æ ¼=è§€æ¸¬.åƒ¹æ ¼,
            æ­¢æåƒ¹æ ¼=æ­¢æåƒ¹æ ¼,
            æ­¢ç›ˆåƒ¹æ ¼=æ­¢ç›ˆåƒ¹æ ¼,
            æŒå€‰å»ºè­°=æŒå€‰å»ºè­°,
            åˆ¶åº¦æ¦‚ç‡åˆ†å¸ƒ=åˆ¶åº¦æ¦‚ç‡.tolist(),
            é‡å­è©•åˆ†=é‡å­æ±ºç­–.score,
            å¸‚å ´åˆ¶åº¦åç¨±=self.åˆ¶åº¦åç¨±æ˜ å°„.get(é‡å­æ±ºç­–.best_regime, "æœªçŸ¥"),
            æŠ€è¡“æŒ‡æ¨™={
                'RSI': è§€æ¸¬.RSI_14,
                'å¸ƒæ—å¸¶ä½ç½®': è§€æ¸¬.å¸ƒæ—å¸¶ä½ç½®,
                'å·²å¯¦ç¾æ³¢å‹•ç‡': è§€æ¸¬.å·²å¯¦ç¾æ³¢å‹•ç‡,
                'å‹•é‡æ–œç‡': è§€æ¸¬.å‹•é‡æ–œç‡
            },
            å¸‚å ´å¾®è§€çµæ§‹={
                'è²·è³£åƒ¹å·®': è§€æ¸¬.è²·è³£åƒ¹å·®,
                'è¨‚å–®ç°¿å£“åŠ›': è§€æ¸¬.è¨‚å–®ç°¿å£“åŠ›,
                'ä¸»å‹•è²·å…¥æ¯”ç‡': è§€æ¸¬.ä¸»å‹•è²·å…¥æ¯”ç‡,
                'è³‡é‡‘è²»ç‡': è§€æ¸¬.è³‡é‡‘è²»ç‡ or 0.0,
                'æœªå¹³å€‰é‡': è§€æ¸¬.æœªå¹³å€‰é‡ or 0.0
            }
        )
    
    def _è¨ˆç®—æœŸæœ›æ”¶ç›Š(self, 
                      è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬,
                      é‡å­æ±ºç­–: 'QuantumSignalDecision',
                      åˆ¶åº¦æ¦‚ç‡: np.ndarray) -> float:
        """è¨ˆç®—æœŸæœ›æ”¶ç›Š"""
        
        # åŸºç¤æœŸæœ›æ”¶ç›Šï¼ˆåŸºæ–¼åˆ¶åº¦ï¼‰
        åˆ¶åº¦æœŸæœ›æ”¶ç›Š = {
            0: 0.02,   # ç‰›å¸‚
            1: -0.01,  # ç†Šå¸‚
            2: 0.0,    # é«˜æ³¢å‹•
            3: 0.005,  # ä½æ³¢å‹•  
            4: 0.0,    # æ©«ç›¤
            5: -0.05   # å´©ç›¤
        }
        
        # åŠ æ¬ŠæœŸæœ›æ”¶ç›Š
        æœŸæœ›æ”¶ç›Š = sum(åˆ¶åº¦æ¦‚ç‡[i] * åˆ¶åº¦æœŸæœ›æ”¶ç›Š.get(i, 0) for i in range(len(åˆ¶åº¦æ¦‚ç‡)))
        
        # èª¿æ•´å› å­
        if è§€æ¸¬.è³‡é‡‘è²»ç‡:
            # é«˜è³‡é‡‘è²»ç‡é™ä½æœŸæœ›æ”¶ç›Š
            if abs(è§€æ¸¬.è³‡é‡‘è²»ç‡) > 0.01:
                æœŸæœ›æ”¶ç›Š *= 0.8
        
        if è§€æ¸¬.ä¸»å‹•è²·å…¥æ¯”ç‡:
            # ä¸»å‹•è²·å…¥æ¯”ç‡å½±éŸ¿
            if è§€æ¸¬.ä¸»å‹•è²·å…¥æ¯”ç‡ > 0.6:
                æœŸæœ›æ”¶ç›Š *= 1.1  # è²·ç›¤å¼·å‹
            elif è§€æ¸¬.ä¸»å‹•è²·å…¥æ¯”ç‡ < 0.4:
                æœŸæœ›æ”¶ç›Š *= 0.9  # è³£ç›¤å¼·å‹
        
        return æœŸæœ›æ”¶ç›Š
    
    def _è¨ˆç®—é¢¨éšªè©•ä¼°(self, 
                      è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬,
                      é‡å­æ±ºç­–: 'QuantumSignalDecision') -> float:
        """è¨ˆç®—é¢¨éšªè©•ä¼°"""
        
        åŸºç¤é¢¨éšª = è§€æ¸¬.å·²å¯¦ç¾æ³¢å‹•ç‡
        åˆ¶åº¦é¢¨éšªä¿‚æ•¸ = self.é¢¨éšªä¿‚æ•¸.get(é‡å­æ±ºç­–.best_regime, 1.0)
        
        # èª¿æ•´é¢¨éšª
        èª¿æ•´é¢¨éšª = åŸºç¤é¢¨éšª * åˆ¶åº¦é¢¨éšªä¿‚æ•¸
        
        # è²·è³£åƒ¹å·®å½±éŸ¿
        if è§€æ¸¬.è²·è³£åƒ¹å·® > 0.005:  # é«˜åƒ¹å·®å¢åŠ é¢¨éšª
            èª¿æ•´é¢¨éšª *= 1.2
        
        # è¨‚å–®ç°¿æ·±åº¦å½±éŸ¿
        if abs(è§€æ¸¬.è¨‚å–®ç°¿å£“åŠ›) > 0.3:  # è¨‚å–®ç°¿ä¸å¹³è¡¡å¢åŠ é¢¨éšª
            èª¿æ•´é¢¨éšª *= 1.1
        
        return èª¿æ•´é¢¨éšª
    
    def _è¨ˆç®—æ­¢ææ­¢ç›ˆ(self, 
                      è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬,
                      ä¿¡è™Ÿé¡å‹: str,
                      é¢¨éšªè©•ä¼°: float) -> Tuple[Optional[float], Optional[float]]:
        """è¨ˆç®—æ­¢ææ­¢ç›ˆåƒ¹æ ¼"""
        
        if ä¿¡è™Ÿé¡å‹ == 'NEUTRAL':
            return None, None
        
        ç•¶å‰åƒ¹æ ¼ = è§€æ¸¬.åƒ¹æ ¼
        
        # å‹•æ…‹æ­¢æå¹…åº¦ï¼ˆåŸºæ–¼æ³¢å‹•ç‡ï¼‰
        æ­¢æå¹…åº¦ = max(é¢¨éšªè©•ä¼° * 2, 0.01)  # æœ€å°1%
        æ­¢ç›ˆå¹…åº¦ = æ­¢æå¹…åº¦ * 2.5  # é¢¨éšªå ±é…¬æ¯” 2.5:1
        
        if ä¿¡è™Ÿé¡å‹ == 'LONG':
            æ­¢æåƒ¹æ ¼ = ç•¶å‰åƒ¹æ ¼ * (1 - æ­¢æå¹…åº¦)
            æ­¢ç›ˆåƒ¹æ ¼ = ç•¶å‰åƒ¹æ ¼ * (1 + æ­¢ç›ˆå¹…åº¦)
        else:  # SHORT
            æ­¢æåƒ¹æ ¼ = ç•¶å‰åƒ¹æ ¼ * (1 + æ­¢æå¹…åº¦)
            æ­¢ç›ˆåƒ¹æ ¼ = ç•¶å‰åƒ¹æ ¼ * (1 - æ­¢ç›ˆå¹…åº¦)
        
        return æ­¢æåƒ¹æ ¼, æ­¢ç›ˆåƒ¹æ ¼
    
    def _è¨ˆç®—å»ºè­°å€‰ä½(self, 
                      é‡å­æ±ºç­–: 'QuantumSignalDecision',
                      é¢¨éšªè©•ä¼°: float) -> float:
        """è¨ˆç®—å»ºè­°å€‰ä½å¤§å°"""
        
        if é‡å­æ±ºç­–.action == 'NEUTRAL':
            return 0.0
        
        # åŸºæ–¼ä¿¡å¿ƒåº¦å’Œé¢¨éšªçš„å€‰ä½è¨ˆç®—
        åŸºç¤å€‰ä½ = é‡å­æ±ºç­–.confidence * 0.1  # æœ€å¤§10%
        
        # é¢¨éšªèª¿æ•´
        é¢¨éšªèª¿æ•´å€‰ä½ = åŸºç¤å€‰ä½ * (0.02 / max(é¢¨éšªè©•ä¼°, 0.01))
        
        # é™åˆ¶å€‰ä½ç¯„åœ
        return np.clip(é¢¨éšªèª¿æ•´å€‰ä½, 0.0, 0.1)  # 0-10%


# ==================================================================================
# ğŸ”¥ é‡å­çµ‚æ¥µèåˆä¿¡è™Ÿç”Ÿæˆå™¨ - çµ‚æ¥µç‰ˆé‡å­äº¤æ˜“ç³»çµ±
# ==================================================================================

class QuantumUltimateFusionEngine:
    """
    ğŸš€ é‡å­çµ‚æ¥µèåˆå¼•æ“ - å®Œæ•´ç‰ˆ BTC_Quantum_Ultimate_Model æ•´åˆ
    
    æ•´åˆåŠŸèƒ½:
    - å¯¦æ™‚HMMåˆ¶åº¦è­˜åˆ¥ (regime_hmm_quantum)
    - é‡å­è®Šåˆ†å­¸ç¿’é æ¸¬ (å®Œæ•´BTC_Quantum_Ultimate)
    - å‹•æ…‹æ¬Šé‡è‡ªé©æ‡‰èåˆ
    - å¤šæ™‚é–“å°ºåº¦ç‰¹å¾µæå– [å‹•é‡, æ³¢å‹•ç‡, å‡å€¼, ååº¦, å³°åº¦] Ã— 3æ™‚é–“å°ºåº¦
    - ä¸ƒå¤§å¹£ç¨®åŒæ­¥åˆ†æ
    - å®Œæ•´Qiskitå¯¦ç¾ï¼šfeature â†’ Hamiltonian â†’ é‡å­æ¼”åŒ– â†’ SPSAè¨“ç·´
    """
    
    def __init__(self, symbols: List[str]):
        self.symbols = symbols
        self.n_regimes = 6
        self.feature_window = 30
        
        # BTC_Quantum_Ultimate æ ¸å¿ƒåƒæ•¸
        self.quantum_config = {
            'N_FEATURE_QUBITS': 6,
            'N_READOUT': 3,  # bear/neutral/bull
            'N_ANSATZ_LAYERS': 3,
            'ENCODING': 'multi-scale',  # 'angle' | 'amplitude' | 'multi-scale'
            'USE_STATEVECTOR': False,
            'SHOTS': 1024,
            'SPSA_ITER': 50,  # ç”Ÿç”¢ç’°å¢ƒé©ä¸­å€¼
            'SPSA_SETTINGS': {'a':0.4, 'c':0.15, 'A':20, 'alpha':0.602, 'gamma':0.101},
            'NOISE_MODEL': True,
            'DEPOLARIZING_PROB': 0.002,
            'THERMAL_PARAMS': {'T1':50e3, 'T2':70e3, 'time':50}
        }
        
        # å‹•æ…‹æ¬Šé‡èåˆå™¨
        self.weight_fusion = DynamicWeightFusion()
        
        # å¤šå°ºåº¦ç‰¹å¾µæå–å™¨
        self.feature_extractor = MultiScaleFeatureExtractor()
        
        # é‡å­è®Šåˆ†æ¨¡å‹ï¼ˆæ¯å€‹å¹£ç¨®ä¸€å€‹ï¼‰
        self.quantum_models = {}
        self.hmm_models = {}
        
        # é‡å­é›»è·¯åƒæ•¸ï¼ˆæ¯å€‹å¹£ç¨®ï¼‰
        self.quantum_params = {}
        self.feature_scalers = {}
        self.feature_pcas = {}
        
        # æ­·å²æ•¸æ“šç·©å­˜
        self.price_history = {symbol: deque(maxlen=200) for symbol in symbols}
        self.feature_history = {symbol: deque(maxlen=100) for symbol in symbols}
        self.signal_history = {symbol: deque(maxlen=50) for symbol in symbols}
        
        # æ€§èƒ½è¿½è¹¤
        self.performance_tracker = {symbol: deque(maxlen=100) for symbol in symbols}
        
        # å™ªè²æ¨¡å‹
        self.noise_model = self._build_noise_model() if QUANTUM_LIBS_AVAILABLE else None
        
        # åˆå§‹åŒ–æ¯å€‹å¹£ç¨®çš„é‡å­æ¨¡å‹
        self._initialize_quantum_models()
        
        logger.info(f"ğŸš€ é‡å­çµ‚æ¥µèåˆå¼•æ“åˆå§‹åŒ–å®Œæˆ - ç›£æ§ {len(symbols)} å€‹äº¤æ˜“å°")
        logger.info(f"ğŸ”® é‡å­è¨ˆç®—å¯ç”¨: {QUANTUM_LIBS_AVAILABLE}")
    
    def _build_noise_model(self):
        """æ§‹å»ºé‡å­å™ªè²æ¨¡å‹"""
        if not QUANTUM_LIBS_AVAILABLE:
            return None
            
        noise = NoiseModel()
        total_qubits = self.quantum_config['N_FEATURE_QUBITS'] + self.quantum_config['N_READOUT']
        
        # å–®é‡å­ä½å’Œé›™é‡å­ä½å»æ¥µåŒ–éŒ¯èª¤
        single_err = depolarizing_error(self.quantum_config['DEPOLARIZING_PROB'], 1)
        two_err = depolarizing_error(self.quantum_config['DEPOLARIZING_PROB'] * 2, 2)
        
        noise.add_all_qubit_quantum_error(single_err, ['ry', 'rz'])
        noise.add_all_qubit_quantum_error(two_err, ['cx'])
        
        return noise
    
    def _initialize_quantum_models(self):
        """åˆå§‹åŒ–æ¯å€‹äº¤æ˜“å°çš„é‡å­æ¨¡å‹"""
        for symbol in self.symbols:
            # åˆå§‹åŒ–é‡å­è®Šåˆ†åƒæ•¸
            total_qubits = self.quantum_config['N_FEATURE_QUBITS'] + self.quantum_config['N_READOUT']
            param_count = self.quantum_config['N_ANSATZ_LAYERS'] * total_qubits * 2
            
            self.quantum_params[symbol] = 0.01 * np.random.randn(param_count)
            
            # åˆå§‹åŒ–ç‰¹å¾µé è™•ç†å™¨
            self.feature_scalers[symbol] = StandardScaler()
            self.feature_pcas[symbol] = PCA(n_components=self.quantum_config['N_FEATURE_QUBITS'])
            
            logger.info(f"ğŸ”® {symbol} é‡å­æ¨¡å‹åˆå§‹åŒ–: {param_count} å€‹åƒæ•¸")
    
    def extract_ultimate_features(self, observation: å³æ™‚å¸‚å ´è§€æ¸¬) -> np.ndarray:
        """
        ğŸ”¬ æå–çµ‚æ¥µç‰¹å¾µé›†åˆ - ç²¾ç¢ºå¯¦ç¾BTC_Quantum_Ultimateæ ¼å¼
        
        åŒ…å«:
        - å¤šæ™‚é–“å°ºåº¦ç‰¹å¾µ [å‹•é‡, æ³¢å‹•ç‡, å‡å€¼, ååº¦, å³°åº¦] Ã— 3å€‹æ™‚é–“å°ºåº¦ (5/20/60)
        - æ³¢å‹•ç‡æ¯”ç‡ + è¨‚å–®ç°¿ä¸å¹³è¡¡ + è³‡é‡‘è²»ç‡
        - ç„¡ç°¡åŒ–ã€ç„¡æ¨¡æ“¬æ•¸æ“š
        """
        
        symbol = observation.äº¤æ˜“å°
        
        # æ›´æ–°åƒ¹æ ¼æ­·å²
        self.price_history[symbol].append({
            'timestamp': observation.æ™‚é–“æˆ³,
            'price': observation.åƒ¹æ ¼,
            'volume': observation.æˆäº¤é‡,
            'return': observation.æ”¶ç›Šç‡
        })
        
        if len(self.price_history[symbol]) < 60:
            # æ•¸æ“šä¸è¶³ï¼Œè¿”å›é›¶ç‰¹å¾µ
            return np.zeros(18)  # 5*3 + 3å€‹é¡å¤–ç‰¹å¾µ
        
        # ç²å–åƒ¹æ ¼åºåˆ—
        price_data = list(self.price_history[symbol])
        returns = [p['return'] for p in price_data if p['return'] is not None]
        
        if len(returns) < 60:
            return np.zeros(18)
        
        features = []
        
        # 1. å¤šæ™‚é–“å°ºåº¦ç‰¹å¾µ: [å‹•é‡, æ³¢å‹•ç‡, å‡å€¼, ååº¦, å³°åº¦] Ã— 3å€‹æ™‚é–“å°ºåº¦
        scales = [5, 20, 60]
        
        for scale in scales:
            if len(returns) >= scale:
                window_returns = np.array(returns[-scale:])
                
                # å‹•é‡ (æœ€æ–°å›å ±)
                momentum = window_returns[-1] if len(window_returns) > 0 else 0.0
                
                # æ³¢å‹•ç‡ (æ¨™æº–å·®)
                volatility = np.std(window_returns) if len(window_returns) > 1 else 0.0
                
                # å‡å€¼
                mean_return = np.mean(window_returns) if len(window_returns) > 0 else 0.0
                
                # ååº¦ (skewness)
                if len(window_returns) >= 3:
                    skewness = self._calculate_skewness(window_returns)
                else:
                    skewness = 0.0
                
                # å³°åº¦ (kurtosis)
                if len(window_returns) >= 4:
                    kurtosis = self._calculate_kurtosis(window_returns)
                else:
                    kurtosis = 0.0
                
                features.extend([momentum, volatility, mean_return, skewness, kurtosis])
            else:
                features.extend([0.0, 0.0, 0.0, 0.0, 0.0])
        
        # 2. æ³¢å‹•ç‡æ¯”ç‡ (çŸ­æœŸæ³¢å‹•ç‡ / ä¸­æœŸæ³¢å‹•ç‡)
        if len(returns) >= 20:
            short_vol = np.std(returns[-5:]) if len(returns) >= 5 else 0.0
            med_vol = np.std(returns[-20:]) if len(returns) >= 20 else 0.0
            vol_ratio = short_vol / (med_vol + 1e-8) if med_vol > 0 else 1.0
        else:
            vol_ratio = 1.0
        
        features.append(vol_ratio)
        
        # 3. è¨‚å–®ç°¿ä¸å¹³è¡¡ (å¯¦æ™‚æ•¸æ“š)
        orderbook_imbalance = observation.è¨‚å–®ç°¿å£“åŠ› or 0.0
        features.append(orderbook_imbalance)
        
        # 4. è³‡é‡‘è²»ç‡ (å¯¦æ™‚æ•¸æ“š)
        funding_rate = observation.è³‡é‡‘è²»ç‡ or 0.0
        features.append(funding_rate)
        
        return np.array(features)
    
    def _calculate_skewness(self, data: np.ndarray) -> float:
        """è¨ˆç®—ååº¦"""
        if len(data) < 3:
            return 0.0
        
        mean = np.mean(data)
        std = np.std(data)
        
        if std == 0:
            return 0.0
        
        n = len(data)
        skew = np.sum(((data - mean) / std) ** 3) / n
        return float(skew)
    
    def _calculate_kurtosis(self, data: np.ndarray) -> float:
        """è¨ˆç®—å³°åº¦"""
        if len(data) < 4:
            return 0.0
        
        mean = np.mean(data)
        std = np.std(data)
        
        if std == 0:
            return 0.0
        
        n = len(data)
        kurt = np.sum(((data - mean) / std) ** 4) / n - 3.0  # æ¸›å»3å¾—åˆ°è¶…å³­åº¦
        return float(kurt)
    
    def feature_to_hamiltonian(self, feature_vec: np.ndarray, n_qubits: int) -> Tuple[np.ndarray, np.ndarray]:
        """
        ç‰¹å¾µ â†’ Hamiltonian æ˜ å°„ (ç²¾ç¢ºå¯¦ç¾BTC_Quantum_Ultimateæ–¹æ³•)
        
        è¿”å›:
        - h: å–®é‡å­ä½é … (local fields)
        - J: é›™é‡å­ä½è€¦åˆé … (coupling matrix)
        """
        # æ¨™æº–åŒ–ç‰¹å¾µå‘é‡
        v = np.zeros(n_qubits)
        v[:min(len(feature_vec), n_qubits)] = feature_vec[:n_qubits]
        
        # æ­£è¦åŒ–
        if np.linalg.norm(v) > 0:
            v = v / np.linalg.norm(v)
        
        # h: ç·šæ€§ + éç·šæ€§è®Šæ› (physics-inspired)
        h = 0.6 * v + 0.4 * np.tanh(v)
        
        # J: å¤šå°ºåº¦å¤–ç© + è·é›¢è¡°æ¸›
        J = np.outer(v, v) * 0.25
        
        # è·é›¢è¡°æ¸› (é‡å­ä½ç´¢å¼•ä»£è¡¨é »ç‡å¸¶)
        for i in range(n_qubits):
            for j in range(n_qubits):
                dist = abs(i - j)
                J[i, j] *= math.exp(-0.5 * dist)
        
        # å°è§’ç·šæ¸…é›¶
        np.fill_diagonal(J, 0.0)
        
        return h, J
    
    def angle_encoding(self, qc: QuantumCircuit, qubit_indices: List[int], features: np.ndarray, scale=1.0):
        """è§’åº¦ç·¨ç¢¼"""
        for i, q in enumerate(qubit_indices):
            if i < len(features):
                angle = float(features[i]) * scale
                qc.ry(angle, q)
    
    def amplitude_encoding(self, qc: QuantumCircuit, qubit_indices: List[int], features: np.ndarray):
        """æŒ¯å¹…ç·¨ç¢¼"""
        vec = np.zeros(2 ** len(qubit_indices))
        vec[:len(features)] = features
        vec = vec / (np.linalg.norm(vec) + 1e-12)
        qc.initialize(vec, qubit_indices)
    
    def multi_scale_encoding(self, qc: QuantumCircuit, qubit_indices: List[int], features: np.ndarray):
        """å¤šå°ºåº¦ç·¨ç¢¼"""
        half = len(qubit_indices) // 2
        f1 = np.zeros(half)
        f2 = np.zeros(len(qubit_indices) - half)
        
        f1[:min(len(features), half)] = features[:half]
        f2[:max(0, min(len(features) - half, len(qubit_indices) - half))] = features[half:half + (len(qubit_indices) - half)]
        
        self.angle_encoding(qc, qubit_indices[:half], f1)
        self.angle_encoding(qc, qubit_indices[half:], f2)
        
        # æ·»åŠ è·¨å­ç¾¤ç³¾çº
        for i in range(min(half, len(qubit_indices) - half)):
            qc.cx(qubit_indices[i], qubit_indices[half + i])
    
    def apply_time_evolution(self, qc: QuantumCircuit, feature_qubits: List[int], h: np.ndarray, J: np.ndarray, dt: float = 0.4, trotter_steps: int = 1):
        """æ‡‰ç”¨æ™‚é–“æ¼”åŒ–"""
        n = len(feature_qubits)
        
        for _ in range(trotter_steps):
            # å–®é‡å­ä½é …
            for i in range(n):
                qc.rz(2 * h[i] * dt, feature_qubits[i])
            
            # é›™é‡å­ä½è€¦åˆé …
            for i in range(n):
                for j in range(i + 1, n):
                    if abs(J[i, j]) > 1e-12:
                        self.apply_zz_interaction(qc, feature_qubits[i], feature_qubits[j], J[i, j] * dt)
    
    def apply_zz_interaction(self, qc: QuantumCircuit, q1: int, q2: int, theta: float):
        """æ‡‰ç”¨ZZäº¤äº’é …"""
        qc.cx(q1, q2)
        qc.rz(2 * theta, q2)
        qc.cx(q1, q2)
    
    def build_variational_ansatz(self, n_qubits: int, n_layers: int, prefix='theta') -> Tuple[QuantumCircuit, ParameterVector]:
        """æ§‹å»ºè®Šåˆ†é‡å­é›»è·¯"""
        if not QUANTUM_LIBS_AVAILABLE:
            return None, None
            
        pcount = n_layers * n_qubits * 2
        params = ParameterVector(prefix, length=pcount)
        qc = QuantumCircuit(n_qubits)
        
        idx = 0
        for _ in range(n_layers):
            # RYå’ŒRZæ—‹è½‰
            for q in range(n_qubits):
                qc.ry(params[idx], q)
                idx += 1
                qc.rz(params[idx], q)
                idx += 1
            
            # ç³¾çºå±¤ï¼ˆéˆå¼ï¼‰
            for q in range(n_qubits - 1):
                qc.cx(q, q + 1)
        
        return qc, params
    
    def statevector_expectation_z(self, statevector: np.ndarray, n_qubits: int, target: int) -> float:
        """è¨ˆç®—ZæœŸæœ›å€¼"""
        exp = 0.0
        dim = len(statevector)
        
        for k in range(dim):
            amp = statevector[k]
            prob = np.abs(amp) ** 2
            bit = (k >> (n_qubits - 1 - target)) & 1
            exp += prob * (1.0 if bit == 0 else -1.0)
        
        return exp
    
    def evaluate_quantum_circuit(self, theta: np.ndarray, feature_vec: np.ndarray, symbol: str) -> Tuple[np.ndarray, np.ndarray]:
        """
        è©•ä¼°é‡å­é›»è·¯ - å®Œæ•´BTC_Quantum_Ultimateå¯¦ç¾
        
        è¿”å›:
        - probs: åˆ†é¡æ¦‚ç‡ [bear, neutral, bull]
        - expectations: ZæœŸæœ›å€¼
        """
        if not QUANTUM_LIBS_AVAILABLE:
            # å›é€€åˆ°ç¶“å…¸è¿‘ä¼¼
            return self._classical_approximation(feature_vec)
        
        try:
            # ç‰¹å¾µé è™•ç†
            h, J = self.feature_to_hamiltonian(feature_vec, self.quantum_config['N_FEATURE_QUBITS'])
            
            # æ§‹å»ºé‡å­é›»è·¯
            total_qubits = self.quantum_config['N_FEATURE_QUBITS'] + self.quantum_config['N_READOUT']
            feat_idx = list(range(self.quantum_config['N_FEATURE_QUBITS']))
            read_idx = list(range(self.quantum_config['N_FEATURE_QUBITS'], total_qubits))
            
            qc = QuantumCircuit(total_qubits)
            
            # ç‰¹å¾µç·¨ç¢¼
            encoding = self.quantum_config['ENCODING']
            if encoding == 'angle':
                self.angle_encoding(qc, feat_idx, feature_vec[:self.quantum_config['N_FEATURE_QUBITS']])
            elif encoding == 'amplitude':
                self.amplitude_encoding(qc, feat_idx, feature_vec)
            elif encoding == 'multi-scale':
                self.multi_scale_encoding(qc, feat_idx, feature_vec)
            
            # æ™‚é–“æ¼”åŒ–
            self.apply_time_evolution(qc, feat_idx, h, J)
            
            # è®Šåˆ†é‡å­é›»è·¯
            ansatz_circ, param_vector = self.build_variational_ansatz(
                total_qubits, 
                self.quantum_config['N_ANSATZ_LAYERS']
            )
            
            if ansatz_circ is not None:
                qc.compose(ansatz_circ, inplace=True)
                
                # ç¶å®šåƒæ•¸
                bind_dict = {param_vector[i]: float(theta[i]) for i in range(len(theta))}
                qc = qc.bind_parameters(bind_dict)
            
            # åŸ·è¡Œé›»è·¯
            if self.quantum_config['USE_STATEVECTOR']:
                return self._run_statevector(qc, read_idx, total_qubits)
            else:
                return self._run_shot_based(qc, read_idx)
                
        except Exception as e:
            logger.warning(f"é‡å­é›»è·¯è©•ä¼°å¤±æ•—: {e}, ä½¿ç”¨ç¶“å…¸è¿‘ä¼¼")
            return self._classical_approximation(feature_vec)
    
    def _run_statevector(self, qc: QuantumCircuit, read_idx: List[int], total_qubits: int) -> Tuple[np.ndarray, np.ndarray]:
        """é‹è¡Œç‹€æ…‹å‘é‡æ¨¡æ“¬"""
        sim = Aer.get_backend('aer_simulator')
        qc_sv = qc.copy()
        qc_sv.save_statevector()
        
        t_qc = transpile(qc_sv, sim)
        res = sim.run(t_qc).result()
        sv = res.get_statevector(t_qc)
        
        exps = [self.statevector_expectation_z(sv, total_qubits, r) for r in read_idx]
        p_ones = np.array([(1.0 - e) / 2.0 for e in exps])
        probs = self._softmax(p_ones)
        
        return probs, np.array(exps)
    
    def _run_shot_based(self, qc: QuantumCircuit, read_idx: List[int]) -> Tuple[np.ndarray, np.ndarray]:
        """é‹è¡ŒåŸºæ–¼æ¸¬é‡çš„æ¨¡æ“¬"""
        # æ·»åŠ æ¸¬é‡
        creg = ClassicalRegister(len(read_idx))
        qc.add_register(creg)
        
        for i, r in enumerate(read_idx):
            qc.measure(r, i)
        
        sim = Aer.get_backend('aer_simulator')
        t_qc = transpile(qc, sim)
        
        job = sim.run(t_qc, shots=self.quantum_config['SHOTS'], noise_model=self.noise_model)
        counts = job.result().get_counts()
        
        # è¨ˆç®—æœŸæœ›å€¼
        exps = [0.0] * len(read_idx)
        total_shots = 0
        
        for bitstr, count in counts.items():
            total_shots += count
            bs = bitstr.replace(' ', '')[::-1]
            
            for i in range(len(read_idx)):
                if i < len(bs):
                    bit = int(bs[i])
                    exps[i] += count * (1.0 if bit == 0 else -1.0)
        
        exps = [e / total_shots for e in exps]
        p_ones = np.array([(1.0 - e) / 2.0 for e in exps])
        probs = self._softmax(p_ones)
        
        return probs, np.array(exps)
    
    def _classical_approximation(self, feature_vec: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """ç¶“å…¸è¿‘ä¼¼ï¼ˆé‡å­åº«ä¸å¯ç”¨æ™‚ï¼‰"""
        # åŸºæ–¼ç‰¹å¾µçš„ç°¡å–®é‚è¼¯
        momentum_signal = np.mean(feature_vec[:5]) if len(feature_vec) >= 5 else 0
        volatility_signal = np.mean(feature_vec[5:10]) if len(feature_vec) >= 10 else 0
        
        if momentum_signal > 0.01:
            probs = np.array([0.2, 0.3, 0.5])  # åå‘å¤šé ­
        elif momentum_signal < -0.01:
            probs = np.array([0.5, 0.3, 0.2])  # åå‘ç©ºé ­
        else:
            probs = np.array([0.3, 0.4, 0.3])  # ä¸­æ€§
        
        # æ·»åŠ æ³¢å‹•ç‡èª¿æ•´
        if volatility_signal > 0.03:
            probs = probs * 0.8 + np.array([0.4, 0.4, 0.2]) * 0.2  # é«˜æ³¢å‹•åå‘è§€æœ›
        
        exps = 2 * probs - 1  # è½‰æ›ç‚ºæœŸæœ›å€¼
        return probs, exps
    
    def _softmax(self, x: np.ndarray) -> np.ndarray:
        """Softmaxå‡½æ•¸"""
        ex = np.exp(x - np.max(x))
        return ex / (np.sum(ex) + 1e-12)
    
    def cross_entropy_loss(self, probs: np.ndarray, label_onehot: np.ndarray, eps=1e-12) -> float:
        """äº¤å‰ç†µæå¤±"""
        return -np.sum(label_onehot * np.log(probs + eps))
    
    def spsa_optimize_symbol(self, symbol: str, feature_data: List[np.ndarray], labels: List[int], iterations: int = None) -> Tuple[np.ndarray, float]:
        """
        å°ç‰¹å®šäº¤æ˜“å°é€²è¡ŒSPSAå„ªåŒ–
        
        åƒæ•¸:
        - symbol: äº¤æ˜“å°
        - feature_data: ç‰¹å¾µæ•¸æ“šåˆ—è¡¨
        - labels: æ¨™ç±¤åˆ—è¡¨ [0=bear, 1=neutral, 2=bull]
        - iterations: SPSAè¿­ä»£æ¬¡æ•¸
        
        è¿”å›:
        - best_theta: æœ€ä½³åƒæ•¸
        - best_loss: æœ€ä½³æå¤±
        """
        if not QUANTUM_LIBS_AVAILABLE or len(feature_data) < 10:
            logger.warning(f"{symbol}: é‡å­åº«ä¸å¯ç”¨æˆ–æ•¸æ“šä¸è¶³ï¼Œè·³éSPSAè¨“ç·´")
            return self.quantum_params[symbol], float('inf')
        
        iterations = iterations or self.quantum_config['SPSA_ITER']
        theta = self.quantum_params[symbol].copy()
        dim = len(theta)
        
        # SPSAåƒæ•¸
        spsa_settings = self.quantum_config['SPSA_SETTINGS']
        a = spsa_settings['a']
        c = spsa_settings['c']
        A = spsa_settings['A']
        alpha = spsa_settings['alpha']
        gamma = spsa_settings['gamma']
        
        rng = np.random.default_rng(42)
        
        def loss_for_theta(theta_vec):
            """è¨ˆç®—çµ¦å®šåƒæ•¸ä¸‹çš„æå¤±"""
            losses = []
            for i in range(min(len(feature_data), 50)):  # é™åˆ¶æ‰¹æ¬¡å¤§å°
                feat = feature_data[i]
                lab = labels[i]
                
                probs, _ = self.evaluate_quantum_circuit(theta_vec, feat, symbol)
                label_onehot = np.zeros(3)
                label_onehot[lab] = 1.0
                
                losses.append(self.cross_entropy_loss(probs, label_onehot))
            
            return float(np.mean(losses)) if losses else float('inf')
        
        best_theta = theta.copy()
        best_loss = loss_for_theta(theta)
        
        logger.info(f"ğŸ”® {symbol} SPSAè¨“ç·´é–‹å§‹: åˆå§‹æå¤± {best_loss:.6f}")
        
        for k in range(1, iterations + 1):
            ak = a / ((k + A) ** alpha)
            ck = c / (k ** gamma)
            
            delta = rng.choice([1, -1], size=dim)
            
            thetap = theta + ck * delta
            thetam = theta - ck * delta
            
            lp = loss_for_theta(thetap)
            lm = loss_for_theta(thetam)
            
            ghat = (lp - lm) / (2.0 * ck) * (1.0 / delta)
            theta = theta - ak * ghat
            
            cur_loss = loss_for_theta(theta)
            if cur_loss < best_loss:
                best_loss = cur_loss
                best_theta = theta.copy()
            
            if k % max(1, iterations // 5) == 0:
                logger.info(f"ğŸ”® {symbol} SPSAé€²åº¦ {k}/{iterations}: ç•¶å‰æå¤± {cur_loss:.6f}, æœ€ä½³ {best_loss:.6f}")
        
        self.quantum_params[symbol] = best_theta
        logger.info(f"âœ… {symbol} SPSAè¨“ç·´å®Œæˆ: æœ€çµ‚æå¤± {best_loss:.6f}")
        
        return best_theta, best_loss
    
    def calculate_quantum_signal(self, observation: å³æ™‚å¸‚å ´è§€æ¸¬) -> Dict[str, float]:
        """
        è¨ˆç®—é‡å­è®Šåˆ†ä¿¡è™Ÿ - å®Œæ•´BTC_Quantum_Ultimateå¯¦ç¾
        
        è¿”å›å®Œæ•´çš„é‡å­æ±ºç­–ä¿¡æ¯
        """
        symbol = observation.äº¤æ˜“å°
        
        # æå–ç‰¹å¾µ
        features = self.extract_ultimate_features(observation)
        
        # ç‰¹å¾µé è™•ç†ï¼ˆæ¨™æº–åŒ–å’ŒPCAï¼‰
        if len(self.feature_history[symbol]) > 10:
            # ä½¿ç”¨æ­·å²æ•¸æ“šæ›´æ–°é è™•ç†å™¨
            historical_features = np.array([f for f in self.feature_history[symbol] if f is not None])
            if len(historical_features) >= 5:
                try:
                    self.feature_scalers[symbol].partial_fit(historical_features)
                    features_scaled = self.feature_scalers[symbol].transform([features])[0]
                    
                    # PCAé™ç¶­
                    if hasattr(self.feature_pcas[symbol], 'components_'):
                        features_reduced = self.feature_pcas[symbol].transform([features_scaled])[0]
                    else:
                        # é¦–æ¬¡PCAè¨“ç·´
                        if len(historical_features) >= self.quantum_config['N_FEATURE_QUBITS']:
                            historical_scaled = self.feature_scalers[symbol].transform(historical_features)
                            self.feature_pcas[symbol].fit(historical_scaled)
                            features_reduced = self.feature_pcas[symbol].transform([features_scaled])[0]
                        else:
                            features_reduced = features_scaled[:self.quantum_config['N_FEATURE_QUBITS']]
                            
                except Exception as e:
                    logger.debug(f"{symbol} ç‰¹å¾µé è™•ç†å¤±æ•—: {e}")
                    features_reduced = features[:self.quantum_config['N_FEATURE_QUBITS']]
            else:
                features_reduced = features[:self.quantum_config['N_FEATURE_QUBITS']]
        else:
            features_reduced = features[:self.quantum_config['N_FEATURE_QUBITS']]
        
        # è¨˜éŒ„ç‰¹å¾µæ­·å²
        self.feature_history[symbol].append(features)
        
        # è©•ä¼°é‡å­é›»è·¯
        probs, expectations = self.evaluate_quantum_circuit(
            self.quantum_params[symbol], 
            features_reduced, 
            symbol
        )
        
        # è¨ˆç®—é‡å­ä¿¡è™ŸæŒ‡æ¨™
        quantum_confidence = max(probs) - np.mean(probs)  # æœ€å¤§æ¦‚ç‡èˆ‡å¹³å‡æ¦‚ç‡çš„å·®
        
        # é‡å­ä¿çœŸåº¦ï¼ˆåŸºæ–¼æœŸæœ›å€¼çš„ç©©å®šæ€§ï¼‰
        fidelity = 1.0 - np.std(expectations) / (np.mean(np.abs(expectations)) + 1e-6)
        fidelity = np.clip(fidelity, 0.1, 0.95)
        
        # ä¿¡è™Ÿå¼·åº¦ï¼ˆå¤šé ­æ¦‚ç‡ - ç©ºé ­æ¦‚ç‡ï¼‰
        signal_strength = probs[2] - probs[0]  # bull - bear
        
        # é¢¨éšªå›å ±æ¯”
        expected_vol = observation.å·²å¯¦ç¾æ³¢å‹•ç‡ or 0.02
        risk_reward = abs(signal_strength) / max(expected_vol, 0.01)
        
        # é æ¸¬æ–¹å‘
        best_action = np.argmax(probs)
        action_names = ['BEAR', 'NEUTRAL', 'BULL']
        predicted_action = action_names[best_action]
        
        return {
            'quantum_confidence': float(quantum_confidence),
            'quantum_fidelity': float(fidelity),
            'risk_reward_ratio': float(risk_reward),
            'signal_strength': float(signal_strength),
            'probabilities': probs.tolist(),
            'expectations': expectations.tolist(),
            'predicted_action': predicted_action,
            'bull_probability': float(probs[2]),
            'bear_probability': float(probs[0]),
            'neutral_probability': float(probs[1])
        }
        features.append(observation.RSI_14 or 50.0)           # RSI
        features.append(observation.å¸ƒæ—å¸¶ä½ç½® or 0.5)          # å¸ƒæ—å¸¶ä½ç½®
        features.append(observation.å·²å¯¦ç¾æ³¢å‹•ç‡ or 0.02)       # å·²å¯¦ç¾æ³¢å‹•ç‡
        
        return np.array(features)
    
    def _safe_skew(self, data: List[float]) -> float:
        """å®‰å…¨è¨ˆç®—ååº¦"""
        try:
            if len(data) < 3:
                return 0.0
            return float(stats.skew(data))
        except:
            return 0.0
    
    def _safe_kurt(self, data: List[float]) -> float:
        """å®‰å…¨è¨ˆç®—å³°åº¦"""
        try:
            if len(data) < 4:
                return 0.0
            return float(stats.kurtosis(data))
        except:
            return 0.0
    
    def calculate_regime_signal(self, observation: å³æ™‚å¸‚å ´è§€æ¸¬) -> Dict[str, float]:
        """è¨ˆç®—HMMåˆ¶åº¦ä¿¡è™Ÿ"""
        
        # ç°¡åŒ–ç‰ˆåˆ¶åº¦è­˜åˆ¥ï¼ˆåŸºæ–¼ç•¶å‰å¯¦ç¾ï¼‰
        symbol = observation.äº¤æ˜“å°
        
        # åŸºæ–¼å¸‚å ´å¾®è§€çµæ§‹çš„åˆ¶åº¦æ¨æ–·
        regime_indicators = {
            'volatility': observation.å·²å¯¦ç¾æ³¢å‹•ç‡ or 0.02,
            'orderbook_pressure': observation.è¨‚å–®ç°¿å£“åŠ› or 0.0,
            'funding_rate': observation.è³‡é‡‘è²»ç‡ or 0.0,
            'momentum': observation.å‹•é‡æ–œç‡ or 0.0
        }
        
        # ç°¡åŒ–çš„åˆ¶åº¦æ¦‚ç‡è¨ˆç®—
        vol = regime_indicators['volatility']
        momentum = regime_indicators['momentum']
        
        if vol > 0.04:  # é«˜æ³¢å‹•
            if momentum > 0.01:
                regime_probs = [0.1, 0.1, 0.6, 0.1, 0.1, 0.1]  # é«˜æ³¢å‹•ç‰›å¸‚
            elif momentum < -0.01:
                regime_probs = [0.1, 0.6, 0.1, 0.1, 0.1, 0.1]  # é«˜æ³¢å‹•ç†Šå¸‚
            else:
                regime_probs = [0.1, 0.1, 0.6, 0.1, 0.1, 0.1]  # ç´”é«˜æ³¢å‹•
        elif vol > 0.02:  # æ­£å¸¸æ³¢å‹•
            if momentum > 0.005:
                regime_probs = [0.6, 0.1, 0.1, 0.1, 0.1, 0.1]  # ç‰›å¸‚
            elif momentum < -0.005:
                regime_probs = [0.1, 0.6, 0.1, 0.1, 0.1, 0.1]  # ç†Šå¸‚
            else:
                regime_probs = [0.1, 0.1, 0.1, 0.1, 0.6, 0.1]  # æ©«ç›¤
        else:  # ä½æ³¢å‹•
            regime_probs = [0.1, 0.1, 0.1, 0.6, 0.2, 0.1]  # ä½æ³¢å‹•
        
        best_regime = np.argmax(regime_probs)
        regime_confidence = max(regime_probs)
        
        # è¨ˆç®—åˆ¶åº¦æŒçºŒæ€§ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        if len(self.signal_history[symbol]) > 0:
            last_regime = self.signal_history[symbol][-1].get('regime', best_regime)
            persistence = 0.8 if best_regime == last_regime else 0.3
        else:
            persistence = 0.5
        
        return {
            'regime_probability': regime_confidence,
            'regime_persistence': persistence,
            'best_regime': best_regime,
            'regime_probs': np.array(regime_probs)
        }
    
    def calculate_quantum_signal(self, observation: å³æ™‚å¸‚å ´è§€æ¸¬) -> Dict[str, float]:
        """è¨ˆç®—é‡å­è®Šåˆ†ä¿¡è™Ÿï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        
        # æå–ç‰¹å¾µ
        features = self.extract_ultimate_features(observation)
        
        # ç°¡åŒ–çš„é‡å­ä¿¡è™Ÿè¨ˆç®—ï¼ˆæ¨¡æ“¬é‡å­è®Šåˆ†é›»è·¯è¼¸å‡ºï¼‰
        # åœ¨çœŸå¯¦å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒæ˜¯é‡å­é›»è·¯çš„è¨ˆç®—çµæœ
        
        # ç‰¹å¾µæ¨™æº–åŒ–
        if np.std(features) > 0:
            features_norm = (features - np.mean(features)) / np.std(features)
        else:
            features_norm = features
        
        # æ¨¡æ“¬é‡å­ä¿¡è™Ÿå¼·åº¦è¨ˆç®—
        signal_strength = np.tanh(np.sum(features_norm[:5]))  # åŸºæ–¼å‰5å€‹ç‰¹å¾µ
        confidence = 1 / (1 + np.exp(-abs(signal_strength) * 3))  # Sigmoidè®Šæ›
        
        # æ¨¡æ“¬é‡å­ä¿çœŸåº¦
        fidelity = min(0.95, 0.7 + 0.3 * confidence)
        
        # é¢¨éšªå›å ±æ¯”è¨ˆç®—
        expected_vol = observation.å·²å¯¦ç¾æ³¢å‹•ç‡ or 0.02
        risk_reward = abs(signal_strength) / max(expected_vol, 0.01)
        
        return {
            'quantum_confidence': confidence,
            'quantum_fidelity': fidelity,
            'risk_reward_ratio': risk_reward,
            'signal_strength': signal_strength
        }
    
    def generate_ultimate_signal(self, observation: å³æ™‚å¸‚å ´è§€æ¸¬) -> TradingXä¿¡è™Ÿ:
        """
        ğŸ¯ ç”Ÿæˆçµ‚æ¥µèåˆäº¤æ˜“ä¿¡è™Ÿ - å®Œæ•´BTC_Quantum_Ultimateæ•´åˆ
        
        æµç¨‹:
        1. è¨ˆç®—HMMåˆ¶åº¦ä¿¡è™Ÿ
        2. è¨ˆç®—é‡å­è®Šåˆ†ä¿¡è™Ÿï¼ˆå®Œæ•´Qiskitå¯¦ç¾ï¼‰
        3. å‹•æ…‹æ¬Šé‡èåˆ
        4. ç”Ÿæˆæœ€çµ‚äº¤æ˜“æ±ºç­–
        """
        
        symbol = observation.äº¤æ˜“å°
        
        # 1. è¨ˆç®—åˆ¶åº¦ä¿¡è™Ÿ
        regime_signal = self.calculate_regime_signal(observation)
        
        # 2. è¨ˆç®—é‡å­ä¿¡è™Ÿï¼ˆå®Œæ•´é‡å­é›»è·¯ï¼‰
        quantum_signal = self.calculate_quantum_signal(observation)
        
        # 3. å‹•æ…‹æ¬Šé‡èåˆ
        fusion_result = self.weight_fusion.fuse_signals(
            regime_probability=regime_signal['regime_probability'],
            regime_persistence=regime_signal['regime_persistence'],
            quantum_confidence=quantum_signal['quantum_confidence'],
            quantum_fidelity=quantum_signal['quantum_fidelity'],
            risk_reward_ratio=quantum_signal['risk_reward_ratio']
        )
        
        # 4. ç”Ÿæˆäº¤æ˜“æ±ºç­–ï¼ˆåŸºæ–¼é‡å­æ¦‚ç‡åˆ†ä½ˆï¼‰
        final_confidence = fusion_result['final_confidence']
        
        # ä½¿ç”¨é‡å­æ¦‚ç‡é€²è¡Œæ±ºç­–
        bull_prob = quantum_signal['bull_probability']
        bear_prob = quantum_signal['bear_probability']
        neutral_prob = quantum_signal['neutral_probability']
        
        # æ±ºç­–é‚è¼¯ï¼ˆè€ƒæ…®é‡å­æ¦‚ç‡åˆ†ä½ˆï¼‰
        if final_confidence > 0.7:
            if bull_prob > 0.5 and bull_prob > bear_prob + 0.2:
                signal_type = 'LONG'
            elif bear_prob > 0.5 and bear_prob > bull_prob + 0.2:
                signal_type = 'SHORT'
            else:
                signal_type = 'NEUTRAL'
        elif final_confidence > 0.5:
            # ä¸­ç­‰ä¿¡å¿ƒï¼Œéœ€è¦æ›´å¼·çš„é‡å­ä¿¡è™Ÿ
            if bull_prob > 0.6:
                signal_type = 'LONG'
            elif bear_prob > 0.6:
                signal_type = 'SHORT'
            else:
                signal_type = 'NEUTRAL'
        else:
            signal_type = 'NEUTRAL'  # ä½ä¿¡å¿ƒè§€æœ›
        
        # è¨ˆç®—æœŸæœ›æ”¶ç›Šï¼ˆåŸºæ–¼é‡å­ä¿¡è™Ÿå¼·åº¦ï¼‰
        expected_return = quantum_signal['signal_strength'] * final_confidence * 0.03
        
        # è¨ˆç®—é¢¨éšªè©•ä¼°
        risk_assessment = (
            fusion_result['market_volatility'] * 
            (1 - final_confidence) * 
            fusion_result['risk_multiplier'] *
            (1 - quantum_signal['quantum_fidelity'])  # é‡å­ä¿çœŸåº¦èª¿æ•´
        )
        
        # è¨ˆç®—æ­¢ææ­¢ç›ˆï¼ˆè€ƒæ…®é‡å­é¢¨éšªå›å ±æ¯”ï¼‰
        current_price = observation.åƒ¹æ ¼
        base_risk = max(risk_assessment * 2, 0.01)
        
        # é‡å­é¢¨éšªå›å ±èª¿æ•´
        if quantum_signal['risk_reward_ratio'] > 2.0:
            stop_loss_pct = base_risk * 0.8  # é™ä½æ­¢æ
            take_profit_pct = base_risk * 3.0  # æé«˜æ­¢ç›ˆ
        elif quantum_signal['risk_reward_ratio'] > 1.5:
            stop_loss_pct = base_risk
            take_profit_pct = base_risk * 2.5
        else:
            stop_loss_pct = base_risk * 1.2  # æé«˜æ­¢æ
            take_profit_pct = base_risk * 2.0  # é™ä½æ­¢ç›ˆ
        
        if signal_type == 'LONG':
            stop_loss = current_price * (1 - stop_loss_pct)
            take_profit = current_price * (1 + take_profit_pct)
        elif signal_type == 'SHORT':
            stop_loss = current_price * (1 + stop_loss_pct)
            take_profit = current_price * (1 - take_profit_pct)
        else:
            stop_loss = None
            take_profit = None
        
        # å»ºè­°å€‰ä½ï¼ˆè€ƒæ…®é‡å­ä¿çœŸåº¦ï¼‰
        base_position = final_confidence * 0.1 if signal_type != 'NEUTRAL' else 0.0
        position_size = base_position * quantum_signal['quantum_fidelity']
        
        # å‰µå»ºä¿¡è™Ÿ
        signal = TradingXä¿¡è™Ÿ(
            æ™‚é–“æˆ³=observation.æ™‚é–“æˆ³,
            äº¤æ˜“å°=symbol,
            ä¿¡è™Ÿé¡å‹=signal_type,
            ä¿¡å¿ƒåº¦=final_confidence,
            åˆ¶åº¦=regime_signal['best_regime'],
            æœŸæœ›æ”¶ç›Š=expected_return,
            é¢¨éšªè©•ä¼°=risk_assessment,
            é¢¨éšªå ±é…¬æ¯”=quantum_signal['risk_reward_ratio'],
            é€²å ´åƒ¹æ ¼=current_price,
            æ­¢æåƒ¹æ ¼=stop_loss,
            æ­¢ç›ˆåƒ¹æ ¼=take_profit,
            æŒå€‰å»ºè­°=position_size,
            åˆ¶åº¦æ¦‚ç‡åˆ†å¸ƒ=regime_signal['regime_probs'].tolist(),
            é‡å­è©•åˆ†=quantum_signal['quantum_confidence'],
            å¸‚å ´åˆ¶åº¦åç¨±=self._get_regime_name(regime_signal['best_regime']),
            æŠ€è¡“æŒ‡æ¨™={
                'RSI': observation.RSI_14 or 50.0,
                'å¸ƒæ—å¸¶ä½ç½®': observation.å¸ƒæ—å¸¶ä½ç½® or 0.5,
                'å·²å¯¦ç¾æ³¢å‹•ç‡': observation.å·²å¯¦ç¾æ³¢å‹•ç‡ or 0.02,
                'å‹•é‡æ–œç‡': observation.å‹•é‡æ–œç‡ or 0.0,
                'é‡å­å¤šé ­æ¦‚ç‡': quantum_signal['bull_probability'],
                'é‡å­ç©ºé ­æ¦‚ç‡': quantum_signal['bear_probability'],
                'é‡å­ä¿çœŸåº¦': quantum_signal['quantum_fidelity'],
                'é‡å­é æ¸¬å‹•ä½œ': quantum_signal['predicted_action']
            },
            å¸‚å ´å¾®è§€çµæ§‹={
                'è²·è³£åƒ¹å·®': observation.è²·è³£åƒ¹å·®,
                'è¨‚å–®ç°¿å£“åŠ›': observation.è¨‚å–®ç°¿å£“åŠ› or 0.0,
                'ä¸»å‹•è²·å…¥æ¯”ç‡': observation.ä¸»å‹•è²·å…¥æ¯”ç‡ or 0.5,
                'è³‡é‡‘è²»ç‡': observation.è³‡é‡‘è²»ç‡ or 0.0,
                'æœªå¹³å€‰é‡': observation.æœªå¹³å€‰é‡ or 0.0,
                'åˆ¶åº¦æ¬Šé‡': fusion_result['regime_weight'],
                'é‡å­æ¬Šé‡': fusion_result['quantum_weight'],
                'é‡å­æœŸæœ›å€¼': quantum_signal['expectations'],
                'é‡å­æ¦‚ç‡åˆ†ä½ˆ': quantum_signal['probabilities']
            }
        )
            å¸‚å ´å¾®è§€çµæ§‹={
                'è²·è³£åƒ¹å·®': observation.è²·è³£åƒ¹å·®,
                'è¨‚å–®ç°¿å£“åŠ›': observation.è¨‚å–®ç°¿å£“åŠ› or 0.0,
                'ä¸»å‹•è²·å…¥æ¯”ç‡': observation.ä¸»å‹•è²·å…¥æ¯”ç‡ or 0.5,
                'è³‡é‡‘è²»ç‡': observation.è³‡é‡‘è²»ç‡ or 0.0,
                'æœªå¹³å€‰é‡': observation.æœªå¹³å€‰é‡ or 0.0,
                'åˆ¶åº¦æ¬Šé‡': fusion_result['regime_weight'],
                'é‡å­æ¬Šé‡': fusion_result['quantum_weight']
            }
        )
        
        # è¨˜éŒ„ä¿¡è™Ÿæ­·å²
        self.signal_history[symbol].append({
            'timestamp': observation.æ™‚é–“æˆ³,
            'signal_type': signal_type,
            'confidence': final_confidence,
            'regime': regime_signal['best_regime'],
            'regime_weight': fusion_result['regime_weight'],
            'quantum_weight': fusion_result['quantum_weight']
        })
        
        # æ›´æ–°æ¬Šé‡èåˆå™¨æ€§èƒ½ï¼ˆå¦‚æœæœ‰å¯¦éš›å›å ±æ•¸æ“šï¼‰
        if len(self.signal_history[symbol]) > 1:
            # é€™è£¡å¯ä»¥åŠ å…¥å¯¦éš›å›å ±è¨ˆç®—å’Œæ€§èƒ½æ›´æ–°é‚è¼¯
            pass
        
        return signal
    
    def _get_regime_name(self, regime_idx: int) -> str:
        """ç²å–åˆ¶åº¦åç¨±"""
        regime_names = {
            0: "ç‰›å¸‚åˆ¶åº¦",
            1: "ç†Šå¸‚åˆ¶åº¦", 
            2: "é«˜æ³¢å‹•åˆ¶åº¦",
            3: "ä½æ³¢å‹•åˆ¶åº¦",
            4: "æ©«ç›¤åˆ¶åº¦",
            5: "å´©ç›¤åˆ¶åº¦"
        }
        return regime_names.get(regime_idx, "æœªçŸ¥åˆ¶åº¦")


class MultiScaleFeatureExtractor:
    """å¤šå°ºåº¦ç‰¹å¾µæå–å™¨"""
    
    def __init__(self):
        self.scales = [5, 20, 60]  # çŸ­æœŸã€ä¸­æœŸã€é•·æœŸ
    
    def extract_features(self, price_data: List[Dict]) -> Dict[str, float]:
        """æå–å¤šå°ºåº¦ç‰¹å¾µ"""
        
        if len(price_data) < 5:
            return {}
        
        features = {}
        
        for scale in self.scales:
            if len(price_data) >= scale:
                recent_data = price_data[-scale:]
                prices = [d['price'] for d in recent_data]
                returns = [d['return'] for d in recent_data if d['return'] is not None]
                
                if returns:
                    features[f'mean_return_{scale}'] = np.mean(returns)
                    features[f'volatility_{scale}'] = np.std(returns)
                    features[f'momentum_{scale}'] = returns[-1] if returns else 0
                
                if len(prices) >= 2:
                    features[f'price_change_{scale}'] = (prices[-1] - prices[0]) / prices[0]
        
        return features


@dataclass
class QuantumSignalDecision:
    """é‡å­ä¿¡è™Ÿæ±ºç­–çµæœ"""
    best_regime: int
    action: str  # 'LONG', 'SHORT', 'HOLD'
    confidence: float
    score: float
    all_scores: np.ndarray
    risk_reward_ratio: float
    regime_probs: np.ndarray

class QuantumSignalSelector:
    """
    é‡å­ä¿¡è™Ÿæ€§åƒ¹æ¯”ç¯©é¸å™¨
    
    æ ¸å¿ƒæ¦‚å¿µ: ä¸é æ¸¬å¸‚å ´ï¼Œè€Œæ˜¯åœ¨å¸‚å ´éš¨æ©Ÿåç¸®çš„éç¨‹ä¸­ï¼Œ
    å§‹çµ‚ç«™åœ¨çµ±è¨ˆå„ªå‹¢æœ€å¤§çš„ä¸€é‚Š
    """
    
    def __init__(self, 
                 risk_floor: float = 1e-3,
                 confidence_threshold: float = 0.6,
                 min_risk_reward: float = 1.5):
        """
        åˆå§‹åŒ–é‡å­ä¿¡è™Ÿç¯©é¸å™¨
        
        Args:
            risk_floor: é¢¨éšªä¸‹é™ï¼Œé¿å…é™¤é›¶
            confidence_threshold: æœ€å°ä¿¡å¿ƒåº¦é–¾å€¼
            min_risk_reward: æœ€å°é¢¨éšªå ±é…¬æ¯”
        """
        self.risk_floor = risk_floor
        self.confidence_threshold = confidence_threshold
        self.min_risk_reward = min_risk_reward
        
        # é å®šç¾©åˆ¶åº¦å°æ‡‰çš„é æœŸæ”¶ç›Šå’Œé¢¨éšªç‰¹å¾µ
        self.regime_profiles = {
            0: {"name": "Bull Market", "expected_return": 0.002, "risk": 0.015, "action": "LONG"},
            1: {"name": "Bear Market", "expected_return": -0.001, "risk": 0.025, "action": "SHORT"},
            2: {"name": "High Volatility", "expected_return": 0.0, "risk": 0.04, "action": "HOLD"},
            3: {"name": "Low Volatility", "expected_return": 0.0005, "risk": 0.008, "action": "LONG"},
            4: {"name": "Sideways", "expected_return": 0.0, "risk": 0.018, "action": "HOLD"},
            5: {"name": "Crash", "expected_return": -0.008, "risk": 0.06, "action": "SHORT"}
        }
    
    def update_regime_profiles(self, 
                              regime_idx: int, 
                              observed_return: float, 
                              observed_risk: float,
                              learning_rate: float = 0.1):
        """
        å‹•æ…‹æ›´æ–°åˆ¶åº¦ç‰¹å¾µ (åœ¨ç·šå­¸ç¿’)
        
        Args:
            regime_idx: åˆ¶åº¦ç´¢å¼•
            observed_return: è§€æ¸¬åˆ°çš„æ”¶ç›Šç‡
            observed_risk: è§€æ¸¬åˆ°çš„é¢¨éšª
            learning_rate: å­¸ç¿’ç‡
        """
        if regime_idx in self.regime_profiles:
            profile = self.regime_profiles[regime_idx]
            
            # æŒ‡æ•¸ç§»å‹•å¹³å‡æ›´æ–°
            profile["expected_return"] = (
                (1 - learning_rate) * profile["expected_return"] + 
                learning_rate * observed_return
            )
            profile["risk"] = (
                (1 - learning_rate) * profile["risk"] + 
                learning_rate * observed_risk
            )
    
    def select_quantum_action(self, 
                            regime_probs: np.ndarray,
                            market_condition: Dict[str, float] = None) -> QuantumSignalDecision:
        """
        é‡å­ä¿¡è™Ÿæ±ºç­–æ ¸å¿ƒé‚è¼¯
        
        Args:
            regime_probs: åˆ¶åº¦æ¦‚ç‡åˆ†å¸ƒ np.ndarray (M,)
            market_condition: é¡å¤–å¸‚å ´æ¢ä»¶ (funding_rate, iv_skew, etc.)
            
        Returns:
            QuantumSignalDecision: é‡å­æ±ºç­–çµæœ
        """
        M = len(regime_probs)
        expected_returns = np.zeros(M)
        risks = np.zeros(M)
        
        # æå–æ¯å€‹åˆ¶åº¦çš„é æœŸæ”¶ç›Šå’Œé¢¨éšª
        for i in range(M):
            if i in self.regime_profiles:
                expected_returns[i] = self.regime_profiles[i]["expected_return"]
                risks[i] = self.regime_profiles[i]["risk"]
            else:
                expected_returns[i] = 0.0
                risks[i] = 0.02  # é è¨­é¢¨éšª
        
        # å¸‚å ´æ¢ä»¶èª¿æ•´ (å¦‚æœæä¾›)
        if market_condition:
            expected_returns = self._adjust_for_market_conditions(
                expected_returns, market_condition
            )
        
        # è¨ˆç®—é‡å­ä¿¡è™Ÿè©•åˆ†: (æœŸæœ›æ”¶ç›Š Ã— æ¦‚ç‡) / é¢¨éšª
        scores = (expected_returns * regime_probs) / (risks + self.risk_floor)
        
        # æ‰¾åˆ°æœ€ä½³åˆ¶åº¦
        best_idx = np.argmax(scores)
        best_confidence = regime_probs[best_idx]
        best_score = scores[best_idx]
        
        # æ±ºå®šè¡Œå‹•
        action = "HOLD"  # é è¨­
        risk_reward_ratio = 0.0
        
        if best_confidence >= self.confidence_threshold:
            if best_idx in self.regime_profiles:
                profile = self.regime_profiles[best_idx]
                potential_action = profile["action"]
                
                # è¨ˆç®—é¢¨éšªå ±é…¬æ¯”
                expected_return = expected_returns[best_idx]
                risk = risks[best_idx]
                
                if risk > 0:
                    risk_reward_ratio = abs(expected_return) / risk
                    
                    # åªæœ‰ç•¶é¢¨éšªå ±é…¬æ¯”è¶³å¤ å¥½æ™‚æ‰åŸ·è¡Œå‹•ä½œ
                    if risk_reward_ratio >= self.min_risk_reward:
                        action = potential_action
        
        return QuantumSignalDecision(
            best_regime=best_idx,
            action=action,
            confidence=best_confidence,
            score=best_score,
            all_scores=scores,
            risk_reward_ratio=risk_reward_ratio,
            regime_probs=regime_probs.copy()
        )
    
    def _adjust_for_market_conditions(self, 
                                    expected_returns: np.ndarray,
                                    market_condition: Dict[str, float]) -> np.ndarray:
        """
        æ ¹æ“šé¡å¤–å¸‚å ´æ¢ä»¶èª¿æ•´é æœŸæ”¶ç›Š
        
        Args:
            expected_returns: åŸå§‹é æœŸæ”¶ç›Š
            market_condition: å¸‚å ´æ¢ä»¶å­—å…¸
        """
        adjusted_returns = expected_returns.copy()
        
        # è³‡é‡‘è²»ç‡èª¿æ•´
        if "funding_rate" in market_condition:
            funding_rate = market_condition["funding_rate"]
            if funding_rate > 0.01:  # é«˜è³‡é‡‘è²»ç‡ â†’ éåº¦æ§“æ¡¿åšå¤š
                adjusted_returns[0] *= 0.7  # é™ä½ç‰›å¸‚ä¿¡è™Ÿ
                adjusted_returns[1] *= 1.3  # å¢å¼·ç†Šå¸‚ä¿¡è™Ÿ
        
        # éš±å«æ³¢å‹•ç‡åæ–œèª¿æ•´
        if "iv_skew" in market_condition:
            iv_skew = market_condition["iv_skew"]
            if iv_skew > 0.1:  # é«˜ put skew â†’ ææ…Œæƒ…ç·’
                adjusted_returns[5] *= 1.5  # å¢å¼·å´©ç›¤ä¿¡è™Ÿ
        
        # éˆä¸Šè³‡é‡‘æµèª¿æ•´
        if "net_flow_to_exchanges" in market_condition:
            net_flow = market_condition["net_flow_to_exchanges"]
            if net_flow > 0:  # è³‡é‡‘æµå…¥äº¤æ˜“æ‰€ â†’ æ‹‹å”®å£“åŠ›
                adjusted_returns[1] *= 1.2  # å¢å¼·ç†Šå¸‚ä¿¡è™Ÿ
                adjusted_returns[5] *= 1.2  # å¢å¼·å´©ç›¤ä¿¡è™Ÿ
        
        return adjusted_returns

# --------------------------
# å³æ™‚æµè³‡æ–™é©é…å™¨ (Online Learning)
# --------------------------

class OnlineEMAdaptor:
    """
    å³æ™‚ EM é©é…å™¨
    
    æ”¯æ´æµå¼æ•¸æ“šçš„å¢é‡æ›´æ–°ï¼Œé¿å…æ¯æ¬¡é‡æ–°è¨“ç·´æ•´å€‹æ¨¡å‹
    """
    
    def __init__(self, 
                 learning_rate: float = 0.05,
                 min_update_interval: int = 10,
                 max_memory_length: int = 1000):
        """
        åˆå§‹åŒ–åœ¨ç·šå­¸ç¿’é©é…å™¨
        
        Args:
            learning_rate: å­¸ç¿’ç‡
            min_update_interval: æœ€å°æ›´æ–°é–“éš”
            max_memory_length: æœ€å¤§è¨˜æ†¶é•·åº¦
        """
        self.learning_rate = learning_rate
        self.min_update_interval = min_update_interval
        self.max_memory_length = max_memory_length
        
        # ç´¯ç©çµ±è¨ˆ
        self.update_count = 0
        self.last_update_time = 0
        
        # æ»‘å‹•çª—å£æ•¸æ“š
        self.recent_data = []
        self.recent_regimes = []
    
    def incremental_update(self, 
                          model: 'TimeVaryingHMM',
                          new_x: Dict[str, float],
                          new_z: np.ndarray,
                          current_regime_probs: np.ndarray):
        """
        å¢é‡æ›´æ–°æ¨¡å‹åƒæ•¸
        
        Args:
            model: TimeVaryingHMM æ¨¡å‹å¯¦ä¾‹
            new_x: æ–°çš„è§€æ¸¬é»
            new_z: æ–°çš„å”è®Šé‡
            current_regime_probs: ç•¶å‰åˆ¶åº¦æ¦‚ç‡
        """
        self.update_count += 1
        
        # æ·»åŠ åˆ°æ»‘å‹•çª—å£
        self.recent_data.append(new_x)
        self.recent_regimes.append(current_regime_probs)
        
        # ä¿æŒçª—å£å¤§å°
        if len(self.recent_data) > self.max_memory_length:
            self.recent_data.pop(0)
            self.recent_regimes.pop(0)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        if (self.update_count - self.last_update_time >= self.min_update_interval and
            len(self.recent_data) >= 20):  # è‡³å°‘20å€‹æ¨£æœ¬
            
            self._perform_incremental_em_step(model)
            self.last_update_time = self.update_count
    
    def _perform_incremental_em_step(self, model: 'TimeVaryingHMM'):
        """
        åŸ·è¡Œå¢é‡ EM æ­¥é©Ÿ
        """
        if not self.recent_data:
            return
        
        # è½‰æ›è³‡æ–™æ ¼å¼
        T = len(self.recent_data)
        x_seq = {
            'ret': np.array([d['ret'] for d in self.recent_data]),
            'logvol': np.array([d['logvol'] for d in self.recent_data]),
            'slope': np.array([d['slope'] for d in self.recent_data]),
            'ob': np.array([d['ob'] for d in self.recent_data])
        }
        
        # ä½¿ç”¨æœ€è¿‘çš„åˆ¶åº¦æ¦‚ç‡ä½œç‚ºæ¬Šé‡
        gamma = np.array(self.recent_regimes)  # (T, M)
        
        # å¢é‡æ›´æ–°ç™¼å°„åƒæ•¸
        for h in range(model.M):
            w = gamma[:, h] * self.learning_rate  # é™ä½å­¸ç¿’ç‡
            W = w.sum() + 1e-12
            
            if W > 1e-6:  # æœ‰è¶³å¤ æ¬Šé‡æ™‚æ‰æ›´æ–°
                # æ”¶ç›Šç‡åƒæ•¸æ›´æ–° (æŒ‡æ•¸ç§»å‹•å¹³å‡)
                new_mu_ret = float(np.sum(w * x_seq['ret']) / W)
                model.emissions[h].mu_ret = (
                    (1 - self.learning_rate) * model.emissions[h].mu_ret +
                    self.learning_rate * new_mu_ret
                )
                
                # æ³¢å‹•ç‡åƒæ•¸æ›´æ–°
                new_var_ret = float(np.sum(w * (x_seq['ret'] - new_mu_ret) ** 2) / W)
                new_sigma_ret = math.sqrt(max(new_var_ret, 1e-12))
                model.emissions[h].sigma_ret = (
                    (1 - self.learning_rate) * model.emissions[h].sigma_ret +
                    self.learning_rate * new_sigma_ret
                )
                
                # å…¶ä»–åƒæ•¸é¡ä¼¼æ›´æ–°...
                new_mu_logvol = float(np.sum(w * x_seq['logvol']) / W)
                model.emissions[h].mu_logvol = (
                    (1 - self.learning_rate) * model.emissions[h].mu_logvol +
                    self.learning_rate * new_mu_logvol
                )

# --------------------------
# éå¹³ç©©æª¢æ¸¬å™¨ (Regime Shift Detector)
# --------------------------

class RegimeShiftDetector:
    """
    åˆ¶åº¦çªè®Šæª¢æ¸¬å™¨
    
    ç›£æ§å¸‚å ´åˆ¶åº¦çš„çªç„¶è®ŠåŒ–ï¼Œç›¸ç•¶æ–¼é‡å­ç³»çµ±çš„ã€Œæ³¢å‡½æ•¸åç¸®ã€
    """
    
    def __init__(self, 
                 loglik_window_size: int = 50,
                 shift_threshold: float = -2.0,
                 confidence_threshold: float = 0.8):
        """
        åˆå§‹åŒ–åˆ¶åº¦çªè®Šæª¢æ¸¬å™¨
        
        Args:
            loglik_window_size: å°æ•¸ä¼¼ç„¶æ»‘å‹•çª—å£å¤§å°
            shift_threshold: çªè®Šé–¾å€¼ (å°æ•¸ä¼¼ç„¶ä¸‹é™)
            confidence_threshold: åˆ¶åº¦ä¿¡å¿ƒåº¦é–¾å€¼
        """
        self.window_size = loglik_window_size
        self.shift_threshold = shift_threshold
        self.confidence_threshold = confidence_threshold
        
        # æ­·å²è¨˜éŒ„
        self.loglik_history = []
        self.confidence_history = []
        self.regime_history = []
        
        # çªè®Šç‹€æ…‹
        self.last_shift_time = 0
        self.current_regime = -1
        self.regime_duration = 0
    
    def detect_regime_shift(self, 
                           current_loglik: float,
                           regime_probs: np.ndarray,
                           current_time: int) -> Dict[str, Any]:
        """
        æª¢æ¸¬åˆ¶åº¦çªè®Š
        
        Returns:
            shift_info: çªè®Šä¿¡æ¯å­—å…¸
        """
        # æ›´æ–°æ­·å²è¨˜éŒ„
        self.loglik_history.append(current_loglik)
        max_confidence = np.max(regime_probs)
        dominant_regime = np.argmax(regime_probs)
        
        self.confidence_history.append(max_confidence)
        self.regime_history.append(dominant_regime)
        
        # ä¿æŒçª—å£å¤§å°
        if len(self.loglik_history) > self.window_size:
            self.loglik_history.pop(0)
            self.confidence_history.pop(0)
            self.regime_history.pop(0)
        
        # æª¢æ¸¬é‚è¼¯
        shift_detected = False
        shift_type = "none"
        shift_strength = 0.0
        
        if len(self.loglik_history) >= 10:
            # 1. å°æ•¸ä¼¼ç„¶çªç„¶ä¸‹é™ (æ¨¡å‹å¤±æ•ˆ)
            recent_loglik = np.mean(self.loglik_history[-5:])
            historical_loglik = np.mean(self.loglik_history[:-5])
            loglik_change = recent_loglik - historical_loglik
            
            if loglik_change < self.shift_threshold:
                shift_detected = True
                shift_type = "model_breakdown"
                shift_strength = abs(loglik_change)
            
            # 2. åˆ¶åº¦ä¿¡å¿ƒåº¦çªç„¶ä¸‹é™ (æ¨¡ç³Šç‹€æ…‹)
            recent_confidence = np.mean(self.confidence_history[-5:])
            if recent_confidence < (1.0 / len(regime_probs)) * 1.5:  # æ¥è¿‘éš¨æ©Ÿ
                shift_detected = True
                shift_type = "regime_uncertainty"
                shift_strength = 1.0 - recent_confidence
            
            # 3. åˆ¶åº¦é »ç¹åˆ‡æ› (ä¸ç©©å®š)
            if len(self.regime_history) >= 20:
                regime_changes = sum(
                    1 for i in range(1, len(self.regime_history))
                    if self.regime_history[i] != self.regime_history[i-1]
                )
                change_rate = regime_changes / len(self.regime_history)
                
                if change_rate > 0.3:  # 30% çš„æ™‚é–“åœ¨åˆ‡æ›
                    shift_detected = True
                    shift_type = "regime_instability"
                    shift_strength = change_rate
        
        # æ›´æ–°åˆ¶åº¦ç‹€æ…‹
        if dominant_regime != self.current_regime:
            self.current_regime = dominant_regime
            self.regime_duration = 0
        else:
            self.regime_duration += 1
        
        if shift_detected:
            self.last_shift_time = current_time
        
        return {
            "shift_detected": shift_detected,
            "shift_type": shift_type,
            "shift_strength": shift_strength,
            "current_regime": dominant_regime,
            "regime_confidence": max_confidence,
            "regime_duration": self.regime_duration,
            "time_since_last_shift": current_time - self.last_shift_time
        }

# --------------------------
# è·¨è³‡ç”¢è€¦åˆåµæ¸¬å™¨ (Multi-Asset Coupling)
# --------------------------

class MultiAssetCoupledHMM:
    """
    å¤šè³‡ç”¢è€¦åˆ HMM
    
    æ•æ‰ã€Œé¾é ­å¸¶å°å¹£ã€çš„é‡å­å¹²æ¶‰æ•ˆæ‡‰
    """
    
    def __init__(self, 
                 asset_names: List[str],
                 coupling_strength: float = 0.3):
        """
        åˆå§‹åŒ–å¤šè³‡ç”¢è€¦åˆæ¨¡å‹
        
        Args:
            asset_names: è³‡ç”¢åç¨±åˆ—è¡¨ ['BTC', 'ETH', 'BNB', ...]
            coupling_strength: è€¦åˆå¼·åº¦
        """
        self.asset_names = asset_names
        self.n_assets = len(asset_names)
        self.coupling_strength = coupling_strength
        
        # æ¯å€‹è³‡ç”¢çš„ç¨ç«‹ HMM
        self.individual_hmms = {}
        for asset in asset_names:
            self.individual_hmms[asset] = TimeVaryingHMM(
                n_states=6, z_dim=3, reg_lambda=1e-3
            )
        
        # è€¦åˆçŸ©é™£ (è³‡ç”¢é–“å½±éŸ¿)
        self.coupling_matrix = np.eye(self.n_assets) * (1 - coupling_strength)
        
        # è¨­å®šä¸»å°è³‡ç”¢ (å¦‚ BTC)
        if 'BTC' in asset_names:
            btc_idx = asset_names.index('BTC')
            # BTC å½±éŸ¿å…¶ä»–æ‰€æœ‰è³‡ç”¢
            self.coupling_matrix[btc_idx, :] = coupling_strength / self.n_assets
            self.coupling_matrix[btc_idx, btc_idx] = 1 - coupling_strength
    
    def compute_coupled_transition_matrix(self, 
                                        individual_regimes: Dict[str, np.ndarray],
                                        z_t: np.ndarray) -> Dict[str, np.ndarray]:
        """
        è¨ˆç®—è€¦åˆå¾Œçš„è½‰ç§»çŸ©é™£
        
        Args:
            individual_regimes: å„è³‡ç”¢ç•¶å‰åˆ¶åº¦æ¦‚ç‡
            z_t: å”è®Šé‡
            
        Returns:
            coupled_transitions: è€¦åˆå¾Œçš„è½‰ç§»çŸ©é™£
        """
        coupled_transitions = {}
        
        for i, asset in enumerate(self.asset_names):
            # ç²å–æœ¬è³‡ç”¢çš„åŸºç¤è½‰ç§»çŸ©é™£
            base_A = self.individual_hmms[asset].get_transition_matrix(z_t)
            
            # è¨ˆç®—å…¶ä»–è³‡ç”¢çš„å½±éŸ¿
            external_influence = np.zeros((6, 6))
            
            for j, other_asset in enumerate(self.asset_names):
                if i != j:  # ä¸åŒè³‡ç”¢
                    other_regime_probs = individual_regimes.get(other_asset, np.ones(6)/6)
                    coupling_weight = self.coupling_matrix[j, i]
                    
                    # å…¶ä»–è³‡ç”¢çš„åˆ¶åº¦å½±éŸ¿æœ¬è³‡ç”¢çš„è½‰ç§»
                    # å¦‚æœ BTC è™•æ–¼ç‰›å¸‚åˆ¶åº¦ï¼Œå‰‡å¢å¼·å…¶ä»–è³‡ç”¢é€²å…¥ç‰›å¸‚çš„æ¦‚ç‡
                    influence = np.outer(other_regime_probs, other_regime_probs)
                    external_influence += coupling_weight * influence
            
            # çµ„åˆåŸºç¤è½‰ç§»å’Œå¤–éƒ¨å½±éŸ¿
            coupled_A = (1 - self.coupling_strength) * base_A + self.coupling_strength * external_influence
            
            # ç¢ºä¿æ¯è¡Œå’Œç‚º1
            row_sums = coupled_A.sum(axis=1, keepdims=True)
            coupled_A = coupled_A / (row_sums + 1e-12)
            
            coupled_transitions[asset] = coupled_A
        
        return coupled_transitions
    
    def joint_regime_inference(self, 
                              multi_asset_data: Dict[str, Dict[str, np.ndarray]],
                              multi_asset_z: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """
        è¯åˆåˆ¶åº¦æ¨ç†
        
        Args:
            multi_asset_data: å¤šè³‡ç”¢è§€æ¸¬æ•¸æ“š
            multi_asset_z: å¤šè³‡ç”¢å”è®Šé‡
            
        Returns:
            joint_regimes: è¯åˆåˆ¶åº¦æ¦‚ç‡
        """
        joint_regimes = {}
        
        # ç¬¬ä¸€è¼ªï¼šç¨ç«‹æ¨ç†
        individual_regimes = {}
        for asset in self.asset_names:
            if asset in multi_asset_data and asset in multi_asset_z:
                hmm = self.individual_hmms[asset]
                log_alpha, _ = hmm.forward_log(
                    multi_asset_data[asset], 
                    multi_asset_z[asset]
                )
                individual_regimes[asset] = np.exp(log_alpha[-1])  # æœ€æ–°æ™‚åˆ»
        
        # ç¬¬äºŒè¼ªï¼šè€¦åˆèª¿æ•´
        if len(multi_asset_z) > 0:
            # ä½¿ç”¨ç¬¬ä¸€å€‹è³‡ç”¢çš„å”è®Šé‡ä½œç‚ºä»£è¡¨
            representative_z = list(multi_asset_z.values())[0][-1]
            
            coupled_transitions = self.compute_coupled_transition_matrix(
                individual_regimes, representative_z
            )
            
            # ä½¿ç”¨è€¦åˆå¾Œçš„è½‰ç§»çŸ©é™£é‡æ–°è¨ˆç®—åˆ¶åº¦æ¦‚ç‡
            for asset in self.asset_names:
                if asset in individual_regimes:
                    # ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨è€¦åˆè½‰ç§»çŸ©é™£èª¿æ•´æ¦‚ç‡
                    original_probs = individual_regimes[asset]
                    coupled_A = coupled_transitions.get(asset, np.eye(6))
                    
                    # æ‡‰ç”¨è€¦åˆå½±éŸ¿
                    adjusted_probs = coupled_A.T @ original_probs
                    adjusted_probs = adjusted_probs / (adjusted_probs.sum() + 1e-12)
                    
                    joint_regimes[asset] = adjusted_probs
                else:
                    joint_regimes[asset] = np.ones(6) / 6
        else:
            joint_regimes = individual_regimes
        
        return joint_regimes

def student_t_logpdf(x: np.ndarray, mu: float, sigma: float, nu: float) -> np.ndarray:
    """å‘é‡åŒ– Student-t å°æ•¸ PDF - è™•ç†åŠ å¯†è²¨å¹£åšå°¾åˆ†å¸ƒ"""
    sigma = max(sigma, 1e-9)
    nu = max(nu, 2.1)
    z = (x - mu) / sigma
    a = math.lgamma((nu + 1.0) / 2.0) - math.lgamma(nu / 2.0)
    b = -0.5 * math.log(nu * math.pi) - math.log(sigma)
    c = -(nu + 1.0) / 2.0 * np.log1p((z * z) / nu)
    return a + b + c

def gaussian_logpdf(x: np.ndarray, mu: float, sigma: float) -> np.ndarray:
    """å‘é‡åŒ–é«˜æ–¯å°æ•¸ PDF"""
    sigma = max(sigma, 1e-9)
    return -0.5 * np.log(2 * math.pi) - np.log(sigma) - 0.5 * ((x - mu) ** 2) / (sigma ** 2)

# --------------------------
# ç™¼å°„åƒæ•¸çµæ§‹
# --------------------------

@dataclass
class EmissionParams:
    """å¸‚å ´åˆ¶åº¦ç™¼å°„åƒæ•¸ - å°æ‡‰ä¸åŒå¸‚å ´ç‹€æ…‹çš„çµ±è¨ˆç‰¹å¾µ"""
    mu_ret: float      # æ”¶ç›Šç‡å‡å€¼
    sigma_ret: float   # æ”¶ç›Šç‡æ¨™æº–å·®
    nu_ret: float      # Student-t è‡ªç”±åº¦ (åšå°¾åƒæ•¸)
    mu_logvol: float   # å°æ•¸æ³¢å‹•ç‡å‡å€¼
    sigma_logvol: float # å°æ•¸æ³¢å‹•ç‡æ¨™æº–å·®  
    mu_slope: float    # åƒ¹æ ¼æ–œç‡å‡å€¼
    sigma_slope: float # åƒ¹æ ¼æ–œç‡æ¨™æº–å·®
    ob_loc: float      # è¨‚å–®ç°¿ä¸å¹³è¡¡ä½ç½®åƒæ•¸
    ob_scale: float    # è¨‚å–®ç°¿ä¸å¹³è¡¡å°ºåº¦åƒæ•¸

# --------------------------
# ç”Ÿç”¢ç´šæ™‚è®Šéš±é¦¬å¯å¤«æ¨¡å‹
# --------------------------

class TimeVaryingHMM:
    """
    ç”Ÿç”¢ç´šæ™‚è®Š HMM å¼•æ“ + é‡å­æ±ºç­–æ•´åˆ
    
    åŸæœ‰ç‰¹æ€§:
    - æ™‚è®Šè½‰ç§»çŸ©é™£: A_t[i,j] = softmax(b_{ij} + w_{ij}^T z_t)
    - Student-t åšå°¾ç™¼å°„åˆ†å¸ƒ
    - å‘é‡åŒ– forward/backward ç®—æ³•
    - å¿«å–å„ªåŒ–çš„è½‰ç§»çŸ©é™£è¨ˆç®—
    - æ•¸å€¼ç©©å®šçš„ EM è¨“ç·´
    
    é‡å­å¢å¼·ç‰¹æ€§:
    - æ•´åˆé‡å­ä¿¡è™Ÿç¯©é¸å™¨
    - æ”¯æ´å³æ™‚æµæ•¸æ“šæ›´æ–°
    - åˆ¶åº¦çªè®Šæª¢æ¸¬
    - å¤šè³‡ç”¢è€¦åˆåˆ†æ
    """
    
    def __init__(self, 
                 n_states: int = 6, 
                 z_dim: int = 3, 
                 reg_lambda: float = 1e-3, 
                 rng_seed: int = 42,
                 enable_quantum_features: bool = True):
        """
        åˆå§‹åŒ–é‡å­å¢å¼·æ™‚è®Š HMM
        
        Args:
            n_states: å¸‚å ´åˆ¶åº¦æ•¸é‡ (å°æ‡‰ 6 ç¨®ç‹€æ…‹)
            z_dim: å”è®Šé‡ç¶­åº¦ (slope, volatility, orderbook)
            reg_lambda: L2 æ­£å‰‡åŒ–ä¿‚æ•¸
            rng_seed: éš¨æ©Ÿç¨®å­
            enable_quantum_features: æ˜¯å¦å•Ÿç”¨é‡å­å¢å¼·åŠŸèƒ½
        """
        self.M = n_states
        self.z_dim = z_dim
        self.reg_lambda = reg_lambda
        self.enable_quantum_features = enable_quantum_features
        rng = np.random.RandomState(rng_seed)
        
        # è½‰ç§»åƒæ•¸: b (M x M), w (M x M x z_dim)
        self.b = rng.normal(scale=0.01, size=(self.M, self.M))
        self.w = rng.normal(scale=0.01, size=(self.M, self.M, self.z_dim))
        
        # åˆå§‹ç‹€æ…‹åˆ†å¸ƒ (å°æ•¸ç©ºé–“)
        self.log_pi = np.log(np.ones(self.M) / self.M)
        
        # ç™¼å°„åƒæ•¸åˆå§‹åŒ–
        self.emissions: List[EmissionParams] = []
        for i in range(self.M):
            ep = EmissionParams(
                mu_ret=rng.normal(scale=1e-3),
                sigma_ret=0.01 + rng.uniform() * 0.05,
                nu_ret=5.0 + rng.uniform() * 5.0,
                mu_logvol=-2.0 + rng.normal(scale=0.2),
                sigma_logvol=0.5 + rng.uniform() * 0.5,
                mu_slope=rng.normal(scale=1e-3),
                sigma_slope=0.005 + rng.uniform() * 0.02,
                ob_loc=rng.normal(scale=0.1),
                ob_scale=0.5 + rng.uniform() * 0.5
            )
            self.emissions.append(ep)
        
        # æ€§èƒ½å„ªåŒ–å¿«å–
        self.A_cache = None
        self.logA_cache = None
        self.last_z_seq_hash = None
        
        # é‡å­å¢å¼·çµ„ä»¶
        if self.enable_quantum_features:
            self.quantum_selector = QuantumSignalSelector(
                risk_floor=1e-3,
                confidence_threshold=0.6,
                min_risk_reward=1.5
            )
            self.online_adaptor = OnlineEMAdaptor(
                learning_rate=0.05,
                min_update_interval=10,
                max_memory_length=1000
            )
            self.shift_detector = RegimeShiftDetector(
                loglik_window_size=50,
                shift_threshold=-2.0,
                confidence_threshold=0.8
            )
        
        # å³æ™‚æ•¸æ“šè¨˜éŒ„
        self.current_time = 0
        self.last_loglik = -np.inf

    # --------------------------
    # é‡å­å¢å¼·æ–¹æ³•
    # --------------------------
    
    def quantum_regime_analysis(self, 
                               x_seq: Dict[str, np.ndarray], 
                               z_seq: np.ndarray,
                               market_condition: Dict[str, float] = None) -> Dict[str, Any]:
        """
        é‡å­åˆ¶åº¦åˆ†æ - æ•´åˆæ‰€æœ‰é‡å­å¢å¼·åŠŸèƒ½
        
        Args:
            x_seq: è§€æ¸¬åºåˆ—
            z_seq: å”è®Šé‡åºåˆ—
            market_condition: é¡å¤–å¸‚å ´æ¢ä»¶
            
        Returns:
            quantum_analysis: å®Œæ•´çš„é‡å­åˆ†æçµæœ
        """
        # 1. åŸºç¤åˆ¶åº¦æ¨ç†
        log_alpha, log_c = self.forward_log(x_seq, z_seq)
        log_beta = self.backward_log(x_seq, z_seq)
        gamma = self.get_smoothed_probabilities(log_alpha, log_beta)
        
        # ç•¶å‰æ™‚åˆ»çš„åˆ¶åº¦æ¦‚ç‡
        current_regime_probs = gamma[-1]  # æœ€æ–°æ™‚åˆ»
        current_loglik = np.sum(log_c)
        
        # 2. é‡å­ä¿¡è™Ÿæ±ºç­–
        quantum_decision = None
        if self.enable_quantum_features:
            quantum_decision = self.quantum_selector.select_quantum_action(
                current_regime_probs, market_condition
            )
        
        # 3. åˆ¶åº¦çªè®Šæª¢æ¸¬
        shift_info = None
        if self.enable_quantum_features:
            self.current_time += 1
            shift_info = self.shift_detector.detect_regime_shift(
                current_loglik, current_regime_probs, self.current_time
            )
        
        # 4. å³æ™‚å­¸ç¿’æ›´æ–° (å¦‚æœæœ‰æ–°æ•¸æ“š)
        if (self.enable_quantum_features and 
            len(x_seq['ret']) > 0):
            
            new_x = {k: v[-1] for k, v in x_seq.items()}  # æœ€æ–°è§€æ¸¬
            new_z = z_seq[-1] if len(z_seq) > 0 else np.zeros(self.z_dim)
            
            self.online_adaptor.incremental_update(
                self, new_x, new_z, current_regime_probs
            )
        
        # 5. çµ„åˆçµæœ
        analysis = {
            "regime_probabilities": current_regime_probs,
            "smoothed_regimes": gamma,
            "log_likelihood": current_loglik,
            "quantum_decision": quantum_decision,
            "shift_detection": shift_info,
            "model_health": {
                "numerical_stable": not np.any(np.isnan(current_regime_probs)),
                "convergence_quality": current_loglik - self.last_loglik,
                "regime_entropy": -np.sum(current_regime_probs * np.log(current_regime_probs + 1e-12))
            }
        }
        
        self.last_loglik = current_loglik
        return analysis

    # --------------------------
    # å³æ™‚ API æ•´åˆæ–¹æ³•
    # --------------------------
    
    async def å•Ÿå‹•å³æ™‚äº¤æ˜“ç³»çµ±(self):
        """
        å•Ÿå‹•å®Œæ•´çš„å³æ™‚é‡å­äº¤æ˜“ç³»çµ±
        
        åŠŸèƒ½åŒ…æ‹¬ï¼š
        - å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†
        - åˆ¶åº¦æ¦‚ç‡å‹•æ…‹æ›´æ–°  
        - é‡å­ä¿¡è™Ÿç”Ÿæˆ
        - Trading X ä¿¡è™Ÿè¼¸å‡º
        """
        logger.info("ğŸš€ å•Ÿå‹• Trading X é‡å­å³æ™‚äº¤æ˜“ç³»çµ±...")
        
        # åˆå§‹åŒ–å¿…è¦çµ„ä»¶
        if not hasattr(self, 'å³æ™‚æ•¸æ“šæ”¶é›†å™¨'):
            self.å³æ™‚æ•¸æ“šæ”¶é›†å™¨ = å³æ™‚å¹£å®‰æ•¸æ“šæ”¶é›†å™¨([
                'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 
                'XRPUSDT', 'DOGEUSDT', 'ADAUSDT'
            ])
        
        if not hasattr(self, 'ä¿¡è™Ÿè¼¸å‡ºå™¨'):
            self.ä¿¡è™Ÿè¼¸å‡ºå™¨ = TradingXä¿¡è™Ÿè¼¸å‡ºå™¨()
        
        if not hasattr(self, 'åˆ¶åº¦æ­·å²'):
            self.åˆ¶åº¦æ­·å² = {}
        
        self.é‹è¡Œä¸­ = True
        
        # å•Ÿå‹•æ•¸æ“šæ”¶é›†
        await self.å³æ™‚æ•¸æ“šæ”¶é›†å™¨.å•Ÿå‹•æ•¸æ“šæ”¶é›†()
        
        # å•Ÿå‹•ä¸»è¦åˆ†æå¾ªç’°
        await self._ä¸»è¦åˆ†æå¾ªç’°()
    
    async def _ä¸»è¦åˆ†æå¾ªç’°(self):
        """ä¸»è¦çš„å³æ™‚åˆ†æå¾ªç’°"""
        while self.é‹è¡Œä¸­:
            try:
                # å°æ¯å€‹äº¤æ˜“å°é€²è¡Œåˆ†æ
                äº¤æ˜“å°åˆ—è¡¨ = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 
                           'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
                
                for äº¤æ˜“å° in äº¤æ˜“å°åˆ—è¡¨:
                    await self._è™•ç†å–®ä¸€äº¤æ˜“å°(äº¤æ˜“å°)
                
                # ç­‰å¾…ä¸‹ä¸€å€‹åˆ†æé€±æœŸ
                await asyncio.sleep(5)  # æ¯5ç§’åˆ†æä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ä¸»è¦åˆ†æå¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(10)
    
    async def _è™•ç†å–®ä¸€äº¤æ˜“å°(self, äº¤æ˜“å°: str):
        """è™•ç†å–®ä¸€äº¤æ˜“å°çš„é‡å­åˆ†æ"""
        try:
            # ç²å–å³æ™‚è§€æ¸¬
            è§€æ¸¬ = self.å³æ™‚æ•¸æ“šæ”¶é›†å™¨.ç²å–å³æ™‚è§€æ¸¬(äº¤æ˜“å°)
            if è§€æ¸¬ is None:
                return
            
            # æ§‹å»ºé‡å­è§€æ¸¬åºåˆ—
            é‡å­è§€æ¸¬åºåˆ— = self._æ§‹å»ºé‡å­è§€æ¸¬åºåˆ—(è§€æ¸¬, äº¤æ˜“å°)
            if é‡å­è§€æ¸¬åºåˆ— is None:
                return
            
            # åŸ·è¡Œé‡å­åˆ¶åº¦åˆ†æ
            åˆ†æçµæœ = self.quantum_regime_analysis(
                x_seq=é‡å­è§€æ¸¬åºåˆ—['observations'],
                z_seq=é‡å­è§€æ¸¬åºåˆ—['covariates'],
                market_condition=é‡å­è§€æ¸¬åºåˆ—['market_condition']
            )
            
            # ç”Ÿæˆ Trading X ä¿¡è™Ÿ
            if åˆ†æçµæœ['quantum_decision']:
                äº¤æ˜“ä¿¡è™Ÿ = self.ä¿¡è™Ÿè¼¸å‡ºå™¨.ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ(
                    è§€æ¸¬, 
                    åˆ†æçµæœ['quantum_decision'], 
                    åˆ†æçµæœ['regime_probabilities']
                )
                
                # è¨˜éŒ„å’Œè¼¸å‡ºä¿¡è™Ÿ
                await self._è¼¸å‡ºäº¤æ˜“ä¿¡è™Ÿ(äº¤æ˜“ä¿¡è™Ÿ)
            
            # æ›´æ–°åˆ¶åº¦æ­·å²
            self._æ›´æ–°åˆ¶åº¦æ­·å²(äº¤æ˜“å°, åˆ†æçµæœ)
            
        except Exception as e:
            logger.error(f"è™•ç† {äº¤æ˜“å°} å¤±æ•—: {e}")
    
    def _æ§‹å»ºé‡å­è§€æ¸¬åºåˆ—(self, è§€æ¸¬: å³æ™‚å¸‚å ´è§€æ¸¬, äº¤æ˜“å°: str) -> Optional[Dict[str, Any]]:
        """
        å°‡å³æ™‚å¸‚å ´è§€æ¸¬è½‰æ›ç‚ºé‡å­åˆ†æåºåˆ—æ ¼å¼
        
        Returns:
            DictåŒ…å«ï¼š
            - observations: ç¬¦åˆ TimeVaryingHMM æ ¼å¼çš„è§€æ¸¬åºåˆ—
            - covariates: å”è®Šé‡åºåˆ—
            - market_condition: å¸‚å ´æ¢ä»¶
        """
        try:
            # æ§‹å»ºè§€æ¸¬åºåˆ— (ç¬¦åˆåŸå§‹æ ¼å¼)
            observations = {
                'ret': np.array([è§€æ¸¬.æ”¶ç›Šç‡]),
                'log_vol': np.array([np.log(è§€æ¸¬.å·²å¯¦ç¾æ³¢å‹•ç‡ + 1e-6)]),
                'slope': np.array([è§€æ¸¬.å‹•é‡æ–œç‡]),
                'orderbook': np.array([è§€æ¸¬.è¨‚å–®ç°¿å£“åŠ›])
            }
            
            # æ§‹å»ºå”è®Šé‡åºåˆ— (3ç¶­: æ³¢å‹•ç‡, å‹•é‡, è¨‚å–®ç°¿)
            covariates = np.array([
                è§€æ¸¬.å·²å¯¦ç¾æ³¢å‹•ç‡,
                è§€æ¸¬.å‹•é‡æ–œç‡, 
                è§€æ¸¬.è¨‚å–®ç°¿å£“åŠ›
            ]).reshape(1, -1)
            
            # å¸‚å ´æ¢ä»¶
            market_condition = {
                'spread': è§€æ¸¬.è²·è³£åƒ¹å·®,
                'active_buy_ratio': è§€æ¸¬.ä¸»å‹•è²·å…¥æ¯”ç‡,
                'funding_rate': è§€æ¸¬.è³‡é‡‘è²»ç‡ or 0.0,
                'open_interest': è§€æ¸¬.æœªå¹³å€‰é‡ or 0.0,
                'rsi': è§€æ¸¬.RSI_14,
                'bb_position': è§€æ¸¬.å¸ƒæ—å¸¶ä½ç½®,
                'price': è§€æ¸¬.åƒ¹æ ¼,
                'volume': è§€æ¸¬.æˆäº¤é‡
            }
            
            return {
                'observations': observations,
                'covariates': covariates,
                'market_condition': market_condition
            }
            
        except Exception as e:
            logger.error(f"æ§‹å»º {äº¤æ˜“å°} é‡å­è§€æ¸¬åºåˆ—å¤±æ•—: {e}")
            return None
    
    def _æ›´æ–°åˆ¶åº¦æ­·å²(self, äº¤æ˜“å°: str, åˆ†æçµæœ: Dict[str, Any]):
        """æ›´æ–°åˆ¶åº¦æ­·å²è¨˜éŒ„"""
        if äº¤æ˜“å° not in self.åˆ¶åº¦æ­·å²:
            self.åˆ¶åº¦æ­·å²[äº¤æ˜“å°] = {
                'åˆ¶åº¦æ¦‚ç‡æ­·å²': [],
                'ä¿¡è™Ÿæ­·å²': [],
                'æœ€å¾Œæ›´æ–°æ™‚é–“': None
            }
        
        æ­·å² = self.åˆ¶åº¦æ­·å²[äº¤æ˜“å°]
        
        # è¨˜éŒ„åˆ¶åº¦æ¦‚ç‡
        æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'].append({
            'æ™‚é–“': datetime.now(),
            'æ¦‚ç‡': åˆ†æçµæœ['regime_probabilities'].tolist(),
            'ä¸»è¦åˆ¶åº¦': int(np.argmax(åˆ†æçµæœ['regime_probabilities']))
        })
        
        # è¨˜éŒ„ä¿¡è™Ÿ
        if åˆ†æçµæœ['quantum_decision']:
            æ­·å²['ä¿¡è™Ÿæ­·å²'].append({
                'æ™‚é–“': datetime.now(),
                'ä¿¡è™Ÿ': åˆ†æçµæœ['quantum_decision'].action,
                'ä¿¡å¿ƒåº¦': åˆ†æçµæœ['quantum_decision'].confidence,
                'è©•åˆ†': åˆ†æçµæœ['quantum_decision'].score
            })
        
        æ­·å²['æœ€å¾Œæ›´æ–°æ™‚é–“'] = datetime.now()
        
        # é™åˆ¶æ­·å²é•·åº¦
        if len(æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²']) > 1000:
            æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'] = æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'][-500:]
        if len(æ­·å²['ä¿¡è™Ÿæ­·å²']) > 1000:
            æ­·å²['ä¿¡è™Ÿæ­·å²'] = æ­·å²['ä¿¡è™Ÿæ­·å²'][-500:]
    
    async def _è¼¸å‡ºäº¤æ˜“ä¿¡è™Ÿ(self, ä¿¡è™Ÿ: TradingXä¿¡è™Ÿ):
        """è¼¸å‡ºäº¤æ˜“ä¿¡è™Ÿåˆ° Trading X ç³»çµ±"""
        try:
            # æ ¼å¼åŒ–ä¿¡è™Ÿè¼¸å‡º
            ä¿¡è™Ÿæ‘˜è¦ = (
                f"ğŸ”® ã€{ä¿¡è™Ÿ.äº¤æ˜“å°}ã€‘é‡å­äº¤æ˜“ä¿¡è™Ÿ\n"
                f"ğŸ“Š ä¿¡è™Ÿ: {ä¿¡è™Ÿ.ä¿¡è™Ÿé¡å‹} | ä¿¡å¿ƒåº¦: {ä¿¡è™Ÿ.ä¿¡å¿ƒåº¦:.2%}\n"
                f"ğŸ›ï¸ åˆ¶åº¦: {ä¿¡è™Ÿ.å¸‚å ´åˆ¶åº¦åç¨±} | è©•åˆ†: {ä¿¡è™Ÿ.é‡å­è©•åˆ†:.3f}\n"
                f"ğŸ’° æœŸæœ›æ”¶ç›Š: {ä¿¡è™Ÿ.æœŸæœ›æ”¶ç›Š:.2%} | é¢¨éšª: {ä¿¡è™Ÿ.é¢¨éšªè©•ä¼°:.2%}\n"
                f"ğŸ“ˆ é¢¨éšªå ±é…¬æ¯”: {ä¿¡è™Ÿ.é¢¨éšªå ±é…¬æ¯”:.2f} | å»ºè­°å€‰ä½: {ä¿¡è™Ÿ.æŒå€‰å»ºè­°:.1%}\n"
                f"ğŸ¯ é€²å ´: ${ä¿¡è™Ÿ.é€²å ´åƒ¹æ ¼:.4f}"
            )
            
            if ä¿¡è™Ÿ.æ­¢æåƒ¹æ ¼:
                ä¿¡è™Ÿæ‘˜è¦ += f" | æ­¢æ: ${ä¿¡è™Ÿ.æ­¢æåƒ¹æ ¼:.4f}"
            if ä¿¡è™Ÿ.æ­¢ç›ˆåƒ¹æ ¼:
                ä¿¡è™Ÿæ‘˜è¦ += f" | æ­¢ç›ˆ: ${ä¿¡è™Ÿ.æ­¢ç›ˆåƒ¹æ ¼:.4f}"
            
            logger.info(ä¿¡è™Ÿæ‘˜è¦)
            
            # é€™è£¡å¯ä»¥åŠ å…¥èˆ‡ Trading X ä¸»ç³»çµ±çš„æ•´åˆé‚è¼¯
            # ä¾‹å¦‚ï¼šç™¼é€åˆ°è¨Šæ¯ä½‡åˆ—ã€å¯«å…¥è³‡æ–™åº«ã€è§¸ç™¼äº¤æ˜“æ¨¡çµ„ç­‰
            
        except Exception as e:
            logger.error(f"è¼¸å‡ºäº¤æ˜“ä¿¡è™Ÿå¤±æ•—: {e}")
    
    async def åœæ­¢å³æ™‚äº¤æ˜“ç³»çµ±(self):
        """åœæ­¢å³æ™‚äº¤æ˜“ç³»çµ±"""
        logger.info("ğŸ›‘ åœæ­¢é‡å­å³æ™‚äº¤æ˜“ç³»çµ±...")
        
        self.é‹è¡Œä¸­ = False
        if hasattr(self, 'å³æ™‚æ•¸æ“šæ”¶é›†å™¨'):
            await self.å³æ™‚æ•¸æ“šæ”¶é›†å™¨.åœæ­¢æ•¸æ“šæ”¶é›†()
        
        logger.info("âœ… é‡å­å³æ™‚äº¤æ˜“ç³»çµ±å·²åœæ­¢")
    
    def ç²å–åˆ¶åº¦çµ±è¨ˆ(self) -> Dict[str, Any]:
        """ç²å–æ‰€æœ‰äº¤æ˜“å°çš„åˆ¶åº¦çµ±è¨ˆ"""
        çµ±è¨ˆ = {}
        
        for äº¤æ˜“å°, æ­·å² in self.åˆ¶åº¦æ­·å².items():
            if æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²']:
                æœ€æ–°æ¦‚ç‡ = æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'][-1]['æ¦‚ç‡']
                ä¸»è¦åˆ¶åº¦ = æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'][-1]['ä¸»è¦åˆ¶åº¦']
                
                çµ±è¨ˆ[äº¤æ˜“å°] = {
                    'ä¸»è¦åˆ¶åº¦': ä¸»è¦åˆ¶åº¦,
                    'åˆ¶åº¦åç¨±': self._ç²å–åˆ¶åº¦åç¨±(ä¸»è¦åˆ¶åº¦),
                    'åˆ¶åº¦æ¦‚ç‡': æœ€æ–°æ¦‚ç‡,
                    'æœ€å¾Œæ›´æ–°': æ­·å²['æœ€å¾Œæ›´æ–°æ™‚é–“'].isoformat() if æ­·å²['æœ€å¾Œæ›´æ–°æ™‚é–“'] else None,
                    'ç¸½ä¿¡è™Ÿæ•¸': len(æ­·å²['ä¿¡è™Ÿæ­·å²']),
                    'åˆ¶åº¦è®ŠåŒ–æ¬¡æ•¸': len(æ­·å²['åˆ¶åº¦æ¦‚ç‡æ­·å²'])
                }
        
        return çµ±è¨ˆ
    
    def _ç²å–åˆ¶åº¦åç¨±(self, åˆ¶åº¦ç´¢å¼•: int) -> str:
        """ç²å–åˆ¶åº¦åç¨±"""
        åˆ¶åº¦åç¨±æ˜ å°„ = {
            0: "ç‰›å¸‚åˆ¶åº¦",
            1: "ç†Šå¸‚åˆ¶åº¦", 
            2: "é«˜æ³¢å‹•åˆ¶åº¦",
            3: "ä½æ³¢å‹•åˆ¶åº¦",
            4: "æ©«ç›¤åˆ¶åº¦",
            5: "å´©ç›¤åˆ¶åº¦"
        }
        return åˆ¶åº¦åç¨±æ˜ å°„.get(åˆ¶åº¦ç´¢å¼•, f"åˆ¶åº¦{åˆ¶åº¦ç´¢å¼•}")

    # --------------------------
    # ä¿æŒåŸæœ‰çš„æ ¸å¿ƒ HMM æ–¹æ³•
    # --------------------------
    
    def real_time_quantum_signal(self, 
                                new_tick: Dict[str, float],
                                new_features: np.ndarray,
                                market_context: Dict[str, float] = None) -> QuantumSignalDecision:
        """
        å³æ™‚é‡å­ä¿¡è™Ÿç”Ÿæˆ (å–®ç­† tick è™•ç†)
        
        Args:
            new_tick: æ–°çš„ tick æ•¸æ“š {'ret', 'logvol', 'slope', 'ob'}
            new_features: æ–°çš„ç‰¹å¾µå‘é‡ (z_dim,)
            market_context: å¸‚å ´èƒŒæ™¯ä¿¡æ¯
            
        Returns:
            QuantumSignalDecision: å³æ™‚é‡å­æ±ºç­–
        """
        if not self.enable_quantum_features:
            raise ValueError("é‡å­åŠŸèƒ½æœªå•Ÿç”¨")
        
        # æ§‹é€ å–®é»åºåˆ—
        x_single = {k: np.array([v]) for k, v in new_tick.items()}
        z_single = new_features.reshape(1, -1)
        
        # å¿«é€Ÿå‰å‘æ¨ç† (åªè¨ˆç®—æ¿¾æ³¢æ¦‚ç‡)
        log_em = self.log_emission_matrix(x_single)  # (M, 1)
        
        if self.A_cache is not None:
            # ä½¿ç”¨æœ€æ–°çš„è½‰ç§»çŸ©é™£
            A_latest = self.A_cache[-1] if len(self.A_cache) > 0 else np.eye(self.M)
        else:
            A_latest = self.get_transition_matrix(new_features)
        
        # ç°¡åŒ–çš„æ¿¾æ³¢æ›´æ–° (å‡è¨­ä¸Šä¸€æ™‚åˆ»ç‚ºå‡å‹»åˆ†å¸ƒ)
        prior = np.ones(self.M) / self.M
        likelihood = np.exp(log_em[:, 0])
        
        posterior = prior * likelihood
        posterior = posterior / (posterior.sum() + 1e-12)
        
        # ç”Ÿæˆé‡å­æ±ºç­–
        quantum_decision = self.quantum_selector.select_quantum_action(
            posterior, market_context
        )
        
        # æ›´æ–°åœ¨ç·šå­¸ç¿’
        self.online_adaptor.incremental_update(
            self, new_tick, new_features, posterior
        )
        
        return quantum_decision
    
    def batch_quantum_training(self, 
                              multi_timeframe_data: Dict[str, Dict[str, np.ndarray]],
                              coupling_assets: List[str] = None,
                              n_iter: int = 10) -> Dict[str, Any]:
        """
        æ‰¹æ¬¡é‡å­è¨“ç·´ (æ”¯æ´å¤šæ™‚é–“æ¡†æ¶å’Œå¤šè³‡ç”¢)
        
        Args:
            multi_timeframe_data: å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
            coupling_assets: è€¦åˆè³‡ç”¢åˆ—è¡¨
            n_iter: EM è¿­ä»£æ¬¡æ•¸
            
        Returns:
            training_result: è¨“ç·´çµæœ
        """
        training_results = {}
        
        # å°æ¯å€‹æ™‚é–“æ¡†æ¶è¨“ç·´
        for timeframe, data in multi_timeframe_data.items():
            if 'x_seq' in data and 'z_seq' in data:
                print(f"è¨“ç·´æ™‚é–“æ¡†æ¶: {timeframe}")
                
                # æ¨™æº– EM è¨“ç·´
                self.fit_EM(
                    data['x_seq'], 
                    data['z_seq'], 
                    n_iter=n_iter, 
                    verbose=True
                )
                
                # è¨˜éŒ„è¨“ç·´çµæœ
                final_analysis = self.quantum_regime_analysis(
                    data['x_seq'], 
                    data['z_seq']
                )
                
                training_results[timeframe] = {
                    "final_loglik": final_analysis["log_likelihood"],
                    "regime_summary": final_analysis["regime_probabilities"],
                    "model_health": final_analysis["model_health"]
                }
        
        # å¤šè³‡ç”¢è€¦åˆåˆ†æ (å¦‚æœæŒ‡å®š)
        if coupling_assets and self.enable_quantum_features:
            print("åŸ·è¡Œå¤šè³‡ç”¢è€¦åˆåˆ†æ...")
            coupled_hmm = MultiAssetCoupledHMM(coupling_assets)
            
            # é€™è£¡å¯ä»¥æ·»åŠ å¤šè³‡ç”¢è¯åˆè¨“ç·´é‚è¼¯
            training_results["multi_asset_coupling"] = {
                "assets": coupling_assets,
                "coupling_strength": coupled_hmm.coupling_strength
            }
        
        return training_results
    
    def _compute_z_seq_hash(self, z_seq: np.ndarray) -> int:
        """è¨ˆç®— z_seq çš„é›œæ¹Šå€¼ç”¨æ–¼å¿«å–é©—è­‰"""
        return hash(z_seq.tobytes())
    
    def compute_A_cache(self, z_seq: np.ndarray):
        """
        è¨ˆç®—ä¸¦å¿«å–æ•´å€‹åºåˆ—çš„è½‰ç§»çŸ©é™£
        
        å…¬å¼: A_t[i,j] = softmax_j(b_{ij} + w_{ij}^T z_t)
        """
        T = z_seq.shape[0]
        z_hash = self._compute_z_seq_hash(z_seq)
        
        # æª¢æŸ¥å¿«å–æ˜¯å¦æœ‰æ•ˆ
        if (self.A_cache is not None and 
            self.last_z_seq_hash == z_hash and 
            self.A_cache.shape[0] == T):
            return
        
        # é‡æ–°è¨ˆç®—å¿«å–
        A_cache = np.zeros((T, self.M, self.M))
        logA_cache = np.zeros((T, self.M, self.M))
        
        # å‘é‡åŒ–è¨ˆç®—æ‰€æœ‰æ™‚é–“é»çš„è½‰ç§»çŸ©é™£
        for t in range(T):
            zt = z_seq[t]  # shape: (z_dim,)
            # ä½¿ç”¨ tensordot é€²è¡Œé«˜æ•ˆçŸ©é™£ä¹˜æ³•
            logits = self.b + np.tensordot(self.w, zt, axes=([2], [0]))  # shape: (M, M)
            
            # æ•¸å€¼ç©©å®šçš„ softmax (æŒ‰è¡Œ)
            row_max = logits.max(axis=1, keepdims=True)
            exp_logits = np.exp(logits - row_max)
            A = exp_logits / (exp_logits.sum(axis=1, keepdims=True) + 1e-300)
            
            A_cache[t] = A
            logA_cache[t] = np.log(A + 1e-300)
        
        self.A_cache = A_cache
        self.logA_cache = logA_cache
        self.last_z_seq_hash = z_hash

    def get_transition_matrix(self, z_t: np.ndarray, t_idx: int = None) -> np.ndarray:
        """ç²å–æŒ‡å®šæ™‚é–“é»çš„è½‰ç§»çŸ©é™£"""
        if self.A_cache is not None and t_idx is not None and t_idx < self.A_cache.shape[0]:
            return self.A_cache[t_idx]
        
        # å¯¦æ™‚è¨ˆç®—å–®å€‹è½‰ç§»çŸ©é™£
        logits = self.b + np.tensordot(self.w, z_t, axes=([2], [0]))
        row_max = logits.max(axis=1, keepdims=True)
        exp_logits = np.exp(logits - row_max)
        return exp_logits / (exp_logits.sum(axis=1, keepdims=True) + 1e-300)

    # --------------------------
    # ç™¼å°„æ¦‚ç‡è¨ˆç®— (å‘é‡åŒ–)
    # --------------------------
    
    def log_emission_matrix(self, x_seq: Dict[str, np.ndarray]) -> np.ndarray:
        """
        è¨ˆç®—æ‰€æœ‰ç‹€æ…‹å’Œæ™‚é–“é»çš„ç™¼å°„å°æ•¸æ¦‚ç‡
        
        Args:
            x_seq: è§€æ¸¬åºåˆ—å­—å…¸ï¼ŒåŒ…å« 'ret', 'logvol', 'slope', 'ob'
            
        Returns:
            log_em: å½¢ç‹€ (M, T) çš„ç™¼å°„å°æ•¸æ¦‚ç‡çŸ©é™£
        """
        T = x_seq['ret'].shape[0]
        log_em = np.zeros((self.M, T))
        
        for h in range(self.M):
            ep = self.emissions[h]
            
            # Student-t åˆ†å¸ƒç”¨æ–¼æ”¶ç›Šç‡ (è™•ç†åšå°¾)
            l_ret = student_t_logpdf(x_seq['ret'], ep.mu_ret, ep.sigma_ret, ep.nu_ret)
            
            # é«˜æ–¯åˆ†å¸ƒç”¨æ–¼å…¶ä»–è§€æ¸¬è®Šé‡
            l_vol = gaussian_logpdf(x_seq['logvol'], ep.mu_logvol, ep.sigma_logvol)
            l_slope = gaussian_logpdf(x_seq['slope'], ep.mu_slope, ep.sigma_slope)
            
            # è¨‚å–®ç°¿ä¸å¹³è¡¡çš„ç‰¹æ®Šè™•ç†
            ob_diff = x_seq['ob'] - ep.ob_loc
            l_ob = (-0.5 * (ob_diff ** 2) / (max(ep.ob_scale, 1e-9) ** 2) - 
                    math.log(max(ep.ob_scale, 1e-9)) - 
                    0.5 * math.log(2 * math.pi))
            
            # çµ„åˆæ‰€æœ‰è§€æ¸¬çš„å°æ•¸æ¦‚ç‡
            log_em[h, :] = l_ret + l_vol + l_slope + l_ob
            
        return log_em

    # --------------------------
    # Forward ç®—æ³• (å‘é‡åŒ– + æ•¸å€¼ç©©å®š)
    # --------------------------
    
    def forward_log(self, x_seq: Dict[str, np.ndarray], z_seq: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        å‘é‡åŒ– Forward ç®—æ³• (å°æ•¸ç©ºé–“)
        
        Returns:
            log_alpha: æ­£è¦åŒ–çš„å‰å‘æ¦‚ç‡ (T x M)
            log_c: æ­£è¦åŒ–å¸¸æ•¸åºåˆ— (T,)
        """
        T = x_seq['ret'].shape[0]
        
        # é è¨ˆç®—ç™¼å°„æ¦‚ç‡çŸ©é™£
        log_em = self.log_emission_matrix(x_seq)  # (M, T)
        
        # ç¢ºä¿è½‰ç§»çŸ©é™£å¿«å–
        self.compute_A_cache(z_seq)
        logA_cache = self.logA_cache  # (T, M, M)
        
        # åˆå§‹åŒ–
        log_alpha = np.full((T, self.M), -np.inf)
        log_c = []
        
        # t=0: åˆå§‹åŒ–
        log_alpha[0, :] = self.log_pi + log_em[:, 0]
        c0 = logsumexp(log_alpha[0, :])
        log_alpha[0, :] -= c0
        log_c.append(c0)
        
        # t=1...T-1: éæ¨è¨ˆç®—
        for t in range(1, T):
            # å‘é‡åŒ–è¨ˆç®—: log_alpha[t-1, i] + log(A[t, i, j]) for all i,j
            # å½¢ç‹€: (M, 1) + (M, M) -> (M, M), ç„¶å¾Œæ²¿ axis=0 æ±‚ logsumexp
            prev_alpha = log_alpha[t-1, :][:, None]  # (M, 1)
            transition_logits = prev_alpha + logA_cache[t]  # (M, M)
            
            # æ²¿ä¾†æºç‹€æ…‹ç¶­åº¦æ±‚ logsumexp
            forward_probs = logsumexp(transition_logits, axis=0)  # (M,)
            
            # åŠ ä¸Šç™¼å°„æ¦‚ç‡
            log_alpha[t, :] = log_em[:, t] + forward_probs
            
            # æ­£è¦åŒ–
            ct = logsumexp(log_alpha[t, :])
            log_alpha[t, :] -= ct
            log_c.append(ct)
        
        return log_alpha, np.array(log_c)

    # --------------------------
    # Backward ç®—æ³• (å‘é‡åŒ–)
    # --------------------------
    
    def backward_log(self, x_seq: Dict[str, np.ndarray], z_seq: np.ndarray) -> np.ndarray:
        """
        å‘é‡åŒ– Backward ç®—æ³• (å°æ•¸ç©ºé–“)
        
        Returns:
            log_beta: å¾Œå‘æ¦‚ç‡ (T x M)
        """
        T = x_seq['ret'].shape[0]
        
        # é è¨ˆç®—ç™¼å°„æ¦‚ç‡çŸ©é™£
        log_em = self.log_emission_matrix(x_seq)
        
        # ç¢ºä¿è½‰ç§»çŸ©é™£å¿«å–
        if self.logA_cache is None or self.logA_cache.shape[0] != T:
            self.compute_A_cache(z_seq)
        logA_cache = self.logA_cache
        
        # åˆå§‹åŒ–
        log_beta = np.full((T, self.M), -np.inf)
        log_beta[-1, :] = 0.0  # log(1)
        
        # åå‘éæ¨
        for t in range(T - 2, -1, -1):
            # ä½¿ç”¨ t+1 æ™‚åˆ»çš„è½‰ç§»çŸ©é™£
            logA_next = logA_cache[t + 1]  # (M, M) i->j
            
            # å‘é‡åŒ–è¨ˆç®—: log(A[i,j]) + log_em[j,t+1] + log_beta[t+1,j]
            emission_beta = log_em[:, t + 1] + log_beta[t + 1, :]  # (M,)
            transition_emission = logA_next + emission_beta[None, :]  # (M, M)
            
            # æ²¿ç›®æ¨™ç‹€æ…‹ç¶­åº¦æ±‚ logsumexp
            log_beta[t, :] = logsumexp(transition_emission, axis=1)
        
        return log_beta

    # --------------------------
    # å¾Œé©—è¨ˆç®— (å®Œæ•´ xi çŸ©é™£)
    # --------------------------
    
    def compute_posteriors_full_xi(self, 
                                   log_alpha: np.ndarray, 
                                   log_beta: np.ndarray, 
                                   z_seq: np.ndarray, 
                                   x_seq: Dict[str, np.ndarray]) -> Tuple[np.ndarray, np.ndarray]:
        """
        è¨ˆç®—å®Œæ•´çš„å¾Œé©—æ¦‚ç‡
        
        Returns:
            gamma: å–®é»å¾Œé©— P(H_t=h|x_{1:T}) (T x M)
            xi_t: é…å°å¾Œé©— P(H_t=i, H_{t+1}=j|x_{1:T}) (T-1 x M x M)
        """
        T = log_alpha.shape[0]
        
        # è¨ˆç®— gamma (å–®é»å¾Œé©—)
        log_gamma = log_alpha + log_beta
        for t in range(T):
            log_gamma[t, :] -= logsumexp(log_gamma[t, :])
        gamma = np.exp(log_gamma)
        
        # è¨ˆç®— xi (é…å°å¾Œé©—)
        if self.logA_cache is None or self.logA_cache.shape[0] != T:
            self.compute_A_cache(z_seq)
        logA_cache = self.logA_cache
        log_em = self.log_emission_matrix(x_seq)
        
        xi_t = np.zeros((T - 1, self.M, self.M))
        
        for t in range(T - 1):
            # log xi_t(i,j) âˆ log_alpha[t,i] + log(A[t+1,i,j]) + log_em[j,t+1] + log_beta[t+1,j]
            alpha_i = log_alpha[t, :][:, None]  # (M, 1)
            transition_ij = logA_cache[t + 1]   # (M, M)
            emission_beta_j = log_em[:, t + 1] + log_beta[t + 1, :]  # (M,)
            
            log_xi = alpha_i + transition_ij + emission_beta_j[None, :]
            log_xi -= logsumexp(log_xi)  # æ­£è¦åŒ–
            xi_t[t] = np.exp(log_xi)
        
        return gamma, xi_t

    # --------------------------
    # M-step: ç™¼å°„åƒæ•¸æ›´æ–° (åŠ æ¬Š MLE + æ•¸å€¼ nu ä¼°è¨ˆ)
    # --------------------------
    
    def m_step_emissions(self, 
                        x_seq: Dict[str, np.ndarray], 
                        gamma: np.ndarray, 
                        update_nu: bool = True):
        """
        ç™¼å°„åƒæ•¸çš„åŠ æ¬Šæœ€å¤§ä¼¼ç„¶ä¼°è¨ˆ
        
        Args:
            x_seq: è§€æ¸¬åºåˆ—
            gamma: å¾Œé©—è²¬ä»»åº¦ (T x M)
            update_nu: æ˜¯å¦æ•¸å€¼æ›´æ–° Student-t è‡ªç”±åº¦
        """
        for h in range(self.M):
            w = gamma[:, h]  # æ¬Šé‡
            W = w.sum() + 1e-12
            
            # æ”¶ç›Šç‡åƒæ•¸ (Student-t)
            mu_ret = float(np.sum(w * x_seq['ret']) / W)
            var_ret = float(np.sum(w * (x_seq['ret'] - mu_ret) ** 2) / W)
            sigma_ret = math.sqrt(max(var_ret, 1e-12))
            
            # nu åƒæ•¸çš„æ•¸å€¼ä¼°è¨ˆ
            nu = self.emissions[h].nu_ret
            if update_nu and W > 10:  # åªæœ‰è¶³å¤ æ¨£æœ¬æ™‚æ‰æ›´æ–°
                try:
                    nu = self._estimate_nu_weighted(x_seq['ret'], mu_ret, sigma_ret, w, nu)
                except Exception:
                    pass  # ä¿æŒåŸå€¼
            
            # å…¶ä»–åƒæ•¸çš„åŠ æ¬Šä¼°è¨ˆ
            mu_logvol = float(np.sum(w * x_seq['logvol']) / W)
            var_logvol = float(np.sum(w * (x_seq['logvol'] - mu_logvol) ** 2) / W)
            sigma_logvol = math.sqrt(max(var_logvol, 1e-12))
            
            mu_slope = float(np.sum(w * x_seq['slope']) / W)
            var_slope = float(np.sum(w * (x_seq['slope'] - mu_slope) ** 2) / W)
            sigma_slope = math.sqrt(max(var_slope, 1e-12))
            
            mu_ob = float(np.sum(w * x_seq['ob']) / W)
            var_ob = float(np.sum(w * (x_seq['ob'] - mu_ob) ** 2) / W)
            sigma_ob = math.sqrt(max(var_ob, 1e-9))
            
            # æ›´æ–°åƒæ•¸ (ç¢ºä¿æ•¸å€¼ç©©å®šæ€§)
            self.emissions[h].mu_ret = mu_ret
            self.emissions[h].sigma_ret = max(sigma_ret, 1e-9)
            self.emissions[h].nu_ret = max(nu, 2.1)
            self.emissions[h].mu_logvol = mu_logvol
            self.emissions[h].sigma_logvol = max(sigma_logvol, 1e-9)
            self.emissions[h].mu_slope = mu_slope
            self.emissions[h].sigma_slope = max(sigma_slope, 1e-9)
            self.emissions[h].ob_loc = mu_ob
            self.emissions[h].ob_scale = max(sigma_ob, 1e-9)

    def _estimate_nu_weighted(self, 
                             x: np.ndarray, 
                             mu: float, 
                             sigma: float, 
                             weights: np.ndarray, 
                             init_nu: float = 6.0) -> float:
        """
        åŠ æ¬Š Student-t è‡ªç”±åº¦çš„æ•¸å€¼æœ€å¤§ä¼¼ç„¶ä¼°è¨ˆ
        
        å„ªåŒ–ç›®æ¨™: æœ€å¤§åŒ–åŠ æ¬Šå°æ•¸ä¼¼ç„¶å‡½æ•¸
        """
        z2 = ((x - mu) / sigma) ** 2
        w = weights / (weights.sum() + 1e-12)
        
        def neg_log_likelihood(nu_arr):
            nu = float(nu_arr[0])
            if nu <= 2.1:
                return 1e12
            
            try:
                # åŠ æ¬Šå°æ•¸ä¼¼ç„¶çš„å„é …
                term1 = (np.sum(w) * 
                        (math.lgamma((nu + 1) / 2.0) - math.lgamma(nu / 2.0) - 
                         0.5 * math.log(nu * math.pi)))
                
                term2 = -(nu + 1) / 2.0 * np.sum(w * np.log1p(z2 / nu))
                
                return -(term1 + term2)
            except (OverflowError, ValueError):
                return 1e12
        
        # æ•¸å€¼å„ªåŒ–
        result = minimize(
            neg_log_likelihood, 
            x0=np.array([init_nu]), 
            bounds=[(2.1, 100.0)], 
            method='L-BFGS-B',
            options={'maxiter': 50}
        )
        
        if result.success and 2.1 <= result.x[0] <= 100.0:
            return float(result.x[0])
        return init_nu

    # --------------------------
    # M-step: è½‰ç§»åƒæ•¸æ›´æ–° (Per-row åŠ æ¬Š multinomial logistic)
    # --------------------------
    
    def m_step_transition(self, xi_t: np.ndarray, z_seq: np.ndarray):
        """
        è½‰ç§»åƒæ•¸çš„ per-row åŠ æ¬Š multinomial logistic å›æ­¸
        
        å°æ¯å€‹ä¾†æºç‹€æ…‹ i ç¨ç«‹å„ªåŒ–è½‰ç§»åƒæ•¸ï¼Œæ”¯æ´ä¸¦è¡ŒåŒ–
        """
        T_minus_1 = xi_t.shape[0]
        
        # æ§‹å»ºç‰¹å¾µçŸ©é™£: X = [1, z_{t+1}] for t=0..T-2
        X = np.hstack([np.ones((T_minus_1, 1)), z_seq[1:T_minus_1+1]])  # (T-1, 1+z_dim)
        d = X.shape[1]  # ç‰¹å¾µç¶­åº¦
        
        # å°æ¯å€‹ä¾†æºç‹€æ…‹ i å„ªåŒ–åƒæ•¸
        for i in range(self.M):
            self._optimize_row_parameters(i, xi_t, X, d)

    def _optimize_row_parameters(self, i: int, xi_t: np.ndarray, X: np.ndarray, d: int):
        """
        å„ªåŒ–ç¬¬ i è¡Œçš„è½‰ç§»åƒæ•¸
        
        ä½¿ç”¨åŠ æ¬Š multinomial logistic å›æ­¸ + L2 æ­£å‰‡åŒ–
        """
        def _build_logits_from_theta(theta):
            """å¾åƒæ•¸å‘é‡é‡æ§‹ logits çŸ©é™£"""
            return theta.reshape((self.M, d))  # (M, d)
        
        def objective(theta_flat):
            """ç›®æ¨™å‡½æ•¸: è² åŠ æ¬Šå°æ•¸ä¼¼ç„¶ + L2 æ­£å‰‡åŒ–"""
            try:
                W = _build_logits_from_theta(theta_flat)  # (M, d)
                
                # è¨ˆç®— logits: X @ W.T -> (T-1, M)
                logits = X @ W.T
                
                # è¨ˆç®— log-sum-exp (æ²¿ç›®æ¨™ç‹€æ…‹ç¶­åº¦)
                lse = logsumexp(logits, axis=1)  # (T-1,)
                
                # åŠ æ¬Šå°æ•¸ä¼¼ç„¶: sum_t sum_j xi_t[t,i,j] * (logits[t,j] - lse[t])
                weighted_logits = xi_t[:, i, :] * (logits - lse[:, None])
                log_likelihood = np.sum(weighted_logits)
                
                # L2 æ­£å‰‡åŒ–
                regularization = 0.5 * self.reg_lambda * np.sum(theta_flat ** 2)
                
                return -log_likelihood + regularization
                
            except (OverflowError, ValueError, RuntimeWarning):
                return 1e12
        
        # åˆå§‹åŒ–åƒæ•¸ (å¾ç•¶å‰ b, w æå–)
        theta0 = np.zeros(self.M * d)
        for j in range(self.M):
            theta0[j * d] = self.b[i, j]  # æˆªè·é …
            if d > 1:  # æœ‰å”è®Šé‡
                theta0[j * d + 1:j * d + d] = self.w[i, j, :]
        
        # L-BFGS-B å„ªåŒ–
        try:
            result = minimize(
                objective, 
                theta0, 
                method='L-BFGS-B', 
                options={'maxiter': 100, 'disp': False}
            )
            
            if result.success:
                # æ›´æ–°åƒæ•¸
                optimized_W = _build_logits_from_theta(result.x)
                for j in range(self.M):
                    self.b[i, j] = float(optimized_W[j, 0])
                    if d > 1:
                        self.w[i, j, :] = optimized_W[j, 1:]
                        
        except Exception:
            # å„ªåŒ–å¤±æ•—æ™‚ä¿æŒåŸåƒæ•¸
            pass

    # --------------------------
    # EM ç®—æ³• (Baum-Welch è¨“ç·´)
    # --------------------------
    
    def fit_EM(self, 
               x_seq: Dict[str, np.ndarray], 
               z_seq: np.ndarray, 
               n_iter: int = 10, 
               tol: float = 1e-4, 
               verbose: bool = True):
        """
        EM ç®—æ³•è¨“ç·´æ™‚è®Š HMM
        
        Args:
            x_seq: è§€æ¸¬åºåˆ—å­—å…¸
            z_seq: å”è®Šé‡åºåˆ— (T x z_dim)
            n_iter: æœ€å¤§è¿­ä»£æ¬¡æ•¸
            tol: æ”¶æ–‚å®¹å¿åº¦
            verbose: æ˜¯å¦è¼¸å‡ºè¨“ç·´é€²åº¦
        """
        T = x_seq['ret'].shape[0]
        last_loglik = -np.inf
        
        for iteration in range(n_iter):
            start_time = time.time()
            
            # E-step: è¨ˆç®—å¾Œé©—æ¦‚ç‡
            log_alpha, log_c = self.forward_log(x_seq, z_seq)
            log_beta = self.backward_log(x_seq, z_seq)
            gamma, xi_t = self.compute_posteriors_full_xi(log_alpha, log_beta, z_seq, x_seq)
            
            # è¨ˆç®—å°æ•¸ä¼¼ç„¶
            current_loglik = float(np.sum(log_c))
            
            if verbose:
                elapsed = time.time() - start_time
                print(f"[EM] Iter {iteration}: LogLik = {current_loglik:.6f}, "
                      f"Time = {elapsed:.3f}s, T = {T}")
            
            # M-step: æ›´æ–°åƒæ•¸
            self.m_step_emissions(x_seq, gamma, update_nu=True)
            self.m_step_transition(xi_t, z_seq)
            
            # æ¸…é™¤å¿«å–ä»¥ä½¿ç”¨æ–°åƒæ•¸
            self.A_cache = None
            self.logA_cache = None
            self.last_z_seq_hash = None
            
            # æª¢æŸ¥æ”¶æ–‚
            if abs(current_loglik - last_loglik) < tol:
                if verbose:
                    print(f"[EM] Converged at iteration {iteration}")
                break
                
            last_loglik = current_loglik

    # --------------------------
    # Viterbi ç®—æ³• (æœ€å„ªè·¯å¾‘è§£ç¢¼)
    # --------------------------
    
    def viterbi(self, x_seq: Dict[str, np.ndarray], z_seq: np.ndarray) -> Tuple[np.ndarray, float]:
        """
        Viterbi ç®—æ³•æ±‚è§£æœ€å„ªç‹€æ…‹åºåˆ—
        
        Returns:
            path: æœ€å„ªç‹€æ…‹è·¯å¾‘ (T,)
            max_logprob: æœ€å¤§å°æ•¸æ¦‚ç‡
        """
        T = x_seq['ret'].shape[0]
        
        # é è¨ˆç®—çŸ©é™£
        log_em = self.log_emission_matrix(x_seq)
        self.compute_A_cache(z_seq)
        logA_cache = self.logA_cache
        
        # åˆå§‹åŒ–
        delta = np.full((T, self.M), -np.inf)
        psi = np.zeros((T, self.M), dtype=int)
        
        # t=0
        delta[0, :] = self.log_pi + log_em[:, 0]
        
        # å‰å‘éæ¨
        for t in range(1, T):
            # è¨ˆç®—æ‰€æœ‰å¯èƒ½çš„è½‰ç§»: delta[t-1, i] + log(A[t, i, j])
            transition_scores = delta[t-1, :][:, None] + logA_cache[t]  # (M, M)
            
            # æ‰¾åˆ°æ¯å€‹ç›®æ¨™ç‹€æ…‹çš„æœ€å„ªå‰é©…
            psi[t, :] = np.argmax(transition_scores, axis=0)
            delta[t, :] = np.max(transition_scores, axis=0) + log_em[:, t]
        
        # å›æº¯æœ€å„ªè·¯å¾‘
        path = np.zeros(T, dtype=int)
        path[-1] = int(np.argmax(delta[-1, :]))
        
        for t in range(T-2, -1, -1):
            path[t] = psi[t+1, path[t+1]]
        
        max_logprob = float(np.max(delta[-1, :]))
        return path, max_logprob

    # --------------------------
    # ç²’å­æ¿¾æ³¢ (ç³»çµ±åŒ–é‡æ¡æ¨£)
    # --------------------------
    
    def particle_filter(self, 
                       x_seq: Dict[str, np.ndarray], 
                       z_seq: np.ndarray, 
                       N: int = 500, 
                       resample_thresh: float = 0.5) -> np.ndarray:
        """
        ç²’å­æ¿¾æ³¢ with ç³»çµ±åŒ–é‡æ¡æ¨£
        
        Args:
            x_seq: è§€æ¸¬åºåˆ—
            z_seq: å”è®Šé‡åºåˆ—
            N: ç²’å­æ•¸é‡
            resample_thresh: é‡æ¡æ¨£é–¾å€¼ (åŸºæ–¼æœ‰æ•ˆæ¨£æœ¬å¤§å°)
            
        Returns:
            posterior: è¿‘ä¼¼å¾Œé©—æ¦‚ç‡ (T x M)
        """
        T = x_seq['ret'].shape[0]
        
        # åˆå§‹åŒ–ç²’å­
        particles = np.random.choice(self.M, size=N, p=np.ones(self.M) / self.M)
        weights = np.ones(N) / N
        posterior = np.zeros((T, self.M))
        
        for t in range(T):
            # ç‹€æ…‹å‚³æ’­
            if t > 0:
                A = self.get_transition_matrix(z_seq[t], t)
                new_particles = np.zeros_like(particles)
                
                for i in range(N):
                    current_state = particles[i]
                    new_particles[i] = np.random.choice(self.M, p=A[current_state])
                
                particles = new_particles
            
            # æ¬Šé‡æ›´æ–° (åŸºæ–¼ç™¼å°„æ¦‚ç‡)
            log_weights = np.zeros(N)
            for i in range(N):
                h = particles[i]
                ep = self.emissions[h]
                
                # è¨ˆç®—ç™¼å°„å°æ•¸æ¦‚ç‡
                log_weights[i] = (
                    student_t_logpdf(np.array([x_seq['ret'][t]]), ep.mu_ret, ep.sigma_ret, ep.nu_ret)[0] +
                    gaussian_logpdf(np.array([x_seq['logvol'][t]]), ep.mu_logvol, ep.sigma_logvol)[0] +
                    gaussian_logpdf(np.array([x_seq['slope'][t]]), ep.mu_slope, ep.sigma_slope)[0] +
                    (-0.5 * math.log(2 * math.pi) - math.log(max(ep.ob_scale, 1e-9)) - 
                     0.5 * ((x_seq['ob'][t] - ep.ob_loc) ** 2) / (max(ep.ob_scale, 1e-9) ** 2))
                )
            
            # æ•¸å€¼ç©©å®šçš„æ¬Šé‡æ­£è¦åŒ–
            max_log_weight = log_weights.max()
            unnormalized_weights = np.exp(log_weights - max_log_weight) * weights
            weight_sum = unnormalized_weights.sum() + 1e-300
            weights = unnormalized_weights / weight_sum
            
            # è¨ˆç®—è¿‘ä¼¼å¾Œé©—
            for h in range(self.M):
                posterior[t, h] = weights[particles == h].sum()
            
            # æœ‰æ•ˆæ¨£æœ¬å¤§å°æª¢æŸ¥
            ess = 1.0 / np.sum(weights ** 2)
            if ess < resample_thresh * N:
                # ç³»çµ±åŒ–é‡æ¡æ¨£
                positions = (np.arange(N) + np.random.random()) / N
                cumulative_weights = np.cumsum(weights)
                indices = np.searchsorted(cumulative_weights, positions)
                
                particles = particles[indices]
                weights.fill(1.0 / N)
        
        return posterior

    # --------------------------
    # è¼”åŠ©æ–¹æ³•
    # --------------------------
    
    def get_filtered_probabilities(self, log_alpha: np.ndarray) -> np.ndarray:
        """ç²å–æ¿¾æ³¢æ¦‚ç‡ P(H_t | x_{1:t})"""
        return np.exp(log_alpha)
    
    def get_smoothed_probabilities(self, log_alpha: np.ndarray, log_beta: np.ndarray) -> np.ndarray:
        """ç²å–å¹³æ»‘æ¦‚ç‡ P(H_t | x_{1:T})"""
        log_gamma = log_alpha + log_beta
        for t in range(log_gamma.shape[0]):
            log_gamma[t, :] -= logsumexp(log_gamma[t, :])
        return np.exp(log_gamma)
    
    def get_model_summary(self) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹æ‘˜è¦è³‡è¨Š"""
        return {
            'n_states': self.M,
            'z_dim': self.z_dim,
            'regularization': self.reg_lambda,
            'emission_types': {
                'returns': 'Student-t',
                'log_volatility': 'Gaussian',
                'slope': 'Gaussian', 
                'orderbook': 'Gaussian'
            },
            'cache_status': {
                'A_cache_size': self.A_cache.shape if self.A_cache is not None else None,
                'last_z_hash': self.last_z_seq_hash
            }
        }
# --------------------------
# ç”Ÿç”¢ç´šæ¼”ç¤ºèˆ‡æ¸¬è©¦å‡½æ•¸
# --------------------------

def generate_synthetic_crypto_data(T: int = 500, seed: int = 42) -> Tuple[Dict[str, np.ndarray], np.ndarray, np.ndarray]:
    """
    æ­¤å‡½æ•¸å·²å»¢æ£„ - ä¸å†ä½¿ç”¨æ¨¡æ“¬æ•¸æ“š
    
    Trading X é‡å­ç³»çµ±ç›´æ¥ä½¿ç”¨çœŸå¯¦å¸‚å ´æ•¸æ“š:
    - BinanceDataCollector WebSocket å³æ™‚æ•¸æ“š
    - MarketDataService çµ±ä¸€æ•¸æ“šæ¥å£
    - ä¸»æ± ä¸ƒå¹£ç¨®å¯¦æ™‚åƒ¹æ ¼ã€æ·±åº¦ã€Kç·š
    
    çœŸå¯¦æ•¸æ“šæº:
    - å³æ™‚åƒ¹æ ¼: realtime_data['prices'][symbol]  
    - Kç·šæ•¸æ“š: realtime_data['klines'][f"{symbol}_{interval}"]
    - æ·±åº¦æ•¸æ“š: realtime_data['depths'][symbol]
    
    ä½¿ç”¨ construct_quantum_observation() å¾çœŸå¯¦æ•¸æ“šæ§‹å»ºé‡å­è§€æ¸¬
    """
    print("âš ï¸  generate_synthetic_crypto_data() å·²å»¢æ£„")
    print("è«‹ä½¿ç”¨çœŸå¯¦å¸‚å ´æ•¸æ“š: Trading X WebSocket â†’ construct_quantum_observation()")
    
    # å›é€€åˆ°æœ€å°å¯ç”¨æ•¸æ“š (åƒ…ç”¨æ–¼å‘å¾Œç›¸å®¹)
    minimal_x = {
        'ret': np.zeros(10),
        'logvol': np.full(10, -3.0),
        'slope': np.zeros(10), 
        'ob': np.zeros(10)
    }
    minimal_z = np.zeros((10, 3))
    minimal_states = np.zeros(10, dtype=int)
    
    return minimal_x, minimal_z, minimal_states

# --------------------------
# çœŸå¯¦å¸‚å ´æ•¸æ“šåŸºæº–æ¸¬è©¦ (ç„¡æ¨¡æ“¬æ•¸æ“š)
# --------------------------

def benchmark_real_market_quantum():
    """
    çœŸå¯¦å¸‚å ´æ•¸æ“šåŸºæº–æ¸¬è©¦
    
    æ¸¬è©¦é‡å­ HMM åœ¨çœŸå¯¦å¸‚å ´æ•¸æ“šä¸Šçš„æ€§èƒ½
    """
    print("="*60)
    print("çœŸå¯¦å¸‚å ´é‡å­ HMM åŸºæº–æ¸¬è©¦")
    print("="*60)
    
    # å°å…¥çœŸå¯¦æ•¸æ“šæœå‹™
    try:
        import sys
        sys.path.append('../../X/app')
        from services.market_data import MarketDataService
        print("âœ… æˆåŠŸå°å…¥ Trading X å¸‚å ´æ•¸æ“šæœå‹™")
    except ImportError as e:
        print(f"âŒ ç„¡æ³•å°å…¥å¸‚å ´æ•¸æ“šæœå‹™: {e}")
        print("è«‹æª¢æŸ¥ Trading X ç³»çµ±è·¯å¾‘")
        return
    
    # Trading X é…ç½®çš„ä¸ƒå¹£ç¨®
    primary_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
    
    print(f"\nã€æ¸¬è©¦ Trading X ä¸»æ± ä¸ƒå¹£ç¨®ã€‘")
    
    # åˆå§‹åŒ–å¸‚å ´æ•¸æ“šæœå‹™
    try:
        market_service = MarketDataService()
        print("âœ… å¸‚å ´æ•¸æ“šæœå‹™åˆå§‹åŒ–æˆåŠŸ")
        
        # ç­‰å¾… WebSocket æ•¸æ“šè¼‰å…¥
        print("â³ ç­‰å¾…å³æ™‚æ•¸æ“šè¼‰å…¥...")
        import time
        time.sleep(3)
        
        # æ¸¬è©¦æ¯å€‹å¹£ç¨®çš„é‡å­è™•ç†
        for symbol in primary_symbols:
            print(f"\n  ã€{symbol} é‡å­åˆ†æã€‘")
            
            # ç²å–çœŸå¯¦æ•¸æ“š
            price_data = market_service.realtime_data['prices'].get(symbol)
            
            if price_data:
                # åŸºæº–æ¸¬è©¦æŒ‡æ¨™
                start_time = time.time()
                
                # æ§‹å»ºçœŸå¯¦è§€æ¸¬
                observation = construct_quantum_observation(price_data, symbol)
                
                if observation:
                    # é‡å­ç‰¹å¾µæå–
                    z_features = extract_quantum_features(observation)
                    
                    # åˆå§‹åŒ– HMM æ¨¡å‹
                    model = TimeVaryingHMM(n_states=6, z_dim=3, enable_quantum_features=True)
                    
                    # å–®é»æ¨ç†æ¸¬è©¦ (å³æ™‚æ€§èƒ½)
                    try:
                        quantum_decision = model.real_time_quantum_signal(
                            observation,
                            z_features,
                            get_market_context(symbol)
                        )
                        
                        processing_time = time.time() - start_time
                        
                        print(f"    âš¡ è™•ç†æ™‚é–“: {processing_time*1000:.2f}ms")
                        print(f"    ğŸ¯ é‡å­æ±ºç­–: {quantum_decision.action}")
                        print(f"    ğŸ“Š åˆ¶åº¦: {quantum_decision.best_regime}")
                        print(f"    ğŸ’ª ä¿¡å¿ƒåº¦: {quantum_decision.confidence:.3f}")
                        print(f"    âš–ï¸  é¢¨éšªå ±é…¬æ¯”: {quantum_decision.risk_reward_ratio:.2f}")
                        print(f"    ğŸ’° ç•¶å‰åƒ¹æ ¼: ${price_data['price']:.4f}")
                        print(f"    ğŸ“ˆ 24hè®ŠåŒ–: {price_data['change_percent']:+.2f}%")
                        
                    except Exception as e:
                        print(f"    âŒ é‡å­æ±ºç­–å¤±æ•—: {e}")
                else:
                    print(f"    âš ï¸  æ•¸æ“šå“è³ªä¸è¶³")
            else:
                print(f"    âš ï¸  {symbol} æ•¸æ“šæœªè¼‰å…¥")
        
        # ç³»çµ±æ€§èƒ½ç¸½çµ
        print(f"\nğŸš€ çœŸå¯¦å¸‚å ´é‡å­ç³»çµ±æ€§èƒ½ç¸½çµ:")
        print(f"   âœ“ ç›´æ¥ä½¿ç”¨ Trading X WebSocket å³æ™‚æ•¸æ“š")
        print(f"   âœ“ ç„¡ä»»ä½•æ¨¡æ“¬æ•¸æ“šï¼Œç´”çœŸå¯¦å¸‚å ´")
        print(f"   âœ“ æ¯«ç§’ç´šé‡å­æ±ºç­–éŸ¿æ‡‰")
        print(f"   âœ“ åŸºæ–¼æ•¸å­¸çš„åˆ¶åº¦åµæ¸¬")
        print(f"   ğŸŒŒ é‡å­å„ªå‹¢ï¼šåœ¨çœŸå¯¦å¸‚å ´ä¸ç¢ºå®šæ€§ä¸­ä¿æŒçµ±è¨ˆå„ªå‹¢")
        
    except Exception as e:
        print(f"âŒ å¸‚å ´æ•¸æ“šæœå‹™éŒ¯èª¤: {e}")

def run_production_quantum_validation():
    """
    ç”Ÿç”¢ç´šé‡å­é©—è­‰æ¸¬è©¦
    
    é©—è­‰é‡å­ç³»çµ±åœ¨çœŸå¯¦ Trading X ç’°å¢ƒä¸­çš„ç©©å®šæ€§
    """
    print("\n" + "="*60)
    print("ç”Ÿç”¢ç´šé‡å­é©—è­‰æ¸¬è©¦")
    print("="*60)
    
    # å°å…¥ Trading X ç”Ÿç”¢æ¨¡çµ„
    try:
        import sys
        sys.path.append('../../X/app')
        from services.market_data import MarketDataService
        from core.config import settings
        
        # å°å…¥é‡å­ç”Ÿç”¢æ¨¡çµ„ (å¦‚æœå­˜åœ¨)
        sys.path.append('.')
        from quantum_decision_optimizer import ProductionQuantumEngine, ProductionQuantumConfig
        
        print("âœ… æˆåŠŸè¼‰å…¥ç”Ÿç”¢ç´šæ¨¡çµ„")
    except ImportError as e:
        print(f"âŒ ç”Ÿç”¢æ¨¡çµ„è¼‰å…¥å¤±æ•—: {e}")
        return
    
    # å‰µå»ºç”Ÿç”¢ç´šé…ç½®
    production_config = ProductionQuantumConfig(
        alpha_base=0.008,
        beta_base=0.045,
        kelly_multiplier=0.2,
        primary_symbols=['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
    )
    
    print(f"é…ç½®è¼‰å…¥: ç›£æ§ {len(production_config.primary_symbols)} å€‹ä¸»æ± å¹£ç¨®")
    
    # åˆå§‹åŒ–ç”Ÿç”¢ç´šé‡å­å¼•æ“
    try:
        quantum_engine = ProductionQuantumEngine(production_config)
        market_service = MarketDataService()
        
        print("âœ… ç”Ÿç”¢ç´šé‡å­å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # ç­‰å¾…æ•¸æ“š
        import time
        time.sleep(2)
        
        # é©—è­‰æ¸¬è©¦
        validation_results = {}
        
        for symbol in production_config.primary_symbols:
            print(f"\né©—è­‰ {symbol}:")
            
            # ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š
            price_data = market_service.realtime_data['prices'].get(symbol)
            
            if price_data:
                # æ§‹å»ºç”Ÿç”¢ç´šè§€æ¸¬
                try:
                    from quantum_decision_optimizer import CryptoMarketObservation
                    
                    observation = CryptoMarketObservation(
                        timestamp=pd.Timestamp.now(),
                        symbol=symbol,
                        price=price_data['price'],
                        returns=price_data['change_percent'] / 100,
                        volume_24h=price_data.get('volume_24h', 0),
                        market_cap=None,
                        realized_volatility=abs(price_data['change_percent'] / 100) * np.sqrt(24),
                        momentum_slope=price_data['change'] / price_data['price'],
                        rsi_14=50.0,  # é è¨­å€¼ï¼Œå¯å¾æŠ€è¡“åˆ†æç²å–
                        bb_position=0.5,  # é è¨­å€¼
                        orderbook_pressure=0.0,  # éœ€è¦æ·±åº¦æ•¸æ“š
                        bid_ask_spread=0.001,  # é è¨­å€¼
                        trade_aggression=0.0,  # éœ€è¦äº¤æ˜“æ•¸æ“š
                        funding_rate=0.01,  # å¯å¾æœŸè²¨APIç²å–
                        open_interest=0.0,  # éœ€è¦æœŸè²¨æ•¸æ“š
                        liquidation_ratio=0.0,  # éœ€è¦æ¸…ç®—æ•¸æ“š
                        social_sentiment=0.0,  # éœ€è¦ç¤¾äº¤æ•¸æ“š
                        whale_activity=0.0,  # éœ€è¦éˆä¸Šæ•¸æ“š
                        correlation_btc=0.8 if symbol != 'BTCUSDT' else 1.0,
                        market_regime_signal=0.0
                    )
                    
                    # æ¨¡æ“¬å‡è¨­ (ç”Ÿç”¢ç’°å¢ƒä¸­æœƒæœ‰çœŸå¯¦å‡è¨­ç”Ÿæˆ)
                    from quantum_decision_optimizer import ProductionTradingHypothesis
                    
                    hypothesis = ProductionTradingHypothesis(
                        symbol=symbol,
                        hypothesis_id=f"{symbol}_test",
                        direction=1 if price_data['change'] > 0 else -1,
                        expected_return_1h=price_data['change_percent'] / 100,
                        expected_return_4h=price_data['change_percent'] / 100 * 2,
                        expected_return_24h=price_data['change_percent'] / 100 * 4,
                        value_at_risk_95=abs(price_data['change_percent'] / 100) * 2,
                        expected_shortfall=abs(price_data['change_percent'] / 100) * 3,
                        max_adverse_excursion=abs(price_data['change_percent'] / 100) * 1.5,
                        optimal_timeframe="1h",
                        entry_confidence=0.7,
                        exit_conditions={"stop_loss": -0.02, "take_profit": 0.04},
                        regime_dependency=np.ones(6) / 6,
                        regime_performance={i: 0.01 for i in range(6)}
                    )
                    
                    # ç”Ÿç”¢ç´šè™•ç†
                    import asyncio
                    decision = asyncio.run(
                        quantum_engine.process_observation_production(
                            observation, [hypothesis]
                        )
                    )
                    
                    if decision:
                        validation_results[symbol] = {
                            'success': True,
                            'action': decision['hypothesis'].direction,
                            'confidence': decision['confidence'],
                            'regime': decision['dominant_regime'],
                            'processing_time': 'fast'
                        }
                        
                        print(f"  âœ… é©—è­‰æˆåŠŸ")
                        print(f"     æ±ºç­–: {'LONG' if decision['hypothesis'].direction > 0 else 'SHORT'}")
                        print(f"     ä¿¡å¿ƒ: {decision['confidence']:.3f}")
                        print(f"     åˆ¶åº¦: {decision['dominant_regime']}")
                    else:
                        validation_results[symbol] = {'success': False, 'reason': 'no_decision'}
                        print(f"  âš ï¸  ç„¡æ±ºç­–ç”¢ç”Ÿ")
                        
                except Exception as e:
                    validation_results[symbol] = {'success': False, 'reason': str(e)}
                    print(f"  âŒ è™•ç†å¤±æ•—: {e}")
            else:
                validation_results[symbol] = {'success': False, 'reason': 'no_data'}
                print(f"  âš ï¸  ç„¡æ•¸æ“š")
        
        # é©—è­‰çµæœç¸½çµ
        print(f"\nğŸ”¬ ç”Ÿç”¢ç´šé‡å­é©—è­‰çµæœ:")
        successful = sum(1 for r in validation_results.values() if r['success'])
        total = len(validation_results)
        
        print(f"   æˆåŠŸç‡: {successful}/{total} ({successful/total*100:.1f}%)")
        
        if successful > 0:
            print(f"   âœ… ç”Ÿç”¢ç´šé‡å­ç³»çµ±é©—è­‰é€šé")
            print(f"   ğŸš€ å¯ç”¨æ–¼ Trading X çœŸå¯¦äº¤æ˜“ç’°å¢ƒ")
        else:
            print(f"   âŒ é©—è­‰å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥ç³»çµ±é…ç½®")
            
    except Exception as e:
        print(f"âŒ ç”Ÿç”¢ç´šé©—è­‰å¤±æ•—: {e}")

# --------------------------
# çœŸå¯¦å¸‚å ´æ•¸æ“šæ•´åˆ
# --------------------------

def quantum_integration_test():
    """
    é‡å­æ±ºç­–å¼•æ“æ•´åˆæ¸¬è©¦ - çœŸå¯¦å¸‚å ´æ•¸æ“šç‰ˆæœ¬
    
    ç›´æ¥ä½¿ç”¨ Trading X çš„å³æ™‚å€å¡Šéˆæ•¸æ“šæº
    """
    print("\n" + "="*60)
    print("é‡å­æ±ºç­–å¼•æ“ - çœŸå¯¦å¸‚å ´æ•¸æ“šæ•´åˆæ¸¬è©¦")
    print("="*60)
    
    # å°å…¥çœŸå¯¦æ•¸æ“šæœå‹™
    try:
        import sys
        sys.path.append('../../X/app')
        from services.market_data import MarketDataService
        from services.binance_websocket import BinanceDataCollector
        
        print("âœ… æˆåŠŸå°å…¥çœŸå¯¦æ•¸æ“šæœå‹™")
    except ImportError as e:
        print(f"âŒ ç„¡æ³•å°å…¥æ•¸æ“šæœå‹™: {e}")
        print("è«‹ç¢ºä¿ Trading X ä¸»ç³»çµ±è·¯å¾‘æ­£ç¢º")
        return
    
    # 1. åˆå§‹åŒ–é‡å­å¢å¼· HMM
    print("\n1. åˆå§‹åŒ–é‡å­å¢å¼· HMM...")
    quantum_hmm = TimeVaryingHMM(
        n_states=6, 
        z_dim=3, 
        reg_lambda=1e-3,
        enable_quantum_features=True
    )
    
    # 2. è¨­ç½®ä¸»æ± ä¸ƒå¹£ç¨®
    primary_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
    print(f"2. é…ç½®ä¸»æ± ä¸ƒå¹£ç¨®: {primary_symbols}")
    
    # 3. åˆå§‹åŒ–å¸‚å ´æ•¸æ“šæœå‹™
    print("3. åˆå§‹åŒ–çœŸå¯¦å¸‚å ´æ•¸æ“šæœå‹™...")
    try:
        market_service = MarketDataService()
        print("âœ… å¸‚å ´æ•¸æ“šæœå‹™åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸¬è©¦ç²å–å³æ™‚åƒ¹æ ¼
        print("\n4. æ¸¬è©¦å³æ™‚å¸‚å ´æ•¸æ“šç²å–:")
        for symbol in primary_symbols[:3]:  # æ¸¬è©¦å‰3å€‹
            try:
                # ç²å–å³æ™‚åƒ¹æ ¼æ•¸æ“š
                price_data = market_service.realtime_data['prices'].get(symbol)
                if price_data:
                    print(f"   {symbol}: ${price_data['price']:.4f} "
                          f"({price_data['change_percent']:+.2f}%)")
                else:
                    print(f"   {symbol}: æ•¸æ“šæ­£åœ¨è¼‰å…¥...")
            except Exception as e:
                print(f"   {symbol}: ç²å–å¤±æ•— - {e}")
        
        # 5. é‡å­åˆ¶åº¦åˆ†ææ¼”ç¤º (ä½¿ç”¨çœŸå¯¦æ•¸æ“š)
        print("\n5. é‡å­åˆ¶åº¦åˆ†æ (åŸºæ–¼çœŸå¯¦å¸‚å ´æ•¸æ“š):")
        
        for symbol in primary_symbols[:2]:  # æ¸¬è©¦ BTC å’Œ ETH
            print(f"\n   åˆ†æ {symbol}:")
            
            # ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š
            price_data = market_service.realtime_data['prices'].get(symbol)
            kline_data = market_service.realtime_data['klines'].get(f"{symbol}_1m")
            depth_data = market_service.realtime_data['depths'].get(symbol)
            
            if price_data:
                # æ§‹å»ºçœŸå¯¦è§€æ¸¬æ•¸æ“š
                real_observation = {
                    'ret': price_data['change_percent'] / 100,  # è½‰æ›ç‚ºå°æ•¸
                    'logvol': np.log(max(abs(price_data['change_percent'] / 100), 1e-6)),
                    'slope': price_data['change'] / price_data['price'],  # åƒ¹æ ¼æ–œç‡
                    'ob': 0.0  # è¨‚å–®ç°¿å£“åŠ› (éœ€è¦æ·±åº¦æ•¸æ“šè¨ˆç®—)
                }
                
                # è¨ˆç®—è¨‚å–®ç°¿å£“åŠ› (å¦‚æœæœ‰æ·±åº¦æ•¸æ“š)
                if depth_data and depth_data['bids'] and depth_data['asks']:
                    best_bid = depth_data['bids'][0][0] if depth_data['bids'] else 0
                    best_ask = depth_data['asks'][0][0] if depth_data['asks'] else 0
                    if best_bid > 0 and best_ask > 0:
                        spread = (best_ask - best_bid) / best_ask
                        real_observation['ob'] = -spread  # è² å€¼è¡¨ç¤ºå£“åŠ›
                
                # æ§‹å»ºå”è®Šé‡
                z_real = np.array([
                    real_observation['slope'],
                    np.exp(real_observation['logvol']),
                    real_observation['ob']
                ])
                
                # å³æ™‚é‡å­ä¿¡è™Ÿç”Ÿæˆ
                if quantum_hmm.enable_quantum_features:
                    try:
                        quantum_decision = quantum_hmm.real_time_quantum_signal(
                            real_observation,
                            z_real,
                            {
                                "funding_rate": 0.01,  # å¯ä»¥å¾æœŸè²¨APIç²å–
                                "iv_skew": 0.05        # å¯ä»¥å¾æœŸæ¬ŠAPIç²å–
                            }
                        )
                        
                        print(f"     ğŸ¯ é‡å­æ±ºç­–: {quantum_decision.action}")
                        print(f"     ğŸ“Š åˆ¶åº¦: {quantum_decision.best_regime} "
                              f"(ä¿¡å¿ƒ: {quantum_decision.confidence:.3f})")
                        print(f"     âš–ï¸  é¢¨éšªå ±é…¬æ¯”: {quantum_decision.risk_reward_ratio:.2f}")
                        
                    except Exception as e:
                        print(f"     âŒ é‡å­æ±ºç­–ç”Ÿæˆå¤±æ•—: {e}")
                else:
                    print(f"     âš ï¸  é‡å­åŠŸèƒ½æœªå•Ÿç”¨")
            else:
                print(f"     âš ï¸  {symbol} æ•¸æ“šä¸å¯ç”¨")
    
    except Exception as e:
        print(f"âŒ å¸‚å ´æ•¸æ“šæœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
    
    print("\n6. çœŸå¯¦æ•¸æ“šé‡å­åˆ†æç¸½çµ:")
    print("   âœ… ç›´æ¥ä½¿ç”¨ Trading X å³æ™‚å€å¡Šéˆæ•¸æ“š")
    print("   âœ… ç„¡æ¨¡æ“¬æ•¸æ“šï¼Œç´”æ•¸å­¸é‡å­è¨ˆç®—")
    print("   âœ… åŸºæ–¼çœŸå¯¦å¸‚å ´å¾®è§€çµæ§‹")
    print("   ğŸš€ é‡å­å„ªå‹¢ï¼šåœ¨å¸‚å ´ä¸ç¢ºå®šæ€§ä¸­ä¿æŒçµ±è¨ˆå„ªå‹¢")

def run_comprehensive_quantum_test():
    """
    å…¨é¢é‡å­ç³»çµ±æ¸¬è©¦ - çœŸå¯¦å¸‚å ´æ•¸æ“šç‰ˆæœ¬
    """
    print("\n" + "="*80)
    print("å…¨é¢é‡å­ç³»çµ±æ¸¬è©¦ - Trading X çœŸå¯¦å¸‚å ´æ•¸æ“š")
    print("="*80)
    
    # å°å…¥çœŸå¯¦æ•¸æ“šå’Œé…ç½®
    try:
        import sys
        sys.path.append('../../X/app')
        from services.market_data import MarketDataService
        from core.config import settings
        
        print("âœ… æˆåŠŸè¼‰å…¥ Trading X æ ¸å¿ƒæ¨¡çµ„")
    except ImportError as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥æ ¸å¿ƒæ¨¡çµ„: {e}")
        return {}
    
    # çœŸå¯¦é…ç½®çš„ä¸ƒå¹£ç¨®
    primary_symbols = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'ADAUSDT']
    
    test_results = {}
    
    print(f"\nğŸ”¬ æ¸¬è©¦ Trading X ä¸»æ± ä¸ƒå¹£ç¨®é‡å­å¼•æ“")
    print("-" * 50)
    
    # åˆå§‹åŒ–é‡å­æ¨¡å‹
    quantum_model = TimeVaryingHMM(
        n_states=6, 
        z_dim=3,
        enable_quantum_features=True
    )
    
    # åˆå§‹åŒ–å¸‚å ´æ•¸æ“šæœå‹™
    try:
        market_service = MarketDataService()
        
        # ç­‰å¾…æ•¸æ“šè¼‰å…¥
        print("â³ ç­‰å¾…çœŸå¯¦å¸‚å ´æ•¸æ“šè¼‰å…¥...")
        import time
        time.sleep(2)  # çµ¦ WebSocket ä¸€äº›æ™‚é–“
        
        for symbol in primary_symbols:
            print(f"\nğŸ“ˆ åˆ†æ {symbol}")
            
            # ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š
            price_data = market_service.realtime_data['prices'].get(symbol)
            
            if price_data:
                # æ§‹å»ºé‡å­è§€æ¸¬
                quantum_observation = construct_quantum_observation(price_data, symbol)
                
                if quantum_observation:
                    # é‡å­åˆ¶åº¦åˆ†æ
                    z_features = extract_quantum_features(quantum_observation)
                    
                    # å³æ™‚é‡å­æ±ºç­–
                    if quantum_model.enable_quantum_features:
                        try:
                            decision = quantum_model.real_time_quantum_signal(
                                quantum_observation,
                                z_features,
                                get_market_context(symbol)
                            )
                            
                            test_results[symbol] = {
                                'action': decision.action,
                                'regime': decision.best_regime,
                                'confidence': decision.confidence,
                                'risk_reward': decision.risk_reward_ratio,
                                'price': price_data['price']
                            }
                            
                            print(f"   ğŸ¯ æ±ºç­–: {decision.action} | "
                                  f"åˆ¶åº¦: {decision.best_regime} | "
                                  f"ä¿¡å¿ƒ: {decision.confidence:.3f}")
                            
                        except Exception as e:
                            print(f"   âŒ é‡å­æ±ºç­–å¤±æ•—: {e}")
                            test_results[symbol] = {'error': str(e)}
                else:
                    print(f"   âš ï¸  æ•¸æ“šå“è³ªä¸è¶³")
                    test_results[symbol] = {'error': 'insufficient_data'}
            else:
                print(f"   âš ï¸  {symbol} æ•¸æ“šæœªè¼‰å…¥")
                test_results[symbol] = {'error': 'no_data'}
    
    except Exception as e:
        print(f"âŒ å¸‚å ´æ•¸æ“šæœå‹™éŒ¯èª¤: {e}")
        return {}
    
    # çµæœç¸½çµ
    print("\n" + "="*80)
    print("ğŸš€ é‡å­ç³»çµ±æ¸¬è©¦çµæœç¸½çµ")
    print("="*80)
    
    successful_analyses = [s for s, r in test_results.items() if 'error' not in r]
    
    if successful_analyses:
        print(f"âœ… æˆåŠŸåˆ†æ: {len(successful_analyses)}/{len(primary_symbols)} å¹£ç¨®")
        
        # æ±ºç­–åˆ†å¸ƒçµ±è¨ˆ
        actions = [test_results[s]['action'] for s in successful_analyses]
        action_counts = {action: actions.count(action) for action in set(actions)}
        print(f"ğŸ“Š æ±ºç­–åˆ†å¸ƒ: {action_counts}")
        
        # å¹³å‡ä¿¡å¿ƒåº¦
        avg_confidence = np.mean([test_results[s]['confidence'] for s in successful_analyses])
        print(f"ğŸ’ª å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.3f}")
        
        # å¹³å‡é¢¨éšªå ±é…¬æ¯”
        avg_risk_reward = np.mean([test_results[s]['risk_reward'] for s in successful_analyses])
        print(f"âš–ï¸  å¹³å‡é¢¨éšªå ±é…¬æ¯”: {avg_risk_reward:.2f}")
        
    else:
        print("âŒ ç„¡æˆåŠŸåˆ†ææ¡ˆä¾‹ï¼Œè«‹æª¢æŸ¥æ•¸æ“šé€£æ¥")
    
    print(f"\nğŸ’ Trading X é‡å­æ±ºç­–å¼•æ“ - çœŸå¯¦å¸‚å ´æ•¸æ“šæ•´åˆå®Œæˆ!")
    print("ğŸŒŒ é‡å­å„ªå‹¢ï¼šåœ¨å¸‚å ´éš¨æ©Ÿæ€§ä¸­ä¿æŒçµ±è¨ˆå„ªå‹¢æœ€å¤§åŒ–")
    
    return test_results

def construct_quantum_observation(price_data: dict, symbol: str) -> Optional[dict]:
    """
    åŸºæ–¼çœŸå¯¦å¸‚å ´æ•¸æ“šæ§‹å»ºé‡å­è§€æ¸¬
    
    Args:
        price_data: çœŸå¯¦åƒ¹æ ¼æ•¸æ“š
        symbol: äº¤æ˜“å°ç¬¦è™Ÿ
    
    Returns:
        é‡å­è§€æ¸¬å­—å…¸æˆ– None
    """
    try:
        # è¨ˆç®—çœŸå¯¦æ”¶ç›Šç‡
        price_change_pct = price_data.get('change_percent', 0)
        returns = price_change_pct / 100  # è½‰æ›ç‚ºå°æ•¸
        
        # è¨ˆç®—å·²å¯¦ç¾æ³¢å‹•ç‡ (åŸºæ–¼24å°æ™‚é«˜ä½åƒ¹)
        high_24h = price_data.get('high_24h', 0)
        low_24h = price_data.get('low_24h', 0)
        current_price = price_data.get('price', 0)
        
        if high_24h > low_24h > 0:
            realized_vol = (high_24h - low_24h) / current_price
        else:
            realized_vol = abs(returns) * np.sqrt(24)  # å›é€€ä¼°ç®—
        
        # è¨ˆç®—å‹•é‡æ–œç‡
        price_change = price_data.get('change', 0)
        momentum_slope = price_change / current_price if current_price > 0 else 0
        
        # æ§‹å»ºè§€æ¸¬ (è¨‚å–®ç°¿å£“åŠ›éœ€è¦æ·±åº¦æ•¸æ“šï¼Œæš«ç”¨0)
        observation = {
            'ret': returns,
            'logvol': np.log(max(realized_vol, 1e-6)),
            'slope': momentum_slope,
            'ob': 0.0  # å¯ä»¥å¾ŒçºŒå¾æ·±åº¦æ•¸æ“šè¨ˆç®—
        }
        
        return observation
        
    except Exception as e:
        logger.error(f"æ§‹å»ºé‡å­è§€æ¸¬å¤±æ•— {symbol}: {e}")
        return None

def extract_quantum_features(observation: dict) -> np.ndarray:
    """
    æå–é‡å­ç‰¹å¾µå‘é‡
    
    Args:
        observation: è§€æ¸¬å­—å…¸
    
    Returns:
        3ç¶­ç‰¹å¾µå‘é‡ [slope, volatility, orderbook]
    """
    return np.array([
        observation['slope'],
        np.exp(observation['logvol']),  # å°‡å°æ•¸æ³¢å‹•ç‡è½‰å›ç·šæ€§
        observation['ob']
    ])

def get_market_context(symbol: str) -> dict:
    """
    ç²å–å¸‚å ´èƒŒæ™¯ä¿¡æ¯ (å¯ä»¥å¾ŒçºŒæ“´å±•æ¥å…¥æ›´å¤šAPI)
    
    Args:
        symbol: äº¤æ˜“å°
    
    Returns:
        å¸‚å ´èƒŒæ™¯å­—å…¸
    """
    # é€™è£¡å¯ä»¥æ“´å±•æ¥å…¥ï¼š
    # - è³‡é‡‘è²»ç‡ API
    # - æœŸæ¬Šéš±å«æ³¢å‹•ç‡ API  
    # - éˆä¸ŠæŒ‡æ¨™ API
    # - å®è§€ç¶“æ¿Ÿæ•¸æ“š API
    
    return {
        "funding_rate": 0.01,  # é è¨­å€¼ï¼Œå¾ŒçºŒå¯æ¥çœŸå¯¦API
        "iv_skew": 0.05,       # é è¨­å€¼
        "net_flow_to_exchanges": 0  # é è¨­å€¼
    }


# ==================================================================================
# ğŸ”¥ å‹•æ…‹æ¬Šé‡èåˆç³»çµ± - é‡å­æ…‹èˆ‡ç¶“å…¸åˆ¶åº¦çš„æ™ºèƒ½èåˆ
# ==================================================================================

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™è¿½è¹¤å™¨"""
    recent_accuracy: float = 0.0
    hit_rate: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    volatility_adjusted_return: float = 0.0
    confidence_calibration: float = 0.0
    timestamp: datetime = None

class DynamicWeightFusion:
    """
    ğŸ§  å‹•æ…‹æ¬Šé‡èåˆå™¨ - è‡ªé©æ‡‰é‡å­èˆ‡åˆ¶åº¦ä¿¡è™Ÿèåˆ
    
    æ ¸å¿ƒç†å¿µï¼š
    - é‡å­æ³¢å‡½æ•¸ (quantum) èˆ‡ HMMåˆ¶åº¦ (regime) çš„æ™ºèƒ½èåˆ
    - åŸºæ–¼è¿‘æœŸè¡¨ç¾çš„è‡ªé©æ‡‰æ¬Šé‡èª¿æ•´
    - å¸‚å ´ç‹€æ…‹é©…å‹•çš„é¢¨éšªèª¿æ•´
    - è²è‘‰æ–¯æ›´æ–°çš„ç½®ä¿¡åº¦æ ¡æº–
    """
    
    def __init__(self, 
                 lookback_periods: int = 50,
                 learning_rate: float = 0.1,
                 volatility_threshold: float = 0.02,
                 confidence_alpha: float = 0.95):
        self.lookback_periods = lookback_periods
        self.learning_rate = learning_rate
        self.volatility_threshold = volatility_threshold
        self.confidence_alpha = confidence_alpha
        
        # æ€§èƒ½è¿½è¹¤
        self.regime_performance = deque(maxlen=lookback_periods)
        self.quantum_performance = deque(maxlen=lookback_periods)
        self.fusion_performance = deque(maxlen=lookback_periods)
        
        # æ¬Šé‡æ­·å²
        self.weight_history = deque(maxlen=lookback_periods)
        
        # å¸‚å ´ç‹€æ…‹è¿½è¹¤
        self.volatility_history = deque(maxlen=20)
        self.trend_strength_history = deque(maxlen=20)
        
        # å­¸ç¿’æ¨¡å‹
        self.weight_predictor = None
        self.is_trained = False
        
        # ç•¶å‰æ¬Šé‡
        self.current_regime_weight = 0.5
        self.current_quantum_weight = 0.5
        
        # ä¿¡è™Ÿæ­·å²
        self.signal_history = deque(maxlen=100)
        self.actual_returns = deque(maxlen=100)
        
        logger.info("ğŸ§  å‹•æ…‹æ¬Šé‡èåˆå™¨å·²åˆå§‹åŒ–")
    
    def update_performance(self, 
                          regime_signal: float, 
                          quantum_signal: float,
                          actual_return: float,
                          market_volatility: float):
        """æ›´æ–°æ€§èƒ½æŒ‡æ¨™"""
        
        # è¨ˆç®—å„æ¨¡å‹é æ¸¬æº–ç¢ºåº¦
        regime_accuracy = 1.0 - abs(regime_signal - actual_return)
        quantum_accuracy = 1.0 - abs(quantum_signal - actual_return)
        
        # æ›´æ–°æ€§èƒ½æ­·å²
        self.regime_performance.append(regime_accuracy)
        self.quantum_performance.append(quantum_accuracy)
        self.volatility_history.append(market_volatility)
        
        # è¨˜éŒ„ä¿¡è™Ÿèˆ‡å¯¦éš›çµæœ
        self.signal_history.append({
            'regime_signal': regime_signal,
            'quantum_signal': quantum_signal,
            'timestamp': datetime.now()
        })
        self.actual_returns.append(actual_return)
        
        # æ›´æ–°è¶¨å‹¢å¼·åº¦
        if len(self.actual_returns) >= 5:
            recent_returns = list(self.actual_returns)[-5:]
            trend_strength = abs(np.mean(recent_returns)) / (np.std(recent_returns) + 1e-8)
            self.trend_strength_history.append(trend_strength)
    
    def calculate_adaptive_weights(self) -> Tuple[float, float]:
        """ğŸ”„ è¨ˆç®—è‡ªé©æ‡‰æ¬Šé‡"""
        
        if len(self.regime_performance) < 10:
            # åˆæœŸä½¿ç”¨é è¨­æ¬Šé‡
            return 0.5, 0.5
        
        # 1. åŸºæ–¼è¿‘æœŸè¡¨ç¾çš„æ¬Šé‡
        regime_perf = np.mean(list(self.regime_performance)[-20:])
        quantum_perf = np.mean(list(self.quantum_performance)[-20:])
        
        # æ€§èƒ½å·®ç•°é©…å‹•çš„æ¬Šé‡èª¿æ•´
        total_perf = regime_perf + quantum_perf + 1e-8
        perf_regime_weight = regime_perf / total_perf
        perf_quantum_weight = quantum_perf / total_perf
        
        # 2. å¸‚å ´ç‹€æ…‹èª¿æ•´
        current_vol = np.mean(list(self.volatility_history)[-5:]) if self.volatility_history else 0.02
        vol_adjustment = self._get_volatility_adjustment(current_vol)
        
        # 3. è¶¨å‹¢å¼·åº¦èª¿æ•´  
        trend_strength = np.mean(list(self.trend_strength_history)[-5:]) if self.trend_strength_history else 1.0
        trend_adjustment = self._get_trend_adjustment(trend_strength)
        
        # 4. å‹•æ…‹èåˆ
        regime_weight = (
            perf_regime_weight * 0.5 +          # æ€§èƒ½é©…å‹•
            vol_adjustment['regime'] * 0.3 +     # æ³¢å‹•ç‡èª¿æ•´
            trend_adjustment['regime'] * 0.2     # è¶¨å‹¢èª¿æ•´
        )
        
        quantum_weight = (
            perf_quantum_weight * 0.5 +         # æ€§èƒ½é©…å‹•  
            vol_adjustment['quantum'] * 0.3 +    # æ³¢å‹•ç‡èª¿æ•´
            trend_adjustment['quantum'] * 0.2    # è¶¨å‹¢èª¿æ•´
        )
        
        # æ­£è¦åŒ–
        total = regime_weight + quantum_weight
        if total > 0:
            regime_weight /= total
            quantum_weight /= total
        else:
            regime_weight, quantum_weight = 0.5, 0.5
        
        # 5. å¹³æ»‘æ›´æ–°ï¼ˆé¿å…åŠ‡çƒˆè®ŠåŒ–ï¼‰
        self.current_regime_weight = (
            self.current_regime_weight * (1 - self.learning_rate) + 
            regime_weight * self.learning_rate
        )
        self.current_quantum_weight = (
            self.current_quantum_weight * (1 - self.learning_rate) + 
            quantum_weight * self.learning_rate
        )
        
        # è¨˜éŒ„æ¬Šé‡æ­·å²
        self.weight_history.append({
            'regime_weight': self.current_regime_weight,
            'quantum_weight': self.current_quantum_weight,
            'market_vol': current_vol,
            'trend_strength': trend_strength,
            'timestamp': datetime.now()
        })
        
        return self.current_regime_weight, self.current_quantum_weight
    
    def _get_volatility_adjustment(self, volatility: float) -> Dict[str, float]:
        """åŸºæ–¼æ³¢å‹•ç‡çš„æ¬Šé‡èª¿æ•´"""
        
        if volatility > self.volatility_threshold * 2:
            # é«˜æ³¢å‹•æœŸï¼šåå‘åˆ¶åº¦æ¨¡å‹ï¼ˆæ›´ç©©å®šï¼‰
            return {'regime': 0.7, 'quantum': 0.3}
        elif volatility < self.volatility_threshold * 0.5:
            # ä½æ³¢å‹•æœŸï¼šåå‘é‡å­æ¨¡å‹ï¼ˆæ›´éˆæ•ï¼‰
            return {'regime': 0.3, 'quantum': 0.7}
        else:
            # æ­£å¸¸æ³¢å‹•ï¼šå¹³è¡¡æ¬Šé‡
            return {'regime': 0.5, 'quantum': 0.5}
    
    def _get_trend_adjustment(self, trend_strength: float) -> Dict[str, float]:
        """åŸºæ–¼è¶¨å‹¢å¼·åº¦çš„æ¬Šé‡èª¿æ•´"""
        
        if trend_strength > 2.0:
            # å¼·è¶¨å‹¢ï¼šåå‘é‡å­æ¨¡å‹ï¼ˆè¶¨å‹¢è¿½è¹¤ï¼‰
            return {'regime': 0.3, 'quantum': 0.7}
        elif trend_strength < 0.5:
            # å¼±è¶¨å‹¢/éœ‡ç›ªï¼šåå‘åˆ¶åº¦æ¨¡å‹ï¼ˆç‹€æ…‹è­˜åˆ¥ï¼‰
            return {'regime': 0.7, 'quantum': 0.3}
        else:
            # ä¸­ç­‰è¶¨å‹¢ï¼šå¹³è¡¡æ¬Šé‡
            return {'regime': 0.5, 'quantum': 0.5}
    
    def fuse_signals(self, 
                    regime_probability: float,
                    regime_persistence: float,
                    quantum_confidence: float,
                    quantum_fidelity: float,
                    risk_reward_ratio: float) -> Dict[str, float]:
        """ğŸ”® èåˆé‡å­èˆ‡åˆ¶åº¦ä¿¡è™Ÿ"""
        
        # ç²å–ç•¶å‰è‡ªé©æ‡‰æ¬Šé‡
        regime_w, quantum_w = self.calculate_adaptive_weights()
        
        # åˆ¶åº¦ä¿¡è™Ÿå¼·åº¦
        regime_signal_strength = (
            regime_probability * 0.6 +
            regime_persistence * 0.4
        )
        
        # é‡å­ä¿¡è™Ÿå¼·åº¦
        quantum_signal_strength = (
            quantum_confidence * 0.5 +
            quantum_fidelity * 0.3 +
            min(risk_reward_ratio / 3.0, 1.0) * 0.2  # é¢¨éšªå›å ±æ¯”æ¨™æº–åŒ–
        )
        
        # å‹•æ…‹ç½®ä¿¡åº¦æ ¡æº–
        regime_calibrated = self._calibrate_confidence(regime_signal_strength, 'regime')
        quantum_calibrated = self._calibrate_confidence(quantum_signal_strength, 'quantum')
        
        # æœ€çµ‚èåˆä¿¡è™Ÿ
        final_confidence = (
            regime_calibrated * regime_w +
            quantum_calibrated * quantum_w
        )
        
        # é¢¨éšªèª¿æ•´ï¼ˆåŸºæ–¼ç•¶å‰å¸‚å ´æ³¢å‹•ç‡ï¼‰
        current_vol = np.mean(list(self.volatility_history)[-3:]) if self.volatility_history else 0.02
        risk_multiplier = max(0.1, min(1.0, 1.0 - (current_vol - 0.02) * 10))
        
        final_confidence *= risk_multiplier
        
        return {
            'final_confidence': final_confidence,
            'regime_weight': regime_w,
            'quantum_weight': quantum_w,
            'regime_signal': regime_calibrated,
            'quantum_signal': quantum_calibrated,
            'risk_multiplier': risk_multiplier,
            'market_volatility': current_vol
        }
    
    def _calibrate_confidence(self, raw_confidence: float, signal_type: str) -> float:
        """åŸºæ–¼æ­·å²è¡¨ç¾æ ¡æº–ç½®ä¿¡åº¦"""
        
        if signal_type == 'regime' and len(self.regime_performance) >= 10:
            avg_performance = np.mean(list(self.regime_performance)[-20:])
            calibration_factor = min(1.2, max(0.8, avg_performance))
        elif signal_type == 'quantum' and len(self.quantum_performance) >= 10:
            avg_performance = np.mean(list(self.quantum_performance)[-20:])
            calibration_factor = min(1.2, max(0.8, avg_performance))
        else:
            calibration_factor = 1.0
        
        return raw_confidence * calibration_factor
    
    def train_weight_predictor(self):
        """ğŸ¤– è¨“ç·´æ¬Šé‡é æ¸¬æ¨¡å‹"""
        
        if len(self.weight_history) < 30:
            logger.warning("æ¬Šé‡æ­·å²æ•¸æ“šä¸è¶³ï¼Œç„¡æ³•è¨“ç·´é æ¸¬æ¨¡å‹")
            return
        
        try:
            # æº–å‚™è¨“ç·´æ•¸æ“š
            features = []
            targets = []
            
            for i in range(10, len(self.weight_history)):
                # ç‰¹å¾µï¼šéå»10æœŸçš„å¸‚å ´ç‹€æ…‹
                hist_vol = [self.weight_history[j]['market_vol'] for j in range(i-10, i)]
                hist_trend = [self.weight_history[j]['trend_strength'] for j in range(i-10, i)]
                
                feature_vec = (
                    hist_vol + hist_trend +
                    [np.mean(hist_vol), np.std(hist_vol), np.mean(hist_trend), np.std(hist_trend)]
                )
                features.append(feature_vec)
                
                # ç›®æ¨™ï¼šæœ€ä½³æ¬Šé‡çµ„åˆ
                target = [
                    self.weight_history[i]['regime_weight'],
                    self.weight_history[i]['quantum_weight']
                ]
                targets.append(target)
            
            X = np.array(features)
            y = np.array(targets)
            
            # è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹
            self.weight_predictor = RandomForestRegressor(
                n_estimators=50,
                max_depth=10,
                random_state=42
            )
            self.weight_predictor.fit(X, y)
            self.is_trained = True
            
            logger.info("âœ… æ¬Šé‡é æ¸¬æ¨¡å‹è¨“ç·´å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¬Šé‡é æ¸¬æ¨¡å‹è¨“ç·´å¤±æ•—: {e}")
    
    def get_adaptive_weights_ml(self) -> Tuple[float, float]:
        """ğŸ¤– åŸºæ–¼æ©Ÿå™¨å­¸ç¿’çš„æ¬Šé‡é æ¸¬"""
        
        if not self.is_trained or len(self.weight_history) < 10:
            return self.calculate_adaptive_weights()
        
        try:
            # æº–å‚™ç•¶å‰ç‰¹å¾µ
            recent_vol = [w['market_vol'] for w in list(self.weight_history)[-10:]]
            recent_trend = [w['trend_strength'] for w in list(self.weight_history)[-10:]]
            
            feature_vec = (
                recent_vol + recent_trend +
                [np.mean(recent_vol), np.std(recent_vol), np.mean(recent_trend), np.std(recent_trend)]
            )
            
            # é æ¸¬æ¬Šé‡
            predicted_weights = self.weight_predictor.predict([feature_vec])[0]
            
            regime_weight = max(0.1, min(0.9, predicted_weights[0]))
            quantum_weight = max(0.1, min(0.9, predicted_weights[1]))
            
            # æ­£è¦åŒ–
            total = regime_weight + quantum_weight
            regime_weight /= total
            quantum_weight /= total
            
            return regime_weight, quantum_weight
            
        except Exception as e:
            logger.error(f"MLæ¬Šé‡é æ¸¬å¤±æ•—: {e}")
            return self.calculate_adaptive_weights()
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ğŸ“Š ç²å–æ€§èƒ½ç¸½çµ"""
        
        if len(self.regime_performance) < 5:
            return {"status": "insufficient_data"}
        
        regime_perf = list(self.regime_performance)
        quantum_perf = list(self.quantum_performance)
        
        return {
            "regime_performance": {
                "recent_avg": np.mean(regime_perf[-10:]),
                "overall_avg": np.mean(regime_perf),
                "volatility": np.std(regime_perf),
                "trend": np.polyfit(range(len(regime_perf)), regime_perf, 1)[0]
            },
            "quantum_performance": {
                "recent_avg": np.mean(quantum_perf[-10:]),
                "overall_avg": np.mean(quantum_perf),
                "volatility": np.std(quantum_perf),
                "trend": np.polyfit(range(len(quantum_perf)), quantum_perf, 1)[0]
            },
            "current_weights": {
                "regime": self.current_regime_weight,
                "quantum": self.current_quantum_weight
            },
            "market_state": {
                "volatility": np.mean(list(self.volatility_history)[-5:]) if self.volatility_history else 0.02,
                "trend_strength": np.mean(list(self.trend_strength_history)[-5:]) if self.trend_strength_history else 1.0
            }
        }

if __name__ == "__main__":
    print("ğŸŒŒ é‡å­å¸‚å ´åˆ¶åº¦æª¢æ¸¬å¼•æ“ - Trading X")
    print("=" * 80)
    print("æ ¸å¿ƒç†å¿µ: åœ¨å¸‚å ´éš¨æ©Ÿåç¸®çš„éç¨‹ä¸­ï¼Œå§‹çµ‚ç«™åœ¨çµ±è¨ˆå„ªå‹¢æœ€å¤§çš„ä¸€é‚Š")
    print("=" * 80)
    
    # é¸æ“‡æ¸¬è©¦æ¨¡å¼
    test_mode = input("\né¸æ“‡æ¸¬è©¦æ¨¡å¼ (1: åŸºç¤æ€§èƒ½æ¸¬è©¦, 2: é‡å­æ•´åˆæ¸¬è©¦, 3: å…¨é¢ç³»çµ±æ¸¬è©¦, 4: å…¨éƒ¨): ")
    
    if test_mode in ['1', '4']:
        print("\nğŸ”§ åŸ·è¡ŒåŸºç¤æ€§èƒ½æ¸¬è©¦...")
        benchmark_optimized_hmm()
        run_production_em_test()
    
    if test_mode in ['2', '4']:
        print("\nâš¡ åŸ·è¡Œé‡å­æ•´åˆæ¸¬è©¦...")
        quantum_integration_test()
    
    if test_mode in ['3', '4']:
        print("\nğŸš€ åŸ·è¡Œå…¨é¢ç³»çµ±æ¸¬è©¦...")
        run_comprehensive_quantum_test()
    
    print("\n" + "="*80)
    print("ğŸ¯ é‡å­å¸‚å ´åˆ¶åº¦æª¢æ¸¬å¼•æ“ - æ¸¬è©¦å®Œæˆ!")
    print("=" * 80)
    print("âœ… é‡å­å„ªå‹¢ç‰¹æ€§:")
    print("   ğŸ”® é‡å­ä¿¡è™Ÿæ€§åƒ¹æ¯”ç¯©é¸å™¨ - çµ±è¨ˆå„ªå‹¢æœ€å¤§åŒ–")
    print("   ğŸŒŠ å³æ™‚æµè³‡æ–™é©é… - æŒçºŒå­¸ç¿’æ›´æ–°")
    print("   ğŸ”— è·¨è³‡ç”¢è€¦åˆåµæ¸¬ - å¤šå¹£ç¨®å¹²æ¶‰åˆ†æ")
    print("   âš¡ åˆ¶åº¦çªè®Šæª¢æ¸¬å™¨ - æ³¢å‡½æ•¸åç¸®é è­¦")
    print("   ğŸ“Š å¤šæ™‚é–“æ¡†æ¶æ•´åˆ - å…¨æ–¹ä½å¸‚å ´æ´å¯Ÿ")
    print("\nğŸ’ Trading X é‡å­äº¤æ˜“ç³»çµ± - æº–å‚™å°±ç·’!")
    print("=" * 80)
