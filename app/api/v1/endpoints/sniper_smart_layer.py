# ğŸ¯ ç‹™æ“Šæ‰‹æ™ºèƒ½åˆ†å±¤ç³»çµ± - API ç«¯é»

from fastapi import APIRouter, Query, HTTPException, BackgroundTasks, Depends
from typing import List, Optional, Dict, Any
from datetime import datetime, timedelta
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import Session
from sqlalchemy import or_
import os

from app.services.sniper_smart_layer import sniper_smart_layer, SniperSmartLayerSystem
from app.services.sniper_emergency_trigger import sniper_emergency_trigger
from app.services.sniper_signal_history_service import sniper_signal_tracker
from app.utils.timezone_utils import get_taiwan_now, ensure_taiwan_timezone
from app.core.database import get_db
from app.models.sniper_signal_history import SniperSignalDetails
import logging

logger = logging.getLogger(__name__)
router = APIRouter()

# ==================== ç²¾æº–ç­–ç•¥æ™‚é–“éæ¿¾å™¨ ====================

async def _apply_precision_time_filter(signals: List[Dict]) -> List[Dict]:
    """
    ğŸš€ ç²¾æº–ç­–ç•¥æ™‚é–“éæ¿¾ - å¤šå±¤æ™‚é–“å„ªå…ˆç¯©é¸
    
    å„ªå…ˆç´šï¼š
    1. âš¡ 10ç§’å…§ï¼šå¯¦æ™‚åˆ†æä¿¡è™Ÿ (æœ€é«˜å„ªå…ˆç´š)
    2. ğŸ”¥ 1åˆ†é˜å…§ï¼šæ–°é®®åˆ†æä¿¡è™Ÿ (é«˜å„ªå…ˆç´š)  
    3. â° 5åˆ†é˜å…§ï¼šè¿‘æœŸåˆ†æä¿¡è™Ÿ (ä¸­å„ªå…ˆç´š)
    4. ğŸ• 15åˆ†é˜å…§ï¼šå¯ç”¨åˆ†æä¿¡è™Ÿ (ä½å„ªå…ˆç´š)
    5. âš ï¸ è¶…é15åˆ†é˜ï¼šå¸¶éæœŸè­¦å‘Š (æœ€ä½å„ªå…ˆç´š)
    """
    try:
        from app.utils.timezone_utils import get_taiwan_now
        
        now = get_taiwan_now().replace(tzinfo=None)  # ç§»é™¤æ™‚å€ä¿¡æ¯é¿å…æ¯”è¼ƒéŒ¯èª¤
        
        tier_1 = []  # â‰¤10ç§’
        tier_2 = []  # â‰¤1åˆ†é˜
        tier_3 = []  # â‰¤5åˆ†é˜
        tier_4 = []  # â‰¤15åˆ†é˜
        tier_5 = []  # >15åˆ†é˜
        
        for signal in signals:
            try:
                # è§£æä¿¡è™Ÿç”Ÿæˆæ™‚é–“
                created_at = signal.get('created_at')
                if isinstance(created_at, str):
                    # ç°¡åŒ–æ™‚é–“è§£æï¼Œé¿å…æ™‚å€éŒ¯èª¤
                    if 'T' in created_at:
                        created_at = created_at.split('T')[0] + ' ' + created_at.split('T')[1].split('+')[0].split('Z')[0]
                    created_at = datetime.strptime(created_at[:19], '%Y-%m-%d %H:%M:%S')
                elif isinstance(created_at, datetime):
                    created_at = created_at.replace(tzinfo=None)
                else:
                    # å¦‚æœæ™‚é–“è§£æå¤±æ•—ï¼Œçµ¦é»˜èªæ™‚é–“å·®
                    signal['time_diff_seconds'] = 600  # 10åˆ†é˜
                    signal['precision_tier'] = 'unknown'
                    tier_4.append(signal)
                    continue
                    
                time_diff = (now - created_at).total_seconds()
                
                # æ·»åŠ æ™‚é–“å·®æ¨™è¨˜
                signal['time_diff_seconds'] = time_diff
                signal['local_created_at'] = created_at.strftime('%Y-%m-%d %H:%M:%S')
                signal['precision_tier'] = None
                
                if time_diff <= 10:
                    signal['precision_tier'] = 'realtime'
                    tier_1.append(signal)
                elif time_diff <= 60:
                    signal['precision_tier'] = 'fresh'
                    tier_2.append(signal)
                elif time_diff <= 300:
                    signal['precision_tier'] = 'recent'
                    tier_3.append(signal)
                elif time_diff <= 900:
                    signal['precision_tier'] = 'available'
                    tier_4.append(signal)
                else:
                    signal['precision_tier'] = 'expired'
                    signal['expiry_warning'] = True
                    tier_5.append(signal)
            except Exception as e:
                logger.warning(f"âš ï¸ ä¿¡è™Ÿæ™‚é–“è§£æå¤±æ•—: {e}")
                signal['time_diff_seconds'] = 600
                signal['precision_tier'] = 'unknown'
                tier_4.append(signal)
        
        # è¨˜éŒ„åˆ†å±¤çµæœ
        logger.info(f"ğŸš€ ç²¾æº–ç­–ç•¥æ™‚é–“åˆ†å±¤: "
                   f"å¯¦æ™‚({len(tier_1)}) | æ–°é®®({len(tier_2)}) | è¿‘æœŸ({len(tier_3)}) | "
                   f"å¯ç”¨({len(tier_4)}) | éæœŸ({len(tier_5)})")
        
        # å„ªå…ˆè¿”å›é«˜å±¤ç´šä¿¡è™Ÿï¼Œä½†æ›´å¯¬é¬†çš„ç­–ç•¥
        combined_signals = []
        
        if tier_1:
            logger.info(f"âš¡ åŒ…å«å¯¦æ™‚ä¿¡è™Ÿ: {len(tier_1)} å€‹ (â‰¤10ç§’)")
            combined_signals.extend(tier_1)
        if tier_2:
            logger.info(f"ğŸ”¥ åŒ…å«æ–°é®®ä¿¡è™Ÿ: {len(tier_2)} å€‹ (â‰¤1åˆ†é˜)")
            combined_signals.extend(tier_2)
        if tier_3:
            logger.info(f"â° åŒ…å«è¿‘æœŸä¿¡è™Ÿ: {len(tier_3)} å€‹ (â‰¤5åˆ†é˜)")
            combined_signals.extend(tier_3)
        if tier_4:
            logger.info(f"ğŸ• åŒ…å«å¯ç”¨ä¿¡è™Ÿ: {len(tier_4)} å€‹ (â‰¤15åˆ†é˜)")
            combined_signals.extend(tier_4)
        
        # å¦‚æœé«˜è³ªé‡ä¿¡è™Ÿä¸å¤ ï¼Œä¹ŸåŒ…å«éæœŸä¿¡è™Ÿä½†æ¨™è¨˜è­¦å‘Š
        if len(combined_signals) < 5 and tier_5:
            logger.info(f"âš ï¸ è£œå……éæœŸä¿¡è™Ÿ: {len(tier_5)} å€‹ (>15åˆ†é˜)")
            combined_signals.extend(tier_5[:10])  # æœ€å¤šæ·»åŠ 10å€‹éæœŸä¿¡è™Ÿ
        
        return combined_signals if combined_signals else signals  # å¦‚æœæ²’æœ‰ä»»ä½•ä¿¡è™Ÿï¼Œè¿”å›åŸå§‹åˆ—è¡¨
    except Exception as e:
        logger.error(f"âŒ ç²¾æº–æ™‚é–“éæ¿¾å¤±æ•—: {e}")
        return signals  # è¿”å›åŸå§‹ä¿¡è™Ÿåˆ—è¡¨

# ==================== Pydantic æ¨¡å‹ ====================

class SmartLayerQuery(BaseModel):
    """æ™ºèƒ½åˆ†å±¤æŸ¥è©¢åƒæ•¸"""
    symbols: Optional[List[str]] = None
    include_analysis: bool = True
    quality_threshold: float = 6.0
    max_signals_per_symbol: int = 1

class LastStrategyQuery(BaseModel):
    """ä¸Šä¸€å–®ç­–ç•¥æŸ¥è©¢åƒæ•¸"""
    include_recommendation: bool = True
    include_risk_assessment: bool = True

class DynamicRiskParamsResponse(BaseModel):
    """å‹•æ…‹é¢¨éšªåƒæ•¸éŸ¿æ‡‰æ¨¡å‹"""
    symbol: str
    market_volatility_score: float
    volume_score: float
    liquidity_score: float
    emotion_multiplier: float
    market_regime: str
    regime_confidence: float
    bull_weight: float
    bear_weight: float
    dynamic_stop_loss: float
    dynamic_take_profit: float
    confidence_threshold: float
    rsi_threshold: List[int]
    ma_periods: List[int]
    position_multiplier: float
    last_update: str

# ==================== API ç«¯é» ====================

@router.delete("/clear-test-signals", response_model=dict)
async def clear_test_signals(
    db: AsyncSession = Depends(get_db)
):
    """ğŸ§¹ æ¸…ç†æ‰€æœ‰æ¸¬è©¦ä¿¡è™Ÿï¼ˆåŒ…å« test_ æˆ– smart_ å‰ç¶´çš„ä¿¡è™Ÿï¼‰"""
    try:
        from sqlalchemy import select, delete
        
        # æŸ¥è©¢åŒ…å«æ¸¬è©¦å‰ç¶´çš„ä¿¡è™Ÿ
        test_prefixes = ['test_', 'smart_', 'demo_']
        conditions = []
        for prefix in test_prefixes:
            conditions.append(SniperSignalDetails.signal_id.like(f'{prefix}%'))
        
        # å…ˆæŸ¥è©¢æ•¸é‡
        count_stmt = select(SniperSignalDetails).filter(or_(*conditions))
        result = await db.execute(count_stmt)
        signals_to_delete = result.scalars().all()
        delete_count = len(signals_to_delete)
        
        # åˆªé™¤æ¸¬è©¦ä¿¡è™Ÿ
        delete_stmt = delete(SniperSignalDetails).where(or_(*conditions))
        await db.execute(delete_stmt)
        await db.commit()
        
        logger.info(f"ğŸ§¹ æ¸…ç†æ¸¬è©¦ä¿¡è™Ÿå®Œæˆ: åˆªé™¤ {delete_count} å€‹ä¿¡è™Ÿ")
        
        return {
            "status": "success",
            "deleted_count": delete_count,
            "message": f"ğŸ§¹ æˆåŠŸæ¸…ç† {delete_count} å€‹æ¸¬è©¦ä¿¡è™Ÿ",
            "cleared_prefixes": test_prefixes,
            "timestamp": get_taiwan_now().isoformat()
        }
        
    except Exception as e:
        await db.rollback()
        logger.error(f"âŒ åˆªé™¤æ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ¸…ç†æ¸¬è©¦ä¿¡è™Ÿå¤±æ•—: {str(e)}"
        )

@router.post("/update-signal-status", response_model=dict)
async def update_signal_status(
    signal_id: str,
    new_status: str,
    pnl_percentage: Optional[float] = None,
    result_price: Optional[float] = None,
    db: AsyncSession = Depends(get_db)
):
    """ğŸ”§ æ‰‹å‹•æ›´æ–°ä¿¡è™Ÿç‹€æ…‹ï¼ˆç”¨æ–¼æ¸¬è©¦çµ±è¨ˆç®—æ³•ï¼‰"""
    try:
        from sqlalchemy import select, update
        from app.models.sniper_signal_history import SniperSignalDetails, SignalStatus
        
        # æŸ¥æ‰¾ä¿¡è™Ÿ
        stmt = select(SniperSignalDetails).where(SniperSignalDetails.signal_id == signal_id)
        result = await db.execute(stmt)
        signal = result.scalar_one_or_none()
        
        if not signal:
            raise HTTPException(status_code=404, detail=f"ä¿¡è™Ÿ {signal_id} ä¸å­˜åœ¨")
        
        # ç‹€æ…‹æ˜ å°„
        status_map = {
            "expired": SignalStatus.EXPIRED,
            "hit_tp": SignalStatus.HIT_TP,
            "hit_sl": SignalStatus.HIT_SL,
            "cancelled": SignalStatus.CANCELLED
        }
        
        if new_status not in status_map:
            raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆç‹€æ…‹: {new_status}")
        
        # æ›´æ–°ä¿¡è™Ÿ
        update_data = {
            "status": status_map[new_status],
            "result_time": get_taiwan_now()
        }
        
        if pnl_percentage is not None:
            update_data["pnl_percentage"] = pnl_percentage
        
        if result_price is not None:
            update_data["result_price"] = result_price
        
        stmt = update(SniperSignalDetails).where(
            SniperSignalDetails.signal_id == signal_id
        ).values(**update_data)
        
        await db.execute(stmt)
        await db.commit()
        
        logger.info(f"ğŸ”§ ä¿¡è™Ÿç‹€æ…‹æ›´æ–°: {signal_id} â†’ {new_status}")
        
        return {
            "status": "success",
            "message": f"ä¿¡è™Ÿ {signal_id} ç‹€æ…‹å·²æ›´æ–°ç‚º {new_status}",
            "updates": update_data,
            "timestamp": get_taiwan_now().isoformat()
        }
        
    except Exception as e:
        await db.rollback()
        logger.error(f"âŒ æ›´æ–°ä¿¡è™Ÿç‹€æ…‹å¤±æ•—: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ›´æ–°ä¿¡è™Ÿç‹€æ…‹å¤±æ•—: {str(e)}"
        )

async def _generate_enhanced_statistics(signals: List[Dict]) -> Dict:
    """ç”Ÿæˆå¢å¼·çµ±è¨ˆä¿¡æ¯"""
    try:
        from app.core.database import get_db
        from app.models.sniper_signal_history import SniperSignalDetails, SignalStatus
        from sqlalchemy import select, func
        
        # ç²å–æ•¸æ“šåº«çµ±è¨ˆ
        db_gen = get_db()
        db = await db_gen.__anext__()
        
        try:
            # åŸºæœ¬çµ±è¨ˆ
            total_result = await db.execute(
                select(func.count(SniperSignalDetails.id))
            )
            total_db_signals = total_result.scalar() or 0
            
            # ç‹€æ…‹çµ±è¨ˆ
            status_result = await db.execute(
                select(
                    SniperSignalDetails.status,
                    func.count(SniperSignalDetails.id),
                    func.avg(SniperSignalDetails.pnl_percentage)
                ).group_by(SniperSignalDetails.status)
            )
            
            status_stats = {}
            for row in status_result.fetchall():
                status_stats[row[0].value] = {
                    'count': row[1],
                    'avg_pnl': round(row[2] or 0, 2)
                }
            
            # è¨ˆç®—çœŸå¯¦çµ±è¨ˆæŒ‡æ¨™
            active_count = status_stats.get('ACTIVE', {}).get('count', 0)
            tp_count = status_stats.get('HIT_TP', {}).get('count', 0)
            sl_count = status_stats.get('HIT_SL', {}).get('count', 0)
            expired_count = status_stats.get('EXPIRED', {}).get('count', 0)
            
            completed_signals = tp_count + sl_count + expired_count
            traditional_win_rate = (tp_count / completed_signals * 100) if completed_signals > 0 else 0.0
            
            # åŸºæ–¼PnLçš„çœŸå¯¦æˆåŠŸç‡
            profitable_result = await db.execute(
                select(func.count(SniperSignalDetails.id))
                .where(SniperSignalDetails.pnl_percentage > 0)
            )
            profitable_count = profitable_result.scalar() or 0
            real_success_rate = (profitable_count / total_db_signals * 100) if total_db_signals > 0 else 0.0
            
            return {
                'database_stats': {
                    'total_signals': total_db_signals,
                    'active_signals': active_count,
                    'traditional_win_rate': round(traditional_win_rate, 1),
                    'real_success_rate': round(real_success_rate, 1),
                    'status_breakdown': status_stats
                },
                'api_stats': {
                    'returned_signals': len(signals),
                    'symbols_covered': len(set(s['symbol'] for s in signals)),
                    'avg_quality_score': round(sum(s.get('quality_score', 0) for s in signals) / len(signals), 2) if signals else 0,
                    'quality_range': {
                        'min': min(s.get('quality_score', 0) for s in signals) if signals else 0,
                        'max': max(s.get('quality_score', 0) for s in signals) if signals else 0
                    }
                },
                'filtering_efficiency': {
                    'db_to_api_ratio': round((len(signals) / total_db_signals * 100), 1) if total_db_signals > 0 else 0,
                    'active_to_api_ratio': round((len(signals) / active_count * 100), 1) if active_count > 0 else 0
                }
            }
            
        finally:
            await db_gen.aclose()
            
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆå¢å¼·çµ±è¨ˆå¤±æ•—: {e}")
        return {
            'database_stats': {'error': str(e)},
            'api_stats': {'returned_signals': len(signals)},
            'filtering_efficiency': {'error': 'calculation_failed'}
        }
