"""
äº‹ä»¶é æ¸¬å¼•æ“ - Trading X Phase 3 Week 1
åŸºæ–¼æ­·å²æ•¸æ“šå’Œå¸‚å ´æ¨¡å¼çš„äº‹ä»¶é æ¸¬ç³»çµ±
"""

import logging
import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import json
from collections import deque
import pickle
import os

logger = logging.getLogger(__name__)

class PredictionConfidence(Enum):
    """é æ¸¬ä¿¡å¿ƒç­‰ç´š"""
    VERY_LOW = "very_low"      # 0.0-0.3
    LOW = "low"                # 0.3-0.5
    MEDIUM = "medium"          # 0.5-0.7
    HIGH = "high"              # 0.7-0.85
    VERY_HIGH = "very_high"    # 0.85-1.0

class EventCategory(Enum):
    """äº‹ä»¶é¡åˆ¥"""
    MACRO_ECONOMIC = "macro_economic"      # å®è§€ç¶“æ¿Ÿäº‹ä»¶
    TECHNICAL_BREAKOUT = "technical_breakout"  # æŠ€è¡“çªç ´äº‹ä»¶
    VOLUME_ANOMALY = "volume_anomaly"      # æˆäº¤é‡ç•°å¸¸
    VOLATILITY_SPIKE = "volatility_spike"  # æ³¢å‹•ç‡æ¿€å¢
    CORRELATION_BREAK = "correlation_break" # ç›¸é—œæ€§ç ´è£‚
    LIQUIDITY_CRISIS = "liquidity_crisis"  # æµå‹•æ€§å±æ©Ÿ

@dataclass
class MarketPattern:
    """å¸‚å ´æ¨¡å¼æ•¸æ“š"""
    pattern_id: str
    category: EventCategory
    pattern_features: Dict[str, float]  # ç‰¹å¾µå‘é‡
    historical_occurrences: int        # æ­·å²ç™¼ç”Ÿæ¬¡æ•¸
    success_rate: float                # æˆåŠŸé æ¸¬ç‡
    avg_lead_time_hours: float         # å¹³å‡æå‰æ™‚é–“ï¼ˆå°æ™‚ï¼‰
    confidence_threshold: float        # ä¿¡å¿ƒé–¾å€¼
    last_occurrence: Optional[datetime] = None

@dataclass
class EventPrediction:
    """äº‹ä»¶é æ¸¬çµæœ"""
    prediction_id: str
    event_category: EventCategory
    predicted_event_time: datetime
    confidence: float
    confidence_level: PredictionConfidence
    affected_symbols: List[str]
    expected_impact_magnitude: float   # é æœŸå½±éŸ¿å¹…åº¦ (0.0-1.0)
    prediction_horizon_hours: int     # é æ¸¬æ™‚é–“ç¯„åœ
    contributing_patterns: List[str]   # è²¢ç»çš„æ¨¡å¼ID
    risk_factors: Dict[str, float]    # é¢¨éšªå› å­
    prediction_timestamp: datetime
    is_early_warning: bool            # æ˜¯å¦ç‚ºæ—©æœŸé è­¦

@dataclass
class PredictionValidation:
    """é æ¸¬é©—è­‰çµæœ"""
    prediction_id: str
    actual_event_occurred: bool
    actual_event_time: Optional[datetime]
    actual_impact_magnitude: Optional[float]
    prediction_accuracy: float        # é æ¸¬æº–ç¢ºåº¦
    time_accuracy: float              # æ™‚é–“æº–ç¢ºåº¦
    impact_accuracy: float            # å½±éŸ¿æº–ç¢ºåº¦
    validation_timestamp: datetime

class EventPredictionEngine:
    """äº‹ä»¶é æ¸¬å¼•æ“"""
    
    def __init__(self):
        self.patterns_database = {}  # æ¨¡å¼æ•¸æ“šåº«
        self.prediction_history = deque(maxlen=1000)  # é æ¸¬æ­·å²
        self.validation_history = deque(maxlen=500)   # é©—è­‰æ­·å²
        self.market_data_cache = {}  # å¸‚å ´æ•¸æ“šå¿«å–
        
        # é æ¸¬å¼•æ“é…ç½®
        self.config = {
            "min_confidence_threshold": 0.3,
            "early_warning_threshold": 0.7,
            "max_prediction_horizon_hours": 168,  # 7å¤©
            "pattern_learning_rate": 0.1,
            "feature_importance_weights": {
                "price_momentum": 0.25,
                "volume_profile": 0.20,
                "volatility_regime": 0.20,
                "market_sentiment": 0.15,
                "correlation_matrix": 0.10,
                "liquidity_conditions": 0.10
            },
            "validation_lookback_hours": 72
        }
        
        # çµ±è¨ˆæ•¸æ“š
        self.stats = {
            "total_predictions": 0,
            "successful_predictions": 0,
            "early_warnings_issued": 0,
            "patterns_learned": 0,
            "avg_prediction_accuracy": 0.0,
            "prediction_by_category": {},
            "model_last_trained": None
        }
        
        # åˆå§‹åŒ–åŸºç¤æ¨¡å¼
        self._initialize_base_patterns()
        logger.info("âœ… äº‹ä»¶é æ¸¬å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_base_patterns(self):
        """åˆå§‹åŒ–åŸºç¤é æ¸¬æ¨¡å¼"""
        base_patterns = [
            # å®è§€ç¶“æ¿Ÿäº‹ä»¶æ¨¡å¼
            MarketPattern(
                pattern_id="macro_fed_meeting",
                category=EventCategory.MACRO_ECONOMIC,
                pattern_features={
                    "fed_meeting_proximity": 1.0,
                    "rate_change_probability": 0.8,
                    "market_volatility_pre": 0.6,
                    "volume_increase_pre": 0.7
                },
                historical_occurrences=24,
                success_rate=0.78,
                avg_lead_time_hours=48,
                confidence_threshold=0.65
            ),
            
            # æŠ€è¡“çªç ´æ¨¡å¼
            MarketPattern(
                pattern_id="technical_resistance_break",
                category=EventCategory.TECHNICAL_BREAKOUT,
                pattern_features={
                    "resistance_test_count": 0.8,
                    "volume_confirmation": 0.7,
                    "momentum_buildup": 0.6,
                    "breakout_strength": 0.9
                },
                historical_occurrences=156,
                success_rate=0.72,
                avg_lead_time_hours=12,
                confidence_threshold=0.60
            ),
            
            # æˆäº¤é‡ç•°å¸¸æ¨¡å¼
            MarketPattern(
                pattern_id="volume_spike_precursor",
                category=EventCategory.VOLUME_ANOMALY,
                pattern_features={
                    "volume_ratio_anomaly": 0.9,
                    "price_volume_divergence": 0.7,
                    "market_microstructure": 0.6,
                    "order_flow_imbalance": 0.8
                },
                historical_occurrences=89,
                success_rate=0.68,
                avg_lead_time_hours=6,
                confidence_threshold=0.55
            ),
            
            # æ³¢å‹•ç‡æ¿€å¢æ¨¡å¼
            MarketPattern(
                pattern_id="volatility_regime_change",
                category=EventCategory.VOLATILITY_SPIKE,
                pattern_features={
                    "vix_term_structure": 0.8,
                    "realized_vol_trend": 0.7,
                    "options_flow_sentiment": 0.6,
                    "fear_greed_momentum": 0.5
                },
                historical_occurrences=67,
                success_rate=0.75,
                avg_lead_time_hours=24,
                confidence_threshold=0.70
            ),
            
            # æµå‹•æ€§å±æ©Ÿæ¨¡å¼
            MarketPattern(
                pattern_id="liquidity_stress_buildup",
                category=EventCategory.LIQUIDITY_CRISIS,
                pattern_features={
                    "bid_ask_widening": 0.9,
                    "depth_deterioration": 0.8,
                    "cross_asset_correlation": 0.7,
                    "funding_stress_indicators": 0.6
                },
                historical_occurrences=23,
                success_rate=0.82,
                avg_lead_time_hours=36,
                confidence_threshold=0.75
            )
        ]
        
        for pattern in base_patterns:
            self.patterns_database[pattern.pattern_id] = pattern
            
        logger.info(f"ğŸ¯ åˆå§‹åŒ– {len(base_patterns)} å€‹åŸºç¤é æ¸¬æ¨¡å¼")
    
    async def analyze_market_conditions(self, symbol: str) -> Dict[str, float]:
        """åˆ†æç•¶å‰å¸‚å ´æ¢ä»¶"""
        try:
            # ç²å–å¸‚å ´æ•¸æ“š (æ¨¡æ“¬å¯¦ç¾)
            current_time = datetime.now()
            
            # æ¨¡æ“¬å¸‚å ´ç‰¹å¾µæå–
            market_features = {
                "price_momentum": np.random.uniform(0.2, 0.9),
                "volume_profile": np.random.uniform(0.3, 0.8),
                "volatility_regime": np.random.uniform(0.1, 0.7),
                "market_sentiment": np.random.uniform(0.2, 0.6),
                "correlation_matrix": np.random.uniform(0.4, 0.8),
                "liquidity_conditions": np.random.uniform(0.3, 0.7),
                "technical_indicators": np.random.uniform(0.2, 0.8),
                "macro_factor_exposure": np.random.uniform(0.1, 0.5)
            }
            
            # å¿«å–å¸‚å ´æ•¸æ“š
            self.market_data_cache[symbol] = {
                "features": market_features,
                "timestamp": current_time
            }
            
            return market_features
            
        except Exception as e:
            logger.error(f"âŒ å¸‚å ´æ¢ä»¶åˆ†æå¤±æ•— {symbol}: {e}")
            return {}
    
    async def generate_predictions(self, symbols: List[str] = None) -> List[EventPrediction]:
        """ç”Ÿæˆäº‹ä»¶é æ¸¬"""
        try:
            if not symbols:
                symbols = ["BTCUSDT", "ETHUSDT", "ADAUSDT"]
            
            predictions = []
            
            for symbol in symbols:
                # åˆ†æå¸‚å ´æ¢ä»¶
                market_features = await self.analyze_market_conditions(symbol)
                if not market_features:
                    continue
                
                # å°æ¯å€‹æ¨¡å¼é€²è¡ŒåŒ¹é…å’Œé æ¸¬
                for pattern_id, pattern in self.patterns_database.items():
                    prediction = await self._evaluate_pattern_match(
                        symbol, pattern, market_features
                    )
                    
                    if prediction and prediction.confidence >= self.config["min_confidence_threshold"]:
                        predictions.append(prediction)
                        
                        # çµ±è¨ˆæ›´æ–°
                        self.stats["total_predictions"] += 1
                        category = prediction.event_category.value
                        self.stats["prediction_by_category"][category] = (
                            self.stats["prediction_by_category"].get(category, 0) + 1
                        )
                        
                        # æ—©æœŸé è­¦æª¢æŸ¥
                        if prediction.confidence >= self.config["early_warning_threshold"]:
                            prediction.is_early_warning = True
                            self.stats["early_warnings_issued"] += 1
            
            # ä¿å­˜é æ¸¬æ­·å²
            for prediction in predictions:
                self.prediction_history.append(prediction)
            
            logger.info(f"ğŸ”® ç”Ÿæˆ {len(predictions)} å€‹äº‹ä»¶é æ¸¬")
            return predictions
            
        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶é æ¸¬ç”Ÿæˆå¤±æ•—: {e}")
            return []
    
    async def _evaluate_pattern_match(self, symbol: str, pattern: MarketPattern, 
                                    market_features: Dict[str, float]) -> Optional[EventPrediction]:
        """è©•ä¼°æ¨¡å¼åŒ¹é…åº¦ä¸¦ç”Ÿæˆé æ¸¬"""
        try:
            # è¨ˆç®—ç‰¹å¾µç›¸ä¼¼åº¦
            similarity_score = 0.0
            feature_count = 0
            
            for pattern_feature, pattern_value in pattern.pattern_features.items():
                if pattern_feature in market_features:
                    market_value = market_features[pattern_feature]
                    # è¨ˆç®—ç‰¹å¾µç›¸ä¼¼åº¦ (ä½¿ç”¨é¤˜å¼¦ç›¸ä¼¼åº¦çš„ç°¡åŒ–ç‰ˆæœ¬)
                    similarity = 1.0 - abs(pattern_value - market_value)
                    similarity_score += similarity
                    feature_count += 1
            
            if feature_count == 0:
                return None
            
            # å¹³å‡ç›¸ä¼¼åº¦
            avg_similarity = similarity_score / feature_count
            
            # èª¿æ•´ä¿¡å¿ƒåº¦ (çµåˆæ¨¡å¼æˆåŠŸç‡å’Œç›¸ä¼¼åº¦)
            confidence = (avg_similarity * 0.6 + pattern.success_rate * 0.4)
            
            # æª¢æŸ¥æ˜¯å¦è¶…éæ¨¡å¼é–¾å€¼
            if confidence < pattern.confidence_threshold:
                return None
            
            # ç¢ºå®šä¿¡å¿ƒç­‰ç´š
            confidence_level = self._determine_confidence_level(confidence)
            
            # é æ¸¬äº‹ä»¶æ™‚é–“
            predicted_time = datetime.now() + timedelta(hours=pattern.avg_lead_time_hours)
            
            # è¨ˆç®—é æœŸå½±éŸ¿å¹…åº¦
            impact_magnitude = min(1.0, confidence * pattern.success_rate * 1.2)
            
            # ç”Ÿæˆé¢¨éšªå› å­
            risk_factors = {
                "pattern_age": min(1.0, (datetime.now() - (pattern.last_occurrence or datetime.now())).days / 30),
                "market_regime_change": market_features.get("volatility_regime", 0.5),
                "liquidity_risk": 1.0 - market_features.get("liquidity_conditions", 0.5),
                "correlation_risk": market_features.get("correlation_matrix", 0.5)
            }
            
            # å‰µå»ºé æ¸¬
            prediction = EventPrediction(
                prediction_id=f"{pattern.pattern_id}_{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                event_category=pattern.category,
                predicted_event_time=predicted_time,
                confidence=confidence,
                confidence_level=confidence_level,
                affected_symbols=[symbol],
                expected_impact_magnitude=impact_magnitude,
                prediction_horizon_hours=int(pattern.avg_lead_time_hours * 1.5),
                contributing_patterns=[pattern.pattern_id],
                risk_factors=risk_factors,
                prediction_timestamp=datetime.now(),
                is_early_warning=False
            )
            
            return prediction
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å¼åŒ¹é…è©•ä¼°å¤±æ•—: {e}")
            return None
    
    def _determine_confidence_level(self, confidence: float) -> PredictionConfidence:
        """ç¢ºå®šä¿¡å¿ƒç­‰ç´š"""
        if confidence >= 0.85:
            return PredictionConfidence.VERY_HIGH
        elif confidence >= 0.7:
            return PredictionConfidence.HIGH
        elif confidence >= 0.5:
            return PredictionConfidence.MEDIUM
        elif confidence >= 0.3:
            return PredictionConfidence.LOW
        else:
            return PredictionConfidence.VERY_LOW
    
    async def validate_predictions(self, lookback_hours: int = 72) -> List[PredictionValidation]:
        """é©—è­‰æ­·å²é æ¸¬æº–ç¢ºæ€§"""
        try:
            validations = []
            cutoff_time = datetime.now() - timedelta(hours=lookback_hours)
            
            # æ‰¾å‡ºéœ€è¦é©—è­‰çš„é æ¸¬
            predictions_to_validate = [
                p for p in self.prediction_history 
                if p.prediction_timestamp >= cutoff_time and 
                   p.predicted_event_time <= datetime.now()
            ]
            
            for prediction in predictions_to_validate:
                validation = await self._validate_single_prediction(prediction)
                if validation:
                    validations.append(validation)
                    self.validation_history.append(validation)
            
            # æ›´æ–°çµ±è¨ˆæ•¸æ“š
            if validations:
                successful_predictions = sum(1 for v in validations if v.actual_event_occurred)
                self.stats["successful_predictions"] += successful_predictions
                
                # è¨ˆç®—å¹³å‡æº–ç¢ºç‡
                avg_accuracy = np.mean([v.prediction_accuracy for v in validations])
                self.stats["avg_prediction_accuracy"] = (
                    self.stats["avg_prediction_accuracy"] * 0.8 + avg_accuracy * 0.2
                )
            
            logger.info(f"ğŸ“Š é©—è­‰ {len(validations)} å€‹æ­·å²é æ¸¬")
            return validations
            
        except Exception as e:
            logger.error(f"âŒ é æ¸¬é©—è­‰å¤±æ•—: {e}")
            return []
    
    async def _validate_single_prediction(self, prediction: EventPrediction) -> Optional[PredictionValidation]:
        """é©—è­‰å–®å€‹é æ¸¬"""
        try:
            # æ¨¡æ“¬äº‹ä»¶é©—è­‰é‚è¼¯
            # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒæŸ¥è©¢çœŸå¯¦çš„å¸‚å ´äº‹ä»¶æ•¸æ“š
            
            # åŸºæ–¼é æ¸¬ä¿¡å¿ƒåº¦æ¨¡æ“¬å¯¦éš›ç™¼ç”Ÿæ¦‚ç‡
            actual_occurred = np.random.random() < (prediction.confidence * 0.8)
            
            if actual_occurred:
                # æ¨¡æ“¬å¯¦éš›äº‹ä»¶æ™‚é–“ (åœ¨é æ¸¬æ™‚é–“é™„è¿‘)
                time_variance_hours = np.random.normal(0, prediction.prediction_horizon_hours * 0.2)
                actual_event_time = prediction.predicted_event_time + timedelta(hours=time_variance_hours)
                
                # æ¨¡æ“¬å¯¦éš›å½±éŸ¿å¹…åº¦
                impact_variance = np.random.normal(1.0, 0.3)
                actual_impact = prediction.expected_impact_magnitude * impact_variance
                actual_impact = max(0.0, min(1.0, actual_impact))
                
                # è¨ˆç®—æº–ç¢ºåº¦
                time_diff_hours = abs((actual_event_time - prediction.predicted_event_time).total_seconds() / 3600)
                time_accuracy = max(0.0, 1.0 - (time_diff_hours / prediction.prediction_horizon_hours))
                
                impact_diff = abs(actual_impact - prediction.expected_impact_magnitude)
                impact_accuracy = max(0.0, 1.0 - impact_diff)
                
                prediction_accuracy = (time_accuracy * 0.5 + impact_accuracy * 0.5)
                
            else:
                actual_event_time = None
                actual_impact = None
                time_accuracy = 0.0
                impact_accuracy = 0.0
                prediction_accuracy = 0.0
            
            validation = PredictionValidation(
                prediction_id=prediction.prediction_id,
                actual_event_occurred=actual_occurred,
                actual_event_time=actual_event_time,
                actual_impact_magnitude=actual_impact,
                prediction_accuracy=prediction_accuracy,
                time_accuracy=time_accuracy,
                impact_accuracy=impact_accuracy,
                validation_timestamp=datetime.now()
            )
            
            return validation
            
        except Exception as e:
            logger.error(f"âŒ å–®å€‹é æ¸¬é©—è­‰å¤±æ•—: {e}")
            return None
    
    async def learn_from_validations(self):
        """å¾é©—è­‰çµæœä¸­å­¸ç¿’ä¸¦æ›´æ–°æ¨¡å¼"""
        try:
            if len(self.validation_history) < 10:
                return
            
            # åˆ†ææ¨¡å¼è¡¨ç¾
            pattern_performance = {}
            
            for validation in self.validation_history:
                # æ‰¾åˆ°å°æ‡‰çš„é æ¸¬
                prediction = next(
                    (p for p in self.prediction_history if p.prediction_id == validation.prediction_id),
                    None
                )
                
                if prediction:
                    for pattern_id in prediction.contributing_patterns:
                        if pattern_id not in pattern_performance:
                            pattern_performance[pattern_id] = []
                        pattern_performance[pattern_id].append(validation.prediction_accuracy)
            
            # æ›´æ–°æ¨¡å¼æˆåŠŸç‡
            updated_patterns = 0
            for pattern_id, accuracies in pattern_performance.items():
                if pattern_id in self.patterns_database:
                    pattern = self.patterns_database[pattern_id]
                    avg_accuracy = np.mean(accuracies)
                    
                    # ä½¿ç”¨å­¸ç¿’ç‡æ›´æ–°æˆåŠŸç‡
                    learning_rate = self.config["pattern_learning_rate"]
                    pattern.success_rate = (
                        pattern.success_rate * (1 - learning_rate) + 
                        avg_accuracy * learning_rate
                    )
                    
                    updated_patterns += 1
            
            self.stats["patterns_learned"] += updated_patterns
            self.stats["model_last_trained"] = datetime.now()
            
            logger.info(f"ğŸ§  å¾é©—è­‰çµæœå­¸ç¿’ï¼Œæ›´æ–° {updated_patterns} å€‹æ¨¡å¼")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å¼å­¸ç¿’å¤±æ•—: {e}")
    
    def get_prediction_summary(self) -> Dict[str, Any]:
        """ç²å–é æ¸¬ç³»çµ±æ‘˜è¦"""
        try:
            recent_predictions = [
                p for p in self.prediction_history 
                if (datetime.now() - p.prediction_timestamp).hours <= 24
            ]
            
            early_warnings = [p for p in recent_predictions if p.is_early_warning]
            
            # æŒ‰é¡åˆ¥çµ±è¨ˆ
            category_stats = {}
            for prediction in recent_predictions:
                category = prediction.event_category.value
                if category not in category_stats:
                    category_stats[category] = {"count": 0, "avg_confidence": 0.0}
                category_stats[category]["count"] += 1
                category_stats[category]["avg_confidence"] += prediction.confidence
            
            # è¨ˆç®—å¹³å‡ä¿¡å¿ƒåº¦
            for category in category_stats:
                if category_stats[category]["count"] > 0:
                    category_stats[category]["avg_confidence"] /= category_stats[category]["count"]
            
            return {
                "engine_status": "active",
                "total_patterns": len(self.patterns_database),
                "recent_predictions_24h": len(recent_predictions),
                "early_warnings_active": len(early_warnings),
                "prediction_categories": category_stats,
                "engine_stats": self.stats,
                "last_analysis_time": datetime.now().isoformat(),
                "prediction_accuracy": self.stats["avg_prediction_accuracy"],
                "system_health": "good" if self.stats["avg_prediction_accuracy"] > 0.6 else "needs_attention"
            }
            
        except Exception as e:
            logger.error(f"âŒ é æ¸¬æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
            return {"engine_status": "error", "error": str(e)}

# å…¨å±€å¯¦ä¾‹
event_prediction_engine = EventPredictionEngine()
