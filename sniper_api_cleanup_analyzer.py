#!/usr/bin/env python3
"""
ç‹™æ“Šæ‰‹ç­–ç•¥APIæ•´ç†åˆ†æå·¥å…·
åˆ†æ ä¿¡è™Ÿç”Ÿæˆ > ç¯©é¸ > å‘ˆç¾ > éæœŸ > æ­·å²è¨˜éŒ„ æµç¨‹ä¸­ä½¿ç”¨çš„API
"""

import re
import os
from pathlib import Path
from typing import Dict, List, Set
import json

class SniperAPIAnalyzer:
    def __init__(self):
        self.api_endpoints = {}
        self.frontend_usage = {}
        self.workflow_apis = {
            'ä¿¡è™Ÿç”Ÿæˆ': [],
            'ä¿¡è™Ÿç¯©é¸': [],
            'å‰ç«¯å‘ˆç¾': [],
            'éæœŸè™•ç†': [],
            'æ­·å²è¨˜éŒ„': []
        }
        
    def extract_api_endpoints(self, file_path: str) -> List[Dict]:
        """å¾APIæ–‡ä»¶ä¸­æå–ç«¯é»"""
        endpoints = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # åŒ¹é… @router.{method}("path") æ ¼å¼
            pattern = r'@router\.(get|post|put|delete|patch)\("([^"]+)"\)'
            matches = re.findall(pattern, content)
            
            for method, path in matches:
                # æŸ¥æ‰¾å‡½æ•¸åå’Œæè¿°
                func_pattern = rf'@router\.{method}\("{re.escape(path)}"\)[^d]*def\s+(\w+)'
                func_match = re.search(func_pattern, content)
                func_name = func_match.group(1) if func_match else "unknown"
                
                # æŸ¥æ‰¾æ–‡æª”å­—ç¬¦ä¸²
                doc_pattern = rf'def\s+{func_name}[^:]*:\s*"""([^"]+)"""'
                doc_match = re.search(doc_pattern, content)
                description = doc_match.group(1).strip() if doc_match else ""
                
                endpoints.append({
                    'file': os.path.basename(file_path),
                    'method': method.upper(),
                    'path': path,
                    'function': func_name,
                    'description': description
                })
        except Exception as e:
            print(f"Error reading {file_path}: {e}")
            
        return endpoints
    
    def extract_frontend_usage(self, file_path: str) -> List[Dict]:
        """å¾å‰ç«¯æ–‡ä»¶ä¸­æå–APIä½¿ç”¨"""
        usages = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # åŒ¹é…å„ç¨®APIèª¿ç”¨æ ¼å¼
            patterns = [
                r"(?:fetch|axios\.(?:get|post|put|delete))\s*\(\s*['\"]([^'\"]*api/v1/[^'\"]*)['\"]",
                r"const\s+\w+\s*=\s*['\"]([^'\"]*api/v1/[^'\"]*)['\"]",
                r"websocket.*?['\"]([^'\"]*api/v1/[^'\"]*)['\"]"
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    usages.append({
                        'file': os.path.basename(file_path),
                        'api_path': match
                    })
        except Exception as e:
            print(f"Error reading {file_path}: {e}")
            
        return usages
    
    def categorize_workflow_apis(self):
        """å°‡APIåˆ†é¡åˆ°ç‹™æ“Šæ‰‹å·¥ä½œæµç¨‹ä¸­"""
        
        # ä¿¡è™Ÿç”Ÿæˆç›¸é—œ
        generation_keywords = [
            'sniper-unified-data-layer', 'pandas-ta-direct', 'signals',
            'phase1a-signal-scoring', 'phase1b-enhanced-signal-scoring', 
            'phase1c-enhanced-signal-scoring', 'create-market-event'
        ]
        
        # ä¿¡è™Ÿç¯©é¸ç›¸é—œ
        filtering_keywords = [
            'dashboard-precision-signals', 'precision-signal', 'precision-signal-stats',
            'signal-health-dashboard', 'multi-timeframe-weights'
        ]
        
        # å‰ç«¯å‘ˆç¾ç›¸é—œ
        presentation_keywords = [
            'dashboard-precision-signals', 'realtime-sync-status', 'performance-metrics',
            'ws', 'websocket'
        ]
        
        # éæœŸè™•ç†ç›¸é—œ
        expiration_keywords = [
            'process-expired', 'cleanup-expired', 'expired', 'process-dynamic-expiration',
            'expiration-scheduler-status', 'manual-expiration-trigger'
        ]
        
        # æ­·å²è¨˜éŒ„ç›¸é—œ
        history_keywords = [
            'history/signals', 'history/performance', 'history/daily-summary',
            'history/statistics', 'history/cleanup'
        ]
        
        # åˆ†é¡API
        for file, endpoints in self.api_endpoints.items():
            for endpoint in endpoints:
                path = endpoint['path']
                
                # æª¢æŸ¥å„å€‹åˆ†é¡
                if any(keyword in path for keyword in generation_keywords):
                    self.workflow_apis['ä¿¡è™Ÿç”Ÿæˆ'].append(endpoint)
                
                if any(keyword in path for keyword in filtering_keywords):
                    self.workflow_apis['ä¿¡è™Ÿç¯©é¸'].append(endpoint)
                
                if any(keyword in path for keyword in presentation_keywords):
                    self.workflow_apis['å‰ç«¯å‘ˆç¾'].append(endpoint)
                
                if any(keyword in path for keyword in expiration_keywords):
                    self.workflow_apis['éæœŸè™•ç†'].append(endpoint)
                
                if any(keyword in path for keyword in history_keywords):
                    self.workflow_apis['æ­·å²è¨˜éŒ„'].append(endpoint)
    
    def find_unused_apis(self) -> List[Dict]:
        """æ‰¾å‡ºæœªä½¿ç”¨çš„API"""
        unused = []
        
        # æ”¶é›†æ‰€æœ‰å‰ç«¯ä½¿ç”¨çš„APIè·¯å¾‘
        used_paths = set()
        for file, usages in self.frontend_usage.items():
            for usage in usages:
                # æ¸…ç†è·¯å¾‘ï¼Œç§»é™¤æŸ¥è©¢åƒæ•¸
                clean_path = usage['api_path'].split('?')[0]
                used_paths.add(clean_path)
        
        # æª¢æŸ¥æ¯å€‹APIæ˜¯å¦è¢«ä½¿ç”¨
        for file, endpoints in self.api_endpoints.items():
            for endpoint in endpoints:
                api_path = f"/api/v1{endpoint['path']}"
                
                # æª¢æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„ä½¿ç”¨
                is_used = False
                for used_path in used_paths:
                    if api_path in used_path or used_path in api_path:
                        is_used = True
                        break
                
                if not is_used:
                    unused.append({
                        **endpoint,
                        'full_path': api_path
                    })
        
        return unused
    
    def analyze(self):
        """åŸ·è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” ç‹™æ“Šæ‰‹ç­–ç•¥APIæ•´ç†åˆ†æ")
        print("=" * 80)
        
        # åˆ†æAPIç«¯é»
        api_files = [
            'app/api/v1/endpoints/scalping_precision.py',
            'app/api/v1/endpoints/sniper_signal_history.py',
            'app/api/v1/endpoints/sniper_smart_layer.py',
            'app/api/v1/endpoints/sniper_email.py',
            'app/api/v1/endpoints/sniper_backtest.py',
            'app/api/v1/endpoints/realtime_market.py',
            'app/api/v1/endpoints/market_analysis.py'
        ]
        
        for file_path in api_files:
            if os.path.exists(file_path):
                endpoints = self.extract_api_endpoints(file_path)
                if endpoints:
                    self.api_endpoints[os.path.basename(file_path)] = endpoints
        
        # åˆ†æå‰ç«¯ä½¿ç”¨
        frontend_files = [
            'frontend/src/views/TradingStrategySniperIntegrated.vue',
            'frontend/src/views/TradingStrategy.vue',
            'frontend/src/views/Market_New.vue',
            'frontend/src/views/Strategies.vue',
            'frontend/src/views/ShortTermHistory.vue',
            'frontend/src/views/Backtest.vue'
        ]
        
        for file_path in frontend_files:
            if os.path.exists(file_path):
                usages = self.extract_frontend_usage(file_path)
                if usages:
                    self.frontend_usage[os.path.basename(file_path)] = usages
        
        # åˆ†é¡å·¥ä½œæµç¨‹API
        self.categorize_workflow_apis()
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæ•´ç†å ±å‘Š"""
        print("\\nğŸ“Š ç‹™æ“Šæ‰‹å·¥ä½œæµç¨‹ API åˆ†é¡:")
        print("-" * 80)
        
        for workflow, apis in self.workflow_apis.items():
            print(f"\\nğŸ¯ {workflow} ({len(apis)} å€‹API):")
            for api in apis:
                status = "âœ… æ ¸å¿ƒ" if workflow in ['ä¿¡è™Ÿç¯©é¸', 'å‰ç«¯å‘ˆç¾'] else "âš ï¸ æª¢æŸ¥"
                print(f"  {status} {api['method']} {api['path']} - {api['description'][:50]}...")
        
        print("\\n" + "=" * 80)
        print("ğŸ“ˆ å‰ç«¯APIä½¿ç”¨çµ±è¨ˆ:")
        print("-" * 80)
        
        total_usage = 0
        for file, usages in self.frontend_usage.items():
            print(f"\\nğŸ“„ {file}: {len(usages)} å€‹APIèª¿ç”¨")
            total_usage += len(usages)
            for usage in usages[:5]:  # åªé¡¯ç¤ºå‰5å€‹
                print(f"  - {usage['api_path']}")
            if len(usages) > 5:
                print(f"  ... å’Œå…¶ä»– {len(usages) - 5} å€‹")
        
        print(f"\\nğŸ“Š ç¸½APIä½¿ç”¨é‡: {total_usage}")
        
        # æ‰¾å‡ºæœªä½¿ç”¨çš„API
        unused = self.find_unused_apis()
        print(f"\\nâš ï¸ å¯èƒ½æœªä½¿ç”¨çš„API ({len(unused)} å€‹):")
        print("-" * 80)
        
        for api in unused[:20]:  # åªé¡¯ç¤ºå‰20å€‹
            print(f"âŒ {api['method']} {api['full_path']}")
            print(f"   æè¿°: {api['description'][:60]}...")
            print(f"   æ–‡ä»¶: {api['file']}")
            print()
        
        if len(unused) > 20:
            print(f"... å’Œå…¶ä»– {len(unused) - 20} å€‹æœªä½¿ç”¨çš„API")
        
        # ç”Ÿæˆæ¸…ç†å»ºè­°
        self.generate_cleanup_suggestions(unused)
    
    def generate_cleanup_suggestions(self, unused_apis: List[Dict]):
        """ç”Ÿæˆæ¸…ç†å»ºè­°"""
        print("\\nğŸ§¹ APIæ¸…ç†å»ºè­°:")
        print("=" * 80)
        
        # æŒ‰æ–‡ä»¶åˆ†çµ„
        by_file = {}
        for api in unused_apis:
            file = api['file']
            if file not in by_file:
                by_file[file] = []
            by_file[file].append(api)
        
        for file, apis in by_file.items():
            print(f"\\nğŸ“„ {file} - å»ºè­°ç§»é™¤ {len(apis)} å€‹ç«¯é»:")
            
            # åˆ†æç§»é™¤çš„å®‰å…¨æ€§
            safe_to_remove = []
            need_review = []
            
            for api in apis:
                path = api['path']
                # åˆ¤æ–·æ˜¯å¦ç‚ºæ¸¬è©¦ã€èª¿è©¦æˆ–å¯¦é©—æ€§API
                if any(keyword in path.lower() for keyword in 
                      ['test', 'debug', 'experimental', 'temp', 'old', 'legacy']):
                    safe_to_remove.append(api)
                else:
                    need_review.append(api)
            
            if safe_to_remove:
                print("  âœ… å®‰å…¨ç§»é™¤:")
                for api in safe_to_remove:
                    print(f"    - {api['method']} {api['path']}")
            
            if need_review:
                print("  âš ï¸ éœ€è¦æª¢æŸ¥:")
                for api in need_review:
                    print(f"    - {api['method']} {api['path']}")

if __name__ == "__main__":
    analyzer = SniperAPIAnalyzer()
    analyzer.analyze()
