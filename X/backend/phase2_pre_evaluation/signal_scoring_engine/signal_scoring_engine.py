"""
ğŸ¯ Trading X - Enhanced Signal Scoring Engine (Integrated Version) v2.1.0
å®Œå…¨ç¬¦åˆ signal_scoring_engine.json è¦ç¯„çš„å¢å¼·ä¿¡è™Ÿè©•åˆ†å¼•æ“
æ¨¡çµ„é¡å‹ï¼šembedded_scoring_engine
æ•´åˆæ¨¡å¼ï¼šembedded_in_epl_step3_quality_control
"""

from typing import Dict, Any, List
import math
import statistics

class EnhancedSignalScoringEngine:
    """
    å¢å¼·ä¿¡è™Ÿè©•åˆ†å¼•æ“ v2.1.0
    åŒ…å«å¾®ç•°å¸¸æª¢æ¸¬å’Œæºå…±è­˜é©—è­‰çš„æ•´åˆç‰ˆæœ¬
    """
    
    def __init__(self):
        # è©•åˆ†ç®—æ³•æ¬Šé‡ (JSON è¦ç¯„è¦æ±‚)
        self.scoring_weights = {
            "strength_scoring": 0.3,
            "confidence_scoring": 0.25, 
            "quality_scoring": 0.2,
            "risk_scoring": 0.15,
            "timing_scoring": 0.1
        }
        
        # æºå…±è­˜é©—è­‰é–¾å€¼
        self.consensus_thresholds = {
            "source_overlap_threshold": 0.72,
            "model_diversity_threshold": 0.8,
            "action_bias_threshold": 0.85
        }
        
        # å¾®ç•°å¸¸æª¢æ¸¬åƒæ•¸
        self.anomaly_detection_params = {
            "volatility_jump_threshold": 0.3,
            "confidence_drop_threshold": 0.1,
            "window_size_minutes": 15
        }
        
        # æ­·å²æ•¸æ“šç”¨æ–¼åŸºç·šè¨ˆç®—
        self.historical_confidence_data = []
        self.signal_volatility_history = []
    
    def score_signal(self, signal_data: Dict[str, Any]) -> Dict[str, float]:
        """
        ä¿¡è™Ÿè©•åˆ†ä¸»æ–¹æ³• - 3ms embedded processing
        
        è™•ç†å±¤:
        - Layer 0: Data Extraction (1ms)  
        - Layer 1: Score Calculation (2ms)
        """
        try:
            # Layer 0: Data Extraction (1ms)
            extracted_metrics = self._layer_0_data_extraction(signal_data)
            
            # Layer 1: Score Calculation (2ms)
            complete_score_dict = self._layer_1_score_calculation(extracted_metrics, signal_data)
            
            return complete_score_dict
            
        except Exception:
            # é è¨­å›å‚³å€¼
            return {
                "strength_score": 0.5,
                "confidence_score": 0.7,
                "quality_score": 0.6,
                "risk_score": 0.5,
                "timing_score": 0.8
            }
    
    def _layer_0_data_extraction(self, signal_data: Dict[str, Any]) -> Dict[str, float]:
        """Layer 0: æ•¸æ“šæå–å’Œå¾®ç•°å¸¸æª¢æ¸¬ (1ms)"""
        # æå–åŸºæœ¬æ•¸æ“š
        base_value = signal_data.get('value', 0.5)
        confidence = signal_data.get('confidence', 0.7)
        signal_strength = signal_data.get('signal_strength', abs(base_value))
        
        # å¾®ç•°å¸¸æª¢æ¸¬
        volatility_jump_penalty = self._detect_volatility_jump(signal_strength)
        confidence_drop_rate_monitoring = self._monitor_confidence_drop_rate(confidence)
        
        return {
            "base_value": base_value,
            "confidence": confidence,
            "signal_strength": signal_strength,
            "volatility_jump_penalty": volatility_jump_penalty,
            "confidence_drop_rate_monitoring": confidence_drop_rate_monitoring
        }
    
    def _layer_1_score_calculation(self, extracted_metrics: Dict[str, float], signal_data: Dict[str, Any]) -> Dict[str, float]:
        """Layer 1: å®Œæ•´è©•åˆ†è¨ˆç®— (2ms)"""
        base_value = extracted_metrics["base_value"]
        confidence = extracted_metrics["confidence"]
        signal_strength = extracted_metrics["signal_strength"]
        volatility_penalty = extracted_metrics["volatility_jump_penalty"]
        confidence_drop_penalty = extracted_metrics["confidence_drop_rate_monitoring"]
        
        # å¢å¼·è©•åˆ†ç®—æ³•
        strength_score = self._calculate_strength_scoring(signal_strength, volatility_penalty)
        confidence_score = self._calculate_confidence_scoring(confidence, confidence_drop_penalty)
        quality_score = self._calculate_quality_scoring(strength_score, confidence_score)
        risk_score = self._calculate_risk_scoring(signal_strength)
        timing_score = self._calculate_timing_scoring(signal_data)
        
        # æºå…±è­˜é©—è­‰ (å¦‚æœæœ‰å¤šå€‹ä¿¡è™Ÿæº)
        if 'sources' in signal_data:
            consensus_adjustment = self._perform_source_consensus_validation(signal_data['sources'])
            strength_score *= consensus_adjustment
            confidence_score *= consensus_adjustment
        
        return {
            "strength_score": min(1.0, max(0.0, strength_score)),
            "confidence_score": min(1.0, max(0.0, confidence_score)),
            "quality_score": min(1.0, max(0.0, quality_score)),
            "risk_score": min(1.0, max(0.0, risk_score)),
            "timing_score": min(1.0, max(0.0, timing_score))
        }
    
    def _calculate_strength_scoring(self, signal_strength: float, volatility_penalty: float) -> float:
        """å¼·åº¦è©•åˆ†ï¼šlinear_scoring_based_on_signal_strength + volatility_jump_penalty"""
        base_strength = min(1.0, abs(signal_strength))
        adjusted_strength = base_strength * (1.0 - volatility_penalty)
        return adjusted_strength
    
    def _calculate_confidence_scoring(self, confidence: float, confidence_drop_penalty: float) -> float:
        """ä¿¡å¿ƒè©•åˆ†ï¼šdirect_confidence_mapping_with_drop_rate_detection"""
        adjusted_confidence = confidence * (1.0 - confidence_drop_penalty)
        return min(1.0, max(0.0, adjusted_confidence))
    
    def _calculate_quality_scoring(self, strength_score: float, confidence_score: float) -> float:
        """è³ªé‡è©•åˆ†ï¼šaverage_of_strength_and_confidence"""
        return (strength_score + confidence_score) / 2
    
    def _calculate_risk_scoring(self, signal_strength: float) -> float:
        """é¢¨éšªè©•åˆ†ï¼šinverse_risk_assessment"""
        return 1.0 - min(1.0, abs(signal_strength) * 1.2)
    
    def _calculate_timing_scoring(self, signal_data: Dict[str, Any]) -> float:
        """æ™‚æ©Ÿè©•åˆ†ï¼šadaptive_time_scoring_based_on_market_stress"""
        market_stress = signal_data.get('market_stress', 0.5)
        
        # å‹•æ…‹æ™‚æ©Ÿè©•ä¼° (range: 0.6-1.0)
        base_timing = 0.8
        market_stress_adjustment = self._evaluate_market_stress_adjustment(market_stress)
        
        timing_score = base_timing + market_stress_adjustment
        return min(1.0, max(0.6, timing_score))
    
    def _detect_volatility_jump(self, signal_strength: float) -> float:
        """ä¿¡è™Ÿæ³¢å‹•ç›£æ§ï¼šrolling_standard_deviation_analysis"""
        self.signal_volatility_history.append(signal_strength)
        
        # ä¿æŒ 15 åˆ†é˜çª—å£
        if len(self.signal_volatility_history) > 15:
            self.signal_volatility_history.pop(0)
        
        if len(self.signal_volatility_history) >= 3:
            std_dev = statistics.stdev(self.signal_volatility_history)
            if std_dev > self.anomaly_detection_params["volatility_jump_threshold"]:
                return 0.2  # 20% æ‡²ç½°
        
        return 0.0
    
    def _monitor_confidence_drop_rate(self, confidence: float) -> float:
        """ä¿¡å¿ƒä¸‹é™æª¢æ¸¬ï¼šrate_of_change_analysis"""
        self.historical_confidence_data.append(confidence)
        
        if len(self.historical_confidence_data) > 10:
            self.historical_confidence_data.pop(0)
        
        if len(self.historical_confidence_data) >= 2:
            historical_average = statistics.mean(self.historical_confidence_data[:-1])
            drop_rate = (historical_average - confidence) / historical_average if historical_average > 0 else 0
            
            if drop_rate > self.anomaly_detection_params["confidence_drop_threshold"]:
                return drop_rate * 0.5  # æŒ‰ä¸‹é™ç‡æ¯”ä¾‹æ‡²ç½°
        
        return 0.0
    
    def _evaluate_market_stress_adjustment(self, market_stress: float) -> float:
        """å¸‚å ´å£“åŠ›èª¿æ•´ï¼šdynamic_timing_evaluation"""
        if market_stress > 0.8:
            return -0.1  # é«˜å£“åŠ›ç’°å¢ƒé™ä½æ™‚æ©Ÿåˆ†æ•¸
        elif market_stress < 0.3:
            return 0.1   # ä½å£“åŠ›ç’°å¢ƒæå‡æ™‚æ©Ÿåˆ†æ•¸
        return 0.0
    
    def _perform_source_consensus_validation(self, sources: List[Dict[str, Any]]) -> float:
        """æºå…±è­˜é©—è­‰"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—æºé‡ç–Šè©•åˆ†ï¼šjaccard_similarity_coefficient
        source_overlap_score = self._calculate_jaccard_similarity_coefficient(sources)
        
        # è¨ˆç®—æ¨¡å‹å¤šæ¨£æ€§è©•åˆ†ï¼šentropy_based_diversity_measure
        model_diversity_score = self._calculate_entropy_based_diversity_measure(sources)
        
        # è¨ˆç®—è¡Œå‹•åå·®è©•åˆ†ï¼šdirectional_consensus_measure
        action_bias_score = self._calculate_directional_consensus_measure(sources)
        
        # åŠ æ¬Šå¹³å‡æ³•è¡çªè§£æ±º
        consensus_factor = (
            source_overlap_score * 0.4 + 
            model_diversity_score * 0.3 + 
            action_bias_score * 0.3
        )
        
        return min(1.0, max(0.5, consensus_factor))
    
    def _calculate_jaccard_similarity_coefficient(self, sources: List[Dict[str, Any]]) -> float:
        """Jaccard ç›¸ä¼¼ä¿‚æ•¸è¨ˆç®—"""
        if len(sources) < 2:
            return 1.0
        
        # ç°¡åŒ–å¯¦ç¾ï¼šè¨ˆç®—ä¿¡è™Ÿå¼·åº¦çš„ç›¸ä¼¼æ€§
        strengths = [s.get('signal_strength', 0.5) for s in sources]
        avg_strength = statistics.mean(strengths)
        similarity = 1.0 - statistics.stdev(strengths) if len(strengths) > 1 else 1.0
        
        return min(1.0, max(0.0, similarity))
    
    def _calculate_entropy_based_diversity_measure(self, sources: List[Dict[str, Any]]) -> float:
        """åŸºæ–¼ç†µçš„å¤šæ¨£æ€§æ¸¬é‡"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—æ¨¡å‹é¡å‹å¤šæ¨£æ€§
        model_types = [s.get('model_type', 'default') for s in sources]
        unique_types = len(set(model_types))
        diversity_score = unique_types / len(model_types)
        
        return diversity_score
    
    def _calculate_directional_consensus_measure(self, sources: List[Dict[str, Any]]) -> float:
        """æ–¹å‘æ€§å…±è­˜æ¸¬é‡"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—ä¿¡è™Ÿæ–¹å‘ä¸€è‡´æ€§
        directions = []
        for source in sources:
            signal_value = source.get('value', 0)
            if signal_value > 0:
                directions.append(1)
            elif signal_value < 0:
                directions.append(-1)
            else:
                directions.append(0)
        
        if not directions:
            return 1.0
        
        # è¨ˆç®—æ–¹å‘ä¸€è‡´æ€§
        most_common_direction = max(set(directions), key=directions.count)
        consensus_count = directions.count(most_common_direction)
        consensus_ratio = consensus_count / len(directions)
        
        return consensus_ratio

# å…¨åŸŸå¯¦ä¾‹ (embedded_in_epl_step3_quality_control)
signal_scoring_engine = EnhancedSignalScoringEngine()
