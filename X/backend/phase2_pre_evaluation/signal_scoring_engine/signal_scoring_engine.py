"""
ğŸ¯ Trading X - Enhanced Signal Scoring Engine (Integrated Version) v2.1.0
å®Œå…¨ç¬¦åˆ signal_scoring_engine.json è¦ç¯„çš„å¢å¼·ä¿¡è™Ÿè©•åˆ†å¼•æ“
æ¨¡çµ„é¡å‹ï¼šembedded_scoring_engine
æ•´åˆæ¨¡å¼ï¼šembedded_in_epl_step3_quality_control
"""

from typing import Dict, Any, List
import math
import statistics

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œæä¾› SignalScoringEngine åˆ¥å
class SignalScoringEngine:
    """å‘å¾Œå…¼å®¹çš„ä¿¡è™Ÿè©•åˆ†å¼•æ“"""
    
    def __init__(self):
        self.enhanced_engine = EnhancedSignalScoringEngine()
    
    def calculate_score(self, signal_data: Dict[str, Any]) -> float:
        """è¨ˆç®—ä¿¡è™Ÿè©•åˆ†"""
        try:
            result = self.enhanced_engine.calculate_enhanced_score(signal_data)
            return result.get('final_score', 0.0)
        except Exception as e:
            return 0.0
    
    def evaluate_signal_quality(self, signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """è©•ä¼°ä¿¡è™Ÿå“è³ª"""
        return self.enhanced_engine.calculate_enhanced_score(signal_data)

class EnhancedSignalScoringEngine:
    """
    å¢å¼·ä¿¡è™Ÿè©•åˆ†å¼•æ“ v2.1.0
    åŒ…å«å¾®ç•°å¸¸æª¢æ¸¬å’Œæºå…±è­˜é©—è­‰çš„æ•´åˆç‰ˆæœ¬
    """
    
    def __init__(self):
        # è©•åˆ†ç®—æ³•æ¬Šé‡ (JSON è¦ç¯„è¦æ±‚)
        self.scoring_weights = {
            "strength_scoring": 0.3,
            "confidence_scoring": 0.25, 
            "quality_scoring": 0.2,
            "risk_scoring": 0.15,
            "timing_scoring": 0.1
        }
        
        # æºå…±è­˜é©—è­‰é–¾å€¼
        self.consensus_thresholds = {
            "source_overlap_threshold": 0.72,
            "model_diversity_threshold": 0.8,
            "action_bias_threshold": 0.85
        }
        
        # å¾®ç•°å¸¸æª¢æ¸¬åƒæ•¸
        self.anomaly_detection_params = {
            "volatility_jump_threshold": 0.3,
            "confidence_drop_threshold": 0.1,
            "window_size_minutes": 15
        }
        
        # æ­·å²æ•¸æ“šç”¨æ–¼åŸºç·šè¨ˆç®—
        self.historical_confidence_data = []
        self.signal_volatility_history = []
        
        # ğŸ¯ åˆ†å±¤ç³»çµ±æ•´åˆ
        self.tier_aware_scoring = True
        self.tier_boost_factors = {
            'CRITICAL': 1.2,    # ğŸš¨ CRITICAL å±¤ç´šä¿¡è™ŸåŠ æˆ 20%
            'HIGH': 1.1,        # ğŸ¯ HIGH å±¤ç´šä¿¡è™ŸåŠ æˆ 10%
            'MEDIUM': 1.0,      # ğŸ“Š MEDIUM å±¤ç´šä¿¡è™Ÿä¿æŒåŸå€¼
            'LOW': 0.9          # ğŸ“ˆ LOW å±¤ç´šä¿¡è™Ÿé™ä½ 10%
        }
    
    def score_signal(self, signal_data: Dict[str, Any]) -> Dict[str, float]:
        """
        ä¿¡è™Ÿè©•åˆ†ä¸»æ–¹æ³• - 3ms embedded processing + åˆ†å±¤æ„è­˜å¢å¼·
        
        è™•ç†å±¤:
        - Layer 0: Data Extraction (1ms)  
        - Layer 1: Score Calculation (2ms)
        - Layer 2: Tier Enhancement (0.5ms) ğŸ¯ æ–°å¢
        """
        try:
            # Layer 0: Data Extraction (1ms)
            extracted_metrics = self._layer_0_data_extraction(signal_data)
            
            # Layer 1: Score Calculation (2ms)
            base_score_dict = self._layer_1_score_calculation(extracted_metrics, signal_data)
            
            # Layer 2: Tier Enhancement (0.5ms) ğŸ¯ åˆ†å±¤å¢å¼·
            if self.tier_aware_scoring:
                enhanced_score_dict = self._layer_2_tier_enhancement(base_score_dict, signal_data)
                return enhanced_score_dict
            else:
                return base_score_dict
            
        except Exception:
            # é è¨­å›å‚³å€¼
            return {
                "strength_score": 0.5,
                "confidence_score": 0.7,
                "quality_score": 0.6,
                "risk_score": 0.5,
                "timing_score": 0.8
            }
    
    def _layer_0_data_extraction(self, signal_data: Dict[str, Any]) -> Dict[str, float]:
        """Layer 0: æ•¸æ“šæå–å’Œå¾®ç•°å¸¸æª¢æ¸¬ (1ms)"""
        # æå–åŸºæœ¬æ•¸æ“š
        base_value = signal_data.get('value', 0.5)
        confidence = signal_data.get('confidence', 0.7)
        signal_strength = signal_data.get('signal_strength', abs(base_value))
        
        # å¾®ç•°å¸¸æª¢æ¸¬
        volatility_jump_penalty = self._detect_volatility_jump(signal_strength)
        confidence_drop_rate_monitoring = self._monitor_confidence_drop_rate(confidence)
        
        return {
            "base_value": base_value,
            "confidence": confidence,
            "signal_strength": signal_strength,
            "volatility_jump_penalty": volatility_jump_penalty,
            "confidence_drop_rate_monitoring": confidence_drop_rate_monitoring
        }
    
    def _layer_1_score_calculation(self, extracted_metrics: Dict[str, float], signal_data: Dict[str, Any]) -> Dict[str, float]:
        """Layer 1: å®Œæ•´è©•åˆ†è¨ˆç®— (2ms)"""
        base_value = extracted_metrics["base_value"]
        confidence = extracted_metrics["confidence"]
        signal_strength = extracted_metrics["signal_strength"]
        volatility_penalty = extracted_metrics["volatility_jump_penalty"]
        confidence_drop_penalty = extracted_metrics["confidence_drop_rate_monitoring"]
        
        # å¢å¼·è©•åˆ†ç®—æ³•
        strength_score = self._calculate_strength_scoring(signal_strength, volatility_penalty)
        confidence_score = self._calculate_confidence_scoring(confidence, confidence_drop_penalty)
        quality_score = self._calculate_quality_scoring(strength_score, confidence_score)
        risk_score = self._calculate_risk_scoring(signal_strength)
        timing_score = self._calculate_timing_scoring(signal_data)
        
        # æºå…±è­˜é©—è­‰ (å¦‚æœæœ‰å¤šå€‹ä¿¡è™Ÿæº)
        if 'sources' in signal_data:
            consensus_adjustment = self._perform_source_consensus_validation(signal_data['sources'])
            strength_score *= consensus_adjustment
            confidence_score *= consensus_adjustment
        
        return {
            "strength_score": min(1.0, max(0.0, strength_score)),
            "confidence_score": min(1.0, max(0.0, confidence_score)),
            "quality_score": min(1.0, max(0.0, quality_score)),
            "risk_score": min(1.0, max(0.0, risk_score)),
            "timing_score": min(1.0, max(0.0, timing_score))
        }
    
    def _calculate_strength_scoring(self, signal_strength: float, volatility_penalty: float) -> float:
        """å¼·åº¦è©•åˆ†ï¼šlinear_scoring_based_on_signal_strength + volatility_jump_penalty"""
        base_strength = min(1.0, abs(signal_strength))
        adjusted_strength = base_strength * (1.0 - volatility_penalty)
        return adjusted_strength
    
    def _calculate_confidence_scoring(self, confidence: float, confidence_drop_penalty: float) -> float:
        """ä¿¡å¿ƒè©•åˆ†ï¼šdirect_confidence_mapping_with_drop_rate_detection"""
        adjusted_confidence = confidence * (1.0 - confidence_drop_penalty)
        return min(1.0, max(0.0, adjusted_confidence))
    
    def _calculate_quality_scoring(self, strength_score: float, confidence_score: float) -> float:
        """è³ªé‡è©•åˆ†ï¼šaverage_of_strength_and_confidence"""
        return (strength_score + confidence_score) / 2
    
    def _calculate_risk_scoring(self, signal_strength: float) -> float:
        """é¢¨éšªè©•åˆ†ï¼šinverse_risk_assessment"""
        return 1.0 - min(1.0, abs(signal_strength) * 1.2)
    
    def _calculate_timing_scoring(self, signal_data: Dict[str, Any]) -> float:
        """æ™‚æ©Ÿè©•åˆ†ï¼šadaptive_time_scoring_based_on_market_stress"""
        market_stress = signal_data.get('market_stress', 0.5)
        
        # å‹•æ…‹æ™‚æ©Ÿè©•ä¼° (range: 0.6-1.0)
        base_timing = 0.8
        market_stress_adjustment = self._evaluate_market_stress_adjustment(market_stress)
        
        timing_score = base_timing + market_stress_adjustment
        return min(1.0, max(0.6, timing_score))
    
    def _detect_volatility_jump(self, signal_strength: float) -> float:
        """ä¿¡è™Ÿæ³¢å‹•ç›£æ§ï¼šrolling_standard_deviation_analysis"""
        self.signal_volatility_history.append(signal_strength)
        
        # ä¿æŒ 15 åˆ†é˜çª—å£
        if len(self.signal_volatility_history) > 15:
            self.signal_volatility_history.pop(0)
        
        if len(self.signal_volatility_history) >= 3:
            std_dev = statistics.stdev(self.signal_volatility_history)
            if std_dev > self.anomaly_detection_params["volatility_jump_threshold"]:
                return 0.2  # 20% æ‡²ç½°
        
        return 0.0
    
    def _monitor_confidence_drop_rate(self, confidence: float) -> float:
        """ä¿¡å¿ƒä¸‹é™æª¢æ¸¬ï¼šrate_of_change_analysis"""
        self.historical_confidence_data.append(confidence)
        
        if len(self.historical_confidence_data) > 10:
            self.historical_confidence_data.pop(0)
        
        if len(self.historical_confidence_data) >= 2:
            historical_average = statistics.mean(self.historical_confidence_data[:-1])
            drop_rate = (historical_average - confidence) / historical_average if historical_average > 0 else 0
            
            if drop_rate > self.anomaly_detection_params["confidence_drop_threshold"]:
                return drop_rate * 0.5  # æŒ‰ä¸‹é™ç‡æ¯”ä¾‹æ‡²ç½°
        
        return 0.0
    
    def _evaluate_market_stress_adjustment(self, market_stress: float) -> float:
        """å¸‚å ´å£“åŠ›èª¿æ•´ï¼šdynamic_timing_evaluation"""
        if market_stress > 0.8:
            return -0.1  # é«˜å£“åŠ›ç’°å¢ƒé™ä½æ™‚æ©Ÿåˆ†æ•¸
        elif market_stress < 0.3:
            return 0.1   # ä½å£“åŠ›ç’°å¢ƒæå‡æ™‚æ©Ÿåˆ†æ•¸
        return 0.0
    
    def _perform_source_consensus_validation(self, sources: List[Dict[str, Any]]) -> float:
        """æºå…±è­˜é©—è­‰"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—æºé‡ç–Šè©•åˆ†ï¼šjaccard_similarity_coefficient
        source_overlap_score = self._calculate_jaccard_similarity_coefficient(sources)
        
        # è¨ˆç®—æ¨¡å‹å¤šæ¨£æ€§è©•åˆ†ï¼šentropy_based_diversity_measure
        model_diversity_score = self._calculate_entropy_based_diversity_measure(sources)
        
        # è¨ˆç®—è¡Œå‹•åå·®è©•åˆ†ï¼šdirectional_consensus_measure
        action_bias_score = self._calculate_directional_consensus_measure(sources)
        
        # åŠ æ¬Šå¹³å‡æ³•è¡çªè§£æ±º
        consensus_factor = (
            source_overlap_score * 0.4 + 
            model_diversity_score * 0.3 + 
            action_bias_score * 0.3
        )
        
        return min(1.0, max(0.5, consensus_factor))
    
    def _calculate_jaccard_similarity_coefficient(self, sources: List[Dict[str, Any]]) -> float:
        """Jaccard ç›¸ä¼¼ä¿‚æ•¸è¨ˆç®—"""
        if len(sources) < 2:
            return 1.0
        
        # ç°¡åŒ–å¯¦ç¾ï¼šè¨ˆç®—ä¿¡è™Ÿå¼·åº¦çš„ç›¸ä¼¼æ€§
        strengths = [s.get('signal_strength', 0.5) for s in sources]
        avg_strength = statistics.mean(strengths)
        similarity = 1.0 - statistics.stdev(strengths) if len(strengths) > 1 else 1.0
        
        return min(1.0, max(0.0, similarity))
    
    def _calculate_entropy_based_diversity_measure(self, sources: List[Dict[str, Any]]) -> float:
        """åŸºæ–¼ç†µçš„å¤šæ¨£æ€§æ¸¬é‡"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—æ¨¡å‹é¡å‹å¤šæ¨£æ€§
        model_types = [s.get('model_type', 'default') for s in sources]
        unique_types = len(set(model_types))
        diversity_score = unique_types / len(model_types)
        
        return diversity_score
    
    def _calculate_directional_consensus_measure(self, sources: List[Dict[str, Any]]) -> float:
        """æ–¹å‘æ€§å…±è­˜æ¸¬é‡"""
        if len(sources) < 2:
            return 1.0
        
        # è¨ˆç®—ä¿¡è™Ÿæ–¹å‘ä¸€è‡´æ€§
        directions = []
        for source in sources:
            signal_value = source.get('value', 0)
            if signal_value > 0:
                directions.append(1)
            elif signal_value < 0:
                directions.append(-1)
            else:
                directions.append(0)
        
        # è¨ˆç®—ä¸€è‡´æ€§æ¯”ä¾‹
        if directions:
            most_common_direction = max(set(directions), key=directions.count)
            consensus_ratio = directions.count(most_common_direction) / len(directions)
            return consensus_ratio
        
        return 1.0
    
    def _layer_2_tier_enhancement(self, base_scores: Dict[str, float], signal_data: Dict[str, Any]) -> Dict[str, float]:
        """Layer 2: åˆ†å±¤å¢å¼·è©•åˆ† - åŸºæ–¼ Phase1A åˆ†å±¤ä¿¡æ¯çš„è©•åˆ†å¢å¼·"""
        try:
            # æå–åˆ†å±¤ä¿¡æ¯
            tier_metadata = signal_data.get('metadata', {}).get('tier_metadata', {})
            tier_config = signal_data.get('metadata', {}).get('tier_config', {})
            signal_tier = tier_metadata.get('tier', 'MEDIUM')
            
            # å¦‚æœæ²’æœ‰åˆ†å±¤ä¿¡æ¯ï¼Œè¿”å›åŸå§‹è©•åˆ†
            if not tier_metadata:
                return base_scores
            
            # ç²å–åˆ†å±¤åŠ æˆä¿‚æ•¸
            tier_str = signal_tier.value if hasattr(signal_tier, 'value') else str(signal_tier)
            tier_boost = self.tier_boost_factors.get(tier_str, 1.0)
            
            # å‰µå»ºå¢å¼·è©•åˆ†å‰¯æœ¬
            enhanced_scores = base_scores.copy()
            
            # 1. åŸºæ–¼ Lean ä¿¡å¿ƒåº¦å¢å¼·ä¿¡å¿ƒè©•åˆ†
            lean_confidence = tier_metadata.get('lean_confidence', 0.0)
            if lean_confidence > 0:
                lean_boost = min(0.3, lean_confidence * 0.5)  # æœ€å¤§30%åŠ æˆ
                enhanced_scores['confidence_score'] = min(1.0, 
                    enhanced_scores['confidence_score'] + lean_boost
                )
            
            # 2. åŸºæ–¼åˆ†å±¤ç­‰ç´šå¢å¼·å¼·åº¦è©•åˆ†
            enhanced_scores['strength_score'] = min(1.0, 
                enhanced_scores['strength_score'] * tier_boost
            )
            
            # 3. åŸºæ–¼å€‰ä½ä¹˜æ•¸èª¿æ•´è³ªé‡è©•åˆ†
            position_multiplier = tier_config.get('position_multiplier', 1.0)
            if position_multiplier > 0.5:  # å¤§å€‰ä½ä¿¡è™Ÿæé«˜è³ªé‡è¦æ±‚
                enhanced_scores['quality_score'] = min(1.0,
                    enhanced_scores['quality_score'] * 1.1
                )
            elif position_multiplier < 0.3:  # å°å€‰ä½ä¿¡è™Ÿé™ä½è³ªé‡è¦æ±‚
                enhanced_scores['quality_score'] = max(0.3,
                    enhanced_scores['quality_score'] * 0.9
                )
            
            # 4. åŸºæ–¼åŸ·è¡Œå„ªå…ˆç´šèª¿æ•´æ™‚é–“è©•åˆ†
            execution_priority = tier_config.get('execution_priority', 3)
            if execution_priority <= 2:  # é«˜å„ªå…ˆç´šä¿¡è™Ÿ
                enhanced_scores['timing_score'] = min(1.0,
                    enhanced_scores['timing_score'] * 1.15
                )
            
            # 5. åŸºæ–¼æœŸæœ›æ”¶ç›Šèª¿æ•´é¢¨éšªè©•åˆ†
            expected_return = tier_metadata.get('expected_return', 0.0)
            if expected_return > 0.01:  # é«˜æœŸæœ›æ”¶ç›Š
                enhanced_scores['risk_score'] = min(1.0,
                    enhanced_scores['risk_score'] * 1.1
                )
            elif expected_return < 0:  # è² æœŸæœ›æ”¶ç›Š
                enhanced_scores['risk_score'] = max(0.3,
                    enhanced_scores['risk_score'] * 0.8
                )
            
            # 6. æ·»åŠ åˆ†å±¤è©•åˆ†å…ƒæ•¸æ“š
            enhanced_scores['tier_enhancement_applied'] = True
            enhanced_scores['tier_boost_factor'] = tier_boost
            enhanced_scores['lean_confidence_boost'] = lean_confidence
            enhanced_scores['tier_level'] = tier_str
            
            return enhanced_scores
            
        except Exception as e:
            # åˆ†å±¤å¢å¼·å¤±æ•—ï¼Œè¿”å›åŸå§‹è©•åˆ†
            base_scores['tier_enhancement_error'] = str(e)
            return base_scores
    
    def get_tier_adjusted_final_score(self, scores: Dict[str, float]) -> float:
        """è¨ˆç®—åˆ†å±¤èª¿æ•´å¾Œçš„æœ€çµ‚è©•åˆ†"""
        try:
            # åŸºç¤åŠ æ¬Šè©•åˆ†
            base_final_score = (
                scores.get('strength_score', 0.5) * self.scoring_weights['strength_scoring'] +
                scores.get('confidence_score', 0.7) * self.scoring_weights['confidence_scoring'] +
                scores.get('quality_score', 0.6) * self.scoring_weights['quality_scoring'] +
                scores.get('risk_score', 0.5) * self.scoring_weights['risk_scoring'] +
                scores.get('timing_score', 0.8) * self.scoring_weights['timing_scoring']
            )
            
            # åˆ†å±¤åŠ æˆ
            tier_boost = scores.get('tier_boost_factor', 1.0)
            final_score = min(1.0, base_final_score * tier_boost)
            
            return final_score
            
        except Exception:
            return 0.7  # é»˜èªè©•åˆ†
        most_common_direction = max(set(directions), key=directions.count)
        consensus_count = directions.count(most_common_direction)
        consensus_ratio = consensus_count / len(directions)
        
        return consensus_ratio

# å…¨åŸŸå¯¦ä¾‹ (embedded_in_epl_step3_quality_control)
signal_scoring_engine = EnhancedSignalScoringEngine()

class TierAwareScoring:
    """åˆ†å±¤æ„ŸçŸ¥è©•åˆ†ç³»çµ± - Phase2 èˆ‡ Phase1A åˆ†å±¤ç³»çµ±æ•´åˆ"""
    
    def __init__(self):
        self.base_scoring_engine = signal_scoring_engine
        
        # åˆ†å±¤æ¬Šé‡èª¿æ•´ç­–ç•¥
        self.tier_weight_adjustments = {
            'CRITICAL': {
                'strength_weight_boost': 0.1,      # å¼·åº¦æ¬Šé‡æå‡
                'confidence_weight_boost': 0.15,   # ä¿¡å¿ƒåº¦æ¬Šé‡å¤§å¹…æå‡
                'quality_requirement_strict': True, # åš´æ ¼è³ªé‡è¦æ±‚
                'risk_tolerance_low': 0.8          # ä½é¢¨éšªå®¹å¿åº¦
            },
            'HIGH': {
                'strength_weight_boost': 0.05,
                'confidence_weight_boost': 0.1,
                'quality_requirement_strict': True,
                'risk_tolerance_low': 0.9
            },
            'MEDIUM': {
                'strength_weight_boost': 0.0,
                'confidence_weight_boost': 0.0,
                'quality_requirement_strict': False,
                'risk_tolerance_low': 1.0
            },
            'LOW': {
                'strength_weight_boost': -0.05,    # æ¢ç´¢æ€§ä¿¡è™Ÿï¼Œé™ä½å¼·åº¦è¦æ±‚
                'confidence_weight_boost': -0.1,
                'quality_requirement_strict': False,
                'risk_tolerance_low': 1.2          # å…è¨±æ›´é«˜é¢¨éšª
            }
        }
    
    def calculate_tier_score(self, signal_data: Dict[str, Any], lean_params: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—åˆ†å±¤æ„ŸçŸ¥è©•åˆ† - çµåˆ Lean ä¿¡å¿ƒåº¦å’ŒæŠ€è¡“æŒ‡æ¨™"""
        
        # æå– Lean åƒæ•¸
        lean_confidence = lean_params.get('confidence_level', 0.5)
        lean_direction = lean_params.get('consensus_direction', 'NEUTRAL')
        lean_expected_return = lean_params.get('expected_return', 0.0)
        signal_tier = lean_params.get('signal_tier', 'MEDIUM')
        
        # åŸºç¤æŠ€è¡“è©•åˆ†
        base_scores = self.base_scoring_engine.score_signal(signal_data)
        
        # åˆ†å±¤æ¬Šé‡èª¿æ•´
        tier_adjustments = self.tier_weight_adjustments.get(signal_tier, self.tier_weight_adjustments['MEDIUM'])
        
        # èª¿æ•´å¾Œçš„è©•åˆ†æ¬Šé‡
        adjusted_weights = self.base_scoring_engine.scoring_weights.copy()
        adjusted_weights['strength_scoring'] += tier_adjustments['strength_weight_boost']
        adjusted_weights['confidence_scoring'] += tier_adjustments['confidence_weight_boost']
        
        # æ­£è¦åŒ–æ¬Šé‡
        total_weight = sum(adjusted_weights.values())
        for key in adjusted_weights:
            adjusted_weights[key] /= total_weight
        
        # Lean ä¿¡å¿ƒåº¦èåˆåˆ°ä¿¡å¿ƒåº¦è©•åˆ†
        lean_boost = lean_confidence * 0.3  # Lean è²¢ç»æœ€å¤š 30%
        enhanced_confidence_score = min(1.0, base_scores.get('confidence_score', 0.7) + lean_boost)
        
        # æœŸæœ›æ”¶ç›Šèåˆåˆ°å¼·åº¦è©•åˆ†
        return_boost = abs(lean_expected_return) * 5.0  # æœŸæœ›æ”¶ç›Šè½‰æ›ç‚ºå¼·åº¦åŠ æˆ
        enhanced_strength_score = min(1.0, base_scores.get('strength_score', 0.5) + return_boost)
        
        # åˆ†å±¤è³ªé‡è¦æ±‚
        quality_score = base_scores.get('quality_score', 0.6)
        if tier_adjustments['quality_requirement_strict'] and quality_score < 0.7:
            quality_score *= 0.8  # åš´æ ¼æ¨¡å¼ä¸‹ï¼Œä½è³ªé‡ä¿¡è™Ÿæ‡²ç½°
        
        # é¢¨éšªå®¹å¿åº¦èª¿æ•´
        risk_score = base_scores.get('risk_score', 0.5)
        risk_adjustment = tier_adjustments['risk_tolerance_low']
        adjusted_risk_score = min(1.0, risk_score * risk_adjustment)
        
        # è¨ˆç®—æœ€çµ‚åˆ†å±¤è©•åˆ†
        tier_aware_scores = {
            'base_strength_score': base_scores.get('strength_score', 0.5),
            'enhanced_strength_score': enhanced_strength_score,
            'base_confidence_score': base_scores.get('confidence_score', 0.7),
            'enhanced_confidence_score': enhanced_confidence_score,
            'quality_score': quality_score,
            'adjusted_risk_score': adjusted_risk_score,
            'timing_score': base_scores.get('timing_score', 0.8),
            'lean_confidence_boost': lean_boost,
            'lean_return_boost': return_boost,
            'signal_tier': signal_tier,
            'tier_weight_adjustments': tier_adjustments
        }
        
        # æœ€çµ‚åŠ æ¬Šè©•åˆ†
        final_tier_score = (
            enhanced_strength_score * adjusted_weights['strength_scoring'] +
            enhanced_confidence_score * adjusted_weights['confidence_scoring'] +
            quality_score * adjusted_weights['quality_scoring'] +
            adjusted_risk_score * adjusted_weights['risk_scoring'] +
            tier_aware_scores['timing_score'] * adjusted_weights['timing_scoring']
        )
        
        tier_aware_scores['final_tier_score'] = final_tier_score
        tier_aware_scores['score_improvement'] = final_tier_score - base_scores.get('final_score', 0.7)
        
        return tier_aware_scores
    
    def compare_tier_performance(self, signals_with_tiers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ¯”è¼ƒä¸åŒåˆ†å±¤çš„æ€§èƒ½è¡¨ç¾"""
        tier_performance = {
            'CRITICAL': {'count': 0, 'avg_score': 0.0, 'scores': []},
            'HIGH': {'count': 0, 'avg_score': 0.0, 'scores': []},
            'MEDIUM': {'count': 0, 'avg_score': 0.0, 'scores': []},
            'LOW': {'count': 0, 'avg_score': 0.0, 'scores': []}
        }
        
        for signal in signals_with_tiers:
            tier = signal.get('signal_tier', 'MEDIUM')
            score = signal.get('final_tier_score', 0.0)
            
            if tier in tier_performance:
                tier_performance[tier]['count'] += 1
                tier_performance[tier]['scores'].append(score)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        for tier in tier_performance:
            scores = tier_performance[tier]['scores']
            if scores:
                tier_performance[tier]['avg_score'] = sum(scores) / len(scores)
                tier_performance[tier]['min_score'] = min(scores)
                tier_performance[tier]['max_score'] = max(scores)
                tier_performance[tier]['score_std'] = (sum((x - tier_performance[tier]['avg_score'])**2 for x in scores) / len(scores))**0.5
        
        return tier_performance
    
    def get_tier_recommendation(self, tier_score_result: Dict[str, float]) -> Dict[str, Any]:
        """åŸºæ–¼åˆ†å±¤è©•åˆ†çµæœæä¾›å»ºè­°"""
        final_score = tier_score_result.get('final_tier_score', 0.0)
        signal_tier = tier_score_result.get('signal_tier', 'MEDIUM')
        score_improvement = tier_score_result.get('score_improvement', 0.0)
        
        recommendation = {
            'execution_recommendation': 'HOLD',
            'confidence_level': 'MEDIUM',
            'suggested_position_size': 0.5,
            'reasoning': []
        }
        
        # åŸºæ–¼åˆ†å±¤å’Œè©•åˆ†çš„åŸ·è¡Œå»ºè­°
        if signal_tier == 'CRITICAL' and final_score > 0.8:
            recommendation['execution_recommendation'] = 'STRONG_BUY'
            recommendation['confidence_level'] = 'HIGH'
            recommendation['suggested_position_size'] = 0.8
            recommendation['reasoning'].append('CRITICALå±¤ç´šä¿¡è™Ÿï¼Œé«˜è©•åˆ†ï¼Œå¼·çƒˆå»ºè­°åŸ·è¡Œ')
            
        elif signal_tier == 'HIGH' and final_score > 0.75:
            recommendation['execution_recommendation'] = 'BUY'
            recommendation['confidence_level'] = 'HIGH'
            recommendation['suggested_position_size'] = 0.6
            recommendation['reasoning'].append('HIGHå±¤ç´šä¿¡è™Ÿï¼Œè‰¯å¥½è©•åˆ†ï¼Œå»ºè­°åŸ·è¡Œ')
            
        elif signal_tier == 'MEDIUM' and final_score > 0.7:
            recommendation['execution_recommendation'] = 'BUY'
            recommendation['confidence_level'] = 'MEDIUM'
            recommendation['suggested_position_size'] = 0.4
            recommendation['reasoning'].append('MEDIUMå±¤ç´šä¿¡è™Ÿï¼Œé”æ¨™è©•åˆ†ï¼Œå¯ä»¥åŸ·è¡Œ')
            
        elif signal_tier == 'LOW' and final_score > 0.6:
            recommendation['execution_recommendation'] = 'SMALL_BUY'
            recommendation['confidence_level'] = 'LOW'
            recommendation['suggested_position_size'] = 0.2
            recommendation['reasoning'].append('LOWå±¤ç´šä¿¡è™Ÿï¼Œæ¢ç´¢æ€§åŸ·è¡Œ')
            
        else:
            recommendation['reasoning'].append(f'{signal_tier}å±¤ç´šä¿¡è™Ÿè©•åˆ†ä¸è¶³({final_score:.2f})ï¼Œå»ºè­°æŒæœ‰')
        
        # æ”¹é€²å»ºè­°
        if score_improvement > 0.1:
            recommendation['reasoning'].append(f'åˆ†å±¤å„ªåŒ–å¸¶ä¾†{score_improvement:.2f}åˆ†æ”¹é€²')
        elif score_improvement < -0.05:
            recommendation['reasoning'].append(f'åˆ†å±¤èª¿æ•´é™ä½{abs(score_improvement):.2f}åˆ†ï¼Œéœ€æª¢æŸ¥åƒæ•¸')
        
        return recommendation

# å…¨åŸŸåˆ†å±¤æ„ŸçŸ¥è©•åˆ†å¯¦ä¾‹
tier_aware_scoring_engine = TierAwareScoring()
