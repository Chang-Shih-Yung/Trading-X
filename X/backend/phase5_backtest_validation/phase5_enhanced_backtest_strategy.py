"""
ğŸ¯ Trading X - Phase5 Lean ç›¸ä¼¼åº¦å›æ¸¬ï¼ˆå¯¦æˆ°å„ªåŒ–ç‰ˆï¼‰
ä¿æŒæ—¢æœ‰ JSON Schemaï¼Œå…§éƒ¨å¯¦ç¾ Lean å„ªåŒ–é‚è¼¯
åŸºæ–¼å½¢ç‹€æ¯”è¼ƒçš„æ­·å²ç›¸ä¼¼åº¦åŒ¹é…ï¼Œé¿å…å¤šæŒ‡æ¨™éæ“¬åˆ
"""

import asyncio
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import json
import warnings
from pathlib import Path

# é—œé–‰è­¦å‘Š
warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

class TimeFrame(Enum):
    """æ™‚é–“æ¡†æ¶æšèˆ‰ - Lean ç‰ˆæœ¬ï¼šH4+D1ä¸»å°ï¼ŒW1åˆ¶åº¦é–˜é–€"""
    H4 = "4h"  # çŸ­æœŸè¶¨å‹¢ï¼Œæ¬Šé‡ 45%
    D1 = "1d"  # ä¸­æœŸè¶¨å‹¢ï¼Œæ¬Šé‡ 55%  
    W1 = "1w"  # åˆ¶åº¦åˆ¤æ–·ï¼Œåƒ…åšé–˜é–€

class MarketDirection(Enum):
    """å¸‚å ´æ–¹å‘"""
    BULLISH = "bullish"
    BEARISH = "bearish"
    NEUTRAL = "neutral"

class MarketRegime(Enum):
    """å¸‚å ´åˆ¶åº¦åˆ†é¡ - 6ç¨®åˆ¶åº¦"""
    TREND_UP_HIGH = "trend_up_high"      # ä¸Šå‡+é«˜æ³¢å‹•
    TREND_UP_MID = "trend_up_mid"        # ä¸Šå‡+ä¸­æ³¢å‹•
    TREND_UP_LOW = "trend_up_low"        # ä¸Šå‡+ä½æ³¢å‹•
    TREND_DOWN_HIGH = "trend_down_high"  # ä¸‹é™+é«˜æ³¢å‹•
    TREND_DOWN_MID = "trend_down_mid"    # ä¸‹é™+ä¸­æ³¢å‹•
    TREND_DOWN_LOW = "trend_down_low"    # ä¸‹é™+ä½æ³¢å‹•
    RANGE_HIGH = "range_high"            # æ©«ç›¤+é«˜æ³¢å‹•
    RANGE_MID = "range_mid"              # æ©«ç›¤+ä¸­æ³¢å‹•
    RANGE_LOW = "range_low"              # æ©«ç›¤+ä½æ³¢å‹•

@dataclass
class LeanPattern:
    """Lean æ­·å²æ¨¡å¼åŒ¹é…çµæœ - åƒ…3å€‹æ ¸å¿ƒåºåˆ—"""
    symbol: str
    timeframe: TimeFrame
    match_date: datetime
    similarity_score: float          # åŸºæ–¼å½¢ç‹€ç›¸ä¼¼åº¦ (cosine)
    subsequent_direction: MarketDirection
    subsequent_return: float
    confidence_level: float
    regime: MarketRegime            # åˆ¶åº¦æ¨™ç±¤
    return_sequence: List[float]    # æ”¶ç›Šç‡åºåˆ—
    rsi_zscore_sequence: List[float] # RSI z-score åºåˆ—

@dataclass
class LeanConsensus:
    """Lean å¤šæ™‚é–“æ¡†æ¶å…±è­˜ - H4+D1æŠ•ç¥¨ï¼ŒW1åˆ¶åº¦é–˜é–€"""
    symbol: str
    current_timestamp: datetime
    h4_patterns: List[LeanPattern]
    d1_patterns: List[LeanPattern]
    w1_regime_gate: bool            # W1åˆ¶åº¦é–˜é–€é€šé/ä¸é€šé
    consensus_direction: MarketDirection
    consensus_confidence: float
    expected_return: float
    position_size_multiplier: float  # æ³¢å‹•å€’æ•¸ç¸®æ”¾
    regime_restriction: str         # åˆ¶åº¦é™åˆ¶èªªæ˜

@dataclass
class ExecutionFilter:
    """åŸ·è¡Œéæ¿¾å™¨ - ä¸‰é‡éæ¿¾æ©Ÿåˆ¶"""
    win_rate_threshold: float = 0.58  # çµ±è¨ˆé¡¯è‘—æ€§é–€æª»
    cost_threshold: float = 0.0008    # æ‰‹çºŒè²»+æ»‘é»Ã—2
    regime_gate_passed: bool = True   # åˆ¶åº¦é–˜é–€
    execution_allowed: bool = False   # æœ€çµ‚åŸ·è¡Œè¨±å¯

class LeanHistoricalMatcher:
    """Lean æ­·å²åŒ¹é…å¼•æ“ - åƒ…å½¢ç‹€æ¯”è¼ƒï¼Œé¿å…éæ“¬åˆ"""
    
    def __init__(self):
        # ä¸»è¦åŠ å¯†è²¨å¹£ (é«˜æµå‹•æ€§)
        self.major_symbols = [
            "BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", 
            "XRPUSDT", "SOLUSDT", "DOTUSDT"
        ]
        
        # Lean æ™‚é–“æ¡†æ¶ï¼šH4+D1æŠ•ç¥¨ï¼ŒW1åˆ¶åº¦
        self.timeframes = [TimeFrame.H4, TimeFrame.D1, TimeFrame.W1]
        
        # æ•¸æ“šå„²å­˜
        self.historical_data = {}
        self.regime_cache = {}
        
        # Lean åƒæ•¸ (å›ºå®šç²—ç²’åº¦æª”ä½ï¼Œé¿å…éæ“¬åˆ)
        self.lean_params = {
            'window_size': 60,          # å›ºå®šçª—å£å¤§å°
            'forward_periods': 10,      # å›ºå®šå‰ç»æœŸé–“
            'top_k_matches': 20,        # å›ºå®šç›¸ä¼¼æ¨¡å¼æ•¸é‡
            'cost_buffer': 0.0008,      # ä¿å®ˆæˆæœ¬ä¼°è¨ˆ (é›™å€)
            'regime_lookback': 60,      # åˆ¶åº¦åˆ¤æ–·å›çœ‹æœŸ
            'vol_lookback': 30          # æ³¢å‹•è¨ˆç®—æœŸé–“
        }
        
    def logret(self, prices: pd.Series) -> pd.Series:
        """è¨ˆç®—å°æ•¸æ”¶ç›Šç‡"""
        return np.log(prices).diff().fillna(0)
    
    def zscore(self, x: pd.Series) -> pd.Series:
        """è¨ˆç®— Z-Score æ¨™æº–åŒ–"""
        x = x.astype(float)
        return (x - x.mean()) / (x.std(ddof=0) + 1e-9)
    
    def cosine_similarity(self, a: np.ndarray, b: np.ndarray) -> float:
        """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
        a = a - a.mean()
        b = b - b.mean()
        denominator = (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9)
        return float(np.dot(a, b) / denominator)
    
    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """è¨ˆç®— RSI - å”¯ä¸€æŠ€è¡“æ¿¾æ³¢"""
        delta = prices.diff()
        up = delta.clip(lower=0).ewm(alpha=1/period, adjust=False).mean()
        down = (-delta.clip(upper=0)).ewm(alpha=1/period, adjust=False).mean()
        rs = up / (down + 1e-9)
        return 100 - 100 / (1 + rs)
    
    def detect_regime(self, df: pd.DataFrame) -> MarketRegime:
        """åˆ¶åº¦æª¢æ¸¬ - è¶¨å‹¢æ–¹å‘ Ã— æ³¢å‹•æ¡¶"""
        try:
            if len(df) < self.lean_params['regime_lookback']:
                return MarketRegime.RANGE_MID
            
            # è¶¨å‹¢æª¢æ¸¬ (60æ—¥æ–œç‡)
            prices = df['close'].tail(self.lean_params['regime_lookback'])
            slope = np.polyfit(range(len(prices)), prices, 1)[0]
            
            # æ³¢å‹•æª¢æ¸¬ (30æ—¥å¯¦éš›æ³¢å‹•åˆ†ä½)
            returns = self.logret(df['close']).tail(self.lean_params['vol_lookback'])
            vol = returns.std() * np.sqrt(365)  # å¹´åŒ–æ³¢å‹•ç‡
            
            # ç°¡åŒ–çš„æ³¢å‹•åˆ†ä½ (é€™è£¡å¯ä»¥ç”¨æ­·å²åˆ†ä½æ•¸ï¼Œç°¡åŒ–ç”¨å›ºå®šé–¾å€¼)
            vol_percentile = 0.33 if vol < 0.3 else (0.67 if vol < 0.6 else 1.0)
            
            # è¶¨å‹¢åˆ†é¡
            if slope > 0.02:
                trend = "trend_up"
            elif slope < -0.02:
                trend = "trend_down"
            else:
                trend = "range"
            
            # æ³¢å‹•åˆ†é¡
            if vol_percentile < 0.4:
                vol_bucket = "low"
            elif vol_percentile < 0.7:
                vol_bucket = "mid"  
            else:
                vol_bucket = "high"
            
            # çµ„åˆåˆ¶åº¦
            regime_str = f"{trend}_{vol_bucket}"
            
            # æ˜ å°„åˆ°æšèˆ‰
            regime_mapping = {
                "trend_up_low": MarketRegime.TREND_UP_LOW,
                "trend_up_mid": MarketRegime.TREND_UP_MID,
                "trend_up_high": MarketRegime.TREND_UP_HIGH,
                "trend_down_low": MarketRegime.TREND_DOWN_LOW,
                "trend_down_mid": MarketRegime.TREND_DOWN_MID,
                "trend_down_high": MarketRegime.TREND_DOWN_HIGH,
                "range_low": MarketRegime.RANGE_LOW,
                "range_mid": MarketRegime.RANGE_MID,
                "range_high": MarketRegime.RANGE_HIGH,
            }
            
            return regime_mapping.get(regime_str, MarketRegime.RANGE_MID)
            
        except Exception as e:
            logger.warning(f"åˆ¶åº¦æª¢æ¸¬å¤±æ•—: {e}")
            return MarketRegime.RANGE_MID
    
    def build_lean_features(self, df: pd.DataFrame, window: int) -> Tuple[np.ndarray, np.ndarray]:
        """æ§‹å»º Lean ç‰¹å¾µ - åƒ…3å€‹åºåˆ—"""
        try:
            # 1. æ”¶ç›Šç‡åºåˆ— (å½¢ç‹€æ¯”è¼ƒæ ¸å¿ƒ)
            returns = self.logret(df['close']).tail(window).fillna(0)
            
            # 2. RSI Z-Score (å”¯ä¸€æŠ€è¡“æ¿¾æ³¢)
            rsi = self.calculate_rsi(df['close']).tail(window)
            rsi_zscore = self.zscore(rsi).fillna(0)
            
            return returns.values, rsi_zscore.values
            
        except Exception as e:
            logger.error(f"ç‰¹å¾µæ§‹å»ºå¤±æ•—: {e}")
            return np.zeros(window), np.zeros(window)
    
    async def find_lean_patterns(self, symbol: str, timeframe: TimeFrame, 
                                df: pd.DataFrame) -> List[LeanPattern]:
        """å°‹æ‰¾ Lean ç›¸ä¼¼æ¨¡å¼ - åŒåˆ¶åº¦å…§æ¯”è¼ƒ"""
        try:
            patterns = []
            window = self.lean_params['window_size']
            forward = self.lean_params['forward_periods']
            top_k = self.lean_params['top_k_matches']
            
            if len(df) < window + forward + 10:
                return patterns
            
            # ç•¶å‰åˆ¶åº¦å’Œç‰¹å¾µ
            current_regime = self.detect_regime(df)
            current_returns, current_rsi_z = self.build_lean_features(df, window)
            
            # æ»‘å‹•çª—å£æœç´¢æ­·å²ç›¸ä¼¼æ¨¡å¼
            for i in range(window, len(df) - forward - 5):
                historical_window = df.iloc[i-window:i+1]
                
                # åˆ¶åº¦éæ¿¾ï¼šåªåœ¨åŒåˆ¶åº¦å…§æ¯”è¼ƒ
                historical_regime = self.detect_regime(historical_window)
                if historical_regime != current_regime:
                    continue
                
                # æ§‹å»ºæ­·å²ç‰¹å¾µ
                hist_returns, hist_rsi_z = self.build_lean_features(historical_window, window)
                
                # Lean ç›¸ä¼¼åº¦è¨ˆç®—ï¼š70% æ”¶ç›Šå½¢ç‹€ + 30% RSI
                returns_sim = self.cosine_similarity(current_returns, hist_returns)
                rsi_sim = self.cosine_similarity(current_rsi_z, hist_rsi_z)
                similarity = 0.7 * returns_sim + 0.3 * rsi_sim
                
                if similarity > 0.0:  # åªä¿ç•™æ­£ç›¸ä¼¼åº¦
                    # åˆ†æå¾ŒçºŒèµ°å‹¢
                    future_data = df.iloc[i+1:i+1+forward]
                    if len(future_data) >= forward:
                        subsequent_direction, subsequent_return = self._analyze_subsequent_movement(
                            df.iloc[i]['close'], future_data
                        )
                        
                        pattern = LeanPattern(
                            symbol=symbol,
                            timeframe=timeframe,
                            match_date=df.iloc[i]['timestamp'] if 'timestamp' in df.columns else datetime.now(),
                            similarity_score=similarity,
                            subsequent_direction=subsequent_direction,
                            subsequent_return=subsequent_return,
                            confidence_level=similarity * 0.8,  # ä¿å®ˆä¿¡å¿ƒåº¦
                            regime=historical_regime,
                            return_sequence=hist_returns.tolist(),
                            rsi_zscore_sequence=hist_rsi_z.tolist()
                        )
                        
                        patterns.append(pattern)
            
            # æ’åºä¸¦è¿”å› top-K
            patterns.sort(key=lambda x: x.similarity_score, reverse=True)
            return patterns[:top_k]
            
        except Exception as e:
            logger.error(f"Lean æ¨¡å¼æœç´¢å¤±æ•—: {e}")
            return []
    
    def _analyze_subsequent_movement(self, entry_price: float, 
                                   future_data: pd.DataFrame) -> Tuple[MarketDirection, float]:
        """åˆ†æå¾ŒçºŒå¸‚å ´èµ°å‹¢"""
        try:
            if len(future_data) == 0:
                return MarketDirection.NEUTRAL, 0.0
            
            exit_price = future_data.iloc[-1]['close']
            total_return = (exit_price - entry_price) / entry_price
            
            # 2% é–¾å€¼åˆ¤æ–·æ–¹å‘
            if total_return > 0.02:
                return MarketDirection.BULLISH, total_return
            elif total_return < -0.02:
                return MarketDirection.BEARISH, total_return
            else:
                return MarketDirection.NEUTRAL, total_return
                
        except Exception as e:
            logger.error(f"å¾ŒçºŒèµ°å‹¢åˆ†æå¤±æ•—: {e}")
            return MarketDirection.NEUTRAL, 0.0
    
    def vote_direction(self, patterns: List[LeanPattern]) -> Tuple[int, float, float]:
        """å¤šæ¨¡å¼æŠ•ç¥¨ - çµ±è¨ˆå‹ç‡èˆ‡æœŸæœ›"""
        try:
            if not patterns:
                return 0, 0.0, 0.0
            
            returns = [p.subsequent_return for p in patterns]
            
            # çµ±è¨ˆå‹ç‡
            up_threshold = 0.01  # 1% 
            down_threshold = -0.01
            
            p_up = sum(1 for r in returns if r > up_threshold) / len(returns)
            p_down = sum(1 for r in returns if r < down_threshold) / len(returns)
            
            # æœŸæœ›æ”¶ç›Š
            expected_return = np.mean(returns)
            
            # ä¿¡å¿ƒåº¦å’Œæ–¹å‘
            confidence = max(p_up, p_down)
            
            if p_up > p_down:
                direction = 1  # çœ‹å¤š
            elif p_down > p_up:
                direction = -1  # çœ‹ç©º
            else:
                direction = 0  # ä¸­æ€§
            
            return direction, confidence, expected_return
            
        except Exception as e:
            logger.error(f"æŠ•ç¥¨è¨ˆç®—å¤±æ•—: {e}")
            return 0, 0.0, 0.0
    
    def check_w1_regime_gate(self, w1_df: pd.DataFrame) -> bool:
        """W1 åˆ¶åº¦é–˜é–€æª¢æŸ¥"""
        try:
            regime = self.detect_regime(w1_df)
            
            # ç¦æ­¢åœ¨æ¥µç«¯é«˜æ³¢å‹•è¶¨å‹¢æœŸäº¤æ˜“
            forbidden_regimes = [
                MarketRegime.TREND_UP_HIGH,
                MarketRegime.TREND_DOWN_HIGH
            ]
            
            return regime not in forbidden_regimes
            
        except Exception as e:
            logger.warning(f"W1 åˆ¶åº¦é–˜é–€æª¢æŸ¥å¤±æ•—: {e}")
            return True  # æª¢æŸ¥å¤±æ•—æ™‚å…è¨±äº¤æ˜“ (ä¿å®ˆç­–ç•¥)
    
    def apply_execution_filter(self, consensus: LeanConsensus) -> ExecutionFilter:
        """æ‡‰ç”¨ä¸‰é‡åŸ·è¡Œéæ¿¾"""
        filter_result = ExecutionFilter()
        
        # 1. çµ±è¨ˆé¡¯è‘—æ€§æª¢æŸ¥
        win_rate_pass = consensus.consensus_confidence > filter_result.win_rate_threshold
        
        # 2. æœŸæœ›æ”¶ç›Šè¶…æˆæœ¬æª¢æŸ¥
        edge = consensus.expected_return - filter_result.cost_threshold
        cost_pass = edge > 0
        
        # 3. åˆ¶åº¦é–˜é–€æª¢æŸ¥
        regime_pass = consensus.w1_regime_gate
        
        # æœ€çµ‚åŸ·è¡Œè¨±å¯
        filter_result.execution_allowed = win_rate_pass and cost_pass and regime_pass
        filter_result.regime_gate_passed = regime_pass
        
        return filter_result
    
    async def generate_lean_consensus(self, symbol: str, 
                                    h4_df: pd.DataFrame, d1_df: pd.DataFrame, 
                                    w1_df: pd.DataFrame) -> LeanConsensus:
        """ç”Ÿæˆ Lean å…±è­˜åˆ†æ"""
        try:
            # H4 å’Œ D1 æ¨¡å¼æœç´¢
            h4_patterns = await self.find_lean_patterns(symbol, TimeFrame.H4, h4_df)
            d1_patterns = await self.find_lean_patterns(symbol, TimeFrame.D1, d1_df)
            
            # W1 åˆ¶åº¦é–˜é–€
            w1_gate = self.check_w1_regime_gate(w1_df)
            
            # å¤šæ™‚é–“æ¡†æ¶æŠ•ç¥¨
            h4_vote = self.vote_direction(h4_patterns)
            d1_vote = self.vote_direction(d1_patterns)
            
            # åŠ æ¬Šèåˆï¼šH4(45%) + D1(55%)
            weighted_direction = 0.45 * h4_vote[0] + 0.55 * d1_vote[0]
            weighted_confidence = 0.45 * h4_vote[1] + 0.55 * d1_vote[1]
            weighted_expected = 0.45 * h4_vote[2] + 0.55 * d1_vote[2]
            
            # æ–¹å‘åˆ¤æ–·
            if weighted_direction > 0.2:
                consensus_direction = MarketDirection.BULLISH
            elif weighted_direction < -0.2:
                consensus_direction = MarketDirection.BEARISH
            else:
                consensus_direction = MarketDirection.NEUTRAL
            
            # æ³¢å‹•å€’æ•¸ç¸®æ”¾
            h4_returns = self.logret(h4_df['close']).tail(48)  # 48 æ ¹ H4
            realized_vol = h4_returns.std()
            target_risk = 0.02  # 2% ç›®æ¨™é¢¨éšª
            size_multiplier = min(1.0, target_risk / (realized_vol + 1e-6))
            
            # åˆ¶åº¦é™åˆ¶èªªæ˜
            current_regime = self.detect_regime(d1_df)
            restriction = f"ç•¶å‰åˆ¶åº¦: {current_regime.value}, W1é–˜é–€: {'é€šé' if w1_gate else 'ç¦æ­¢'}"
            
            return LeanConsensus(
                symbol=symbol,
                current_timestamp=datetime.now(),
                h4_patterns=h4_patterns,
                d1_patterns=d1_patterns,
                w1_regime_gate=w1_gate,
                consensus_direction=consensus_direction,
                consensus_confidence=weighted_confidence,
                expected_return=weighted_expected,
                position_size_multiplier=size_multiplier,
                regime_restriction=restriction
            )
            
        except Exception as e:
            logger.error(f"Lean å…±è­˜åˆ†æå¤±æ•—: {e}")
            return LeanConsensus(
                symbol=symbol,
                current_timestamp=datetime.now(),
                h4_patterns=[],
                d1_patterns=[],
                w1_regime_gate=False,
                consensus_direction=MarketDirection.NEUTRAL,
                consensus_confidence=0.0,
                expected_return=0.0,
                position_size_multiplier=0.0,
                regime_restriction="åˆ†æå¤±æ•—"
            )

async def generate_lean_backtest_config(lean_consensus_results: List[LeanConsensus]) -> Dict:
    """ç”Ÿæˆ Lean å›æ¸¬é…ç½® - ä¿æŒæ—¢æœ‰ JSON Schema"""
    logger.info("ğŸ“Š ç”Ÿæˆ Lean å›æ¸¬é…ç½®...")
    
    try:
        # çµ±è¨ˆ Lean å…±è­˜çµæœ
        bullish_count = sum(1 for result in lean_consensus_results 
                           if result.consensus_direction == MarketDirection.BULLISH and 
                           result.w1_regime_gate)
        bearish_count = sum(1 for result in lean_consensus_results 
                          if result.consensus_direction == MarketDirection.BEARISH and 
                          result.w1_regime_gate)
        
        total_valid = len([r for r in lean_consensus_results if r.w1_regime_gate])
        
        # è¨ˆç®—å¸‚å ´å‚¾å‘
        if total_valid > 0:
            market_sentiment = "BULLISH" if bullish_count > bearish_count else "BEARISH"
            market_confidence = max(bullish_count, bearish_count) / total_valid
        else:
            market_sentiment = "NEUTRAL"
            market_confidence = 0.5
        
        # è¨ˆç®—å¹³å‡ Lean æŒ‡æ¨™
        avg_confidence = np.mean([r.consensus_confidence for r in lean_consensus_results if r.w1_regime_gate]) if total_valid > 0 else 0.7
        avg_expected_return = np.mean([r.expected_return for r in lean_consensus_results if r.w1_regime_gate]) if total_valid > 0 else 0.0
        avg_size_multiplier = np.mean([r.position_size_multiplier for r in lean_consensus_results]) if lean_consensus_results else 1.0
        
        # ä¿æŒæ—¢æœ‰ JSON Schema çµæ§‹ï¼Œå…§éƒ¨å¡«å…¥ Lean å„ªåŒ–åƒæ•¸
        lean_config = {
            # ========== ä¿æŒåŸæœ‰çµæ§‹ ==========
            "input_specifications": {
                "real_time_data_sources": {
                    "binance_websocket": {
                        "price_stream": "real_time",
                        "volume_stream": "real_time",
                        "orderbook_stream": "real_time",
                        "funding_rate_api": "periodic"
                    }
                },
                "required_parameters": {
                    "dynamic_parameters": ["market_regime", "trading_session"],
                    "orderbook_integration": ["spread_calculation", "depth_analysis", "liquidity_ratio"],
                    "signal_thresholds": ["strength_minimum", "confidence_threshold"]
                }
            },
            
            "output_specifications": {
                "signal_format": "BasicSignal",
                "market_data_format": "MarketData",
                "output_channels": ["phase1b_volatility", "phase1c_coordination", "phase2_pre_evaluation"]
            },
            
            # ========== Lean å„ªåŒ–åƒæ•¸ (éš±è—åœ¨ç¾æœ‰çµæ§‹ä¸­) ==========
            
            # åœ¨ phase1a_basic_signal_generation_dependency ä¸­æ³¨å…¥ Lean åƒæ•¸
            "phase1a_basic_signal_generation_dependency": {
                "version": "2.0.0-lean",
                "created_date": datetime.now().strftime("%Y-%m-%d"),
                "description": "Phase1A Lean ç›¸ä¼¼åº¦å›æ¸¬å„ªåŒ–é…ç½® - åƒ…å½¢ç‹€æ¯”è¼ƒï¼Œé¿å…éæ“¬åˆ",
                "module_type": "lean_signal_generation_foundation",
                
                # Lean æ ¸å¿ƒé…ç½®
                "lean_optimization": {
                    "enabled": True,
                    "methodology": "shape_comparison_only",
                    "feature_count": 3,  # åƒ…3å€‹åºåˆ—
                    "timeframe_strategy": "h4_d1_voting_w1_gate",
                    "regime_filtering": "same_regime_comparison",
                    "execution_filter": "triple_filter_mechanism"
                },
                
                # æ³¨å…¥åˆ°ç¾æœ‰çš„é…ç½®çµæ§‹
                "configuration": {
                    "signal_generation_params": {
                        "basic_mode": {
                            # ä¿æŒåŸæœ‰åƒæ•¸åï¼Œä½†ç”¨ Lean è¨ˆç®—å€¼
                            "price_change_threshold": {
                                "base_value": max(0.001, avg_expected_return * 0.5),  # åŸºæ–¼æœŸæœ›æ”¶ç›Šèª¿æ•´
                                "type": "dynamic_parameter",
                                "parameter_id": "lean_price_change_threshold",
                                "market_regime_dependent": True,
                                "lean_optimization": True,
                                "description": "Lean å„ªåŒ–ï¼šåŸºæ–¼æ­·å²ç›¸ä¼¼åº¦çš„åƒ¹æ ¼è®ŠåŒ–é–¾å€¼"
                            },
                            "confidence_threshold": {
                                "base_value": max(0.7, avg_confidence * 0.9),  # åŸºæ–¼ Lean å…±è­˜ä¿¡å¿ƒåº¦
                                "type": "dynamic_parameter", 
                                "parameter_id": "lean_confidence_threshold",
                                "market_regime_dependent": True,
                                "lean_optimization": True,
                                "description": "Lean å„ªåŒ–ï¼šåŸºæ–¼å¤šæ™‚é–“æ¡†æ¶å…±è­˜çš„ä¿¡å¿ƒåº¦é–¾å€¼"
                            }
                        }
                    },
                    
                    # Lean ç‰¹å®šåƒæ•¸ (éš±è—åœ¨ performance_targets ä¸­)
                    "performance_targets": {
                        "processing_latency_p99": "<30ms",
                        "signal_generation_rate": "5-25 signals/minute",  # æ›´ä¿å®ˆ
                        "accuracy_baseline": f">{max(60, avg_confidence * 100):.0f}%",  # åŸºæ–¼å¯¦éš› Lean çµæœ
                        "system_availability": ">99.5%",
                        
                        # Lean éš±è—åƒæ•¸
                        "lean_win_rate_target": max(0.58, avg_confidence),
                        "lean_expected_return": avg_expected_return,
                        "lean_position_multiplier": avg_size_multiplier,
                        "lean_regime_gate_rate": total_valid / len(lean_consensus_results) if lean_consensus_results else 0.8
                    }
                }
            },
            
            # åœ¨ç¾æœ‰åƒæ•¸ä¸­åµŒå…¥ Lean å„ªåŒ–å€¼
            "rsi_period": int(15 + avg_confidence * 5),  # Lean å‹•æ…‹èª¿æ•´ RSI æœŸé–“
            "macd_fast": int(12 + avg_expected_return * 20),  # åŸºæ–¼æœŸæœ›æ”¶ç›Šèª¿æ•´
            "macd_slow": int(26 + market_confidence * 10),  # åŸºæ–¼å¸‚å ´ä¿¡å¿ƒåº¦èª¿æ•´
            
            # æ¨™è¨˜ç‚º Lean å„ªåŒ–
            "optimization_timestamp": datetime.now().isoformat(),
            "optimized_by": "Phase5_Lean_Optimizer",
            "lean_mode": True,
            "performance_boost": min(1.2, 1.0 + avg_confidence * 0.3),
            "optimization_method": "lean_similarity_matching",
            
            # Lean å›æ¸¬çµæœæ‘˜è¦ (éš±è—åœ¨ metadata ä¸­)
            "lean_backtest_summary": {
                "total_symbols_analyzed": len(lean_consensus_results),
                "regime_gate_passed": total_valid,
                "bullish_consensus": bullish_count,
                "bearish_consensus": bearish_count,
                "market_sentiment": market_sentiment,
                "market_confidence": round(market_confidence, 3),
                "avg_lean_confidence": round(avg_confidence, 3),
                "avg_expected_return": round(avg_expected_return, 4),
                "avg_position_sizing": round(avg_size_multiplier, 3)
            }
        }
        
        # ç‚ºæ¯å€‹å¹£ç¨®æ·»åŠ å…·é«”èª¿æ•´ (ä¿æŒåŸæœ‰æ ¼å¼)
        for result in lean_consensus_results:
            if result.w1_regime_gate:  # åªç‚ºé€šéåˆ¶åº¦é–˜é–€çš„å¹£ç¨®èª¿æ•´
                symbol_key = f"{result.symbol.lower()}_lean_adjustment"
                lean_config[symbol_key] = {
                    "direction_bias": result.consensus_direction.value,
                    "confidence_level": round(result.consensus_confidence, 3),
                    "expected_return": round(result.expected_return, 4),
                    "position_multiplier": round(result.position_size_multiplier, 3),
                    "regime_status": result.regime_restriction,
                    "h4_pattern_count": len(result.h4_patterns),
                    "d1_pattern_count": len(result.d1_patterns)
                }
        
        return lean_config
        
    except Exception as e:
        logger.error(f"Lean å›æ¸¬é…ç½®ç”Ÿæˆå¤±æ•—: {e}")
        # è¿”å›ä¿å®ˆçš„é è¨­é…ç½®
        return {
            "optimization_timestamp": datetime.now().isoformat(),
            "optimized_by": "Phase5_Lean_Optimizer_Fallback",
            "lean_mode": True,
            "error": str(e),
            "fallback_mode": True
        }

async def save_lean_config_to_phase5_backup(lean_config: Dict) -> str:
    """ä¿å­˜ Lean é…ç½®åˆ° Phase5 å‚™ä»½ç›®éŒ„ï¼Œä¾› Phase1A è®€å–"""
    try:
        # Phase5 å‚™ä»½ç›®éŒ„ (ç•¶å‰ç›®éŒ„çš„ safety_backups/working)
        backup_dir = Path(__file__).parent / "safety_backups" / "working"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ™‚é–“æˆ³æª”å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"phase1a_backup_deployment_initial_{timestamp}.json"
        filepath = backup_dir / filename
        
        # ä¿å­˜é…ç½®
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(lean_config, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"âœ… Lean é…ç½®å·²ä¿å­˜: {filename}")
        logger.info(f"ğŸ“ è·¯å¾‘: {filepath}")
        return str(filepath)
        
    except Exception as e:
        logger.error(f"Lean é…ç½®ä¿å­˜å¤±æ•—: {e}")
        return ""

# ==================== ä¸»è¦åŸ·è¡Œå‡½æ•¸ ====================

async def run_lean_backtest_analysis(symbols: List[str] = None) -> Dict:
    """åŸ·è¡Œ Lean å›æ¸¬åˆ†æä¸»æµç¨‹"""
    logger.info("ğŸš€ å•Ÿå‹• Phase5 Lean ç›¸ä¼¼åº¦å›æ¸¬åˆ†æ...")
    
    try:
        # ä½¿ç”¨é è¨­ä¸»è¦å¹£ç¨®æˆ–ç”¨æˆ¶æŒ‡å®š
        if symbols is None:
            symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "XRPUSDT", "SOLUSDT", "DOTUSDT"]
        
        lean_matcher = LeanHistoricalMatcher()
        lean_results = []
        
        # æ¨¡æ“¬æ­·å²æ•¸æ“š (å¯¦éš›æ‡‰å¾ API ç²å–)
        for symbol in symbols:
            logger.info(f"ğŸ” åˆ†æ {symbol} - Lean ç›¸ä¼¼åº¦åŒ¹é…...")
            
            try:
                # æ¨¡æ“¬ç”Ÿæˆä¸åŒæ™‚é–“æ¡†æ¶çš„æ­·å²æ•¸æ“š
                h4_df = await generate_mock_historical_data(symbol, "4h", days=30)
                d1_df = await generate_mock_historical_data(symbol, "1d", days=90) 
                w1_df = await generate_mock_historical_data(symbol, "1w", days=365)
                
                # ç”Ÿæˆ Lean å…±è­˜
                lean_consensus = await lean_matcher.generate_lean_consensus(symbol, h4_df, d1_df, w1_df)
                
                # æ‡‰ç”¨åŸ·è¡Œéæ¿¾
                execution_filter = lean_matcher.apply_execution_filter(lean_consensus)
                
                # è¨˜éŒ„çµæœ
                lean_results.append(lean_consensus)
                
                filter_status = "âœ… é€šé" if execution_filter.execution_allowed else "âŒ è¢«éæ¿¾"
                logger.info(f"   {symbol}: {lean_consensus.consensus_direction.value} "
                          f"(ä¿¡å¿ƒåº¦: {lean_consensus.consensus_confidence:.2%}, "
                          f"æœŸæœ›: {lean_consensus.expected_return:.2%}) {filter_status}")
                
            except Exception as e:
                logger.error(f"   âŒ {symbol} åˆ†æå¤±æ•—: {e}")
        
        # ç”Ÿæˆ Lean é…ç½®
        lean_config = await generate_lean_backtest_config(lean_results)
        
        # ä¿å­˜åˆ° Phase5 å‚™ä»½ç›®éŒ„
        config_path = await save_lean_config_to_phase5_backup(lean_config)
        
        # ç”Ÿæˆåˆ†ææ‘˜è¦
        analysis_summary = {
            "lean_analysis_timestamp": datetime.now().isoformat(),
            "methodology": "shape_comparison_similarity_matching",
            "symbols_analyzed": len(symbols),
            "successful_analysis": len(lean_results),
            "config_saved_path": config_path,
            "lean_optimization_enabled": True,
            "next_phase1a_will_load": bool(config_path),
            "summary": {
                "avg_confidence": np.mean([r.consensus_confidence for r in lean_results]) if lean_results else 0,
                "avg_expected_return": np.mean([r.expected_return for r in lean_results]) if lean_results else 0,
                "regime_gate_pass_rate": len([r for r in lean_results if r.w1_regime_gate]) / len(lean_results) if lean_results else 0,
                "bullish_signals": len([r for r in lean_results if r.consensus_direction == MarketDirection.BULLISH]),
                "bearish_signals": len([r for r in lean_results if r.consensus_direction == MarketDirection.BEARISH])
            }
        }
        
        logger.info("âœ… Phase5 Lean åˆ†æå®Œæˆ")
        logger.info(f"ğŸ“Š å¹³å‡ä¿¡å¿ƒåº¦: {analysis_summary['summary']['avg_confidence']:.2%}")
        logger.info(f"ğŸ“ˆ å¹³å‡æœŸæœ›æ”¶ç›Š: {analysis_summary['summary']['avg_expected_return']:.2%}")
        logger.info(f"ğŸšª åˆ¶åº¦é–˜é–€é€šéç‡: {analysis_summary['summary']['regime_gate_pass_rate']:.1%}")
        
        return analysis_summary
        
    except Exception as e:
        logger.error(f"âŒ Lean å›æ¸¬åˆ†æå¤±æ•—: {e}")
        return {"error": str(e), "lean_analysis_timestamp": datetime.now().isoformat()}

async def generate_mock_historical_data(symbol: str, interval: str, days: int = 30) -> pd.DataFrame:
    """ç”Ÿæˆæ¨¡æ“¬æ­·å²æ•¸æ“š (å¯¦éš›æ‡‰å¾ Binance API ç²å–)"""
    try:
        # æ ¹æ“šæ™‚é–“é–“éš”è¨ˆç®—æ•¸æ“šé»æ•¸é‡
        if interval == "4h":
            periods = days * 6  # ä¸€å¤©6æ ¹4å°æ™‚Kç·š
        elif interval == "1d":
            periods = days     # ä¸€å¤©1æ ¹æ—¥Kç·š
        elif interval == "1w":
            periods = days // 7  # ä¸€é€±1æ ¹é€±Kç·š
        else:
            periods = days * 24  # é è¨­å°æ™‚Kç·š
        
        # ç”Ÿæˆæ™‚é–“åºåˆ—
        end_time = datetime.now()
        if interval == "4h":
            freq = "4H"
        elif interval == "1d":
            freq = "D"
        elif interval == "1w":
            freq = "W"
        else:
            freq = "H"
        
        timestamps = pd.date_range(end=end_time, periods=periods, freq=freq)
        
        # æ¨¡æ“¬åƒ¹æ ¼èµ°å‹¢ (å¸¶æœ‰ä¸€å®šè¶¨å‹¢æ€§)
        base_price = 30000 if "BTC" in symbol else (2000 if "ETH" in symbol else 300)
        
        # ç”Ÿæˆå¸¶è¶¨å‹¢çš„éš¨æ©ŸéŠèµ°
        returns = np.random.normal(0.0001, 0.02, periods)  # å°å¹…æ­£å‘è¶¨å‹¢ + 2%æ³¢å‹•
        returns[0] = 0  # ç¬¬ä¸€å€‹æ”¶ç›Šç‡ç‚º0
        
        prices = base_price * np.exp(np.cumsum(returns))
        
        # ç”Ÿæˆ OHLC æ•¸æ“š
        highs = prices * (1 + np.abs(np.random.normal(0, 0.01, periods)))
        lows = prices * (1 - np.abs(np.random.normal(0, 0.01, periods)))
        opens = np.roll(prices, 1)
        opens[0] = prices[0]
        
        # ç”Ÿæˆæˆäº¤é‡
        volumes = np.random.lognormal(10, 1, periods)
        
        df = pd.DataFrame({
            'timestamp': timestamps,
            'open': opens,
            'high': highs,
            'low': lows,
            'close': prices,
            'volume': volumes
        })
        
        return df
        
    except Exception as e:
        logger.error(f"æ¨¡æ“¬æ•¸æ“šç”Ÿæˆå¤±æ•—: {e}")
        return pd.DataFrame()

# ä¸»è¦åŸ·è¡Œå‡½æ•¸
async def run_enhanced_backtest_analysis():
    """åŸ·è¡Œ Lean å›æ¸¬åˆ†æ - é‡æ–°è·¯ç”±åˆ°æ–°å‡½æ•¸"""
    return await run_lean_backtest_analysis()

if __name__ == "__main__":
    # åŸ·è¡Œ Lean å›æ¸¬åˆ†æ
    asyncio.run(run_lean_backtest_analysis())
