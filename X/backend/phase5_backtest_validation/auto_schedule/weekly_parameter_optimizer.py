#!/usr/bin/env python3
"""
ğŸ¯ Trading X - æ¯é€±è‡ªå‹•åƒæ•¸å„ªåŒ–å™¨
è‡ªå‹•èª¿æ•´ Phase1A åƒæ•¸ä»¥é”åˆ° 70% å‹ç‡ç›®æ¨™
"""

import asyncio
import logging
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import numpy as np
from dataclasses import dataclass
import itertools

@dataclass
class OptimizationTarget:
    """å„ªåŒ–ç›®æ¨™"""
    win_rate: float = 0.70      # 70% å‹ç‡ç›®æ¨™
    profit_loss_ratio: float = 1.5   # 1.5 ç›ˆè™§æ¯”ç›®æ¨™
    sharpe_ratio: float = 1.0   # 1.0 å¤æ™®æ¯”ç‡ç›®æ¨™

@dataclass
class ParameterSet:
    """åƒæ•¸çµ„åˆ"""
    confidence_threshold: float
    price_change_threshold: float
    volume_change_threshold: float
    
    def to_dict(self) -> Dict[str, float]:
        return {
            'confidence_threshold': self.confidence_threshold,
            'price_change_threshold': self.price_change_threshold,
            'volume_change_threshold': self.volume_change_threshold
        }

class WeeklyParameterOptimizer:
    """æ¯é€±åƒæ•¸è‡ªå‹•å„ªåŒ–å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.optimization_target = OptimizationTarget()
        self.current_best_params = None
        self.optimization_history = []
        
        # åƒæ•¸æœå°‹ç©ºé–“
        self.parameter_space = {
            'confidence_threshold': np.arange(0.65, 0.86, 0.02),
            'price_change_threshold': np.arange(0.0005, 0.0021, 0.0001),
            'volume_change_threshold': np.arange(1.0, 2.6, 0.1)
        }
    
    async def run_weekly_optimization(self) -> Dict[str, Any]:
        """åŸ·è¡Œæ¯é€±åƒæ•¸å„ªåŒ–"""
        self.logger.info("ğŸš€ é–‹å§‹æ¯é€±åƒæ•¸å„ªåŒ–...")
        
        start_time = datetime.now()
        
        try:
            # 1. ç²å–ç•¶å‰æ€§èƒ½åŸºæº–
            current_performance = await self._get_current_performance()
            
            # 2. åˆ¤æ–·æ˜¯å¦éœ€è¦å„ªåŒ–
            if self._meets_targets(current_performance):
                self.logger.info("âœ… ç•¶å‰åƒæ•¸å·²é”æ¨™ï¼Œè·³éå„ªåŒ–")
                return {
                    'status': 'skip',
                    'reason': 'å·²é”åˆ°ç›®æ¨™æ€§èƒ½',
                    'current_performance': current_performance
                }
            
            # 3. åŸ·è¡Œæ™ºèƒ½åƒæ•¸æœå°‹
            best_params, best_performance = await self._intelligent_parameter_search()
            
            # 4. é©—è­‰æœ€ä½³åƒæ•¸
            validated_performance = await self._test_parameter_set(best_params)
            
            # 5. æ›´æ–° Phase1A åƒæ•¸
            if self._should_update_parameters(validated_performance, current_performance):
                await self._update_phase1a_parameters(best_params)
                
                optimization_result = {
                    'status': 'success',
                    'optimization_time': (datetime.now() - start_time).total_seconds(),
                    'old_parameters': self.current_best_params.to_dict() if self.current_best_params else None,
                    'new_parameters': best_params.to_dict(),
                    'old_performance': current_performance,
                    'new_performance': validated_performance,
                    'improvement': self._calculate_improvement(current_performance, validated_performance)
                }
                
                self.current_best_params = best_params
                self.optimization_history.append(optimization_result)
                
                self.logger.info(f"âœ… åƒæ•¸å„ªåŒ–å®Œæˆï¼å‹ç‡æå‡è‡³ {validated_performance['win_rate']:.2%}")
                return optimization_result
            
            else:
                return {
                    'status': 'no_improvement',
                    'reason': 'æ–°åƒæ•¸æœªèƒ½é¡¯è‘—æ”¹å–„æ€§èƒ½',
                    'tested_performance': validated_performance
                }
                
        except Exception as e:
            self.logger.error(f"âŒ åƒæ•¸å„ªåŒ–å¤±æ•—: {e}")
            return {
                'status': 'error',
                'error': str(e)
            }
    
    async def _intelligent_parameter_search(self) -> Tuple[ParameterSet, Dict[str, float]]:
        """æ™ºèƒ½åƒæ•¸æœå°‹ç®—æ³•"""
        self.logger.info("ğŸ” é–‹å§‹æ™ºèƒ½åƒæ•¸æœå°‹...")
        
        # ä½¿ç”¨æ”¹é€²çš„ç¶²æ ¼æœå°‹ + è²è‘‰æ–¯å„ªåŒ–
        best_score = -float('inf')
        best_params = None
        best_performance = None
        
        # ç¬¬ä¸€éšæ®µï¼šç²—ç³™ç¶²æ ¼æœå°‹
        coarse_grid = self._generate_coarse_grid()
        self.logger.info(f"ğŸ“Š ç²—ç³™æœå°‹: {len(coarse_grid)} å€‹åƒæ•¸çµ„åˆ")
        
        for i, params in enumerate(coarse_grid):
            if i % 10 == 0:
                self.logger.info(f"   é€²åº¦: {i}/{len(coarse_grid)} ({i/len(coarse_grid)*100:.1f}%)")
            
            performance = await self._test_parameter_set(params)
            score = self._calculate_composite_score(performance)
            
            if score > best_score:
                best_score = score
                best_params = params
                best_performance = performance
        
        # ç¬¬äºŒéšæ®µï¼šåœ¨æœ€ä½³å€åŸŸç²¾ç´°æœå°‹
        if best_params:
            self.logger.info("ğŸ¯ åœ¨æœ€ä½³å€åŸŸé€²è¡Œç²¾ç´°æœå°‹...")
            fine_tuned_params, fine_tuned_performance = await self._fine_tune_parameters(best_params)
            
            if self._calculate_composite_score(fine_tuned_performance) > best_score:
                best_params = fine_tuned_params
                best_performance = fine_tuned_performance
        
        return best_params, best_performance
    
    def _generate_coarse_grid(self) -> List[ParameterSet]:
        """ç”Ÿæˆç²—ç³™ç¶²æ ¼"""
        # æ¯å€‹åƒæ•¸é¸æ“‡ 5 å€‹ä»£è¡¨æ€§å€¼
        conf_values = np.linspace(0.65, 0.85, 5)
        price_values = np.linspace(0.0005, 0.002, 5)
        volume_values = np.linspace(1.0, 2.5, 5)
        
        grid = []
        for conf, price, volume in itertools.product(conf_values, price_values, volume_values):
            grid.append(ParameterSet(
                confidence_threshold=float(conf),
                price_change_threshold=float(price),
                volume_change_threshold=float(volume)
            ))
        
        return grid
    
    async def _fine_tune_parameters(self, base_params: ParameterSet) -> Tuple[ParameterSet, Dict[str, float]]:
        """åœ¨æœ€ä½³åƒæ•¸é™„è¿‘ç²¾ç´°èª¿æ•´"""
        best_params = base_params
        best_performance = await self._test_parameter_set(base_params)
        best_score = self._calculate_composite_score(best_performance)
        
        # åœ¨æœ€ä½³åƒæ•¸å‘¨åœ Â±10% ç¯„åœå…§æœå°‹
        adjustments = [-0.1, -0.05, 0, 0.05, 0.1]
        
        for conf_adj in adjustments:
            for price_adj in adjustments:
                for volume_adj in adjustments:
                    new_params = ParameterSet(
                        confidence_threshold=max(0.65, min(0.85, base_params.confidence_threshold * (1 + conf_adj))),
                        price_change_threshold=max(0.0005, min(0.002, base_params.price_change_threshold * (1 + price_adj))),
                        volume_change_threshold=max(1.0, min(2.5, base_params.volume_change_threshold * (1 + volume_adj)))
                    )
                    
                    performance = await self._test_parameter_set(new_params)
                    score = self._calculate_composite_score(performance)
                    
                    if score > best_score:
                        best_score = score
                        best_params = new_params
                        best_performance = performance
        
        return best_params, best_performance
    
    async def _test_parameter_set(self, params: ParameterSet) -> Dict[str, float]:
        """æ¸¬è©¦ç‰¹å®šåƒæ•¸çµ„åˆçš„æ€§èƒ½"""
        try:
            self.logger.info(f"ğŸ§ª æ¸¬è©¦åƒæ•¸çµ„åˆ: {params.to_dict()}")
            
            # é€™è£¡æœƒèª¿ç”¨ Phase5 å›æ¸¬ç³»çµ±ä¾†æ¸¬è©¦åƒæ•¸
            import sys
            from pathlib import Path
            sys.path.append(str(Path(__file__).parent.parent / "auto_backtest_validator"))
            from auto_backtest_validator import AutoBacktestValidator  # type: ignore
            
            validator = AutoBacktestValidator()
            
            # è‡¨æ™‚æ›´æ–° Phase1A åƒæ•¸
            await self._temporarily_update_phase1a_parameters(params)
            
            # é‹è¡Œ 7 å¤©å›æ¸¬
            result = await validator.run_phase1a_validation_cycle()
            
            if result is None:
                self.logger.error("âŒ åƒæ•¸æ¸¬è©¦è¿”å› None")
                return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
            
            if 'error' in result:
                self.logger.error(f"âŒ åƒæ•¸æ¸¬è©¦å¤±æ•—: {result['error']}")
                return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
            
            # æå–æ€§èƒ½æŒ‡æ¨™
            overall_perf = result.get('overall_performance', {})
            performance = {
                'win_rate': overall_perf.get('overall_win_rate', 0),
                'avg_pnl_ratio': overall_perf.get('avg_pnl_ratio', 0),
                'total_signals': overall_perf.get('total_signals', 0),
                'sharpe_ratio': self._calculate_sharpe_ratio(result)
            }
            
            self.logger.info(f"ğŸ“Š åƒæ•¸æ¸¬è©¦çµæœ: å‹ç‡ {performance['win_rate']:.2%}")
            return performance
            
        except Exception as e:
            self.logger.error(f"âŒ åƒæ•¸æ¸¬è©¦ç•°å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
    
    def _calculate_composite_score(self, performance: Dict[str, float]) -> float:
        """è¨ˆç®—ç¶œåˆè©•åˆ†"""
        win_rate = performance.get('win_rate', 0)
        pnl_ratio = performance.get('avg_pnl_ratio', 0)
        sharpe_ratio = performance.get('sharpe_ratio', 0)
        
        # åŠ æ¬Šç¶œåˆè©•åˆ†
        score = (
            win_rate * 50 +           # å‹ç‡æ¬Šé‡ 50%
            min(pnl_ratio / 1.5, 1) * 30 +  # ç›ˆè™§æ¯”æ¬Šé‡ 30%
            min(sharpe_ratio, 1) * 20        # å¤æ™®æ¯”ç‡æ¬Šé‡ 20%
        )
        
        # å¦‚æœé”åˆ°æ‰€æœ‰ç›®æ¨™ï¼Œçµ¦äºˆé¡å¤–çå‹µ
        if win_rate >= 0.70 and pnl_ratio >= 1.5 and sharpe_ratio >= 1.0:
            score += 10
        
        return score
    
    def _meets_targets(self, performance: Dict[str, float]) -> bool:
        """æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™"""
        return (
            performance.get('win_rate', 0) >= self.optimization_target.win_rate and
            performance.get('avg_pnl_ratio', 0) >= self.optimization_target.profit_loss_ratio and
            performance.get('sharpe_ratio', 0) >= self.optimization_target.sharpe_ratio
        )
    
    async def _get_current_performance(self) -> Dict[str, float]:
        """ç²å–ç•¶å‰åƒæ•¸çš„æ€§èƒ½è¡¨ç¾"""
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent.parent / "auto_backtest_validator"))
        from auto_backtest_validator import AutoBacktestValidator  # type: ignore
        
        try:
            validator = AutoBacktestValidator()
            self.logger.info("ğŸ”„ é–‹å§‹åŸ·è¡Œ Phase1A é©—è­‰å¾ªç’°...")
            result = await validator.run_phase1a_validation_cycle()
            
            self.logger.info(f"ğŸ“Š é©—è­‰å¾ªç’°åŸ·è¡Œå®Œæˆ")
            self.logger.info(f"ğŸ“Š çµæœé¡å‹: {type(result)}")
            
            if result is None:
                self.logger.error("âŒ é©—è­‰çµæœç‚º None")
                return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
            
            self.logger.info(f"ğŸ“Š çµæœå…§å®¹æ‘˜è¦: {str(result)[:200]}...")
            
            if 'error' in result:
                self.logger.error(f"âŒ é©—è­‰å¤±æ•—: {result['error']}")
                return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
            
            # æå–æ€§èƒ½æŒ‡æ¨™
            overall_perf = result.get('overall_performance', {})
            performance = {
                'win_rate': overall_perf.get('overall_win_rate', 0),
                'avg_pnl_ratio': overall_perf.get('avg_pnl_ratio', 0),
                'total_signals': overall_perf.get('total_signals', 0),
                'sharpe_ratio': self._calculate_sharpe_ratio(result)
            }
            
            self.logger.info(f"ğŸ“Š ç•¶å‰æ€§èƒ½: å‹ç‡ {performance['win_rate']:.2%}, ç›ˆè™§æ¯” {performance['avg_pnl_ratio']:.2f}")
            return performance
            
        except Exception as e:
            self.logger.error(f"âŒ æ€§èƒ½ç²å–å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return {'win_rate': 0, 'avg_pnl_ratio': 0, 'total_signals': 0, 'sharpe_ratio': 0}
    
    
    async def _update_phase1a_parameters(self, params: ParameterSet):
        """æ›´æ–° Phase1A åƒæ•¸"""
        # æ›´æ–° JSON é…ç½®æ–‡ä»¶
        from pathlib import Path
        config_path = Path(__file__).parent.parent.parent.parent / "backend" / "phase1_signal_generation" / "phase1a_basic_signal_generation" / "phase1a_basic_signal_generation.json"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æ›´æ–°åŸºç¤æ¨¡å¼åƒæ•¸
        config['phase1a_basic_signal_generation_dependency']['configuration']['signal_generation_params']['basic_mode']['confidence_threshold']['base_value'] = params.confidence_threshold
        config['phase1a_basic_signal_generation_dependency']['configuration']['signal_generation_params']['basic_mode']['price_change_threshold']['base_value'] = params.price_change_threshold
        config['phase1a_basic_signal_generation_dependency']['configuration']['signal_generation_params']['basic_mode']['volume_change_threshold']['base_value'] = params.volume_change_threshold
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"âœ… Phase1A åƒæ•¸å·²æ›´æ–°: {params.to_dict()}")
    
    async def _temporarily_update_phase1a_parameters(self, params: ParameterSet):
        """è‡¨æ™‚æ›´æ–° Phase1A åƒæ•¸é€²è¡Œæ¸¬è©¦"""
        await self._update_phase1a_parameters(params)
    
    def _calculate_sharpe_ratio(self, result: Dict) -> float:
        """è¨ˆç®—å¤æ™®æ¯”ç‡"""
        # å¾å›æ¸¬çµæœè¨ˆç®—å¤æ™®æ¯”ç‡
        performance_data = result.get('overall_performance', {})
        win_rate = performance_data.get('overall_win_rate', 0)
        avg_pnl = performance_data.get('avg_pnl_ratio', 0)
        
        # ç°¡åŒ–çš„å¤æ™®æ¯”ç‡è¨ˆç®—ï¼ˆå¯¦éš›æ‡‰è©²ä½¿ç”¨æ”¶ç›Šçš„æ¨™æº–å·®ï¼‰
        if win_rate > 0:
            return min(avg_pnl * win_rate * 0.5, 2.0)  # æœ€å¤§é™åˆ¶ç‚º 2.0
        return 0
    
    def _calculate_improvement(self, old_performance: Dict[str, float], new_performance: Dict[str, float]) -> Dict[str, float]:
        """è¨ˆç®—æ€§èƒ½æ”¹å–„å¹…åº¦"""
        improvement = {}
        for key in ['win_rate', 'avg_pnl_ratio', 'sharpe_ratio']:
            old_val = old_performance.get(key, 0)
            new_val = new_performance.get(key, 0)
            if old_val > 0:
                improvement[f'{key}_improvement'] = (new_val - old_val) / old_val
            else:
                improvement[f'{key}_improvement'] = float('inf') if new_val > 0 else 0
        return improvement
    
    def _should_update_parameters(self, new_performance: Dict[str, float], current_performance: Dict[str, float]) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²æ›´æ–°åƒæ•¸"""
        new_score = self._calculate_composite_score(new_performance)
        current_score = self._calculate_composite_score(current_performance)
        
        # éœ€è¦è‡³å°‘ 5% çš„æ”¹å–„æ‰æ›´æ–°
        improvement_threshold = 0.05
        return (new_score - current_score) / max(current_score, 1) > improvement_threshold
    
    def _generate_coarse_grid(self) -> List[ParameterSet]:
        """ç”Ÿæˆç²—ç³™ç¶²æ ¼æœå°‹åƒæ•¸"""
        param_sets = []
        
        # 5x5x5 = 125 ç¨®çµ„åˆ
        confidence_values = [0.65, 0.70, 0.75, 0.80, 0.85]
        price_change_values = [0.0005, 0.001, 0.0015, 0.002, 0.0025]
        volume_change_values = [1.0, 1.25, 1.5, 1.75, 2.0]
        
        for conf in confidence_values:
            for price in price_change_values:
                for volume in volume_change_values:
                    param_sets.append(ParameterSet(
                        confidence_threshold=conf,
                        price_change_threshold=price,
                        volume_change_threshold=volume
                    ))
        
        return param_sets
    
    def _generate_fine_grid(self, best_params: ParameterSet) -> List[ParameterSet]:
        """åœ¨æœ€ä½³åƒæ•¸å‘¨åœç”Ÿæˆç´°ç·»ç¶²æ ¼"""
        param_sets = []
        
        # åœ¨æœ€ä½³åƒæ•¸çš„ Â±10% ç¯„åœå…§ç”Ÿæˆ 3x3x3 = 27 ç¨®çµ„åˆ
        for conf_factor in [0.9, 1.0, 1.1]:
            for price_factor in [0.9, 1.0, 1.1]:
                for volume_factor in [0.9, 1.0, 1.1]:
                    new_conf = max(0.5, min(0.95, best_params.confidence_threshold * conf_factor))
                    new_price = max(0.0001, min(0.005, best_params.price_change_threshold * price_factor))
                    new_volume = max(0.5, min(3.0, best_params.volume_change_threshold * volume_factor))
                    
                    param_sets.append(ParameterSet(
                        confidence_threshold=new_conf,
                        price_change_threshold=new_price,
                        volume_change_threshold=new_volume
                    ))
        
        return param_sets
    
    def _validate_parameters(self, new_performance: Dict[str, float], current_performance: Dict[str, float]) -> bool:
        """é©—è­‰æ–°åƒæ•¸æ˜¯å¦æ¯”ç•¶å‰åƒæ•¸æ›´å¥½"""
        new_score = self._calculate_composite_score(new_performance)
        current_score = self._calculate_composite_score(current_performance)
        
        # éœ€è¦è‡³å°‘ 2% çš„æ”¹å–„æ‰æ¡ç”¨æ–°åƒæ•¸
        improvement_threshold = 0.02
        improvement = (new_score - current_score) / max(current_score, 1)
        
        self.logger.info(f"ğŸ“Š åƒæ•¸é©—è­‰: æ–°åˆ†æ•¸ {new_score:.2f}, ç•¶å‰åˆ†æ•¸ {current_score:.2f}, æ”¹å–„ {improvement:.2%}")
        return improvement > improvement_threshold

# å…¨å±€å„ªåŒ–å™¨å¯¦ä¾‹
weekly_optimizer = WeeklyParameterOptimizer()

async def run_weekly_optimization():
    """åŸ·è¡Œæ¯é€±å„ªåŒ–ï¼ˆå…¨å±€å‡½æ•¸ï¼‰"""
    # è¨­å®šè©³ç´°æ—¥èªŒ
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)
    logger.info("ğŸš€ é–‹å§‹æ¯é€±åƒæ•¸å„ªåŒ–...")
    
    result = await weekly_optimizer.run_weekly_optimization()
    logger.info(f"ğŸ“Š å„ªåŒ–çµæœ: {result}")
    return result

if __name__ == "__main__":
    # æ¸¬è©¦é‹è¡Œ
    result = asyncio.run(run_weekly_optimization())
    print(json.dumps(result, indent=2, ensure_ascii=False))
