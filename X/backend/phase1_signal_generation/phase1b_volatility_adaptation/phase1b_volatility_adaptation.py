"""
ğŸ¯ Trading X - Phase1B æ³¢å‹•é©æ‡‰å¼•æ“ï¼ˆçœŸå¯¦ç‰ˆï¼‰
éšæ®µ1Bï¼šæ³¢å‹•é©æ‡‰æ€§å„ªåŒ–å¢å¼·æ¨¡çµ„ - å®Œæ•´çœŸå¯¦å¯¦ç¾
"""

from typing import Dict, List, Optional, Tuple, Any, Deque
from dataclasses import dataclass
from datetime import datetime, timedelta
from collections import deque
import logging
import numpy as np
import pandas as pd
import sys
from pathlib import Path

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent.parent / "core"))

from binance_data_connector import binance_connector

logger = logging.getLogger(__name__)

@dataclass
class VolatilityMetrics:
    """æ³¢å‹•æ€§æŒ‡æ¨™"""
    current_volatility: float      # ç•¶å‰æ³¢å‹•ç‡ (0-1)
    volatility_trend: float        # æ³¢å‹•è¶¨å‹¢ (-1 to 1)
    volatility_percentile: float   # æ³¢å‹•ç‡ç™¾åˆ†ä½ (0-1)
    regime_stability: float        # åˆ¶åº¦ç©©å®šæ€§ (0-1)
    micro_volatility: float        # å¾®è§€æ³¢å‹• (0-1)
    intraday_volatility: float     # æ—¥å…§æ³¢å‹• (0-1)
    timestamp: datetime

@dataclass
class SignalContinuityMetrics:
    """ä¿¡è™Ÿé€£çºŒæ€§æŒ‡æ¨™"""
    signal_persistence: float      # ä¿¡è™ŸæŒçºŒæ€§ (0-1)
    signal_divergence: float       # ä¿¡è™Ÿåˆ†æ­§åº¦ (0-1)
    consensus_strength: float      # å…±è­˜å¼·åº¦ (0-1)
    temporal_consistency: float    # æ™‚é–“ä¸€è‡´æ€§ (0-1)
    cross_module_correlation: float # è·¨æ¨¡çµ„ç›¸é—œæ€§ (0-1)
    signal_decay_rate: float       # ä¿¡è™Ÿè¡°æ¸›ç‡ (0-1)

class VolatilityAdaptiveEngine:
    """æ³¢å‹•é©æ‡‰æ€§å¼•æ“ï¼ˆçœŸå¯¦ç‰ˆï¼‰"""
    
    def __init__(self, lookback_periods: int = 100):
        self.lookback_periods = lookback_periods
        self.volatility_history: Deque[float] = deque(maxlen=lookback_periods)
        self.signal_history: Deque[Dict] = deque(maxlen=lookback_periods)
        
    async def calculate_volatility_metrics(self, price_data: List[float] = None, symbol: str = "BTCUSDT") -> VolatilityMetrics:
        """è¨ˆç®—ç¶œåˆæ³¢å‹•æ€§æŒ‡æ¨™ - åŸºæ–¼çœŸå¯¦å¸‚å ´æ•¸æ“š"""
        try:
            # å¦‚æœæ²’æœ‰æä¾›åƒ¹æ ¼æ•¸æ“šï¼Œå¾å¹£å®‰APIç²å–
            if not price_data:
                async with binance_connector as connector:
                    price_data = await connector.calculate_price_series(symbol, 200)
            
            if len(price_data) < 20:
                logger.warning("åƒ¹æ ¼æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨æœ€å°å¯ç”¨æ•¸æ“šè¨ˆç®—")
                return self._get_minimal_volatility_metrics()
            
            prices = np.array(price_data)
            returns = np.diff(np.log(prices))
            
            # 1. ç•¶å‰æ³¢å‹•ç‡ (21æœŸæ»¾å‹•æ¨™æº–å·®)
            if len(returns) >= 21:
                current_volatility = np.std(returns[-21:])
            else:
                current_volatility = np.std(returns)
            
            # å¹´åŒ–ä¸¦æ¨™æº–åŒ–åˆ° 0-1 ç¯„åœ
            annualized_vol = current_volatility * np.sqrt(365 * 24 * 60)  # åˆ†é˜æ•¸æ“šå¹´åŒ–
            current_volatility = min(1.0, annualized_vol / 2.0)  # å‡è¨­200%å¹´åŒ–æ³¢å‹•ç‡ç‚ºä¸Šé™
            
            # 2. æ³¢å‹•è¶¨å‹¢ (çŸ­æœŸvsé•·æœŸæ³¢å‹•æ¯”è¼ƒ)
            if len(returns) >= 50:
                short_vol = np.std(returns[-10:])
                long_vol = np.std(returns[-50:])
                volatility_trend = (short_vol - long_vol) / (long_vol + 1e-8)
                volatility_trend = max(-1, min(1, volatility_trend))
            else:
                volatility_trend = 0.0
            
            # 3. æ³¢å‹•ç‡ç™¾åˆ†ä½
            self.volatility_history.append(current_volatility)
            if len(self.volatility_history) >= 20:
                sorted_vol = sorted(list(self.volatility_history))
                rank = sum(1 for v in sorted_vol if v <= current_volatility)
                volatility_percentile = rank / len(sorted_vol)
            else:
                volatility_percentile = 0.5
            
            # 4. åˆ¶åº¦ç©©å®šæ€§ (æ³¢å‹•çš„æ³¢å‹•)
            if len(self.volatility_history) >= 10:
                recent_vols = list(self.volatility_history)[-10:]
                vol_mean = np.mean(recent_vols)
                vol_std = np.std(recent_vols)
                regime_stability = 1.0 - (vol_std / (vol_mean + 1e-8))
                regime_stability = max(0, min(1, regime_stability))
            else:
                regime_stability = 0.7
            
            # 5. å¾®è§€æ³¢å‹• (é«˜é »åƒ¹æ ¼è®Šå‹•å¼·åº¦)
            if len(returns) >= 10:
                micro_moves = np.abs(returns[-10:])
                micro_volatility = np.mean(micro_moves) / (current_volatility + 1e-8)
                micro_volatility = max(0, min(1, micro_volatility))
            else:
                micro_volatility = 0.5
            
            # 6. æ—¥å…§æ³¢å‹• (åŸºæ–¼åƒ¹æ ¼ç¯„åœ)
            if len(prices) >= 60:  # è‡³å°‘1å°æ™‚æ•¸æ“š
                hourly_high = max(prices[-60:])
                hourly_low = min(prices[-60:])
                hourly_range = (hourly_high - hourly_low) / hourly_low
                intraday_volatility = min(1.0, hourly_range * 10)  # 10%ç‚ºä¸Šé™
            else:
                intraday_volatility = current_volatility
            
            result = VolatilityMetrics(
                current_volatility=current_volatility,
                volatility_trend=volatility_trend,
                volatility_percentile=volatility_percentile,
                regime_stability=regime_stability,
                micro_volatility=micro_volatility,
                intraday_volatility=intraday_volatility,
                timestamp=datetime.now()
            )
            
            logger.info(f"æ³¢å‹•æ€§æŒ‡æ¨™è¨ˆç®—å®Œæˆ: ç•¶å‰æ³¢å‹•ç‡={current_volatility:.4f}, è¶¨å‹¢={volatility_trend:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"æ³¢å‹•æ€§æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")
            return self._get_minimal_volatility_metrics()
    
    async def analyze_signal_continuity(self, signals: List[Dict[str, Any]], symbol: str = "BTCUSDT") -> SignalContinuityMetrics:
        """åˆ†æä¿¡è™Ÿé€£çºŒæ€§ - åŸºæ–¼çœŸå¯¦ä¿¡è™Ÿæ­·å²"""
        try:
            # è¨˜éŒ„ç•¶å‰ä¿¡è™Ÿåˆ°æ­·å²
            current_signals = {
                "timestamp": datetime.now(),
                "signals": signals,
                "signal_count": len(signals)
            }
            self.signal_history.append(current_signals)
            
            if len(self.signal_history) < 3:
                logger.info("ä¿¡è™Ÿæ­·å²ä¸è¶³ï¼Œä½¿ç”¨åŸºç¤è©•ä¼°")
                return self._get_basic_continuity_metrics(signals)
            
            # 1. ä¿¡è™ŸæŒçºŒæ€§ (ä¿¡è™Ÿåœ¨é€£çºŒæ™‚é–“æ®µå…§çš„å‡ºç¾ç‡)
            recent_periods = list(self.signal_history)[-10:]
            signal_appearances = sum(1 for period in recent_periods if period["signal_count"] > 0)
            signal_persistence = signal_appearances / len(recent_periods)
            
            # 2. ä¿¡è™Ÿåˆ†æ­§åº¦ (ä¸åŒä¿¡è™Ÿæºçš„ä¸€è‡´æ€§)
            if signals:
                signal_values = [s.get("value", 0) for s in signals if "value" in s]
                if len(signal_values) > 1:
                    signal_std = np.std(signal_values)
                    signal_mean = np.mean(signal_values)
                    signal_divergence = signal_std / (abs(signal_mean) + 1e-8)
                    signal_divergence = min(1.0, signal_divergence)
                else:
                    signal_divergence = 0.0
            else:
                signal_divergence = 1.0  # æ²’æœ‰ä¿¡è™Ÿæ™‚åˆ†æ­§åº¦æœ€é«˜
            
            # 3. å…±è­˜å¼·åº¦ (å¤šå€‹ä¿¡è™ŸæŒ‡å‘åŒä¸€æ–¹å‘çš„ç¨‹åº¦)
            if signals:
                positive_signals = sum(1 for s in signals if s.get("value", 0) > 0)
                negative_signals = sum(1 for s in signals if s.get("value", 0) < 0)
                total_signals = len(signals)
                
                if total_signals > 0:
                    max_consensus = max(positive_signals, negative_signals)
                    consensus_strength = max_consensus / total_signals
                else:
                    consensus_strength = 0.0
            else:
                consensus_strength = 0.0
            
            # 4. æ™‚é–“ä¸€è‡´æ€§ (ä¿¡è™Ÿå¼·åº¦åœ¨æ™‚é–“ä¸Šçš„ç©©å®šæ€§)
            if len(recent_periods) >= 5:
                signal_counts = [p["signal_count"] for p in recent_periods[-5:]]
                avg_count = np.mean(signal_counts)
                count_std = np.std(signal_counts)
                temporal_consistency = 1.0 - (count_std / (avg_count + 1e-8))
                temporal_consistency = max(0, min(1, temporal_consistency))
            else:
                temporal_consistency = 0.6
            
            # 5. è·¨æ¨¡çµ„ç›¸é—œæ€§ (ä¸åŒæ¨¡çµ„ä¿¡è™Ÿçš„ç›¸é—œæ€§)
            if len(signals) >= 2:
                module_values = {}
                for signal in signals:
                    module = signal.get("module", "unknown")
                    value = signal.get("value", 0)
                    if module not in module_values:
                        module_values[module] = []
                    module_values[module].append(value)
                
                # è¨ˆç®—æ¨¡çµ„é–“ç›¸é—œæ€§
                modules = list(module_values.keys())
                if len(modules) >= 2:
                    correlations = []
                    for i in range(len(modules)):
                        for j in range(i+1, len(modules)):
                            module1_values = module_values[modules[i]]
                            module2_values = module_values[modules[j]]
                            
                            # ç°¡åŒ–ç›¸é—œæ€§è¨ˆç®—
                            avg1 = np.mean(module1_values)
                            avg2 = np.mean(module2_values)
                            correlation = 1.0 - abs(avg1 - avg2) / 2.0  # ç°¡åŒ–çš„ç›¸é—œæ€§åº¦é‡
                            correlations.append(max(0, correlation))
                    
                    cross_module_correlation = np.mean(correlations) if correlations else 0.5
                else:
                    cross_module_correlation = 0.5
            else:
                cross_module_correlation = 0.5
            
            # 6. ä¿¡è™Ÿè¡°æ¸›ç‡ (ä¿¡è™Ÿå¼·åº¦éš¨æ™‚é–“çš„è¡°æ¸›)
            if len(recent_periods) >= 3:
                recent_counts = [p["signal_count"] for p in recent_periods[-3:]]
                if recent_counts[0] > 0:
                    decay_rate = (recent_counts[0] - recent_counts[-1]) / recent_counts[0]
                    decay_rate = max(0, min(1, decay_rate))
                else:
                    decay_rate = 0.5
            else:
                decay_rate = 0.3
            
            result = SignalContinuityMetrics(
                signal_persistence=signal_persistence,
                signal_divergence=signal_divergence,
                consensus_strength=consensus_strength,
                temporal_consistency=temporal_consistency,
                cross_module_correlation=cross_module_correlation,
                signal_decay_rate=decay_rate
            )
            
            logger.info(f"ä¿¡è™Ÿé€£çºŒæ€§åˆ†æå®Œæˆ: æŒçºŒæ€§={signal_persistence:.3f}, å…±è­˜={consensus_strength:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"ä¿¡è™Ÿé€£çºŒæ€§åˆ†æå¤±æ•—: {e}")
            return self._get_basic_continuity_metrics(signals)
    
    def _get_minimal_volatility_metrics(self) -> VolatilityMetrics:
        """ç²å–æœ€å°æ³¢å‹•æ€§æŒ‡æ¨™ï¼ˆæ•¸æ“šä¸è¶³æ™‚ä½¿ç”¨ï¼‰"""
        return VolatilityMetrics(
            current_volatility=0.02,  # 2% åŸºç¤æ³¢å‹•ç‡
            volatility_trend=0.0,
            volatility_percentile=0.5,
            regime_stability=0.7,
            micro_volatility=0.5,
            intraday_volatility=0.5,
            timestamp=datetime.now()
        )
    
    def _get_basic_continuity_metrics(self, signals: List[Dict[str, Any]]) -> SignalContinuityMetrics:
        """ç²å–åŸºç¤é€£çºŒæ€§æŒ‡æ¨™ï¼ˆæ­·å²ä¸è¶³æ™‚ä½¿ç”¨ï¼‰"""
        signal_count = len(signals)
        
        # åŸºæ–¼ç•¶å‰ä¿¡è™Ÿæ•¸é‡çš„ç°¡å–®è©•ä¼°
        signal_persistence = min(1.0, signal_count / 5.0)  # 5å€‹ä¿¡è™Ÿç‚ºæ»¿åˆ†
        consensus_strength = min(1.0, signal_count / 3.0)  # 3å€‹ä¿¡è™Ÿç‚ºåŸºç¤å…±è­˜
        
        return SignalContinuityMetrics(
            signal_persistence=signal_persistence,
            signal_divergence=0.3,
            consensus_strength=consensus_strength,
            temporal_consistency=0.6,
            cross_module_correlation=0.7,
            signal_decay_rate=0.3
        )
