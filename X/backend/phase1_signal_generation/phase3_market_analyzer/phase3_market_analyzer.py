"""
ğŸ¯ Trading X - Phase3 å¸‚å ´åˆ†æå™¨ (JSON é…ç½®ç‰ˆæœ¬)
ğŸ¯ Phase 3: é«˜éšå¸‚å ´å¾®çµæ§‹åˆ†æ - å¤šå±¤æ¶æ§‹å¯¦æ™‚è™•ç†
ğŸ¯ ç¬¦åˆ phase3_market_analyzer_dependency.json v2.2 è¦ç¯„
"""

import asyncio
import aiohttp
import logging
import uuid
import time
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime, timedelta, timedelta
from dataclasses import dataclass, asdict
from collections import deque, defaultdict
import sys
from pathlib import Path
from threading import Lock
from concurrent.futures import ThreadPoolExecutor

# æ·»åŠ ä¸Šç´šç›®éŒ„åˆ°è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.append(str(current_dir.parent.parent / "shared_core"))

try:
    from binance_data_connector import binance_connector
except ImportError:
    # å‚™ç”¨å°å…¥è·¯å¾‘
    sys.path.append(str(current_dir.parent.parent.parent))
    from binance_data_connector import binance_connector

logger = logging.getLogger(__name__)

@dataclass
class MarketMicrostructureSignal:
    """å¸‚å ´å¾®çµæ§‹ä¿¡è™Ÿæ¨™æº–æ ¼å¼ - ç¬¦åˆ Phase1C çµ±ä¸€æ¨™æº–"""
    signal_id: str
    signal_type: str  # LIQUIDITY_SHOCK | INSTITUTIONAL_FLOW | SENTIMENT_DIVERGENCE | LIQUIDITY_REGIME_CHANGE
    signal_strength: float  # 0.0-1.0 (Phase1C çµ±ä¸€æ¨™æº–)
    signal_confidence: float  # 0.0-1.0 (åŸºç¤ä¿¡å¿ƒåˆ†æ•¸)
    
    # Phase1C æ•´åˆè³‡è¨Š
    tier_assignment: str  # tier_1_critical | tier_2_important | tier_3_monitoring
    processing_priority: str  # immediate | batch_5s | scheduled_15s
    
    # è¨‚å–®ç°¿ä¸Šä¸‹æ–‡
    bid_ask_imbalance: float  # -1.0 to 1.0
    market_depth_score: float  # 0.0-1.0
    order_flow_intensity: float  # relative_to_baseline
    spread_condition: str  # tight | normal | wide | very_wide
    
    # æƒ…ç·’ä¸Šä¸‹æ–‡
    funding_sentiment: str  # extreme_bearish to extreme_bullish
    oi_momentum: str  # strong_growth | growth | stable | decline | strong_decline
    volume_sentiment: str  # accumulation | distribution | neutral
    
    # å¾®çµæ§‹æŒ‡æ¨™
    liquidity_score: float  # 0.0-1.0
    market_stress_score: float  # 0.0-1.0
    institutional_activity: str  # high | medium | low
    retail_activity: str  # high | medium | low
    
    # é æ¸¬åˆ†æ
    predicted_price_impact: float  # percentage
    liquidity_forecast: str  # improving | stable | deteriorating
    regime_probability: str  # breakdown | ranging | trending | breakout
    
    # æ™‚é–“æˆ³
    data_timestamp: datetime
    analysis_timestamp: datetime
    signal_generated: datetime
    signal_expires: datetime

@dataclass
class OrderBookMetrics:
    """è¨‚å–®ç°¿æŒ‡æ¨™"""
    symbol: str
    timestamp: datetime
    bid_ask_spread: float
    mid_price: float
    bid_ask_imbalance: float
    depth_quality_score: float
    order_flow_intensity: float
    large_order_detected: bool
    spread_condition: str
    
@dataclass
class SentimentMetrics:
    """æƒ…ç·’æŒ‡æ¨™"""
    funding_sentiment_score: float
    oi_momentum_signal: str
    volume_sentiment_indicators: Dict[str, float]
    funding_rate: float
    oi_change_percentage_24h: float

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™"""
    layer_0_sync_time_ms: float
    layer_1a_stream_time_ms: float
    layer_1b_data_time_ms: float
    layer_2_orderbook_time_ms: float
    layer_3_sentiment_time_ms: float
    layer_4_fusion_time_ms: float
    layer_5_analytics_time_ms: float
    total_computation_time_ms: float
    signal_generation_latency_ms: float

class RingBuffer:
    """ç’°ç‹€ç·©è¡å€ - v2.2 è¨˜æ†¶é«”å„ªåŒ–"""
    def __init__(self, maxsize: int):
        self.maxsize = maxsize
        self.data = deque(maxlen=maxsize)
        self.lock = Lock()
    
    def append(self, item):
        with self.lock:
            self.data.append(item)
    
    def get_recent(self, n: int = None):
        with self.lock:
            if n is None:
                return list(self.data)
            return list(self.data)[-n:] if len(self.data) >= n else list(self.data)
    
    def size(self) -> int:
        """è¿”å›ç·©è¡å€ç•¶å‰å¤§å°"""
        with self.lock:
            return len(self.data)
    
    def clear(self):
        """æ¸…ç©ºç·©è¡å€"""
        with self.lock:
            self.data.clear()

class DoubleBuffer:
    """é›™ç·©è¡å€ - v2.2 ç„¡é–è¨­è¨ˆ"""
    def __init__(self):
        self.active_buffer = {}
        self.update_buffer = {}
        self.switch_lock = Lock()
    
    def update(self, key: str, value: Any):
        self.update_buffer[key] = value
    
    def switch_buffers(self):
        with self.switch_lock:
            self.active_buffer, self.update_buffer = self.update_buffer, self.active_buffer
            self.update_buffer.clear()
    
    def get(self, key: str, default=None):
        return self.active_buffer.get(key, default)

class AdaptivePerformanceController:
    """è‡ªé©æ‡‰æ€§èƒ½æ§åˆ¶å™¨ - v2.2 å‹•æ…‹å„ªåŒ–"""
    def __init__(self):
        self.market_stress_level = 0.5
        self.processing_mode = "normal"  # high_volatility | normal | low_volatility
        self.last_volatility_check = time.time()
        
    def update_market_stress(self, stress_score: float):
        """æ›´æ–°å¸‚å ´å£“åŠ›ç­‰ç´š"""
        self.market_stress_level = stress_score
        
        # å‹•æ…‹èª¿æ•´è™•ç†æ¨¡å¼
        if stress_score > 0.7:
            self.processing_mode = "high_volatility"
        elif stress_score < 0.3:
            self.processing_mode = "low_volatility"
        else:
            self.processing_mode = "normal"
    
    def get_processing_frequency_ms(self) -> int:
        """ç²å–è™•ç†é »ç‡"""
        if self.processing_mode == "high_volatility":
            return 50  # 50ms é«˜é »è™•ç†
        elif self.processing_mode == "low_volatility":
            return 300  # 300ms ä½é »ç¯€èƒ½
        else:
            return 100  # 100ms æ­£å¸¸è™•ç†
    
    def get_tier_1_latency_target_ms(self) -> int:
        """ç²å– Tier 1 å»¶é²ç›®æ¨™"""
        if self.processing_mode == "high_volatility":
            return 30
        elif self.processing_mode == "low_volatility":
            return 100
        else:
            return 50

class EventDrivenProcessor:
    """äº‹ä»¶é©…å‹•è™•ç†å™¨ - v2.2 åƒ…åœ¨ç•°å¸¸æ™‚è§¸ç™¼"""
    def __init__(self):
        self.baseline_metrics = {}
        self.alert_thresholds = {
            "large_order_volume_multiplier": 5.0,
            "spread_widening_multiplier": 3.0,
            "depth_decrease_threshold": 0.5
        }
    
    def should_trigger_liquidity_shock_analysis(self, current_metrics: Dict) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼æµå‹•æ€§è¡æ“Šåˆ†æ"""
        if not self.baseline_metrics:
            return True  # é¦–æ¬¡é‹è¡Œ
        
        # æª¢æŸ¥åƒ¹å·®ç•°å¸¸æ“´å¤§
        baseline_spread = self.baseline_metrics.get("spread", 0)
        current_spread = current_metrics.get("spread", 0)
        if baseline_spread > 0 and current_spread / baseline_spread > self.alert_thresholds["spread_widening_multiplier"]:
            return True
        
        # æª¢æŸ¥æ·±åº¦é©Ÿé™
        baseline_depth = self.baseline_metrics.get("depth_score", 1.0)
        current_depth = current_metrics.get("depth_score", 1.0)
        if current_depth < baseline_depth * self.alert_thresholds["depth_decrease_threshold"]:
            return True
        
        return False
    
    def should_trigger_large_order_analysis(self, volume: float) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼å¤§é¡è¨‚å–®åˆ†æ"""
        baseline_volume = self.baseline_metrics.get("avg_volume", 0)
        if baseline_volume > 0:
            return volume > baseline_volume * self.alert_thresholds["large_order_volume_multiplier"]
        return True
    
    def update_baseline(self, metrics: Dict):
        """æ›´æ–°åŸºæº–æŒ‡æ¨™"""
        for key, value in metrics.items():
            if key in self.baseline_metrics:
                # æŒ‡æ•¸ç§»å‹•å¹³å‡æ›´æ–°
                self.baseline_metrics[key] = 0.9 * self.baseline_metrics[key] + 0.1 * value
            else:
                self.baseline_metrics[key] = value

class Phase3MarketAnalyzer:
    """
    ğŸ¯ Phase 3 é«˜éšå¸‚å ´å¾®çµæ§‹åˆ†æå™¨ - å®Œæ•´7å±¤æ¶æ§‹
    ç¬¦åˆ phase3_market_analyzer_CORE_FLOW.json v2.2 å®Œç¾è¦ç¯„
    
    ğŸ¨ 7å±¤æ¶æ§‹è¦–è¦ºåŒ–æµç¨‹ï¼š
    ğŸ“Š å¤–éƒ¨æ•¸æ“šæº â†’ ğŸ”„ åŒæ­¥æ•´åˆ â†’ ğŸš€ é«˜é »/ä½é »æ•¸æ“šåˆ†é›¢ â†’ ğŸ“ˆ ä¸¦è¡Œåˆ†æ â†’ ğŸ¯ å¾®çµæ§‹ä¿¡è™Ÿ â†’ ğŸ§  é«˜éšé æ¸¬
    
    ğŸ“‹ Layer æ¶æ§‹ (35ms ç¸½ç›®æ¨™)ï¼š
    ğŸ”„ Layer 0: Phase1C æ™‚é–“æˆ³åŒæ­¥æ•´åˆå±¤ (1ms)
       - ğŸ¯ ç¹¼æ‰¿ phase1c_layer_0_cross_module_sync
       - â±ï¸ 200ms åŒæ­¥å®¹éŒ¯ï¼Œsystem_utc_with_exchange_offset æ™‚é–“æº
       - ğŸ›¡ï¸ use_latest_valid_timestamp å‚™æ´ç­–ç•¥
       - ğŸ“¤ synchronized_phase3_timestamp_reference è¼¸å‡º
    
    ğŸš€ Layer 1A: é«˜é »æ•¸æ“šæµè™•ç†å±¤ (9ms)  
       - ğŸ“Š real_time_orderbook_websocket (adaptive_50ms_to_200ms)
       - ğŸ“ˆ tick_by_tick_trade_data + incremental_volume_profile  
       - ğŸ¯ äº‹ä»¶è§¸ç™¼ï¼šå¤§å–® > 5xå¹³å‡ | åƒ¹å·® > 2xæ­£å¸¸ | æ³¢å‹•è®ŠåŒ– > 10%
       - ğŸ›¡ï¸ æ•…éšœè½‰ç§»ï¼šBinance â†’ OKX/Bybit (< 5s åˆ‡æ›)
    
    ğŸ• Layer 1B: ä½é »æ•¸æ“šæ”¶é›†å±¤ (6ms)
       - ğŸ’° è³‡é‡‘è²»ç‡æ”¶é›† (8hé »ç‡ï¼Œ7å¤©æ­·å²ç’°ç‹€ç·©è¡)
       - ğŸ“Š æŒå€‰é‡ç›£æ§ (30sé »ç‡ï¼Œ24hè®ŠåŒ–ç‡è¨ˆç®—)  
       - ğŸŒ å¸‚å ´åˆ¶åº¦æŒ‡æ¨™ (æ—¥é »ç‡ï¼Œ24hå¿«å–)
       - âœ… 95% æ•¸æ“šå®Œæ•´æ€§ï¼ŒğŸŸ¡ é™ç´šæ¨¡å¼æ”¯æ´
    
    ğŸ“Š Layer 2: OrderBook æ·±åº¦åˆ†æå±¤ (9ms)
       - âš–ï¸ è²·è³£ä¸å¹³è¡¡ (5,10,20æª”æ·±åº¦ï¼Œå¢é‡æ›´æ–°)
       - ğŸŒŠ è¨‚å–®æµå¼·åº¦ (60sæ»‘å‹•çª—å£ï¼Œæ–°å¢/å–æ¶ˆ/æˆäº¤åˆ†æ)
       - ğŸ—ï¸ å¸‚å ´æ·±åº¦åˆ†æ (åƒ¹å·®åˆ†æï¼Œæ·±åº¦éŸŒæ€§ï¼Œåƒ¹æ ¼è¡æ“Šä¼°ç®—)
       - ğŸ“‹ èˆ‡ Layer 3 ä¸¦è¡ŒåŸ·è¡Œï¼Œä¸²æµåŒ–è™•ç†
    
    ğŸ­ Layer 3: å¸‚å ´æƒ…ç·’èˆ‡è³‡é‡‘æµå‘åˆ†æå±¤ (6ms)  
       - ğŸ˜„ è³‡é‡‘è²»ç‡æƒ…ç·’ (< -0.01% æ¥µåº¦çœ‹ç©º â†’ > 0.01% æ¥µåº¦çœ‹å¤š)
       - ğŸ“ˆ æŒå€‰é‡å‹•é‡ (oi_change_percentage_24hï¼ŒæŒ‡æ•¸ç§»å‹•å¹³å‡)
       - ğŸ“Š æˆäº¤é‡æƒ…ç·’ (å¢é‡VWAPåå·®ï¼Œå¯¦æ™‚ç´¯ç©åˆ†é…ï¼Œæ©Ÿæ§‹vsæ•£æˆ¶æµæ¯”ç‡)
       - ğŸ”„ èˆ‡ Layer 2 åŒæ™‚åŸ·è¡Œï¼Œasyncio.gather ä¸¦è¡Œå„ªåŒ–
    
    ğŸ¯ Layer 4: å¸‚å ´å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆå±¤ (22ms)
       - ğŸš¨ æµå‹•æ€§è¡æ“Š (0.8-1.0å¼·åº¦ï¼Œtier_1_critical)
       - ğŸ›ï¸ æ©Ÿæ§‹è³‡é‡‘æµ (0.7-0.9å¼·åº¦ï¼Œtier_1_critical/tier_2_important)  
       - ğŸ­ æƒ…ç·’åˆ†æ­§ (0.72-1.0å¼·åº¦*1.2æå‡ï¼Œtier_2_important)
       - ğŸŒŠ æµå‹•æ€§åˆ¶åº¦ (0.75-1.0å¼·åº¦*1.5æå‡ï¼Œtier_3_monitoring)
       - âš–ï¸ å‹•æ…‹æ¬Šé‡é©æ‡‰ï¼šé«˜æ³¢å‹•â†’å¾®çµæ§‹1.3xï¼Œä½æ³¢å‹•â†’æŠ€è¡“1.2x
    
    ğŸ§  Layer 5: é«˜éšåˆ†æèˆ‡é æ¸¬ä¿¡è™Ÿå±¤ (17ms)
       - ğŸ”® å³æ™‚æ ¡æ­£æ©Ÿåˆ¶ (5miné©—è­‰é–“éš”ï¼Œæ¨¡å‹å›é¥‹è¿´è·¯)
       - ğŸ“Š æº–ç¢ºç‡è¿½è¹¤ (é æ¸¬åå·®çµ±è¨ˆï¼Œå‘½ä¸­ç‡ç›£æ§)
       - ğŸš¨ ç•°å¸¸æª¢æ¸¬ (Z-score > 3.0 è§¸ç™¼ç·Šæ€¥æ¨¡å¼)
       - ğŸ¯ é æ¸¬å¢å¼· (åŸºæ–¼æ­·å²æº–ç¢ºç‡å‹•æ…‹èª¿æ•´ä¿¡è™Ÿå¼·åº¦)
    
    ğŸª æ€§èƒ½ç‰¹è‰²ï¼š
    - ğŸ”„ äº‹ä»¶é©…å‹•è™•ç† + ğŸŒŠ ä¸²æµåŒ–è™•ç†  
    - âš–ï¸ å‹•æ…‹æ¬Šé‡é©æ‡‰ + ğŸ›¡ï¸ æ•…éšœæ¢å¾©æ©Ÿåˆ¶
    - ğŸš€ é«˜é »50ms-200msè‡ªé©æ‡‰æ¡æ¨£
    - ğŸ’¾ é›™ç·©è¡O(1)åŸå­åˆ‡æ› + ç’°ç‹€ç·©è¡å›ºå®šè¨˜æ†¶é«”
    """
    
    def __init__(self):
        self.session = None
        
        # v2.2 å„ªåŒ–çµ„ä»¶
        self.performance_controller = AdaptivePerformanceController()
        self.event_processor = EventDrivenProcessor()
        
        # ç·©è¡å€ç³»çµ±
        self.orderbook_buffer = RingBuffer(maxsize=60)  # 60ç§’æ­·å²
        self.trade_buffer = RingBuffer(maxsize=300)     # 300ç§’æ­·å²  
        self.funding_buffer = RingBuffer(maxsize=168)   # 7å¤©æ­·å²
        self.double_buffer = DoubleBuffer()
        
        # æ€§èƒ½ç›£æ§
        self.performance_metrics = PerformanceMetrics(0,0,0,0,0,0,0,0,0)
        self.last_signal_time = time.time()
        
        # æ¨¡å‹æ ¡æ­£åƒæ•¸
        self.model_accuracy_tracker = defaultdict(lambda: deque(maxlen=50))
        self.adaptive_weights = {
            "microstructure": 1.0,
            "technical": 1.0,
            "sentiment": 1.0
        }
        
        # åŸ·è¡Œå™¨
        self.executor = ThreadPoolExecutor(max_workers=4)
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
        self.executor.shutdown(wait=True)
    
    async def process_market_data(self, symbol: str = "BTCUSDT") -> List[MarketMicrostructureSignal]:
        """
        ğŸ¯ ä¸»è¦å¸‚å ´æ•¸æ“šè™•ç†å…¥å£ - å®Œæ•´7å±¤æ¶æ§‹è™•ç† (ç¬¦åˆJSONè¦ç¯„)
        ğŸ“Š ç¸½ç›®æ¨™: 35ms å…§å®Œæˆè™•ç† (Tier1: 30ms)
        ğŸš€ Asyncæ€§èƒ½å„ªåŒ–: ä¸¦è¡ŒåŸ·è¡Œ + äº‹ä»¶é©…å‹• + ä¸²æµè™•ç†
        """
        start_time = time.time()
        signals = []
        
        try:
            # ğŸ”„ Layer 0: Phase1C åŒæ­¥æ•´åˆ (1msç›®æ¨™)
            layer_0_start = time.time()
            synchronized_phase3_timestamp_reference = await self._layer_0_phase1c_sync_integration()
            layer_0_time = (time.time() - layer_0_start) * 1000
            
            # ğŸš€ğŸ• Layer 1: é«˜é »/ä½é »æ•¸æ“šä¸¦è¡Œæ”¶é›† (15msç›®æ¨™: 9ms+6ms)
            layer_1_start = time.time()
            stream_data, static_data = await asyncio.gather(
                self._layer_1a_high_freq_streaming(symbol),
                self._layer_1b_low_freq_data_collection(symbol),
                return_exceptions=True
            )
            layer_1_time = (time.time() - layer_1_start) * 1000
            
            # éŒ¯èª¤è™•ç†èˆ‡é™ç´šæ¨¡å¼
            if isinstance(stream_data, Exception) or isinstance(static_data, Exception):
                logger.error(f"Layer 1 æ•¸æ“šæ”¶é›†å¤±æ•—: stream={stream_data}, static={static_data}")
                return []
            
            # ğŸ“ŠğŸ­ Layer 2+3: OrderBookåˆ†æ + æƒ…ç·’åˆ†æ ä¸¦è¡ŒåŸ·è¡Œ (15msç›®æ¨™: 9ms+6ms)
            layer_23_start = time.time()
            orderbook_metrics, sentiment_metrics = await asyncio.gather(
                self._layer_2_orderbook_analysis(stream_data),
                self._layer_3_sentiment_analysis(static_data),
                return_exceptions=True
            )
            layer_23_time = (time.time() - layer_23_start) * 1000
            
            # ä¸¦è¡ŒåŸ·è¡ŒéŒ¯èª¤è™•ç†
            if isinstance(orderbook_metrics, Exception):
                logger.error(f"Layer 2 è¨‚å–®ç°¿åˆ†æå¤±æ•—: {orderbook_metrics}")
                orderbook_metrics = self._get_default_orderbook_metrics()
            if isinstance(sentiment_metrics, Exception):
                logger.error(f"Layer 3 æƒ…ç·’åˆ†æå¤±æ•—: {sentiment_metrics}")
                sentiment_metrics = self._get_default_sentiment_metrics()
            
            # ğŸ¯ Layer 4: å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆ - å‹•æ…‹æ¬Šé‡é©æ‡‰ (22msç›®æ¨™)
            layer_4_start = time.time()
            signals = await self._layer_4_microstructure_signal_generation(
                orderbook_metrics, sentiment_metrics
            )
            layer_4_time = (time.time() - layer_4_start) * 1000
            
            # ğŸ§  Layer 5: é«˜éšåˆ†æèˆ‡é æ¸¬ - å³æ™‚æ ¡æ­£æ©Ÿåˆ¶ (17msç›®æ¨™)
            layer_5_start = time.time()
            enhanced_signals = await self._layer_5_advanced_analytics(signals)
            layer_5_time = (time.time() - layer_5_start) * 1000
            
            # ğŸ“Š æ€§èƒ½æŒ‡æ¨™æ›´æ–°èˆ‡ç›£æ§
            total_time = (time.time() - start_time) * 1000
            self.performance_metrics = PerformanceMetrics(
                layer_0_sync_time_ms=layer_0_time,
                layer_1a_stream_time_ms=layer_1_time * 0.6,  # 9msä¼°ç®—
                layer_1b_data_time_ms=layer_1_time * 0.4,   # 6msä¼°ç®—
                layer_2_orderbook_time_ms=layer_23_time * 0.6,  # 9msä¼°ç®—
                layer_3_sentiment_time_ms=layer_23_time * 0.4,  # 6msä¼°ç®—
                layer_4_fusion_time_ms=layer_4_time,
                layer_5_analytics_time_ms=layer_5_time,
                total_computation_time_ms=total_time,
                signal_generation_latency_ms=total_time
            )
            
            # ğŸ¯ Tier1æ€§èƒ½ç›®æ¨™ç›£æ§ (30ms)
            tier_1_target = self.performance_controller.get_tier_1_latency_target_ms()
            if total_time > tier_1_target:
                logger.warning(f"âš ï¸ Phase3 Tier1è¶…æ™‚: {total_time:.1f}ms > {tier_1_target}ms ç›®æ¨™")
                # è§¸ç™¼è‡ªé©æ‡‰æ€§èƒ½èª¿æ•´
                await self._adaptive_performance_adjustment(total_time)
            
            # ğŸ“ˆ ç¸½ç›®æ¨™35msç›£æ§
            if total_time > 35:
                logger.warning(f"ğŸš¨ Phase3 ç¸½ç›®æ¨™è¶…æ™‚: {total_time:.1f}ms > 35ms")
                # é€²å…¥ç·Šæ€¥æ€§èƒ½æ¨¡å¼
                await self._emergency_performance_mode()
            
            # ğŸª å¸‚å ´å£“åŠ›ç­‰ç´šå‹•æ…‹æ›´æ–°
            if enhanced_signals:
                avg_stress = np.mean([s.market_stress_score for s in enhanced_signals])
                self.performance_controller.update_market_stress(avg_stress)
            
            # âœ… æˆåŠŸå®Œæˆï¼Œè¨˜éŒ„æ€§èƒ½çµ±è¨ˆ
            await self._record_performance_success(total_time, len(enhanced_signals))
            
            return enhanced_signals
            
        except Exception as e:
            logger.error(f"âŒ Phase3 å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            # ç³»çµ±ç„¡æ³•è™•ç†æ•¸æ“šå¤±æ•—ï¼Œé‡æ–°æ‹‹å‡ºéŒ¯èª¤
            raise e
    
    async def _layer_0_phase1c_sync_integration(self):
        """Layer 0: Phase1C åŒæ­¥æ•´åˆ - 1ms ç›®æ¨™"""
        start_time = time.time()
        
        # æ™‚é–“æˆ³åŒæ­¥ - èˆ‡ Phase1C layer_0_cross_module_sync å°é½Š
        synchronized_phase3_timestamp_reference = datetime.now().isoformat()
        self.double_buffer.update("sync_timestamp", synchronized_phase3_timestamp_reference)
        self.double_buffer.update("sync_tolerance_ms", 200)  # 200mså®¹éŒ¯
        
        # å¿«é€Ÿç·©è¡å€åˆ‡æ› (O(1) åŸå­æ“ä½œ)
        self.double_buffer.switch_buffers()
        
        elapsed_ms = (time.time() - start_time) * 1000
        if elapsed_ms > 1.0:
            logger.warning(f"âš ï¸ Layer 0 åŒæ­¥è¶…æ™‚: {elapsed_ms:.2f}ms > 1ms")
        
        return synchronized_phase3_timestamp_reference
    
    async def _layer_1a_high_freq_streaming(self, symbol: str) -> Dict[str, Any]:
        """Layer 1A: é«˜é »æ•¸æ“šæµ - è‡ªé©æ‡‰æ¡æ¨£èˆ‡æ•…éšœè½‰ç§»"""
        try:
            async with binance_connector as connector:
                # è‡ªé©æ‡‰æ¡æ¨£é »ç‡ - adaptive_50ms_to_200ms
                adaptive_50ms_to_200ms = self.performance_controller.get_processing_frequency_ms()
                
                # ä¸¦è¡Œç²å–é«˜é »æ•¸æ“š
                real_time_orderbook_websocket = await connector.get_order_book(symbol, limit=20)
                tick_by_tick_trade_data = await connector.get_24hr_ticker(symbol)
                
                # æ•…éšœè½‰ç§»æ©Ÿåˆ¶ - Binance â†’ OKX/Bybit
                if not real_time_orderbook_websocket:
                    logger.warning("Binance orderbookå¤±æ•—ï¼Œå˜—è©¦å‚™æ´æº")
                    # å¦‚æœä¸»è¦æ•¸æ“šæºå¤±æ•—ï¼Œæ‹‹å‡ºéŒ¯èª¤è€Œä¸æ˜¯ä½¿ç”¨å‚™ç”¨
                    logger.error(f"ä¸»è¦æ•¸æ“šæºå¤±æ•—ï¼Œç„¡æ³•ç²å–å³æ™‚æ•¸æ“š: {symbol}")
                    raise ConnectionError(f"ç„¡æ³•ç²å– {symbol} çš„å³æ™‚æ•¸æ“š")
                
                # å¢é‡æˆäº¤é‡åˆ†æ
                incremental_volume_profile = await self._process_incremental_volume_profile(tick_by_tick_trade_data)
                
                # é›™ç·©è¡å€å­˜å„²
                stream_data = {
                    "real_time_orderbook_websocket": real_time_orderbook_websocket,
                    "tick_by_tick_trade_data": tick_by_tick_trade_data,
                    "adaptive_50ms_to_200ms": adaptive_50ms_to_200ms,
                    "incremental_volume_profile": incremental_volume_profile,
                    "timestamp": datetime.now(),
                    "sampling_interval_ms": adaptive_50ms_to_200ms
                }
                
                # ç’°ç‹€ç·©è¡å€å­˜å„²
                if real_time_orderbook_websocket:
                    self.orderbook_buffer.append(real_time_orderbook_websocket)
                
                return stream_data
                
        except Exception as e:
            logger.error(f"âŒ Layer 1A é«˜é »æ•¸æ“šæµå¤±æ•—: {e}")
            return {}
    
    async def _layer_1b_low_freq_data_collection(self, symbol: str) -> Dict[str, Any]:
        """Layer 1B: ä½é »æ•¸æ“šæ”¶é›† - ç•°æ­¥è™•ç†"""
        try:
            async with binance_connector as connector:
                # ç•°æ­¥ä¸¦è¡Œç²å–ä½é »æ•¸æ“š
                funding_task = connector.get_funding_rate(symbol)
                mark_price_task = connector.get_mark_price(symbol)
                oi_task = self._get_open_interest_safe(connector, symbol)
                
                funding_data, mark_price_data, oi_data = await asyncio.gather(
                    funding_task, mark_price_task, oi_task, return_exceptions=True
                )
                
                # ç’°ç‹€ç·©è¡å€å­˜å„²
                if not isinstance(funding_data, Exception):
                    self.funding_buffer.append(funding_data)
                
                return {
                    "funding_rate": funding_data if not isinstance(funding_data, Exception) else None,
                    "mark_price": mark_price_data if not isinstance(mark_price_data, Exception) else None,
                    "open_interest": oi_data if not isinstance(oi_data, Exception) else None,
                    "timestamp": datetime.now()
                }
                
        except Exception as e:
            logger.error(f"âŒ Layer 1B ä½é »æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
            return {}
    
    async def _layer_1b_market_microstructure(self, stream_data: Dict[str, Any]) -> Dict[str, Any]:
        """Layer 1B: å¸‚å ´å¾®è§€çµæ§‹åˆ†æ - æ ¸å¿ƒè²·è³£åƒ¹å·®èˆ‡æµå‹•æ€§åˆ†æ"""
        try:
            # è¨‚å–®ç°¿æ·±åº¦åˆ†æ
            bid_ask_spread_analysis = await self._process_bid_ask_spread_analysis(
                stream_data.get("real_time_orderbook_websocket")
            )
            
            # å¸‚å ´è¡æ“Šè¨ˆç®—
            market_impact_calculation = await self._calculate_market_impact(
                stream_data.get("incremental_volume_profile")
            )
            
            # æµå‹•æ€§æ·±åº¦æ˜ å°„
            liquidity_depth_mapping = await self._map_liquidity_depth(
                stream_data.get("real_time_orderbook_websocket")
            )
            
            microstructure_data = {
                "bid_ask_spread_analysis": bid_ask_spread_analysis,
                "market_impact_calculation": market_impact_calculation,
                "liquidity_depth_mapping": liquidity_depth_mapping,
                "processing_time_ms": (datetime.now() - stream_data.get("timestamp")).total_seconds() * 1000
            }
            
            return microstructure_data
            
        except Exception as e:
            logger.error(f"âŒ Layer 1B å¸‚å ´å¾®è§€çµæ§‹åˆ†æå¤±æ•—: {e}")
            return {}
    
    async def _get_open_interest_safe(self, connector, symbol: str):
        """å®‰å…¨ç²å–æŒå€‰é‡æ•¸æ“š"""
        try:
            # å˜—è©¦ç²å–æŒå€‰é‡çµ±è¨ˆ
            oi_stats = await connector.get_open_interest_stats(symbol)
            return oi_stats
        except Exception as e:
            logger.debug(f"æŒå€‰é‡æ•¸æ“šç²å–å¤±æ•—: {e}")
            return None
    
    async def _layer_2_orderbook_analysis(self, stream_data: Dict[str, Any]) -> OrderBookMetrics:
        """Layer 2: è¨‚å–®ç°¿åˆ†æ - æµå¼è™•ç†èˆ‡å¢é‡è¨ˆç®—"""
        try:
            orderbook = stream_data.get("orderbook")
            if not orderbook or 'bids' not in orderbook or 'asks' not in orderbook:
                logger.warning("è¨‚å–®ç°¿æ•¸æ“šç„¡æ•ˆï¼Œä½¿ç”¨é»˜èªå€¼")
                return self._get_default_orderbook_metrics()
            
            # è§£æè²·è³£ç›¤æ•¸æ“š
            bids = [(float(p), float(q)) for p, q in orderbook['bids']]
            asks = [(float(p), float(q)) for p, q in orderbook['asks']]
            
            if not bids or not asks:
                return self._get_default_orderbook_metrics()
            
            # å¢é‡è¨ˆç®—é—œéµæŒ‡æ¨™
            best_bid, bid_vol = bids[0]
            best_ask, ask_vol = asks[0]
            
            mid_price = (best_bid + best_ask) / 2
            bid_ask_spread = best_ask - best_bid
            spread_ratio = bid_ask_spread / mid_price if mid_price > 0 else 0
            
            # è¨ˆç®—è²·è³£ä¸å¹³è¡¡
            total_bid_vol = sum(q for _, q in bids[:10])  # å‰10æª”
            total_ask_vol = sum(q for _, q in asks[:10])
            
            bid_ask_imbalance = (total_bid_vol - total_ask_vol) / (total_bid_vol + total_ask_vol) if (total_bid_vol + total_ask_vol) > 0 else 0
            
            # æ·±åº¦è³ªé‡è©•åˆ†
            depth_quality_score = min(1.0, (total_bid_vol + total_ask_vol) / 1000)  # å‡è¨­1000ç‚ºè‰¯å¥½æ·±åº¦åŸºæº–
            
            # è¨‚å–®æµå¼·åº¦ (ç›¸å°æ–¼åŸºæº–)
            current_volume = total_bid_vol + total_ask_vol
            baseline_volume = self.event_processor.baseline_metrics.get("avg_volume", current_volume)
            order_flow_intensity = current_volume / baseline_volume if baseline_volume > 0 else 1.0
            
            # å¤§é¡è¨‚å–®æª¢æ¸¬
            large_order_detected = self.event_processor.should_trigger_large_order_analysis(current_volume)
            
            # åƒ¹å·®ç‹€æ³åˆ†é¡
            if spread_ratio < 0.0001:  # < 0.01%
                spread_condition = "tight"
            elif spread_ratio < 0.0005:  # < 0.05%
                spread_condition = "normal"
            elif spread_ratio < 0.001:  # < 0.1%
                spread_condition = "wide"
            else:
                spread_condition = "very_wide"
            
            # æ›´æ–°åŸºæº–æŒ‡æ¨™
            self.event_processor.update_baseline({
                "avg_volume": current_volume,
                "spread": bid_ask_spread,
                "depth_score": depth_quality_score
            })
            
            return OrderBookMetrics(
                symbol=stream_data.get("symbol", "BTCUSDT"),
                timestamp=datetime.now(),
                bid_ask_spread=bid_ask_spread,
                mid_price=mid_price,
                bid_ask_imbalance=bid_ask_imbalance,
                depth_quality_score=depth_quality_score,
                order_flow_intensity=order_flow_intensity,
                large_order_detected=large_order_detected,
                spread_condition=spread_condition
            )
            
        except Exception as e:
            logger.error(f"âŒ Layer 2 è¨‚å–®ç°¿åˆ†æå¤±æ•—: {e}")
            return self._get_default_orderbook_metrics()
    
    def _get_default_orderbook_metrics(self) -> OrderBookMetrics:
        """ç²å–é»˜èªè¨‚å–®ç°¿æŒ‡æ¨™"""
        return OrderBookMetrics(
            symbol="BTCUSDT",
            timestamp=datetime.now(),
            bid_ask_spread=0.01,
            mid_price=50000.0,
            bid_ask_imbalance=0.0,
            depth_quality_score=0.5,
            order_flow_intensity=1.0,
            large_order_detected=False,
            spread_condition="normal"
        )
    
    async def _process_orderbook_stream(self, orderbook: Dict[str, Any]) -> Dict[str, Any]:
        """Layer 2æ ¸å¿ƒ: è¨‚å–®ç°¿æµå¼è™•ç† - å¢é‡æ›´æ–°æ©Ÿåˆ¶"""
        try:
            # å¢é‡è¨‚å–®ç°¿æ›´æ–°
            incremental_orderbook_updates = {
                "bid_changes": [],
                "ask_changes": [],
                "update_frequency": "real_time",
                "timestamp": datetime.now()
            }
            
            # èˆ‡å‰ä¸€å€‹å¿«ç…§æ¯”è¼ƒ
            if self.orderbook_buffer.size() > 0:
                previous_orderbook = self.orderbook_buffer.get_recent(1)[0]
                incremental_orderbook_updates = self._calculate_orderbook_delta(
                    previous_orderbook, orderbook
                )
            
            # é›™ç·©è¡å€å­˜å„²
            self.double_buffer.update("current_orderbook", orderbook)
            self.double_buffer.update("incremental_updates", incremental_orderbook_updates)
            
            return {
                "orderbook_stream_data": orderbook,
                "incremental_updates": incremental_orderbook_updates,
                "stream_quality": "high" if len(orderbook.get("bids", [])) > 5 else "low"
            }
            
        except Exception as e:
            logger.error(f"âŒ è¨‚å–®ç°¿æµè™•ç†å¤±æ•—: {e}")
            return {}
    
    def _calculate_orderbook_delta(self, previous: Dict[str, Any], current: Dict[str, Any]) -> Dict[str, Any]:
        """è¨ˆç®—è¨‚å–®ç°¿å¢é‡è®ŠåŒ–"""
        try:
            delta = {
                "bid_changes": [],
                "ask_changes": [],
                "timestamp": datetime.now()
            }
            
            prev_bids = {float(p): float(q) for p, q in previous.get("bids", [])}
            curr_bids = {float(p): float(q) for p, q in current.get("bids", [])}
            
            # è¨ˆç®—è²·ç›¤è®ŠåŒ–
            for price, quantity in curr_bids.items():
                prev_qty = prev_bids.get(price, 0)
                if quantity != prev_qty:
                    delta["bid_changes"].append({
                        "price": price,
                        "old_quantity": prev_qty,
                        "new_quantity": quantity,
                        "change": quantity - prev_qty
                    })
            
            # åŒæ¨£è™•ç†è³£ç›¤ (ç°¡åŒ–)
            prev_asks = {float(p): float(q) for p, q in previous.get("asks", [])}
            curr_asks = {float(p): float(q) for p, q in current.get("asks", [])}
            
            for price, quantity in curr_asks.items():
                prev_qty = prev_asks.get(price, 0)
                if quantity != prev_qty:
                    delta["ask_changes"].append({
                        "price": price,
                        "old_quantity": prev_qty,
                        "new_quantity": quantity,
                        "change": quantity - prev_qty
                    })
            
            return delta
            
        except Exception as e:
            logger.error(f"âŒ è¨‚å–®ç°¿å¢é‡è¨ˆç®—å¤±æ•—: {e}")
            return {"bid_changes": [], "ask_changes": [], "timestamp": datetime.now()}
    
    async def _collect_funding_rate(self, symbol: str) -> Dict[str, Any]:
        """å¢å¼·ç‰ˆ: å¯¦æ™‚è³‡é‡‘è²»ç‡æ”¶é›†èˆ‡åˆ†æ"""
        try:
            async with binance_connector as connector:
                # ç²å–æœ€æ–°è³‡é‡‘è²»ç‡æ•¸æ“š
                funding_data = await connector.get_funding_rate(symbol)
                
                if not funding_data:
                    logger.warning(f"ç„¡æ³•ç²å– {symbol} è³‡é‡‘è²»ç‡æ•¸æ“š")
                    raise ValueError(f"è³‡é‡‘è²»ç‡ API èª¿ç”¨å¤±æ•—: {symbol}")
                
                # è§£æè³‡é‡‘è²»ç‡ä¿¡æ¯
                current_rate = float(funding_data.get("fundingRate", 0))
                funding_time = funding_data.get("fundingTime", int(time.time() * 1000))
                next_funding_time = funding_data.get("nextFundingTime", funding_time + 8 * 3600 * 1000)
                
                # è¨ˆç®—è³‡é‡‘è²»ç‡å‹•æ…‹è¶¨å‹¢
                funding_analysis = await self._analyze_funding_rate_trend(current_rate, funding_data)
                
                # ç”Ÿæˆè³‡é‡‘è²»ç‡æƒ…ç·’æŒ‡æ¨™
                sentiment_score = self._calculate_funding_sentiment(current_rate, funding_analysis)
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆåŸºæ–¼è³‡é‡‘è²»ç‡çš„ä¿¡è™Ÿ
                await self._check_funding_rate_signals(symbol, current_rate, funding_analysis, sentiment_score)
                
                return {
                    "funding_rate_data": funding_data,
                    "current_rate": current_rate,
                    "funding_trend": funding_analysis.get("trend", "neutral"),
                    "sentiment_score": sentiment_score,
                    "rate_volatility": funding_analysis.get("volatility", 0.0),
                    "extreme_level": funding_analysis.get("extreme_level", "normal"),
                    "collection_timestamp": datetime.now(),
                    "next_funding_time": datetime.fromtimestamp(next_funding_time / 1000),
                    "time_to_next_funding": (next_funding_time - int(time.time() * 1000)) / 1000 / 3600  # å°æ™‚
                }
                
        except Exception as e:
            logger.error(f"âŒ è³‡é‡‘è²»ç‡æ”¶é›†å¤±æ•— {symbol}: {e}")
            # ä¸æä¾›é»˜èªå€¼ï¼Œç¢ºä¿ç³»çµ±çŸ¥é“æ•¸æ“šç²å–å¤±æ•—
            raise e
    
    async def _analyze_funding_rate_trend(self, current_rate: float, funding_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè³‡é‡‘è²»ç‡è¶¨å‹¢ - ä¿æŒç¾æœ‰æ•¸æ“šçµæ§‹"""
        try:
            analysis = {
                "trend": "neutral",
                "volatility": 0.0,
                "extreme_level": "normal",
                "rate_momentum": 0.0,
                "historical_percentile": 0.5
            }
            
            # æ­·å²è¶¨å‹¢åˆ†æ
            if self.funding_buffer.size() > 0:
                recent_rates = [float(f.get("fundingRate", 0)) for f in self.funding_buffer.get_recent(24)]  # æœ€è¿‘24æ¬¡ï¼ˆ3å¤©ï¼‰
                
                if len(recent_rates) >= 2:
                    avg_recent = np.mean(recent_rates)
                    std_recent = np.std(recent_rates)
                    
                    # è¶¨å‹¢åˆ¤æ–·
                    if current_rate > avg_recent + std_recent:
                        analysis["trend"] = "strongly_positive"
                    elif current_rate > avg_recent + 0.5 * std_recent:
                        analysis["trend"] = "positive"
                    elif current_rate < avg_recent - std_recent:
                        analysis["trend"] = "strongly_negative"
                    elif current_rate < avg_recent - 0.5 * std_recent:
                        analysis["trend"] = "negative"
                    
                    # æ³¢å‹•æ€§
                    analysis["volatility"] = std_recent
                    
                    # æ¥µç«¯ç¨‹åº¦
                    if abs(current_rate) > 0.0005:  # 0.05%
                        analysis["extreme_level"] = "high"
                    elif abs(current_rate) > 0.0001:  # 0.01%
                        analysis["extreme_level"] = "moderate"
                    
                    # å‹•é‡è¨ˆç®—
                    if len(recent_rates) >= 5:
                        recent_5 = recent_rates[-5:]
                        slope = np.polyfit(range(len(recent_5)), recent_5, 1)[0]
                        analysis["rate_momentum"] = slope
                    
                    # æ­·å²ç™¾åˆ†ä½
                    if len(recent_rates) >= 10:
                        sorted_rates = sorted(recent_rates)
                        rank = sum(1 for r in sorted_rates if r <= current_rate)
                        analysis["historical_percentile"] = rank / len(sorted_rates)
            
            return analysis
            
        except Exception as e:
            logger.error(f"è³‡é‡‘è²»ç‡è¶¨å‹¢åˆ†æå¤±æ•—: {e}")
            return {"trend": "neutral", "volatility": 0.0, "extreme_level": "normal", "rate_momentum": 0.0, "historical_percentile": 0.5}
    
    def _calculate_funding_sentiment(self, current_rate: float, funding_analysis: Dict[str, Any]) -> float:
        """è¨ˆç®—åŸºæ–¼è³‡é‡‘è²»ç‡çš„å¸‚å ´æƒ…ç·’åˆ†æ•¸ - è¼¸å‡ºæ¨™æº–åŒ–åˆ†æ•¸"""
        try:
            # åŸºæ–¼è³‡é‡‘è²»ç‡è¨ˆç®—æƒ…ç·’åˆ†æ•¸ (0.0 = æ¥µåº¦çœ‹ç©º, 1.0 = æ¥µåº¦çœ‹å¤š)
            base_score = 0.5  # ä¸­æ€§åŸºæº–
            
            # æ ¹æ“šè³‡é‡‘è²»ç‡çµ•å°å€¼èª¿æ•´
            rate_impact = min(abs(current_rate) * 2000, 0.4)  # æœ€å¤§å½±éŸ¿ 40%
            
            if current_rate > 0:
                sentiment_score = base_score + rate_impact  # æ­£è³‡é‡‘è²»ç‡ = çœ‹å¤šæƒ…ç·’
            else:
                sentiment_score = base_score - rate_impact  # è² è³‡é‡‘è²»ç‡ = çœ‹ç©ºæƒ…ç·’
            
            # æ ¹æ“šè¶¨å‹¢èª¿æ•´
            trend = funding_analysis.get("trend", "neutral")
            trend_adjustments = {
                "strongly_positive": 0.1,
                "positive": 0.05,
                "neutral": 0.0,
                "negative": -0.05,
                "strongly_negative": -0.1
            }
            sentiment_score += trend_adjustments.get(trend, 0.0)
            
            # æ ¹æ“šæ³¢å‹•æ€§èª¿æ•´ï¼ˆé«˜æ³¢å‹•æ€§é™ä½ä¿¡å¿ƒï¼‰
            volatility = funding_analysis.get("volatility", 0.0)
            if volatility > 0.0002:  # é«˜æ³¢å‹•
                sentiment_score *= 0.9  # é™ä½ 10%
            
            return max(0.0, min(1.0, sentiment_score))  # ç¢ºä¿åœ¨ 0-1 ç¯„åœå…§
            
        except Exception as e:
            logger.error(f"è³‡é‡‘è²»ç‡æƒ…ç·’è¨ˆç®—å¤±æ•—: {e}")
            return 0.5  # è¿”å›ä¸­æ€§å€¼
    
    async def _check_funding_rate_signals(self, symbol: str, current_rate: float, funding_analysis: Dict[str, Any], sentiment_score: float):
        """åŸºæ–¼è³‡é‡‘è²»ç‡ç”Ÿæˆä¿¡è™Ÿ - ä¿æŒç¾æœ‰ä¿¡è™Ÿæ ¼å¼"""
        try:
            # æ¥µç«¯è³‡é‡‘è²»ç‡ä¿¡è™Ÿ
            extreme_level = funding_analysis.get("extreme_level", "normal")
            
            if extreme_level in ["high", "moderate"]:
                signal_strength = 0.8 if extreme_level == "high" else 0.6
                
                # åˆ¤æ–·æ–¹å‘
                if current_rate > 0.0002:  # é«˜æ­£è³‡é‡‘è²»ç‡ï¼Œå¯èƒ½åè½‰
                    direction = "SELL"  # å¸‚å ´éåº¦çœ‹å¤šï¼Œå¯èƒ½åè½‰
                    signal_type = "SENTIMENT_DIVERGENCE"
                elif current_rate < -0.0002:  # é«˜è² è³‡é‡‘è²»ç‡ï¼Œå¯èƒ½åè½‰
                    direction = "BUY"   # å¸‚å ´éåº¦çœ‹ç©ºï¼Œå¯èƒ½åè½‰
                    signal_type = "SENTIMENT_DIVERGENCE"
                else:
                    return  # ä¸åœ¨ä¿¡è™Ÿç¯„åœå…§
                
                # ç”Ÿæˆå¾®çµæ§‹ä¿¡è™Ÿï¼ˆä¿æŒç¾æœ‰æ ¼å¼ï¼‰
                signal = MarketMicrostructureSignal(
                    signal_id=f"funding_rate_{symbol}_{int(time.time())}",
                    signal_type=signal_type,
                    signal_strength=signal_strength,
                    signal_confidence=min(0.9, abs(current_rate) * 5000),  # è²»ç‡è¶Šæ¥µç«¯ï¼Œä¿¡å¿ƒè¶Šé«˜
                    tier_assignment="tier_2_important",
                    processing_priority="batch_5s",
                    bid_ask_imbalance=0.0,  # ç”±æ–¼ä¸æ˜¯è¨‚å–®ç°¿ä¿¡è™Ÿï¼Œè¨­ç‚º0
                    liquidity_shock_magnitude=abs(current_rate) * 1000,  # å°‡è²»ç‡è½‰æ›ç‚ºæµå‹•æ€§è¡æ“Šç¨‹åº¦
                    institutional_flow_direction=direction,
                    funding_sentiment=self._map_sentiment_to_category(sentiment_score),
                    timestamp=datetime.now()
                )
                
                # è¨˜éŒ„åˆ°é©ç•¶çš„ç·©è¡å€ï¼ˆä¿æŒç¾æœ‰æ•¸æ“šæµï¼‰
                logger.info(f"ğŸ¯ ç”Ÿæˆè³‡é‡‘è²»ç‡ä¿¡è™Ÿ: {signal.signal_id} | æ–¹å‘: {direction} | å¼·åº¦: {signal_strength:.2f} | è²»ç‡: {current_rate:.6f}")
                
                # é€™è£¡å¯ä»¥å°‡ä¿¡è™Ÿç™¼é€åˆ° Phase1C æˆ–å…¶ä»–ä¸‹æ¸¸æ¨¡å¡Š
                # ä¿æŒç¾æœ‰çš„ä¿¡è™Ÿåˆ†ç™¼æ©Ÿåˆ¶
                
        except Exception as e:
            logger.error(f"è³‡é‡‘è²»ç‡ä¿¡è™Ÿç”Ÿæˆå¤±æ•— {symbol}: {e}")
    
    def _map_sentiment_to_category(self, sentiment_score: float) -> str:
        """å°‡æƒ…ç·’åˆ†æ•¸æ˜ å°„åˆ°é¡åˆ¥ - ä¿æŒç¾æœ‰æšèˆ‰æ ¼å¼"""
        if sentiment_score >= 0.8:
            return "extreme_bullish"
        elif sentiment_score >= 0.65:
            return "bullish"
        elif sentiment_score >= 0.55:
            return "mild_bullish"
        elif sentiment_score <= 0.2:
            return "extreme_bearish"
        elif sentiment_score <= 0.35:
            return "bearish"
        elif sentiment_score <= 0.45:
            return "mild_bearish"
        else:
            return "neutral"

    async def _process_bid_ask_spread_analysis(self, orderbook: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¸å¿ƒæ–¹æ³•: è²·è³£åƒ¹å·®æ·±åº¦åˆ†æ"""
        try:
            if not orderbook or not orderbook.get("bids") or not orderbook.get("asks"):
                return {}
            
            bids = [(float(p), float(q)) for p, q in orderbook["bids"][:10]]
            asks = [(float(p), float(q)) for p, q in orderbook["asks"][:10]]
            
            best_bid, best_ask = bids[0][0], asks[0][0]
            spread = best_ask - best_bid
            mid_price = (best_bid + best_ask) / 2
            
            # å¤šå±¤åƒ¹å·®åˆ†æ
            spreads_analysis = {
                "level_1_spread": spread,
                "level_5_spread": asks[4][0] - bids[4][0] if len(bids) > 4 and len(asks) > 4 else spread,
                "level_10_spread": asks[9][0] - bids[9][0] if len(bids) > 9 and len(asks) > 9 else spread,
                "spread_ratio": spread / mid_price if mid_price > 0 else 0,
                "spread_stability": self._calculate_spread_stability(),
                "analysis_timestamp": datetime.now()
            }
            
            return spreads_analysis
            
        except Exception as e:
            logger.error(f"âŒ è²·è³£åƒ¹å·®åˆ†æå¤±æ•—: {e}")
            return {}
    
    def _calculate_spread_stability(self) -> float:
        """è¨ˆç®—åƒ¹å·®ç©©å®šæ€§"""
        if self.orderbook_buffer.size() < 3:
            return 1.0
            
        recent_spreads = []
        for ob in self.orderbook_buffer.get_recent(10):
            if ob and "bids" in ob and "asks" in ob and ob["bids"] and ob["asks"]:
                spread = float(ob["asks"][0][0]) - float(ob["bids"][0][0])
                recent_spreads.append(spread)
        
        if len(recent_spreads) < 2:
            return 1.0
            
        spread_std = np.std(recent_spreads)
        spread_mean = np.mean(recent_spreads)
        
        # ç©©å®šæ€§ = 1 - (æ¨™æº–å·®/å¹³å‡å€¼)ï¼Œç¯„åœ [0, 1]
        stability = max(0, 1 - (spread_std / spread_mean if spread_mean > 0 else 1))
        return stability
    
    async def _calculate_market_impact(self, volume_profile: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¸å¿ƒæ–¹æ³•: å¸‚å ´è¡æ“Šè¨ˆç®—"""
        try:
            if not volume_profile:
                return {"market_impact_score": 0.0, "impact_category": "low"}
            
            # è¨ˆç®—å¸‚å ´è¡æ“ŠæŒ‡æ•¸
            current_volume = volume_profile.get("total_volume", 0)
            baseline_volume = self.event_processor.baseline_metrics.get("avg_volume", current_volume)
            
            if baseline_volume == 0:
                impact_ratio = 1.0
            else:
                impact_ratio = current_volume / baseline_volume
            
            # è¡æ“Šåˆ†é¡
            if impact_ratio > 3.0:
                impact_category = "very_high"
                impact_score = 0.9
            elif impact_ratio > 2.0:
                impact_category = "high"
                impact_score = 0.7
            elif impact_ratio > 1.5:
                impact_category = "medium"
                impact_score = 0.5
            else:
                impact_category = "low"
                impact_score = 0.2
            
            return {
                "market_impact_score": impact_score,
                "impact_category": impact_category,
                "impact_ratio": impact_ratio,
                "current_volume": current_volume,
                "baseline_volume": baseline_volume,
                "calculation_timestamp": datetime.now()
            }
            
        except Exception as e:
            logger.error(f"âŒ å¸‚å ´è¡æ“Šè¨ˆç®—å¤±æ•—: {e}")
            return {"market_impact_score": 0.0, "impact_category": "low"}
    
    async def _map_liquidity_depth(self, orderbook: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¸å¿ƒæ–¹æ³•: æµå‹•æ€§æ·±åº¦æ˜ å°„"""
        try:
            if not orderbook or not orderbook.get("bids") or not orderbook.get("asks"):
                return {}
            
            bids = [(float(p), float(q)) for p, q in orderbook["bids"][:20]]
            asks = [(float(p), float(q)) for p, q in orderbook["asks"][:20]]
            
            # è¨ˆç®—ä¸åŒæ·±åº¦çš„æµå‹•æ€§
            liquidity_levels = {}
            
            for level in [5, 10, 15, 20]:
                bid_liquidity = sum(q for p, q in bids[:level]) if len(bids) >= level else 0
                ask_liquidity = sum(q for p, q in asks[:level]) if len(asks) >= level else 0
                total_liquidity = bid_liquidity + ask_liquidity
                
                liquidity_levels[f"level_{level}"] = {
                    "bid_liquidity": bid_liquidity,
                    "ask_liquidity": ask_liquidity,
                    "total_liquidity": total_liquidity,
                    "imbalance": (bid_liquidity - ask_liquidity) / total_liquidity if total_liquidity > 0 else 0
                }
            
            # è¨ˆç®—æµå‹•æ€§è³ªé‡åˆ†æ•¸
            max_liquidity = max([l["total_liquidity"] for l in liquidity_levels.values()])
            liquidity_quality_score = min(1.0, max_liquidity / 10000)  # å‡è¨­10000ç‚ºå„ªè³ªæµå‹•æ€§åŸºæº–
            
            return {
                "liquidity_levels": liquidity_levels,
                "liquidity_quality_score": liquidity_quality_score,
                "max_depth_liquidity": max_liquidity,
                "depth_mapping_timestamp": datetime.now()
            }
            
        except Exception as e:
            logger.error(f"âŒ æµå‹•æ€§æ·±åº¦æ˜ å°„å¤±æ•—: {e}")
            return {}
    
    async def _process_incremental_volume_profile(self, trade_data: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¸å¿ƒæ–¹æ³•: å¢é‡æˆäº¤é‡åˆ†æ"""
        try:
            if not trade_data:
                return {}
            
            # è§£æäº¤æ˜“æ•¸æ“š
            current_volume = float(trade_data.get("volume", 0))
            current_count = int(trade_data.get("count", 0))
            current_price = float(trade_data.get("lastPrice", 0))
            
            # è¨ˆç®—å¢é‡è®ŠåŒ–
            volume_change_24h = float(trade_data.get("priceChangePercent", 0))
            
            # æˆäº¤é‡åˆ†å¸ƒåˆ†æ
            volume_profile = {
                "current_volume": current_volume,
                "volume_change_24h": volume_change_24h,
                "trade_count": current_count,
                "avg_trade_size": current_volume / current_count if current_count > 0 else 0,
                "price_weighted_volume": current_volume * current_price,
                "volume_intensity": self._calculate_volume_intensity(current_volume),
                "profile_timestamp": datetime.now()
            }
            
            # å­˜å„²åˆ°äº¤æ˜“ç·©è¡å€
            self.trade_buffer.append(volume_profile)
            
            return volume_profile
            
        except Exception as e:
            logger.error(f"âŒ å¢é‡æˆäº¤é‡åˆ†æå¤±æ•—: {e}")
            return {}
    
    def _calculate_volume_intensity(self, current_volume: float) -> str:
        """è¨ˆç®—æˆäº¤é‡å¼·åº¦"""
        if self.trade_buffer.size() == 0:
            return "normal"
        
        recent_volumes = [t.get("current_volume", 0) for t in self.trade_buffer.get_recent(10)]
        avg_volume = np.mean(recent_volumes) if recent_volumes else current_volume
        
        if current_volume > avg_volume * 2:
            return "very_high"
        elif current_volume > avg_volume * 1.5:
            return "high"
        elif current_volume > avg_volume * 0.5:
            return "normal"
        else:
            return "low"
    
    async def _adaptive_performance_adjustment(self, current_time_ms: float):
        """ğŸ¯ è‡ªé©æ‡‰æ€§èƒ½èª¿æ•´ - Tier1è¶…æ™‚è§¸ç™¼"""
        try:
            logger.info(f"ğŸ”§ è§¸ç™¼è‡ªé©æ‡‰æ€§èƒ½èª¿æ•´: {current_time_ms:.1f}ms")
            
            # æ ¹æ“šè¶…æ™‚ç¨‹åº¦èª¿æ•´æ¡æ¨£é »ç‡
            if current_time_ms > 40:
                # åš´é‡è¶…æ™‚ï¼Œé™ä½æ¡æ¨£é »ç‡
                self.performance_controller.processing_mode = "low_volatility"
                logger.info("ğŸ“‰ é™ç´šè‡³ä½é »æ¡æ¨£æ¨¡å¼ (300ms)")
            elif current_time_ms > 30:
                # è¼•å¾®è¶…æ™‚ï¼Œä½¿ç”¨æ­£å¸¸æ¨¡å¼
                self.performance_controller.processing_mode = "normal"
                logger.info("âš–ï¸ èª¿æ•´è‡³æ­£å¸¸æ¡æ¨£æ¨¡å¼ (100ms)")
            
            # èª¿æ•´ç·©è¡å€å¤§å°
            if self.orderbook_buffer.maxsize > 30:
                # æ¸›å°‘ç·©è¡å€å¤§å°ç¯€çœè¨˜æ†¶é«”
                self.orderbook_buffer.maxsize = max(30, self.orderbook_buffer.maxsize - 10)
            
        except Exception as e:
            logger.error(f"âŒ è‡ªé©æ‡‰æ€§èƒ½èª¿æ•´å¤±æ•—: {e}")
    
    async def _emergency_performance_mode(self):
        """ğŸš¨ ç·Šæ€¥æ€§èƒ½æ¨¡å¼ - 35msç¸½ç›®æ¨™è¶…æ™‚è§¸ç™¼"""
        try:
            logger.warning("ğŸš¨ é€²å…¥ç·Šæ€¥æ€§èƒ½æ¨¡å¼")
            
            # å¼·åˆ¶é€²å…¥é«˜æ•ˆæ¨¡å¼
            self.performance_controller.processing_mode = "high_volatility"
            self.performance_controller.market_stress_level = 0.9
            
            # æ¸›å°‘ä¸¦è¡Œä»»å‹™æ•¸é‡
            self.executor._max_workers = max(2, self.executor._max_workers - 1)
            
            # æ¸…ç†èˆŠç·©è¡å€æ•¸æ“š
            if self.trade_buffer.size() > 100:
                # æ¸…é™¤èˆŠæ•¸æ“šï¼Œä¿ç•™æœ€è¿‘100ç­†
                recent_data = self.trade_buffer.get_recent(100)
                self.trade_buffer.data.clear()
                for item in recent_data:
                    self.trade_buffer.append(item)
            
            logger.info("âœ… ç·Šæ€¥æ€§èƒ½æ¨¡å¼å•Ÿå‹•å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç·Šæ€¥æ€§èƒ½æ¨¡å¼å•Ÿå‹•å¤±æ•—: {e}")
    
    async def _record_performance_success(self, total_time_ms: float, signal_count: int):
        """ğŸ“Š è¨˜éŒ„æˆåŠŸæ€§èƒ½çµ±è¨ˆ"""
        try:
            # æ›´æ–°æˆåŠŸè™•ç†çµ±è¨ˆ
            self.last_signal_time = time.time()
            
            # æ€§èƒ½ç­‰ç´šè©•ä¼°
            if total_time_ms <= 30:
                performance_grade = "ğŸ† å„ªç§€"
            elif total_time_ms <= 35:
                performance_grade = "âœ… è‰¯å¥½"  
            elif total_time_ms <= 40:
                performance_grade = "âš ï¸ å¯æ¥å—"
            else:
                performance_grade = "âŒ éœ€å„ªåŒ–"
            
            logger.info(f"ğŸ“Š Phase3è™•ç†å®Œæˆ: {total_time_ms:.1f}ms | {signal_count}ä¿¡è™Ÿ | {performance_grade}")
            
        except Exception as e:
            logger.debug(f"æ€§èƒ½çµ±è¨ˆè¨˜éŒ„å¤±æ•—: {e}")
    
    def _get_default_sentiment_metrics(self) -> SentimentMetrics:
        """ç²å–é»˜èªæƒ…ç·’æŒ‡æ¨™"""
        return SentimentMetrics(
            funding_sentiment_score=0.5,
            oi_momentum_signal="stable",
            volume_sentiment_indicators={"accumulation": 0.5, "distribution": 0.5},
            funding_rate=0.0,
            oi_change_percentage_24h=0.0
        )
    
    async def _layer_3_sentiment_analysis(self, static_data: Dict[str, Any]) -> SentimentMetrics:
        """Layer 3: æƒ…ç·’åˆ†æ - ä¸¦è¡ŒåŸ·è¡Œå¤šç¶­åº¦åˆ†æ"""
        try:
            # ä¸¦è¡Œè¨ˆç®—ä¸åŒæƒ…ç·’æŒ‡æ¨™
            funding_sentiment_task = asyncio.create_task(
                self._calculate_funding_sentiment(static_data.get("funding_rate"))
            )
            oi_momentum_task = asyncio.create_task(
                self._calculate_oi_momentum(static_data.get("open_interest"))
            )
            volume_sentiment_task = asyncio.create_task(
                self._calculate_volume_sentiment(static_data)
            )
            
            # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
            funding_sentiment, oi_momentum, volume_sentiment = await asyncio.gather(
                funding_sentiment_task, oi_momentum_task, volume_sentiment_task
            )
            
            # æå–è³‡é‡‘è²»ç‡æ•¸å€¼
            funding_rate = 0.0
            if static_data.get("funding_rate"):
                funding_rate = float(static_data["funding_rate"].get("fundingRate", 0))
            
            # æå–æŒå€‰é‡è®ŠåŒ–
            oi_change_percentage = 0.0
            if static_data.get("open_interest"):
                # é€™è£¡éœ€è¦è¨ˆç®—24å°æ™‚è®ŠåŒ–ï¼Œç°¡åŒ–è™•ç†
                oi_change_percentage = 0.0  # å¯¦éš›å¯¦ç¾ä¸­æ‡‰è©²æ¯”è¼ƒæ­·å²æ•¸æ“š
            
            return SentimentMetrics(
                funding_sentiment_score=funding_sentiment,
                oi_momentum_signal=oi_momentum,
                volume_sentiment_indicators=volume_sentiment,
                funding_rate=funding_rate,
                oi_change_percentage_24h=oi_change_percentage
            )
            
        except Exception as e:
            logger.error(f"âŒ Layer 3 æƒ…ç·’åˆ†æå¤±æ•—: {e}")
            return SentimentMetrics(
                funding_sentiment_score=0.5,
                oi_momentum_signal="stable",
                volume_sentiment_indicators={"accumulation": 0.5, "distribution": 0.5},
                funding_rate=0.0,
                oi_change_percentage_24h=0.0
            )
    
    async def _calculate_funding_sentiment(self, funding_data: Optional[Dict]) -> float:
        """è¨ˆç®—è³‡é‡‘è²»ç‡æƒ…ç·’åˆ†æ•¸"""
        if not funding_data:
            return 0.5  # ä¸­æ€§
        
        try:
            rate = float(funding_data.get("fundingRate", 0))
            
            # æ ¹æ“š JSON é…ç½®çš„åˆ†é¡æ¨™æº–
            if rate > 0.0005:  # > 0.05%
                return 1.0  # extreme_bullish
            elif rate > 0.0001:  # > 0.01%
                return 0.8  # bullish
            elif rate > 0.00005:  # > 0.005%
                return 0.6  # mild_bullish
            elif rate >= -0.00005:  # >= -0.005%
                return 0.5  # neutral
            elif rate >= -0.0001:  # >= -0.01%
                return 0.4  # bearish
            else:
                return 0.0  # extreme_bearish
                
        except Exception:
            return 0.5
    
    async def _calculate_oi_momentum(self, oi_data: Optional[Dict]) -> str:
        """è¨ˆç®—æŒå€‰é‡å‹•é‡ä¿¡è™Ÿ"""
        if not oi_data:
            return "stable"
        
        try:
            # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰è©²æ¯”è¼ƒæ­·å²æ•¸æ“š
            # é€™è£¡è¿”å›é»˜èªå€¼ï¼Œå¯¦éš›å¯¦ç¾éœ€è¦æ™‚é–“åºåˆ—åˆ†æ
            return "stable"
            
        except Exception:
            return "stable"
    
    async def _calculate_volume_sentiment(self, static_data: Dict) -> Dict[str, float]:
        """è¨ˆç®—æˆäº¤é‡æƒ…ç·’æŒ‡æ¨™"""
        try:
            # ç°¡åŒ–å¯¦ç¾ï¼Œè¿”å›å¹³è¡¡çš„æƒ…ç·’æŒ‡æ¨™
            return {
                "incremental_vwap_deviation": 0.0,
                "real_time_accumulation_distribution": 0.5,
                "institutional_vs_retail_flow_ratio": 1.0
            }
            
        except Exception:
            return {
                "incremental_vwap_deviation": 0.0,
                "real_time_accumulation_distribution": 0.5,
                "institutional_vs_retail_flow_ratio": 1.0
            }
    
    async def _layer_4_microstructure_signal_generation(self, 
                                                       orderbook_metrics: OrderBookMetrics,
                                                       sentiment_metrics: SentimentMetrics) -> List[MarketMicrostructureSignal]:
        """Layer 4: å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆ - å‹•æ…‹æ¬Šé‡é©æ‡‰"""
        signals = []
        current_time = datetime.now()
        
        try:
            # ä¸¦è¡Œç”Ÿæˆä¸åŒé¡å‹çš„ä¿¡è™Ÿ
            signal_tasks = [
                self._generate_liquidity_shock_signal(orderbook_metrics, sentiment_metrics, current_time),
                self._generate_institutional_flow_signal(orderbook_metrics, sentiment_metrics, current_time),
                self._generate_sentiment_divergence_signal(orderbook_metrics, sentiment_metrics, current_time),
                self._generate_liquidity_regime_signal(orderbook_metrics, sentiment_metrics, current_time)
            ]
            
            # ç­‰å¾…æ‰€æœ‰ä¿¡è™Ÿç”Ÿæˆå®Œæˆ
            generated_signals = await asyncio.gather(*signal_tasks, return_exceptions=True)
            
            # éæ¿¾æœ‰æ•ˆä¿¡è™Ÿ
            for signal in generated_signals:
                if not isinstance(signal, Exception) and signal is not None:
                    signals.append(signal)
            
            return signals
            
        except Exception as e:
            logger.error(f"âŒ Layer 4 å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return []
    
    async def _generate_liquidity_shock_signal(self, orderbook: OrderBookMetrics, 
                                              sentiment: SentimentMetrics, 
                                              timestamp: datetime) -> Optional[MarketMicrostructureSignal]:
        """ç”Ÿæˆæµå‹•æ€§è¡æ“Šä¿¡è™Ÿ"""
        try:
            # æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼æµå‹•æ€§è¡æ“Šåˆ†æ
            current_metrics = {
                "spread": orderbook.bid_ask_spread,
                "depth_score": orderbook.depth_quality_score
            }
            
            if not self.event_processor.should_trigger_liquidity_shock_analysis(current_metrics):
                return None
            
            # è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ (0.8-1.0 ç¯„åœ)
            depth_factor = 1.0 - orderbook.depth_quality_score
            spread_factor = min(1.0, orderbook.bid_ask_spread / orderbook.mid_price * 1000)
            flow_factor = min(1.0, orderbook.order_flow_intensity / 5.0)
            
            signal_strength = 0.8 + 0.2 * (depth_factor * 0.4 + spread_factor * 0.3 + flow_factor * 0.3)
            signal_strength = min(1.0, max(0.8, signal_strength))
            
            # è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
            confidence = orderbook.depth_quality_score * 0.6 + (1.0 - spread_factor) * 0.4
            
            return MarketMicrostructureSignal(
                signal_id=str(uuid.uuid4()),
                signal_type="LIQUIDITY_SHOCK",
                signal_strength=signal_strength,
                signal_confidence=confidence,
                tier_assignment="tier_1_critical",
                processing_priority="immediate",
                bid_ask_imbalance=orderbook.bid_ask_imbalance,
                market_depth_score=orderbook.depth_quality_score,
                order_flow_intensity=orderbook.order_flow_intensity,
                spread_condition=orderbook.spread_condition,
                funding_sentiment=self._score_to_sentiment(sentiment.funding_sentiment_score),
                oi_momentum=sentiment.oi_momentum_signal,
                volume_sentiment="neutral",  # ç°¡åŒ–
                liquidity_score=orderbook.depth_quality_score,
                market_stress_score=1.0 - orderbook.depth_quality_score,
                institutional_activity="high" if orderbook.large_order_detected else "medium",
                retail_activity="medium",
                predicted_price_impact=signal_strength * 0.01,  # å‡è¨­æœ€å¤§1%å½±éŸ¿
                liquidity_forecast="deteriorating",
                regime_probability="breakdown",
                data_timestamp=orderbook.timestamp,
                analysis_timestamp=timestamp,
                signal_generated=timestamp,
                signal_expires=timestamp + timedelta(minutes=5)
            )
            
        except Exception as e:
            logger.error(f"âŒ æµå‹•æ€§è¡æ“Šä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_institutional_flow_signal(self, orderbook: OrderBookMetrics, 
                                                 sentiment: SentimentMetrics, 
                                                 timestamp: datetime) -> Optional[MarketMicrostructureSignal]:
        """ç”Ÿæˆæ©Ÿæ§‹è³‡é‡‘æµä¿¡è™Ÿ"""
        try:
            # æª¢æŸ¥å¤§é¡è¨‚å–®
            if not orderbook.large_order_detected:
                return None
            
            # è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ (0.7-0.9 ç¯„åœ)
            flow_intensity = min(1.0, orderbook.order_flow_intensity / 3.0)
            imbalance_strength = abs(orderbook.bid_ask_imbalance)
            
            signal_strength = 0.7 + 0.2 * (flow_intensity * 0.6 + imbalance_strength * 0.4)
            signal_strength = min(0.9, max(0.7, signal_strength))
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºé¯¨é­šè¨‚å–®
            is_whale_order = orderbook.order_flow_intensity > 5.0
            tier = "tier_1_critical" if is_whale_order else "tier_2_important"
            
            return MarketMicrostructureSignal(
                signal_id=str(uuid.uuid4()),
                signal_type="INSTITUTIONAL_FLOW",
                signal_strength=signal_strength,
                signal_confidence=orderbook.depth_quality_score,
                tier_assignment=tier,
                processing_priority="immediate" if is_whale_order else "batch_5s",
                bid_ask_imbalance=orderbook.bid_ask_imbalance,
                market_depth_score=orderbook.depth_quality_score,
                order_flow_intensity=orderbook.order_flow_intensity,
                spread_condition=orderbook.spread_condition,
                funding_sentiment=self._score_to_sentiment(sentiment.funding_sentiment_score),
                oi_momentum=sentiment.oi_momentum_signal,
                volume_sentiment="accumulation" if orderbook.bid_ask_imbalance > 0 else "distribution",
                liquidity_score=orderbook.depth_quality_score,
                market_stress_score=min(1.0, orderbook.order_flow_intensity / 10.0),
                institutional_activity="high",
                retail_activity="low",
                predicted_price_impact=signal_strength * 0.005,
                liquidity_forecast="stable",
                regime_probability="trending",
                data_timestamp=orderbook.timestamp,
                analysis_timestamp=timestamp,
                signal_generated=timestamp,
                signal_expires=timestamp + timedelta(minutes=15)
            )
            
        except Exception as e:
            logger.error(f"âŒ æ©Ÿæ§‹è³‡é‡‘æµä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_sentiment_divergence_signal(self, orderbook: OrderBookMetrics, 
                                                   sentiment: SentimentMetrics, 
                                                   timestamp: datetime) -> Optional[MarketMicrostructureSignal]:
        """ç”Ÿæˆæƒ…ç·’åˆ†æ­§ä¿¡è™Ÿ"""
        try:
            # æª¢æŸ¥æƒ…ç·’åˆ†æ­§
            funding_bullish = sentiment.funding_sentiment_score > 0.6
            funding_bearish = sentiment.funding_sentiment_score < 0.4
            orderbook_bullish = orderbook.bid_ask_imbalance > 0.2
            orderbook_bearish = orderbook.bid_ask_imbalance < -0.2
            
            # å°‹æ‰¾åˆ†æ­§æ¨¡å¼
            divergence_detected = False
            divergence_strength = 0.0
            
            if funding_bullish and orderbook_bearish:
                divergence_detected = True
                divergence_strength = sentiment.funding_sentiment_score - (0.5 - orderbook.bid_ask_imbalance)
            elif funding_bearish and orderbook_bullish:
                divergence_detected = True
                divergence_strength = (0.5 + orderbook.bid_ask_imbalance) - sentiment.funding_sentiment_score
            
            if not divergence_detected:
                return None
            
            # è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ (0.72-1.0 ç¯„åœï¼ŒPhase1C æ¨™æº–åŒ–æå‡ *1.2)
            base_strength = min(1.0, divergence_strength * 2.0)
            signal_strength = 0.72 + 0.28 * base_strength
            
            return MarketMicrostructureSignal(
                signal_id=str(uuid.uuid4()),
                signal_type="SENTIMENT_DIVERGENCE",
                signal_strength=signal_strength,
                signal_confidence=base_strength,
                tier_assignment="tier_2_important",
                processing_priority="batch_5s",
                bid_ask_imbalance=orderbook.bid_ask_imbalance,
                market_depth_score=orderbook.depth_quality_score,
                order_flow_intensity=orderbook.order_flow_intensity,
                spread_condition=orderbook.spread_condition,
                funding_sentiment=self._score_to_sentiment(sentiment.funding_sentiment_score),
                oi_momentum=sentiment.oi_momentum_signal,
                volume_sentiment="neutral",
                liquidity_score=orderbook.depth_quality_score,
                market_stress_score=divergence_strength,
                institutional_activity="medium",
                retail_activity="high",
                predicted_price_impact=signal_strength * 0.008,
                liquidity_forecast="stable",
                regime_probability="ranging",
                data_timestamp=orderbook.timestamp,
                analysis_timestamp=timestamp,
                signal_generated=timestamp,
                signal_expires=timestamp + timedelta(minutes=30)
            )
            
        except Exception as e:
            logger.error(f"âŒ æƒ…ç·’åˆ†æ­§ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _generate_liquidity_regime_signal(self, orderbook: OrderBookMetrics, 
                                               sentiment: SentimentMetrics, 
                                               timestamp: datetime) -> Optional[MarketMicrostructureSignal]:
        """ç”Ÿæˆæµå‹•æ€§åˆ¶åº¦ä¿¡è™Ÿ"""
        try:
            # æµå‹•æ€§åˆ¶åº¦åˆ†é¡
            liquidity_score = orderbook.depth_quality_score
            spread_ratio = orderbook.bid_ask_spread / orderbook.mid_price if orderbook.mid_price > 0 else 0
            
            if liquidity_score > 0.8 and spread_ratio < 0.0005:
                regime = "high_liquidity_stable"
                regime_prob = "ranging"
            elif liquidity_score < 0.3 or spread_ratio > 0.002:
                regime = "low_liquidity_volatile"
                regime_prob = "breakdown"
            elif orderbook.order_flow_intensity > 2.0:
                regime = "liquidity_breakout_preparation"
                regime_prob = "breakout"
            else:
                regime = "liquidity_distribution_phase"
                regime_prob = "trending"
            
            # è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ (0.75-1.0 ç¯„åœï¼ŒPhase1C æ¨™æº–åŒ–æå‡ *1.5)
            regime_strength = 0.5 + 0.5 * (liquidity_score + min(1.0, orderbook.order_flow_intensity / 3.0)) / 2
            signal_strength = 0.75 + 0.25 * regime_strength
            
            return MarketMicrostructureSignal(
                signal_id=str(uuid.uuid4()),
                signal_type="LIQUIDITY_REGIME_CHANGE",
                signal_strength=signal_strength,
                signal_confidence=liquidity_score,
                tier_assignment="tier_3_monitoring",
                processing_priority="scheduled_15s",
                bid_ask_imbalance=orderbook.bid_ask_imbalance,
                market_depth_score=orderbook.depth_quality_score,
                order_flow_intensity=orderbook.order_flow_intensity,
                spread_condition=orderbook.spread_condition,
                funding_sentiment=self._score_to_sentiment(sentiment.funding_sentiment_score),
                oi_momentum=sentiment.oi_momentum_signal,
                volume_sentiment="neutral",
                liquidity_score=liquidity_score,
                market_stress_score=1.0 - liquidity_score,
                institutional_activity="low",
                retail_activity="medium",
                predicted_price_impact=signal_strength * 0.003,
                liquidity_forecast="improving" if liquidity_score > 0.6 else "deteriorating",
                regime_probability=regime_prob,
                data_timestamp=orderbook.timestamp,
                analysis_timestamp=timestamp,
                signal_generated=timestamp,
                signal_expires=timestamp + timedelta(hours=1)
            )
            
        except Exception as e:
            logger.error(f"âŒ æµå‹•æ€§åˆ¶åº¦ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    def _score_to_sentiment(self, score: float) -> str:
        """å°‡æƒ…ç·’åˆ†æ•¸è½‰æ›ç‚ºæ–‡å­—æè¿°"""
        if score >= 0.9:
            return "extreme_bullish"
        elif score >= 0.7:
            return "bullish"
        elif score >= 0.6:
            return "mild_bullish"
        elif score >= 0.4:
            return "neutral"
        elif score >= 0.3:
            return "bearish"
        else:
            return "extreme_bearish"
    
    async def _layer_5_advanced_analytics(self, signals: List[MarketMicrostructureSignal]) -> List[MarketMicrostructureSignal]:
        """Layer 5: é«˜éšåˆ†æèˆ‡é æ¸¬ - å³æ™‚æ ¡æ­£æ©Ÿåˆ¶"""
        if not signals:
            return signals
        
        try:
            # æ¨¡å‹æº–ç¢ºç‡è¿½è¹¤èˆ‡æ¬Šé‡èª¿æ•´
            await self._update_model_accuracy_tracking(signals)
            
            # å‹•æ…‹æ¬Šé‡èª¿æ•´
            enhanced_signals = []
            for signal in signals:
                enhanced_signal = await self._apply_predictive_enhancements(signal)
                enhanced_signals.append(enhanced_signal)
            
            # ç•°å¸¸æª¢æ¸¬èˆ‡ç·Šæ€¥æ¨¡å¼
            await self._anomaly_detection_and_emergency_mode(enhanced_signals)
            
            return enhanced_signals
            
        except Exception as e:
            logger.error(f"âŒ Layer 5 é«˜éšåˆ†æå¤±æ•—: {e}")
            return signals
    
    async def _update_model_accuracy_tracking(self, signals: List[MarketMicrostructureSignal]):
        """æ›´æ–°æ¨¡å‹æº–ç¢ºç‡è¿½è¹¤"""
        try:
            for signal in signals:
                # é€™è£¡æ‡‰è©²æ¯”è¼ƒé æ¸¬èˆ‡å¯¦éš›çµæœ
                # ç°¡åŒ–å¯¦ç¾ï¼Œå‡è¨­ 80% æº–ç¢ºç‡
                accuracy = 0.8
                self.model_accuracy_tracker[signal.signal_type].append(accuracy)
            
        except Exception as e:
            logger.debug(f"æ¨¡å‹æº–ç¢ºç‡è¿½è¹¤æ›´æ–°å¤±æ•—: {e}")
    
    async def _apply_predictive_enhancements(self, signal: MarketMicrostructureSignal) -> MarketMicrostructureSignal:
        """æ‡‰ç”¨é æ¸¬å¢å¼·"""
        try:
            # åŸºæ–¼æ­·å²æº–ç¢ºç‡èª¿æ•´ä¿¡è™Ÿå¼·åº¦
            signal_type_accuracy = self.model_accuracy_tracker.get(signal.signal_type, [0.8])
            avg_accuracy = np.mean(signal_type_accuracy) if signal_type_accuracy else 0.8
            
            # å‹•æ…‹èª¿æ•´
            adjustment_factor = 0.9 + 0.2 * avg_accuracy  # 0.9-1.1 ç¯„åœ
            signal.signal_strength = min(1.0, signal.signal_strength * adjustment_factor)
            
            return signal
            
        except Exception as e:
            logger.debug(f"é æ¸¬å¢å¼·å¤±æ•—: {e}")
            return signal
    
    async def _anomaly_detection_and_emergency_mode(self, signals: List[MarketMicrostructureSignal]):
        """ç•°å¸¸æª¢æ¸¬èˆ‡ç·Šæ€¥æ¨¡å¼"""
        try:
            if not signals:
                return
            
            # è¨ˆç®— Z-score
            stress_scores = [s.market_stress_score for s in signals]
            if len(stress_scores) > 1:
                mean_stress = np.mean(stress_scores)
                std_stress = np.std(stress_scores)
                
                if std_stress > 0:
                    max_z_score = max(abs(score - mean_stress) / std_stress for score in stress_scores)
                    
                    # Z-score > 3.0 è§¸ç™¼ç·Šæ€¥æ¨¡å¼
                    if max_z_score > 3.0:
                        logger.warning(f"ğŸš¨ ç•°å¸¸æª¢æ¸¬è§¸ç™¼ç·Šæ€¥æ¨¡å¼: Z-score={max_z_score:.2f}")
                        await self._enter_emergency_mode()
            
        except Exception as e:
            logger.debug(f"ç•°å¸¸æª¢æ¸¬å¤±æ•—: {e}")
    
    async def _enter_emergency_mode(self):
        """é€²å…¥ç·Šæ€¥æ¨¡å¼"""
        try:
            logger.warning("ğŸš¨ Phase3 é€²å…¥ç·Šæ€¥æ¨¡å¼ - 30ç§’å…§å®Œæˆæ¨¡å‹åƒæ•¸èª¿æ•´")
            
            # èª¿æ•´æ€§èƒ½æ§åˆ¶å™¨
            self.performance_controller.update_market_stress(0.9)
            
            # é‡ç½®æ¨¡å‹æ¬Šé‡
            self.adaptive_weights = {
                "microstructure": 1.2,  # æå‡å¾®çµæ§‹æ¬Šé‡
                "technical": 0.8,       # é™ä½æŠ€è¡“åˆ†ææ¬Šé‡
                "sentiment": 1.0
            }
            
            logger.info("âœ… ç·Šæ€¥æ¨¡å¼åƒæ•¸èª¿æ•´å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ç·Šæ€¥æ¨¡å¼è™•ç†å¤±æ•—: {e}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½å ±å‘Š"""
        return {
            "performance_metrics": asdict(self.performance_metrics),
            "processing_mode": self.performance_controller.processing_mode,
            "market_stress_level": self.performance_controller.market_stress_level,
            "adaptive_weights": self.adaptive_weights,
            "buffer_status": {
                "orderbook_buffer_size": len(self.orderbook_buffer.data),
                "trade_buffer_size": len(self.trade_buffer.data),
                "funding_buffer_size": len(self.funding_buffer.data)
            },
            "model_accuracy": {
                signal_type: np.mean(accuracy_list) if accuracy_list else 0.0
                for signal_type, accuracy_list in self.model_accuracy_tracker.items()
            }
        }
