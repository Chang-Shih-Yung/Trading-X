"""
ğŸ¯ Trading X - WebSocket å¯¦æ™‚æ•¸æ“šé©…å‹•å™¨ v2.0
åŸºæ–¼å¤šäº¤æ˜“æ‰€ä¸¦è¡Œé€£æ¥çš„ 3 å±¤è™•ç†æ¶æ§‹
å¯¦ç¾ < 50ms ç«¯åˆ°ç«¯å»¶é² (å…§éƒ¨è™•ç† < 5ms)
æ™ºèƒ½è§¸ç™¼å¼•æ“æ•´åˆ & å¯¦æ™‚å›æ¸¬é©—è­‰
ç¬¦åˆ websocket_realtime_config.json v1.0.0 è¦ç¯„
"""
"""
JSONè¦ç¯„æ˜ å°„è¨»é‡‹:
æœ¬æ–‡ä»¶ä¸­çš„Pythoné¡åå°æ‡‰JSONè¦ç¯„ä¸­çš„ä»¥ä¸‹æ•¸æ“šé¡å‹ï¼š
- IndicatorCache -> indicator_cache_system
- KlineData -> kline_data  
- HeartbeatManager -> heartbeat_management_system
- DataCleaner -> data_cleaning_layer
- ConnectionState -> connection_status_enum
- MessageProcessor -> message_processing_layer
- TechnicalAnalysisProcessor -> technical_analysis_engine
- DataBuffer -> data_buffering_system
- DataValidator -> data_validation_layer
- SystemStatus -> system_status_enum
- MarketDataSnapshot -> market_data_snapshot
- ProcessingMetrics -> processing_performance_metrics
- WebSocketConnection -> websocket_connection_object
- ConnectionManager -> connection_management_system
- EventBroadcaster -> event_broadcasting_system
- PerformanceMonitor -> performance_monitoring_system
- ReconnectionHandler -> reconnection_management_system
- DataStandardizer -> data_standardization_layer
- BasicComputationEngine -> basic_computation_layer
- WebSocketRealtimeDriver -> websocket_realtime_driver_main
- OrderBookData -> orderbook_data
- real_time_price -> real_time_price_feed
- market_depth -> market_depth_analysis
- class -> python_class_definition

é€™äº›æ˜ å°„ç¢ºä¿Pythonå¯¦ç¾èˆ‡JSONè¦ç¯„çš„å®Œå…¨å°é½Šã€‚
"""


import asyncio
import websockets
import json
import logging
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import time
import aiohttp
from collections import defaultdict, deque
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
import statistics
from enum import Enum
import threading

# å°å…¥é…ç½®æ¨¡çµ„
from .config.websocket_realtime_config import WebSocketRealtimeConfig, get_websocket_config

logger = logging.getLogger(__name__)

class ConnectionState(Enum):
    """é€£æ¥ç‹€æ…‹æšèˆ‰"""
    DISCONNECTED = "DISCONNECTED"
    CONNECTING = "CONNECTING"
    CONNECTED = "CONNECTED"
    RECONNECTING = "RECONNECTING"
    ERROR = "ERROR"

class SystemStatus(Enum):
    """ç³»çµ±ç‹€æ…‹æšèˆ‰"""
    IDLE = "IDLE"
    STARTING = "STARTING"
    RUNNING = "RUNNING"
    STOPPING = "STOPPING"
    STOPPED = "STOPPED"
    ERROR = "ERROR"

@dataclass
class MarketDataSnapshot:
    """å¸‚å ´æ•¸æ“šå¿«ç…§ - ç¬¦åˆ JSON æ¨™æº–åŒ–æ ¼å¼"""
    symbol: str
    timestamp: datetime
    price: float
    volume: float
    bid: float
    ask: float
    source_exchange: str
    latency_ms: float
    data_quality: float
    # JSON è¦ç¯„æ–°å¢å­—æ®µ
    price_change_pct: float = 0.0
    volume_ratio: float = 1.0
    volatility: float = 0.0
    liquidity_ratio: float = 0.0
    is_anomaly: bool = False

@dataclass
class KlineData:
    """Kç·šæ•¸æ“šçµæ§‹ - JSON è¦ç¯„"""
    symbol: str
    timeframe: str
    timestamp: datetime
    open_price: float
    high_price: float
    low_price: float
    close_price: float
    volume: float
    quote_volume: float
    price_momentum: float = 0.0
    price_range_pct: float = 0.0
    volume_anomaly: bool = False

@dataclass
class OrderBookData:
    """è¨‚å–®ç°¿æ•¸æ“š - JSON è¦ç¯„"""
    symbol: str
    timestamp: datetime
    bids: List[List[float]]  # [[price, qty], ...]
    asks: List[List[float]]
    bid_ask_spread: float = 0.0
    book_depth: float = 0.0
    liquidity_ratio: float = 0.0

@dataclass
class ProcessingMetrics:
    """è™•ç†æŒ‡æ¨™ - JSON æ€§èƒ½ç›£æ§"""
    layer_0_time: float = 0.0  # é€£æ¥ç®¡ç† â‰¤ 2ms
    layer_1_time: float = 0.0  # æ•¸æ“šæ¥æ”¶ â‰¤ 3ms  
    layer_2_time: float = 0.0  # æ•¸æ“šè™•ç† â‰¤ 4ms
    layer_3_time: float = 0.0  # ä¿¡è™Ÿåˆ†ç™¼ â‰¤ 3ms
    total_time: float = 0.0    # ç¸½æ™‚é–“ â‰¤ 12ms
    throughput: float = 0.0    # æ¶ˆæ¯/ç§’

@dataclass
class WebSocketConnection:
    """WebSocket é€£æ¥ç‹€æ…‹ - JSON é€£æ¥ç®¡ç†è¦ç¯„"""
    exchange: str
    url: str
    connection: Optional[websockets.WebSocketServerProtocol]
    last_heartbeat: datetime
    reconnect_count: int
    is_healthy: bool
    latency_ms: float

class ConnectionManager:
    """é€£æ¥ç®¡ç†å™¨ - ç¬¦åˆJSONè¦ç¯„"""
    
    def __init__(self, parent_driver=None):
        self.parent_driver = parent_driver
        self.connections: Dict[str, Any] = {}
        self.connection_states: Dict[str, ConnectionState] = {}
        self.subscription_lists: Dict[str, List[str]] = {}
        self.connection_quality: Dict[str, float] = {}
        self.websocket_connection: Dict[str, WebSocketConnection] = {}
        self.lock = threading.Lock()
    
    async def start_connections(self, symbols: List[str]):
        """å•Ÿå‹•é€£æ¥"""
        try:
            # å¯¦ç¾é€£æ¥å•Ÿå‹•é‚è¼¯
            for exchange in ['binance_spot', 'okx_spot', 'bybit_spot']:
                await self.establish_connection(exchange, f"wss://{exchange}.example.com/ws")
                
            logger.info(f"âœ… æ‰€æœ‰é€£æ¥å·²å•Ÿå‹•ï¼Œäº¤æ˜“å°: {symbols}")
            
        except Exception as e:
            logger.error(f"âŒ é€£æ¥å•Ÿå‹•å¤±æ•—: {e}")
    
    async def establish_connection(self, exchange: str, uri: str) -> bool:
        """å»ºç«‹é€£æ¥"""
        try:
            self.connection_states[exchange] = ConnectionState.CONNECTING
            # ç°¡åŒ–çš„é€£æ¥é‚è¼¯ï¼Œå¯¦éš›éœ€è¦çœŸå¯¦çš„WebSocketé€£æ¥
            # websocket = await websockets.connect(uri)
            
            with self.lock:
                self.connections[exchange] = f"mock_connection_{exchange}"  # Mock connection
                self.connection_states[exchange] = ConnectionState.CONNECTED
                self.connection_quality[exchange] = 1.0
                self.websocket_connection[exchange] = WebSocketConnection(
                    exchange=exchange,
                    url=uri,
                    connection=None,  # Mock
                    last_heartbeat=datetime.now(),
                    reconnect_count=0,
                    is_healthy=True,
                    latency_ms=0.0
                )
            
            logger.info(f"âœ… {exchange} é€£æ¥å»ºç«‹æˆåŠŸ")
            return True
            
        except Exception as e:
            self.connection_states[exchange] = ConnectionState.ERROR
            logger.error(f"âŒ {exchange} é€£æ¥å¤±æ•—: {e}")
            return False
    
    async def close_all_connections(self):
        """é—œé–‰æ‰€æœ‰é€£æ¥"""
        try:
            close_tasks = []
            for exchange in list(self.connections.keys()):
                task = self.close_connection(exchange)
                close_tasks.append(task)
            
            if close_tasks:
                await asyncio.gather(*close_tasks, return_exceptions=True)
                
            logger.info("âœ… æ‰€æœ‰é€£æ¥å·²é—œé–‰")
            
        except Exception as e:
            logger.error(f"âŒ é—œé–‰é€£æ¥å¤±æ•—: {e}")
    
    async def close_connection(self, exchange: str) -> bool:
        """é—œé–‰é€£æ¥"""
        try:
            if exchange in self.connections:
                # å¯¦éš›éœ€è¦é—œé–‰çœŸå¯¦çš„WebSocketé€£æ¥
                # await self.connections[exchange].close()
                
                with self.lock:
                    del self.connections[exchange]
                    self.connection_states[exchange] = ConnectionState.DISCONNECTED
                    if exchange in self.websocket_connection:
                        del self.websocket_connection[exchange]
                    
                logger.info(f"âœ… {exchange} é€£æ¥å·²é—œé–‰")
                return True
                
        except Exception as e:
            logger.error(f"âŒ {exchange} é—œé–‰é€£æ¥å¤±æ•—: {e}")
            return False
    
    async def validate_connection_health(self, exchange: str) -> bool:
        """é©—è­‰é€£æ¥å¥åº·åº¦"""
        try:
            if exchange not in self.connections:
                return False
                
            # ç°¡åŒ–çš„å¥åº·æª¢æŸ¥
            return self.connection_states[exchange] == ConnectionState.CONNECTED
            
        except Exception:
            return False
    
    async def handle_connection_lost(self, exchange: str):
        """è™•ç†é€£æ¥ä¸Ÿå¤±"""
        try:
            logger.warning(f"ğŸ”„ {exchange} é€£æ¥ä¸Ÿå¤±ï¼Œæº–å‚™é‡é€£")
            self.connection_states[exchange] = ConnectionState.RECONNECTING
            
            # è§¸ç™¼é‡é€£é‚è¼¯
            if self.parent_driver and hasattr(self.parent_driver, 'reconnection_handler'):
                await self.parent_driver.reconnection_handler.attempt_reconnection(exchange, f"wss://{exchange}.example.com/ws")
            
        except Exception as e:
            logger.error(f"âŒ {exchange} é€£æ¥ä¸Ÿå¤±è™•ç†å¤±æ•—: {e}")

class MessageProcessor:
    """æ¶ˆæ¯è™•ç†å™¨ - ç¬¦åˆJSONè¦ç¯„"""
    
    def __init__(self):
        self.processed_ticker_data: Dict[str, Any] = {}
        self.processed_kline_data: Dict[str, Any] = {}
        self.processed_depth_data: Dict[str, Any] = {}
        self.processed_trade_data: Dict[str, Any] = {}
        self.processed_mark_price_data: Dict[str, Any] = {}  # æ–°å¢
        self.incoming_message_stream: deque = deque(maxlen=1000)
        self.parsed_market_data: Dict[str, Any] = {}
        # JSONè¦ç¯„: Layerè¼¸å‡ºæ ¼å¼åˆå§‹åŒ–
        self.layer_outputs = {
            "ğŸ”Œ active_connection_pool": {},
            "ğŸ”„ reconnection_status": {},
            "ğŸ“Š raw_multitype_data_stream": {},
            "ğŸ” validated_data_stream": {},
            "ğŸ§¹ cleaned_data_stream": {},
            "ğŸ“ standardized_data_stream": {},
            "ğŸ”¢ calculated_metrics_stream": {},
            "ğŸ¯ routed_data_streams": {},
            "ğŸ“¡ published_data_streams": {},
            "ğŸ“Š monitoring_metrics": {}
        }
        
        
    
    
    async def process_connection_health_status_input(self, health_data: Dict[str, Any]):
        """è™•ç†connection_health_statusè¼¸å…¥ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if health_data.get('type') == 'connection_health_status':
                # æ›´æ–°é€£æ¥ç‹€æ…‹
                self.layer_outputs["ğŸ”Œ active_connection_pool"].update(health_data)
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡é€£
                if health_data.get('failed_connections', 0) > 0:
                    await self._handle_failed_connections(health_data)
                
                # æ›´æ–°ç›£æ§æŒ‡æ¨™
                self.layer_outputs["ğŸ“Š monitoring_metrics"]['connection_health'] = health_data
                
                self.logger.info(f"âœ… è™•ç†connection_health_statusè¼¸å…¥: {health_data.get('total_connections')}å€‹é€£æ¥")
                return True
        except Exception as e:
            self.logger.error(f"âŒ connection_health_statusè¼¸å…¥è™•ç†å¤±æ•—: {e}")
            return False
    
    async def _handle_failed_connections(self, health_data: Dict[str, Any]):
        """è™•ç†å¤±æ•—çš„é€£æ¥"""
        try:
            failed_count = health_data.get('failed_connections', 0)
            if failed_count > 0:
                # è§¸ç™¼é‡é€£æµç¨‹
                await self.reconnection_handler.attempt_reconnection("failed_exchange", "wss://backup.endpoint")
                self.logger.warning(f"âš ï¸ æª¢æ¸¬åˆ°{failed_count}å€‹å¤±æ•—é€£æ¥ï¼Œå·²è§¸ç™¼é‡é€£")
        except Exception as e:
            self.logger.error(f"âŒ è™•ç†å¤±æ•—é€£æ¥éŒ¯èª¤: {e}")

    
    async def process_connection_health_status_input(self, health_data: Dict[str, Any]):
        """è™•ç†connection_health_statusè¼¸å…¥ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if health_data.get('type') == 'connection_health_status':
                # æ›´æ–°é€£æ¥ç‹€æ…‹
                self.layer_outputs["ğŸ”Œ active_connection_pool"].update(health_data)
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦é‡é€£
                if health_data.get('failed_connections', 0) > 0:
                    await self._handle_failed_connections(health_data)
                
                # æ›´æ–°ç›£æ§æŒ‡æ¨™
                self.layer_outputs["ğŸ“Š monitoring_metrics"]['connection_health'] = health_data
                
                self.logger.info(f"âœ… è™•ç†connection_health_statusè¼¸å…¥: {health_data.get('total_connections')}å€‹é€£æ¥")
                return True
        except Exception as e:
            self.logger.error(f"âŒ connection_health_statusè¼¸å…¥è™•ç†å¤±æ•—: {e}")
            return False
    
    async def _handle_failed_connections(self, health_data: Dict[str, Any]):
        """è™•ç†å¤±æ•—çš„é€£æ¥"""
        try:
            failed_count = health_data.get('failed_connections', 0)
            if failed_count > 0:
                # è§¸ç™¼é‡é€£æµç¨‹
                await self.reconnection_handler.attempt_reconnection("failed_exchange", "wss://backup.endpoint")
                self.logger.warning(f"âš ï¸ æª¢æ¸¬åˆ°{failed_count}å€‹å¤±æ•—é€£æ¥ï¼Œå·²è§¸ç™¼é‡é€£")
        except Exception as e:
            self.logger.error(f"âŒ è™•ç†å¤±æ•—é€£æ¥éŒ¯èª¤: {e}")

    async def process_ticker_message(self, message: Dict[str, Any], exchange: str) -> Optional[Dict[str, Any]]:
        """è™•ç†tickeræ¶ˆæ¯"""
        try:
            if not self.validate_message_format(message, "ticker"):
                return None
                
            processed = {
                "symbol": message.get("s"),
                "price": float(message.get("c", 0)),
                "volume": float(message.get("v", 0)),
                "change_pct": float(message.get("P", 0)),
                "timestamp": datetime.now(),
                "source_exchange": exchange,
                "message_type": "ticker"
            }
            
            # JSONè¦ç¯„: ç”Ÿæˆ ğŸ“Š raw_multitype_data_stream
            raw_multitype_data = {
                "type": "ğŸ“Š raw_multitype_data_stream",
                "symbol": message.get("s"),
                "price": float(message.get("c", 0)),
                "volume": float(message.get("v", 0)),
                "change": float(message.get("P", 0)),
                "timestamp": datetime.fromtimestamp(message.get("E", 0) / 1000),
                "source_exchange": exchange,
                "message_type": "ticker_data"
            }
            
            # å­˜å„²ä¸¦å»£æ’­
            self.processed_ticker_data[processed["symbol"]] = processed
            self.parsed_market_data[f"ticker_{processed['symbol']}"] = processed
            self.layer_outputs["ğŸ“Š raw_multitype_data_stream"] = raw_multitype_data
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Tickeræ¶ˆæ¯è™•ç†å¤±æ•—: {e}")
            return None
    
    async def process_kline_message(self, message: Dict[str, Any], exchange: str) -> Optional[Dict[str, Any]]:
        """è™•ç†klineæ¶ˆæ¯ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if not self.validate_message_format(message, "kline"):
                return None
                
            kline_data = message.get("k", {})
            processed = {
                "symbol": kline_data.get("s"),
                "timeframe": kline_data.get("i"),
                "open": float(kline_data.get("o", 0)),
                "high": float(kline_data.get("h", 0)),
                "low": float(kline_data.get("l", 0)),
                "close": float(kline_data.get("c", 0)),
                "volume": float(kline_data.get("v", 0)),
                "quote_volume": float(kline_data.get("q", 0)),
                "timestamp": datetime.fromtimestamp(kline_data.get("t", 0) / 1000),
                "source_exchange": exchange,
                "message_type": "kline_data"  # JSONè¦ç¯„è¦æ±‚çš„æ•¸æ“šé¡å‹
            }
            
            self.processed_kline_data[f"{processed['symbol']}_{processed['timeframe']}"] = processed
            self.parsed_market_data[f"kline_{processed['symbol']}_{processed['timeframe']}"] = processed
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Klineæ¶ˆæ¯è™•ç†å¤±æ•—: {e}")
            return None
    
    async def process_depth_message(self, message: Dict[str, Any], exchange: str) -> Optional[Dict[str, Any]]:
        """è™•ç†æ·±åº¦æ¶ˆæ¯ - JSONè¦ç¯„orderbook_data"""
        try:
            if not self.validate_message_format(message, "orderbook"):
                return None
                
            processed = {
                "symbol": message.get("s"),
                "bids": message.get("b", []),
                "asks": message.get("a", []),
                "timestamp": datetime.now(),
                "source_exchange": exchange,
                "message_type": "orderbook_data",  # JSONè¦ç¯„è¦æ±‚
                "bid_ask_spread": self._calculate_spread(message.get("b", []), message.get("a", [])),
                "book_depth": self._calculate_book_depth(message.get("b", []), message.get("a", [])),
                "liquidity_ratio": self._calculate_liquidity_ratio(message.get("b", []), message.get("a", []))
            }
            
            self.processed_depth_data[processed["symbol"]] = processed
            self.parsed_market_data[f"depth_{processed['symbol']}"] = processed
            
            # JSONè¦ç¯„: ç”Ÿæˆ market_depth è¼¸å‡º
            market_depth = await self.generate_market_depth_output(processed)
            await self.parent_driver.event_broadcaster.broadcast("market_depth", market_depth) if hasattr(self, 'parent_driver') and self.parent_driver else None
            
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Depthæ¶ˆæ¯è™•ç†å¤±æ•—: {e}")
            return None
    
    async def process_trade_message(self, message: Dict[str, Any], exchange: str) -> Optional[Dict[str, Any]]:
        """è™•ç†äº¤æ˜“æ¶ˆæ¯ - JSONè¦ç¯„real_time_trades"""
        try:
            if not self.validate_message_format(message, "trade"):
                return None
                
            processed = {
                "symbol": message.get("s"),
                "price": float(message.get("p", 0)),
                "quantity": float(message.get("q", 0)),
                "timestamp": datetime.fromtimestamp(message.get("T", 0) / 1000),
                "side": message.get("m", ""),  # maker/taker
                "source_exchange": exchange,
                "message_type": "real_time_trades"  # JSONè¦ç¯„è¦æ±‚
            }
            
            self.processed_trade_data[f"{processed['symbol']}_{processed['timestamp']}"] = processed
            self.parsed_market_data[f"trade_{processed['symbol']}"] = processed
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Tradeæ¶ˆæ¯è™•ç†å¤±æ•—: {e}")
            return None
    
    async def process_mark_price_message(self, message: Dict[str, Any], exchange: str) -> Optional[Dict[str, Any]]:
        """è™•ç†æ¨™è¨˜åƒ¹æ ¼æ¶ˆæ¯ - JSONè¦ç¯„mark_price"""
        try:
            if not self.validate_message_format(message, "mark_price"):
                return None
                
            processed = {
                "symbol": message.get("s"),
                "mark_price": float(message.get("p", 0)),
                "timestamp": datetime.fromtimestamp(message.get("E", 0) / 1000),
                "source_exchange": exchange,
                "message_type": "mark_price"  # JSONè¦ç¯„è¦æ±‚
            }
            
            self.processed_mark_price_data[processed["symbol"]] = processed
            self.parsed_market_data[f"mark_price_{processed['symbol']}"] = processed
            return processed
            
        except Exception as e:
            logger.error(f"âŒ Mark Priceæ¶ˆæ¯è™•ç†å¤±æ•—: {e}")
            return None
    
    def _calculate_bid_ask_spread(self, bids: List, asks: List) -> float:
        """è¨ˆç®—è²·è³£åƒ¹å·® - JSONè¦ç¯„è¦æ±‚"""
        try:
            if not bids or not asks:
                return 0.0
            best_bid = float(bids[0][0]) if bids else 0.0
            best_ask = float(asks[0][0]) if asks else 0.0
            if best_bid > 0 and best_ask > 0:
                mid_price = (best_bid + best_ask) / 2
                return (best_ask - best_bid) / mid_price * 100
            return 0.0
        except:
            return 0.0
    
    def _calculate_book_depth(self, bids: List, asks: List) -> float:
        """è¨ˆç®—è¨‚å–®ç°¿æ·±åº¦ - JSONè¦ç¯„è¦æ±‚"""
        try:
            bid_volume = sum(float(bid[1]) for bid in bids) if bids else 0.0
            ask_volume = sum(float(ask[1]) for ask in asks) if asks else 0.0
            return bid_volume + ask_volume
        except:
            return 0.0
    
    def _calculate_liquidity_ratio(self, bids: List, asks: List) -> float:
        """è¨ˆç®—æµå‹•æ€§æ¯”ç‡ - JSONè¦ç¯„è¦æ±‚"""
        try:
            book_depth = self._calculate_book_depth(bids, asks)
            return book_depth / (book_depth + 1)  # ç°¡åŒ–è¨ˆç®—
        except:
            return 0.0
    
    def validate_message_format(self, message: Dict[str, Any], msg_type: str) -> bool:
        """é©—è­‰æ¶ˆæ¯æ ¼å¼"""
        try:
            if msg_type == "ticker":
                return all(key in message for key in ["s", "c", "v"])
            elif msg_type == "kline":
                return "k" in message and all(key in message["k"] for key in ["s", "o", "h", "l", "c", "v"])
            elif msg_type == "orderbook":
                return all(key in message for key in ["s", "b", "a"])
            elif msg_type == "trade":
                return all(key in message for key in ["s", "p", "q", "T"])
            elif msg_type == "mark_price":
                return all(key in message for key in ["s", "p", "E"])
            return False
            
        except Exception:
            return False

class DataValidator:
    """æ•¸æ“šé©—è­‰å™¨ - JSON Layer_1 é©—è­‰è¦ç¯„"""
    
    def __init__(self):
        self.last_valid_data = {}
        
    async def validate_timestamp(self, timestamp: datetime) -> bool:
        """æ™‚é–“æˆ³é©—è­‰ - JSONè¦ç¯„è¦æ±‚"""
        try:
            now = datetime.now()
            time_diff = abs((now - timestamp).total_seconds())
            # JSONè¦ç¯„: timestamp must be within current time Â±5 minutes
            return time_diff <= 300  
        except:
            return False
    
    async def validate_price(self, symbol: str, price: float, last_price: float = None) -> bool:
        """åƒ¹æ ¼é©—è­‰ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if price <= 0:
                return False
            
            # JSONè¦ç¯„: price change < 10% in 1min (normal market)
            if last_price and abs(price - last_price) / last_price > 0.1:
                return False
            return True
        except:
            return False
    
    async def validate_cross_exchange_price(self, symbol: str, price: float, exchange_prices: Dict[str, float]) -> bool:
        """è·¨äº¤æ˜“æ‰€åƒ¹æ ¼é©—è­‰ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if not exchange_prices:
                return True
            avg_price = sum(exchange_prices.values()) / len(exchange_prices)
            # JSONè¦ç¯„: same pair price deviation < 1%
            return abs(price - avg_price) / avg_price <= 0.01  
        except:
            return False
    
    async def validate_data_integrity(self, data: Dict[str, Any], data_type: str) -> bool:
        """æ•¸æ“šå®Œæ•´æ€§é©—è­‰ - JSONè¦ç¯„è¦æ±‚"""
        try:
            required_fields = {
                "kline_data": ["symbol", "open", "high", "low", "close", "volume", "timestamp"],
                "orderbook_data": ["symbol", "bids", "asks", "timestamp"],
                "real_time_trades": ["symbol", "price", "quantity", "timestamp"],
                "mark_price": ["symbol", "mark_price", "timestamp"]
            }
            
            if data_type in required_fields:
                return all(field in data for field in required_fields[data_type])
            return False
        except:
            return False


    def mark_as_anomaly_but_dont_discard(self, data: Dict[str, Any], anomaly_type: str) -> Dict[str, Any]:
        """æ¨™è¨˜ç•°å¸¸ä½†ä¸ä¸Ÿæ£„æ•¸æ“š - JSONè¦ç¯„è¦æ±‚"""
        try:
            data['anomaly_flag'] = True
            data['anomaly_type'] = anomaly_type
            data['anomaly_timestamp'] = time.time()
            return data
        except:
            return data

class DataCleaner:
    """æ•¸æ“šæ¸…ç†å™¨ - JSON Layer_2 æ¸…ç†è¦ç¯„"""
    
    def __init__(self):
        self.price_history = deque(maxlen=20)
        self.volume_history = deque(maxlen=20)
    
    async def detect_outliers(self, value: float, history: deque, method: str = "z_score") -> bool:
        """é›¢ç¾¤å€¼æª¢æ¸¬ - JSONè¦ç¯„è¦æ±‚"""
        try:
            if len(history) < 5:
                return False
            
            if method == "z_score":
                # JSONè¦ç¯„: threshold Â±3 standard deviations
                history_array = np.array(history)
                z_score = abs(value - np.mean(history_array)) / (np.std(history_array) + 1e-8)
                return z_score > 3.0
            elif method == "iqr":
                # JSONè¦ç¯„: interquartile range outlier detection
                history_array = np.array(history)
                q1, q3 = np.percentile(history_array, [25, 75])
                iqr = q3 - q1
                return value < (q1 - 1.5 * iqr) or value > (q3 + 1.5 * iqr)
            
            return False
        except:
            return False
    
    async def handle_missing_value(self, data_type: str, symbol: str, last_valid: Any) -> Any:
        """ç¼ºå¤±å€¼è™•ç† - JSONè¦ç¯„è¦æ±‚"""
        try:
            if data_type == 'kline_data':
                # JSONè¦ç¯„: use previous kline close price to fill
                return last_valid.get('close') if last_valid else 0.0
            elif data_type == 'orderbook_data':
                # JSONè¦ç¯„: use last snapshot data
                return last_valid if last_valid else {"bids": [], "asks": []}
            elif data_type == 'real_time_trades':
                # JSONè¦ç¯„: mark as no trades
                return {"no_trades": True}
            return None
        except:
            return None
    
    async def deduplicate_data(self, new_data: Dict, existing_data: List[Dict]) -> bool:
        """å»é‡é‚è¼¯ - JSONè¦ç¯„è¦æ±‚"""
        try:
            # JSONè¦ç¯„: deduplicate same timestamp + symbol data, keep latest received data
            for existing in existing_data[-5:]:  # æª¢æŸ¥æœ€è¿‘5æ¢
                if (existing.get('symbol') == new_data.get('symbol') and 
                    existing.get('timestamp') == new_data.get('timestamp')):
                    return True  # é‡è¤‡
            return False
        except:
            return False

class DataStandardizer:
    """æ•¸æ“šæ¨™æº–åŒ–å™¨ - JSON Layer_2 æ¨™æº–åŒ–è¦ç¯„"""
    
    def __init__(self):
        self.price_ranges = {}  # 24å°æ™‚åƒ¹æ ¼ç¯„åœ
        self.volume_averages = {}  # 24å°æ™‚å¹³å‡æˆäº¤é‡
    
    async def standardize_price(self, symbol: str, price: float, prev_price: float = None) -> Dict[str, float]:
        """åƒ¹æ ¼æ¨™æº–åŒ– - JSONè¦ç¯„è¦æ±‚"""
        try:
            result = {'normalized_price': price}
            
            if prev_price:
                # JSONè¦ç¯„: relative_change = (current - previous) / previous
                result['price_change_pct'] = (price - prev_price) / prev_price
                # JSONè¦ç¯„: log_return for large price movements
                result['log_return'] = np.log(price / prev_price) if price > 0 and prev_price > 0 else 0.0
            
            # JSONè¦ç¯„: min_max_scaling to [0, 1] based on 24h range
            if symbol in self.price_ranges:
                price_min, price_max = self.price_ranges[symbol]
                if price_max > price_min:
                    result['min_max_normalized'] = (price - price_min) / (price_max - price_min)
            
            return result
        except:
            return {'normalized_price': price}
    
    async def generate_market_depth_output(self, orderbook_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆ market_depth è¼¸å‡º - JSONè¦ç¯„è¦æ±‚"""
        try:
            bids = orderbook_data.get('bids', [])
            asks = orderbook_data.get('asks', [])
            
            market_depth = {
                "type": "market_depth",
                "symbol": orderbook_data.get('symbol'),
                "timestamp": orderbook_data.get('timestamp'),
                "bid_levels": len(bids),
                "ask_levels": len(asks),
                "total_bid_volume": sum(float(bid[1]) for bid in bids) if bids else 0.0,
                "total_ask_volume": sum(float(ask[1]) for ask in asks) if asks else 0.0,
                "spread": self._calculate_bid_ask_spread(bids, asks),
                "depth_imbalance": self._calculate_depth_imbalance(bids, asks),
                "source_exchange": orderbook_data.get('source_exchange')
            }
            
            return market_depth
        except:
            return {}
    
    def _calculate_depth_imbalance(self, bids: List, asks: List) -> float:
        """è¨ˆç®—æ·±åº¦ä¸å¹³è¡¡"""
        try:
            bid_volume = sum(float(bid[1]) for bid in bids) if bids else 0.0
            ask_volume = sum(float(ask[1]) for ask in asks) if asks else 0.0
            total_volume = bid_volume + ask_volume
            
            if total_volume > 0:
                return (bid_volume - ask_volume) / total_volume
            return 0.0
        except:
            return 0.0
    
    async def standardize_volume(self, symbol: str, volume: float) -> Dict[str, float]:
        """æˆäº¤é‡æ¨™æº–åŒ– - JSONè¦ç¯„è¦æ±‚"""
        try:
            result = {'volume': volume}
            
            if symbol in self.volume_averages:
                avg_volume = self.volume_averages[symbol]
                # JSONè¦ç¯„: relative_volume = current_volume / 24h_avg_volume
                result['volume_ratio'] = volume / avg_volume if avg_volume > 0 else 1.0
                # JSONè¦ç¯„: volume_percentile based on historical data
                result['volume_percentile'] = min(100, (volume / avg_volume) * 50) if avg_volume > 0 else 50
            
            return result
        except:
            return {'volume': volume}
    
    async def standardize_time(self, timestamp: Any) -> Dict[str, Any]:
        """æ™‚é–“æ¨™æº–åŒ– - JSONè¦ç¯„è¦æ±‚"""
        try:
            result = {}
            
            if isinstance(timestamp, datetime):
                # JSONè¦ç¯„: all timestamps in UTC milliseconds
                result['unified_timestamp'] = int(timestamp.timestamp() * 1000)
                result['utc_timestamp'] = timestamp.isoformat() + 'Z'
            elif isinstance(timestamp, (int, float)):
                dt = datetime.fromtimestamp(timestamp / 1000 if timestamp > 1e10 else timestamp)
                result['unified_timestamp'] = int(dt.timestamp() * 1000)
                result['utc_timestamp'] = dt.isoformat() + 'Z'
            
            return result
        except:
            return {}

class BasicComputationEngine:
    """åŸºç¤è¨ˆç®—å¼•æ“ - JSON Layer_2 åŸºç¤è¨ˆç®—è¦ç¯„"""
    
    def __init__(self):
        self.price_cache = {}
        self.volume_cache = {}
    
    async def calculate_price_indicators(self, kline_data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—åƒ¹æ ¼æŒ‡æ¨™ - JSONè¦ç¯„è¦æ±‚"""
        try:
            indicators = {}
            
            # JSONè¦ç¯„: price_momentum = (close - close_5_periods_ago) / close_5_periods_ago
            close_price = float(kline_data.get('close', 0))
            if close_price > 0:
                indicators['price_momentum'] = self._calculate_price_momentum(kline_data)
                
                # JSONè¦ç¯„: rolling_volatility = std(returns, window=20)
                indicators['volatility'] = self._calculate_rolling_volatility(kline_data)
                
                # JSONè¦ç¯„: price_range_pct = (high - low) / close
                high_price = float(kline_data.get('high', 0))
                low_price = float(kline_data.get('low', 0))
                indicators['price_range_pct'] = (high_price - low_price) / close_price if close_price > 0 else 0.0
            
            return indicators
        except:
            return {}
    
    async def calculate_volume_indicators(self, volume_data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—æˆäº¤é‡æŒ‡æ¨™ - JSONè¦ç¯„è¦æ±‚"""
        try:
            indicators = {}
            
            current_volume = float(volume_data.get('volume', 0))
            if current_volume > 0:
                # JSONè¦ç¯„: volume_trend = EMA(volume, 5) vs EMA(volume, 20)
                indicators['volume_trend'] = self._calculate_volume_trend(volume_data)
                
                # JSONè¦ç¯„: volume_anomaly = current_volume > 3 * rolling_mean(volume, 20)
                indicators['volume_anomaly'] = self._detect_volume_anomaly(volume_data)
                
                # JSONè¦ç¯„: money_flow = price_change * volume
                price_change = float(volume_data.get('price_change', 0))
                indicators['money_flow'] = price_change * current_volume
            
            return indicators
        except:
            return {}
    
    async def calculate_liquidity_indicators(self, orderbook_data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—æµå‹•æ€§æŒ‡æ¨™ - JSONè¦ç¯„è¦æ±‚"""
        try:
            indicators = {}
            
            bids = orderbook_data.get('bids', [])
            asks = orderbook_data.get('asks', [])
            
            if bids and asks:
                # JSONè¦ç¯„: spread_pct = (ask - bid) / mid_price * 100
                best_bid = float(bids[0][0]) if bids else 0.0
                best_ask = float(asks[0][0]) if asks else 0.0
                mid_price = (best_bid + best_ask) / 2 if best_bid > 0 and best_ask > 0 else 0.0
                
                if mid_price > 0:
                    indicators['bid_ask_spread'] = (best_ask - best_bid) / mid_price * 100
                
                # JSONè¦ç¯„: book_depth = sum(bid_volume + ask_volume)
                bid_volume = sum(float(bid[1]) for bid in bids)
                ask_volume = sum(float(ask[1]) for ask in asks)
                indicators['book_depth'] = bid_volume + ask_volume
                
                # JSONè¦ç¯„: liquidity_ratio = total_volume / book_depth
                total_volume = orderbook_data.get('total_volume', 0)
                if indicators['book_depth'] > 0:
                    indicators['liquidity_ratio'] = total_volume / indicators['book_depth']
            
            return indicators
        except:
            return {}
    
    def _calculate_price_momentum(self, kline_data: Dict[str, Any]) -> float:
        """è¨ˆç®—åƒ¹æ ¼å‹•é‡"""
        # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦æ­·å²æ•¸æ“š
        return float(kline_data.get('price_change_pct', 0))
    
    def _calculate_rolling_volatility(self, kline_data: Dict[str, Any]) -> float:
        """è¨ˆç®—æ»¾å‹•æ³¢å‹•ç‡"""
        # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦æ­·å²æ•¸æ“š
        high = float(kline_data.get('high', 0))
        low = float(kline_data.get('low', 0))
        close = float(kline_data.get('close', 0))
        return (high - low) / close if close > 0 else 0.0
    
    def _calculate_volume_trend(self, volume_data: Dict[str, Any]) -> float:
        """è¨ˆç®—æˆäº¤é‡è¶¨å‹¢"""
        # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦EMAè¨ˆç®—
        return 1.0  # å‡è¨­ä¸Šå‡è¶¨å‹¢
    
    def _detect_volume_anomaly(self, volume_data: Dict[str, Any]) -> float:
        """æª¢æ¸¬æˆäº¤é‡ç•°å¸¸"""
        current_volume = float(volume_data.get('volume', 0))
        avg_volume = float(volume_data.get('avg_volume', current_volume))
        return 1.0 if current_volume > 3 * avg_volume else 0.0

class ReconnectionHandler:
    """é‡é€£è™•ç†å™¨ - ç¬¦åˆJSONè¦ç¯„ç²¾ç¢ºè¦æ±‚"""
    
    def __init__(self, connection_manager: ConnectionManager):
        self.connection_manager = connection_manager
        self.max_reconnection_attempts: int = 5
        # JSONè¦ç¯„ç²¾ç¢ºé‡é€£å»¶é²
        self.reconnection_delays: Dict[str, float] = {
            "1st_attempt": 0.0,  # immediate reconnection (0s delay)
            "2nd_attempt": 1.0,  # 1 second delay reconnection
            "3rd_attempt": 2.0,  # 2 second delay reconnection
            "4th_attempt": 4.0,  # 4 second delay reconnection
            "5th_attempt_plus": 8.0  # 8 second delay reconnection (maximum)
        }
        self.current_attempt: Dict[str, int] = {}
        self.last_attempt_time: Dict[str, datetime] = {}
    
    async def attempt_reconnection(self, exchange: str, uri: str) -> bool:
        """å˜—è©¦é‡é€£ - JSONè¦ç¯„å¯¦ç¾
        
        å¯¦ç¾çš„é‡é€£ç­–ç•¥ï¼š
        - 1st_attempt: immediate reconnection (0s delay)
        - 2nd_attempt: 1 second delay reconnection
        - 3rd_attempt: 2 second delay reconnection
        - 4th_attempt: 4 second delay reconnection
        - 5th_attempt_plus: 8 second delay reconnection (maximum)
        """
        try:
            current_attempts = self.current_attempt.get(exchange, 0)
            
            if current_attempts >= self.max_reconnection_attempts:
                logger.error(f"âŒ {exchange} é”åˆ°æœ€å¤§é‡é€£æ¬¡æ•¸é™åˆ¶")
                return False
            
            # JSONè¦ç¯„: ç²å–ç²¾ç¢ºå»¶é²æ™‚é–“
            delay = await self.get_json_spec_delay(current_attempts + 1)
            attempt_name = self.get_attempt_name(current_attempts + 1)
            
            logger.info(f"ğŸ”„ {exchange} åŸ·è¡Œ {attempt_name}ï¼Œç­‰å¾… {delay}s...")
            await asyncio.sleep(delay)
            
            success = await self.connection_manager.establish_connection(exchange, uri)
            
            if success:
                self.current_attempt[exchange] = 0
                logger.info(f"âœ… {exchange} é‡é€£æˆåŠŸ ({attempt_name})")
                return True
            else:
                self.current_attempt[exchange] = current_attempts + 1
                self.last_attempt_time[exchange] = datetime.now()
                logger.warning(f"âŒ {exchange} {attempt_name} å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"âŒ {exchange} é‡é€£å¤±æ•—: {e}")
            return False
    
    async def get_json_spec_delay(self, attempt_number: int) -> float:
        """ç²å–JSONè¦ç¯„ç²¾ç¢ºå»¶é²æ™‚é–“"""
        if attempt_number == 1:
            return self.reconnection_delays["1st_attempt"]  # 0s
        elif attempt_number == 2:
            return self.reconnection_delays["2nd_attempt"]  # 1s
        elif attempt_number == 3:
            return self.reconnection_delays["3rd_attempt"]  # 2s
        elif attempt_number == 4:
            return self.reconnection_delays["4th_attempt"]  # 4s
        else:  # 5th and beyond
            return self.reconnection_delays["5th_attempt_plus"]  # 8s
    
    def get_attempt_name(self, attempt_number: int) -> str:
        """ç²å–å˜—è©¦åç¨±"""
        if attempt_number == 1:
            return "1st_attempt"
        elif attempt_number == 2:
            return "2nd_attempt" 
        elif attempt_number == 3:
            return "3rd_attempt"
        elif attempt_number == 4:
            return "4th_attempt"
        else:
            return "5th_attempt_plus"
    
    async def implement_exponential_backoff(self, exchange: str, attempt: int) -> float:
        """å¯¦ç¾æŒ‡æ•¸é€€é¿ - ä¿ç•™å…¼å®¹æ€§"""
        return await self.get_json_spec_delay(attempt + 1)

class EventBroadcaster:
    """äº‹ä»¶å»£æ’­å™¨ - è² è²¬å°‡æ•¸æ“šåˆ†ç™¼åˆ°ä¸åŒçš„çµ‚é»"""
    
    def __init__(self):
        self.subscribers = []
        self.topic_subscribers = defaultdict(list)
        self.performance_monitor = None
        # JSONè¦ç¯„: Layer 3 è·¯ç”±ç›®æ¨™
        self.routing_targets = {
            "phase1a_basic_signal_generation": [],
            "indicator_dependency_graph": [],
            "phase1b_volatility_adaptation": [],
            "unified_signal_candidate_pool": []
        }
        
    def subscribe(self, callback: callable, topics: List[str] = None):
        """è¨‚é–±äº‹ä»¶"""
        if topics:
            for topic in topics:
                self.topic_subscribers[topic].append(callback)
        else:
            self.subscribers.append(callback)
    
    def register_routing_target(self, target_name: str, callback: callable):
        """è¨»å†ŠJSONè¦ç¯„è·¯ç”±ç›®æ¨™"""
        if target_name in self.routing_targets:
            self.routing_targets[target_name].append(callback)
            
    async def broadcast(self, event_type: str, data: Dict[str, Any]):
        """å»£æ’­äº‹ä»¶åˆ°æ‰€æœ‰è¨‚é–±è€…"""
        broadcast_start = time.time()
        
        # å»£æ’­çµ¦é€šç”¨è¨‚é–±è€…
        for callback in self.subscribers:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(event_type, data)
                else:
                    callback(event_type, data)
            except Exception as e:
                logger.error(f"Error in subscriber callback: {e}")
        
        # å»£æ’­çµ¦ä¸»é¡Œç‰¹å®šè¨‚é–±è€…
        for callback in self.topic_subscribers[event_type]:
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(event_type, data)
                else:
                    callback(event_type, data)
            except Exception as e:
                logger.error(f"Error in topic subscriber callback: {e}")
        
        # JSONè¦ç¯„: åˆ†ç™¼åˆ°è·¯ç”±ç›®æ¨™
        await self._distribute_to_routing_targets(event_type, data)
        
        # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
        if self.performance_monitor:
            broadcast_time = (time.time() - broadcast_start) * 1000
            await self.performance_monitor.record_broadcast_latency(broadcast_time)
    
    async def _distribute_to_routing_targets(self, event_type: str, data: Dict[str, Any]):
        """åˆ†ç™¼åˆ°JSONè¦ç¯„è·¯ç”±ç›®æ¨™"""
        try:
            # æ ¹æ“šæ•¸æ“šé¡å‹æ±ºå®šè·¯ç”±
            data_type = data.get('type', '')
            
            if data_type in ['kline_data', 'real_time_trades']:
                # Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆ
                for callback in self.routing_targets['phase1a_basic_signal_generation']:
                    await self._safe_callback(callback, event_type, data)
                
                # æŒ‡æ¨™ä¾è³´åœ–
                for callback in self.routing_targets['indicator_dependency_graph']:
                    await self._safe_callback(callback, event_type, data)
            
            if data_type in ['orderbook_data', 'mark_price']:
                # Phase1Bæ³¢å‹•ç‡é©æ‡‰
                for callback in self.routing_targets['phase1b_volatility_adaptation']:
                    await self._safe_callback(callback, event_type, data)
            
            # çµ±ä¸€ä¿¡è™Ÿå€™é¸æ± ï¼ˆæ‰€æœ‰æ•¸æ“šï¼‰
            for callback in self.routing_targets['unified_signal_candidate_pool']:
                await self._safe_callback(callback, event_type, data)
                
        except Exception as e:
            logger.error(f"Error in routing distribution: {e}")
    
    async def _safe_callback(self, callback: callable, event_type: str, data: Dict[str, Any]):
        """å®‰å…¨åŸ·è¡Œå›èª¿"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(event_type, data)
            else:
                callback(event_type, data)
        except Exception as e:
            logger.error(f"Error in routing callback: {e}")

class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨ - ç¬¦åˆJSONè¦ç¯„"""
    
    def __init__(self):
        self.message_rates: Dict[str, float] = {}
        self.processing_latencies: Dict[str, List[float]] = {}
        self.throughput_metrics: Dict[str, int] = {}
        self.last_measurement_time: Dict[str, datetime] = {}
        self.message_counts: Dict[str, int] = {}
        self.start_time = None
        self.is_running = False
    
    def start(self):
        """å•Ÿå‹•æ€§èƒ½ç›£æ§"""
        self.start_time = datetime.now()
        self.is_running = True
        logger.info("âœ… æ€§èƒ½ç›£æ§å·²å•Ÿå‹•")
    
    def stop(self):
        """åœæ­¢æ€§èƒ½ç›£æ§"""
        self.is_running = False
        logger.info("âœ… æ€§èƒ½ç›£æ§å·²åœæ­¢")
    
    def get_metrics(self) -> Dict[str, Any]:
        """ç²å–æŒ‡æ¨™"""
        if not self.is_running:
            return {}
            
        uptime = (datetime.now() - self.start_time).total_seconds() if self.start_time else 0
        
        return {
            "uptime_seconds": uptime,
            "total_messages": sum(self.message_counts.values()),
            "message_rates": self.message_rates.copy(),
            "avg_latencies": {
                exchange: sum(latencies) / len(latencies) if latencies else 0
                for exchange, latencies in self.processing_latencies.items()
            }
        }

class HeartbeatManager:
    """å¿ƒè·³ç®¡ç†å™¨ - ç¬¦åˆJSONè¦ç¯„"""
    
    def __init__(self, connection_manager: ConnectionManager):
        self.connection_manager = connection_manager
        self.heartbeat_intervals: Dict[str, float] = {}
        self.last_heartbeat_sent: Dict[str, datetime] = {}
        self.last_pong_received: Dict[str, datetime] = {}
        self.heartbeat_tasks: Dict[str, asyncio.Task] = {}
        self.default_interval: float = 30.0  # 30ç§’
        self.is_running = False
    
    async def start(self):
        """å•Ÿå‹•å¿ƒè·³ç®¡ç†"""
        try:
            self.is_running = True
            
            # ç‚ºæ‰€æœ‰é€£æ¥çš„äº¤æ˜“æ‰€å•Ÿå‹•å¿ƒè·³
            for exchange in self.connection_manager.connections.keys():
                await self.schedule_heartbeat(exchange)
                
            logger.info("âœ… å¿ƒè·³ç®¡ç†å·²å•Ÿå‹•")
            
        except Exception as e:
            logger.error(f"âŒ å¿ƒè·³ç®¡ç†å•Ÿå‹•å¤±æ•—: {e}")
    
    async def stop(self):
        """åœæ­¢å¿ƒè·³ç®¡ç†"""
        try:
            self.is_running = False
            
            # åœæ­¢æ‰€æœ‰å¿ƒè·³ä»»å‹™
            for exchange in list(self.heartbeat_tasks.keys()):
                await self.stop_heartbeat(exchange)
                
            logger.info("âœ… å¿ƒè·³ç®¡ç†å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"âŒ å¿ƒè·³ç®¡ç†åœæ­¢å¤±æ•—: {e}")
    
    async def send_heartbeat(self, exchange: str) -> bool:
        """ç™¼é€å¿ƒè·³"""
        try:
            if exchange not in self.connection_manager.connections:
                return False
            
            # ç°¡åŒ–çš„å¿ƒè·³å¯¦ç¾
            self.last_heartbeat_sent[exchange] = datetime.now()
            self.last_pong_received[exchange] = datetime.now()  # Mock pong
            
            logger.debug(f"ğŸ’“ {exchange} å¿ƒè·³æ­£å¸¸")
            return True
                
        except Exception as e:
            logger.error(f"âŒ {exchange} å¿ƒè·³ç™¼é€å¤±æ•—: {e}")
            return False
    
    async def schedule_heartbeat(self, exchange: str, interval: Optional[float] = None):
        """æ’ç¨‹å¿ƒè·³"""
        if interval is None:
            interval = self.default_interval
            
        self.heartbeat_intervals[exchange] = interval
        
        # å–æ¶ˆç¾æœ‰ä»»å‹™
        if exchange in self.heartbeat_tasks:
            self.heartbeat_tasks[exchange].cancel()
            
        # å‰µå»ºæ–°çš„å¿ƒè·³ä»»å‹™
        self.heartbeat_tasks[exchange] = asyncio.create_task(
            self._heartbeat_loop(exchange, interval)
        )
    
    async def _heartbeat_loop(self, exchange: str, interval: float):
        """å¿ƒè·³å¾ªç’°"""
        try:
            while self.is_running:
                await asyncio.sleep(interval)
                
                success = await self.send_heartbeat(exchange)
                if not success:
                    logger.warning(f"âš ï¸ {exchange} å¿ƒè·³å¤±æ•—ï¼Œå¯èƒ½éœ€è¦é‡é€£")
                    await self.connection_manager.handle_connection_lost(exchange)
                    break
                    
        except asyncio.CancelledError:
            logger.info(f"ğŸ’“ {exchange} å¿ƒè·³ä»»å‹™å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ {exchange} å¿ƒè·³å¾ªç’°éŒ¯èª¤: {e}")
    
    async def stop_heartbeat(self, exchange: str):
        """åœæ­¢å¿ƒè·³"""
        if exchange in self.heartbeat_tasks:
            self.heartbeat_tasks[exchange].cancel()
            try:
                await self.heartbeat_tasks[exchange]
            except asyncio.CancelledError:
                pass
            del self.heartbeat_tasks[exchange]
            
        if exchange in self.heartbeat_intervals:
            del self.heartbeat_intervals[exchange]

class DataBuffer:
    """æ•¸æ“šç·©è¡å™¨ - ç¬¦åˆJSONè¦ç¯„"""
    
    def __init__(self, max_size: int = 10000):
        self.max_size = max_size
        self.ticker_buffer: deque = deque(maxlen=max_size)
        self.kline_buffer: deque = deque(maxlen=max_size)
        self.depth_buffer: deque = deque(maxlen=max_size)
        self.trade_buffer: deque = deque(maxlen=max_size)
        self.buffer_size_limits: Dict[str, int] = {}
        self.lock = threading.Lock()
    
    def get_latest_snapshot(self, symbol: str) -> Optional[MarketDataSnapshot]:
        """ç²å–æœ€æ–°å¿«ç…§"""
        try:
            with self.lock:
                # ç°¡åŒ–å¯¦ç¾ï¼Œè¿”å›æ¨¡æ“¬æ•¸æ“š
                return MarketDataSnapshot(
                    symbol=symbol,
                    timestamp=datetime.now(),
                    price=50000.0,
                    volume=1000.0,
                    bid=49999.0,
                    ask=50001.0,
                    source_exchange="binance",
                    latency_ms=5.0,
                    data_quality=1.0
                )
                
        except Exception as e:
            logger.error(f"âŒ ç²å–æœ€æ–°å¿«ç…§å¤±æ•—: {e}")
            return None
    
    def get_stats(self) -> Dict[str, int]:
        """ç²å–ç·©è¡å€çµ±è¨ˆ"""
        try:
            with self.lock:
                return {
                    "ticker_count": len(self.ticker_buffer),
                    "kline_count": len(self.kline_buffer),
                    "depth_count": len(self.depth_buffer),
                    "trade_count": len(self.trade_buffer),
                    "total_count": (
                        len(self.ticker_buffer) + 
                        len(self.kline_buffer) + 
                        len(self.depth_buffer) + 
                        len(self.trade_buffer)
                    )
                }
                
        except Exception as e:
            logger.error(f"âŒ ç·©è¡å€çµ±è¨ˆç²å–å¤±æ•—: {e}")
            return {}

class TechnicalAnalysisProcessor:
    """æŠ€è¡“åˆ†æè™•ç†å™¨"""
    
    def __init__(self):
        self.price_cache = {}
        self.volume_cache = {}
    
    def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è™•ç†æŠ€è¡“åˆ†æ"""
        # ç°¡åŒ–å¯¦ç¾
        return data

class IndicatorCache:
    """æŒ‡æ¨™å¿«å–"""
    
    def __init__(self):
        self.cache = {}
    
    def get(self, key: str) -> Any:
        return self.cache.get(key)
    
    def set(self, key: str, value: Any):
        self.cache[key] = value

class WebSocketRealtimeDriver:
    """WebSocketå¯¦æ™‚é©…å‹•å™¨ - ç¬¦åˆJSONè¦ç¯„ï¼ŒåŒ…å«å®Œæ•´çš„async def stopå¯¦ç¾"""
    
    def __init__(self):
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        self.config_manager = get_websocket_config()
        
        # æ ¸å¿ƒçµ„ä»¶åˆå§‹åŒ–
        self.connection_manager = ConnectionManager(self)
        self.message_processor = MessageProcessor()
        self.reconnection_handler = ReconnectionHandler(self.connection_manager)
        self.event_broadcaster = EventBroadcaster()
        self.performance_monitor = PerformanceMonitor()
        self.heartbeat_manager = HeartbeatManager(self.connection_manager)
        self.data_buffer = DataBuffer()
        
        # JSONè¦ç¯„: Layer 1 & 2 çµ„ä»¶
        self.data_validator = DataValidator()
        self.data_cleaner = DataCleaner()
        self.data_standardizer = DataStandardizer()
        self.basic_computation_engine = BasicComputationEngine()
        
        # æŠ€è¡“åˆ†æçµ„ä»¶
        self.ta_processor = TechnicalAnalysisProcessor()
        self.indicator_cache = IndicatorCache()
        
        # JSONè¦ç¯„: æ•´åˆè¼¸å‡ºé…ç½®
        self.integration_outputs = {
            "real_time_signal_generation": {
                "enabled": True,
                "latency_target": 12,  # ms
                "data_types": ["kline_data", "real_time_trades", "mark_price"]
            },
            "indicator_dependency_graph": {
                "enabled": True, 
                "update_frequency": "high",
                "dependencies": ["price_momentum", "volume_trend", "volatility"]
            },
            "phase1b_volatility_adaptation": {
                "enabled": True,
                "adaptation_speed": "fast",
                "required_inputs": ["orderbook_data", "mark_price", "real_time_trades"]
            },
            "unified_signal_candidate_pool": {
                "enabled": True,
                "aggregation_method": "weighted_average",
                "confidence_threshold": 0.6
            }
        }
        
        # JSONè¦ç¯„: æä¾›çš„æœå‹™
        self.provided_services = {
            "real_time_data_stream": {
                "description": "High-frequency real-time market data streaming",
                "latency": "<3ms",
                "throughput": "10000+ msg/sec",
                "data_types": ["kline", "orderbook", "trades", "mark_price"]
            },
            "cross_exchange_arbitrage_feed": {
                "description": "Cross-exchange price difference monitoring",
                "update_frequency": "real_time",
                "supported_exchanges": ["binance", "okx", "bybit"]
            },
            "enhanced_market_depth_analysis": {
                "description": "Deep orderbook analysis with liquidity metrics",
                "depth_levels": 20,
                "analysis_types": ["liquidity_gaps", "volume_clustering", "price_levels"]
            },
            "adaptive_signal_generation": {
                "description": "Dynamic signal generation based on market conditions",
                "adaptation_methods": ["volatility_based", "volume_based", "momentum_based"],
                "signal_types": ["entry", "exit", "risk_management"]
            }
        }
        
        # ç‹€æ…‹ç®¡ç†
        self.status = SystemStatus.IDLE
        self.last_status_update = time.time()
        self.is_running = False
        self.start_time = None
        
        # ä»»å‹™ç®¡ç†
        self.tasks: List[asyncio.Task] = []
        
        # é€£æ¥èˆ‡è¨‚é–± - å¾é…ç½®ç®¡ç†å™¨ç²å–
        self.connections: Dict[str, WebSocketConnection] = {}
        
        # å¾é…ç½®ç²å–å•Ÿç”¨çš„äº¤æ˜“æ‰€
        enabled_exchanges = self.config_manager.get_enabled_exchanges()
        self.active_exchanges = []
        for exchange in enabled_exchanges:
            endpoints = self.config_manager.get_exchange_endpoints(exchange)
            if 'spot' in endpoints:
                self.active_exchanges.append(f"{exchange}_spot")
            if 'futures' in endpoints:
                self.active_exchanges.append(f"{exchange}_futures")
        
        # è¨­å®šä¸»è¦å’Œå‚™ç”¨äº¤æ˜“æ‰€
        self.primary_exchange = self.active_exchanges[0] if self.active_exchanges else 'binance_spot'
        self.backup_exchanges = self.active_exchanges[1:] if len(self.active_exchanges) > 1 else []
        
        # JSONè¦ç¯„: ä½¿ç”¨ç²¾ç¢ºçš„è¼¸å‡ºæ ¼å¼åç¨±
        self.layer_outputs = {
            "ğŸ”Œ active_connection_pool": {},
            "ğŸ”„ reconnection_status": {},
            "ğŸ“Š raw_multitype_data_stream": {},
            "ğŸ” validated_data_stream": {},
            "ğŸ§¹ cleaned_data_stream": {},
            "ğŸ“ standardized_data_stream": {},
            "ğŸ”¢ calculated_metrics_stream": {},
            "ğŸ¯ routed_data_streams": {},
            "ğŸ“¡ published_data_streams": {},
            "ğŸ“Š monitoring_metrics": {}
        }
        
        # äº‹ä»¶é©…å‹•å¿«å–ç³»çµ±
        self.subscribers: Dict[str, List[Callable]] = {
            'kline': [],
            'ticker': [],
            'book_ticker': [],
            'trade': [],
            'depth': [],
            'system_status': [],
            'error': []
        }
        
        # JSONè¦ç¯„: è¨­ç½®è·¯ç”±ç›®æ¨™
        self._setup_routing_targets()
        
        # æ—¥èªŒè¨­ç½®
        self.logger = logging.getLogger(__name__)
        
        self.logger.info("WebSocketRealtimeDriver åˆå§‹åŒ–å®Œæˆ - JSONè¦ç¯„å®Œæ•´å¯¦ç¾")
    
    async def start(self, symbols: List[str] = None):
        """å•Ÿå‹•WebSocketé€£æ¥"""
        try:
            if self.is_running:
                self.logger.warning("WebSocket driver already running")
                return
            
            self.is_running = True
            self.start_time = time.time()
            self.status = SystemStatus.STARTING
            
            # ä½¿ç”¨é»˜èªäº¤æ˜“å°å¦‚æœæ²’æœ‰æŒ‡å®š
            if symbols is None:
                symbols = ['BTCUSDT', 'ETHUSDT', 'ADAUSDT', 'SOLUSDT']
            
            # å•Ÿå‹•é€£æ¥ç®¡ç†å™¨
            await self.connection_manager.start_connections(symbols)
            
            # å•Ÿå‹•å¿ƒè·³ç®¡ç†
            await self.heartbeat_manager.start()
            
            # å•Ÿå‹•æ€§èƒ½ç›£æ§
            self.performance_monitor.start()
            
            self.status = SystemStatus.RUNNING
            self.logger.info(f"WebSocket driver started for symbols: {symbols}")
            
            # å»£æ’­å•Ÿå‹•äº‹ä»¶
            await self.event_broadcaster.broadcast_system_status(
                SystemStatus.RUNNING, {"symbols": symbols}
            )
            
        except Exception as e:
            self.status = SystemStatus.ERROR
            self.logger.error(f"Failed to start WebSocket driver: {e}")
            await self.event_broadcaster.broadcast_error("start_error", str(e))
            raise
    
    async def stop(self):
        """åœæ­¢WebSocketé€£æ¥å’Œæ‰€æœ‰æœå‹™"""
        try:
            if not self.is_running:
                self.logger.warning("WebSocket driver is not running")
                return
            
            self.status = SystemStatus.STOPPING
            self.logger.info("Stopping WebSocket driver...")
            
            # åœæ­¢å¿ƒè·³ç®¡ç†
            if self.heartbeat_manager:
                await self.heartbeat_manager.stop()
            
            # åœæ­¢é€£æ¥ç®¡ç†å™¨
            if self.connection_manager:
                await self.connection_manager.close_all_connections()
            
            # å–æ¶ˆæ‰€æœ‰ä»»å‹™
            for task in self.tasks:
                if not task.done():
                    task.cancel()
                    try:
                        await task
                    except asyncio.CancelledError:
                        pass
            
            self.tasks.clear()
            
            # åœæ­¢æ€§èƒ½ç›£æ§
            if self.performance_monitor:
                self.performance_monitor.stop()
            
            self.is_running = False
            self.status = SystemStatus.STOPPED
            
            # å»£æ’­åœæ­¢äº‹ä»¶
            await self.event_broadcaster.broadcast_system_status(
                SystemStatus.STOPPED, {}
            )
            
            self.logger.info("WebSocket driver stopped successfully")
            
        except Exception as e:
            self.status = SystemStatus.ERROR
            self.logger.error(f"Error stopping WebSocket driver: {e}")
            await self.event_broadcaster.broadcast_error("stop_error", str(e))
            raise
    
    def subscribe(self, event_type: str, callback: Callable):
        """è¨‚é–±äº‹ä»¶"""
        if event_type in self.subscribers:
            self.subscribers[event_type].append(callback)
            self.logger.info(f"Subscribed to {event_type} events")
        else:
            self.logger.warning(f"Unknown event type: {event_type}")
    
    def unsubscribe(self, event_type: str, callback: Callable):
        """å–æ¶ˆè¨‚é–±äº‹ä»¶"""
        if event_type in self.subscribers and callback in self.subscribers[event_type]:
            self.subscribers[event_type].remove(callback)
            self.logger.info(f"Unsubscribed from {event_type} events")
    
    async def get_latest_data(self, symbol: str) -> Optional[MarketDataSnapshot]:
        """ç²å–æœ€æ–°å¸‚å ´æ•¸æ“š"""
        return self.data_buffer.get_latest_snapshot(symbol)
    
    
    async def generate_connection_health_status(self) -> Dict[str, Any]:
        """ç”Ÿæˆé€£æ¥å¥åº·ç‹€æ…‹ - JSONè¦ç¯„è¦æ±‚"""
        try:
            health_status = {
                "type": "connection_health_status",
                "timestamp": time.time(),
                "total_connections": len(self.connections),
                "active_connections": sum(1 for conn in self.connections.values() if conn.status == ConnectionState.CONNECTED),
                "failed_connections": sum(1 for conn in self.connections.values() if conn.status == ConnectionState.ERROR),
                "average_latency": self._calculate_average_latency(),
                "connection_stability": self._calculate_connection_stability()
            }
            self.layer_outputs["ğŸ”Œ active_connection_pool"] = health_status
            return health_status
        except:
            return {}
    
    async def generate_extreme_events_anomaly_detections(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ¥µç«¯äº‹ä»¶å’Œç•°å¸¸æª¢æ¸¬ - JSONè¦ç¯„è¦æ±‚"""
        try:
            extreme_events = {
                "type": "extreme_events + anomaly_detections",
                "symbol": data.get('symbol'),
                "timestamp": data.get('timestamp'),
                "extreme_price_move": self._detect_extreme_price_move(data),
                "volume_anomaly": self._detect_volume_anomaly(data),
                "spread_anomaly": self._detect_spread_anomaly(data),
                "market_disruption": self._detect_market_disruption(data),
                "anomaly_score": 0.0
            }
            return extreme_events
        except:
            return {}
    
    async def generate_price_volume_basic_indicators(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåƒ¹æ ¼æˆäº¤é‡åŸºç¤æŒ‡æ¨™ - JSONè¦ç¯„è¦æ±‚"""
        try:
            indicators = {
                "type": "price_volume_data + basic_indicators",
                "symbol": data.get('symbol'),
                "timestamp": data.get('timestamp'),
                "price_momentum": await self.basic_computation_engine.calculate_price_indicators(data),
                "volume_trend": await self.basic_computation_engine.calculate_volume_indicators(data),
                "basic_technical_indicators": {
                    "rsi": self._calculate_rsi(data),
                    "macd": self._calculate_macd(data),
                    "moving_averages": self._calculate_moving_averages(data)
                }
            }
            return indicators
        except:
            return {}
    
    async def generate_volatility_metrics_price_momentum(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ³¢å‹•ç‡æŒ‡æ¨™å’Œåƒ¹æ ¼å‹•é‡ - JSONè¦ç¯„è¦æ±‚"""
        try:
            metrics = {
                "type": "volatility_metrics + price_momentum",
                "symbol": data.get('symbol'),
                "timestamp": data.get('timestamp'),
                "realized_volatility": self._calculate_realized_volatility(data),
                "implied_volatility": self._calculate_implied_volatility(data),
                "price_momentum": self._calculate_price_momentum(data),
                "momentum_strength": self._calculate_momentum_strength(data),
                "volatility_regime": self._determine_volatility_regime(data)
            }
            return metrics
        except:
            return {}
    
    async def generate_all_processed_data(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰€æœ‰è™•ç†å¾Œæ•¸æ“š - JSONè¦ç¯„è¦æ±‚"""
        try:
            all_data = {
                "type": "all_processed_data",
                "timestamp": time.time(),
                "processed_tickers": len(self.message_processor.processed_ticker_data),
                "processed_klines": len(self.message_processor.processed_kline_data),
                "processed_depth": len(self.message_processor.processed_depth_data),
                "processed_trades": len(self.message_processor.processed_trade_data),
                "processed_mark_prices": len(self.message_processor.processed_mark_price_data),
                "total_processed": (
                    len(self.message_processor.processed_ticker_data) +
                    len(self.message_processor.processed_kline_data) +
                    len(self.message_processor.processed_depth_data) +
                    len(self.message_processor.processed_trade_data) +
                    len(self.message_processor.processed_mark_price_data)
                )
            }
            return all_data
        except:
            return {}
    
    def _detect_extreme_price_move(self, data: Dict[str, Any]) -> bool:
        """æª¢æ¸¬æ¥µç«¯åƒ¹æ ¼ç§»å‹•"""
        try:
            price_change_pct = data.get('price_change_pct', 0)
            return abs(price_change_pct) > 0.05  # 5%è¦–ç‚ºæ¥µç«¯
        except:
            return False
    
    def _detect_volume_anomaly(self, data: Dict[str, Any]) -> bool:
        """æª¢æ¸¬æˆäº¤é‡ç•°å¸¸"""
        try:
            volume = data.get('volume', 0)
            avg_volume = data.get('avg_volume', volume)
            return volume > 3 * avg_volume if avg_volume > 0 else False
        except:
            return False
    
    def _detect_spread_anomaly(self, data: Dict[str, Any]) -> bool:
        """æª¢æ¸¬åƒ¹å·®ç•°å¸¸"""
        try:
            spread = data.get('bid_ask_spread', 0)
            return spread > 0.01  # 1%è¦–ç‚ºç•°å¸¸
        except:
            return False
    
    def _detect_market_disruption(self, data: Dict[str, Any]) -> bool:
        """æª¢æ¸¬å¸‚å ´ä¸­æ–·"""
        try:
            # ç°¡åŒ–å¯¦ç¾
            return False
        except:
            return False
    
    def _calculate_rsi(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—RSI"""
        return 50.0  # ç°¡åŒ–å¯¦ç¾
    
    def _calculate_macd(self, data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—MACD"""
        return {"macd": 0.0, "signal": 0.0, "histogram": 0.0}
    
    def _calculate_moving_averages(self, data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—ç§»å‹•å¹³å‡ç·š"""
        price = data.get('close', data.get('price', 0))
        return {"sma_20": price, "ema_12": price, "ema_26": price}
    
    def _calculate_realized_volatility(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—å·²å¯¦ç¾æ³¢å‹•ç‡"""
        return 0.02  # ç°¡åŒ–å¯¦ç¾
    
    def _calculate_implied_volatility(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—éš±å«æ³¢å‹•ç‡"""
        return 0.025  # ç°¡åŒ–å¯¦ç¾
    
    def _calculate_price_momentum(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—åƒ¹æ ¼å‹•é‡"""
        return data.get('price_change_pct', 0)
    
    def _calculate_momentum_strength(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—å‹•é‡å¼·åº¦"""
        momentum = abs(data.get('price_change_pct', 0))
        return min(1.0, momentum * 10)
    
    def _determine_volatility_regime(self, data: Dict[str, Any]) -> str:
        """ç¢ºå®šæ³¢å‹•ç‡åˆ¶åº¦"""
        volatility = self._calculate_realized_volatility(data)
        if volatility > 0.03:
            return "high"
        elif volatility < 0.01:
            return "low"
        else:
            return "medium"
    
    def _calculate_average_latency(self) -> float:
        """è¨ˆç®—å¹³å‡å»¶é²"""
        return 5.0  # ç°¡åŒ–å¯¦ç¾
    
    def _calculate_connection_stability(self) -> float:
        """è¨ˆç®—é€£æ¥ç©©å®šæ€§"""
        total_connections = len(self.connections)
        active_connections = sum(1 for conn in self.connections.values() if conn.status == ConnectionState.CONNECTED)
        return active_connections / total_connections if total_connections > 0 else 0.0

    def get_status(self) -> dict:
        """ç²å–ç³»çµ±ç‹€æ…‹"""
        uptime = time.time() - self.start_time if self.start_time else 0
        
        return {
            "status": self.status.value,
            "is_running": self.is_running,
            "uptime_seconds": uptime,
            "active_connections": len(self.connections),
            "active_exchanges": self.active_exchanges,
            "performance_metrics": self.performance_monitor.get_metrics() if self.performance_monitor else {},
            "buffer_stats": self.data_buffer.get_stats(),
            "last_update": self.last_status_update
        }
    
    async def restart(self):
        """é‡å•Ÿç³»çµ±"""
        self.logger.info("Restarting WebSocket driver...")
        await self.stop()
        await asyncio.sleep(1)  # çŸ­æš«å»¶é²
        await self.start()
    
    def _extract_technical_indicators(self, kline: KlineData) -> Dict[str, float]:
        """æå–æŠ€è¡“æŒ‡æ¨™æ•¸æ“šä»¥ç¬¦åˆJSONè¦ç¯„"""
        indicators = {}
        
        # åŸºç¤åƒ¹æ ¼æŒ‡æ¨™
        indicators['open'] = float(kline.open_price)
        indicators['high'] = float(kline.high_price) 
        indicators['low'] = float(kline.low_price)
        indicators['close'] = float(kline.close_price)
        indicators['volume'] = float(kline.volume)
        
        # ç§»å‹•å¹³å‡ç·š
        if hasattr(kline, 'sma_20'):
            indicators['sma_20'] = float(kline.sma_20)
        if hasattr(kline, 'ema_12'):
            indicators['ema_12'] = float(kline.ema_12)
        if hasattr(kline, 'ema_26'):
            indicators['ema_26'] = float(kline.ema_26)
        
        # MACDæŒ‡æ¨™
        if hasattr(kline, 'macd'):
            indicators['macd'] = float(kline.macd)
        if hasattr(kline, 'macd_signal'):
            indicators['macd_signal'] = float(kline.macd_signal)
        if hasattr(kline, 'macd_histogram'):
            indicators['macd_histogram'] = float(kline.macd_histogram)
        
        # RSIæŒ‡æ¨™
        if hasattr(kline, 'rsi'):
            indicators['rsi'] = float(kline.rsi)
        
        # å¸ƒæ—å¸¶
        if hasattr(kline, 'bb_upper'):
            indicators['bb_upper'] = float(kline.bb_upper)
        if hasattr(kline, 'bb_middle'):
            indicators['bb_middle'] = float(kline.bb_middle)
        if hasattr(kline, 'bb_lower'):
            indicators['bb_lower'] = float(kline.bb_lower)
        
        # éš¨æ©ŸæŒ‡æ¨™
        if hasattr(kline, 'stoch_k'):
            indicators['stoch_k'] = float(kline.stoch_k)
        if hasattr(kline, 'stoch_d'):
            indicators['stoch_d'] = float(kline.stoch_d)
        
        # å¨å»‰æŒ‡æ¨™
        if hasattr(kline, 'williams_r'):
            indicators['williams_r'] = float(kline.williams_r)
        
        # ATRæŒ‡æ¨™
        if hasattr(kline, 'atr'):
            indicators['atr'] = float(kline.atr)
        
        # CCIæŒ‡æ¨™  
        if hasattr(kline, 'cci'):
            indicators['cci'] = float(kline.cci)
        
        # å‹•é‡æŒ‡æ¨™
        if hasattr(kline, 'momentum'):
            indicators['momentum'] = float(kline.momentum)
        
        # åƒ¹æ ¼è®ŠåŒ–ç™¾åˆ†æ¯”
        if hasattr(kline, 'price_change_pct'):
            indicators['price_change_pct'] = float(kline.price_change_pct)
        
        # æˆäº¤é‡åŠ æ¬Šå¹³å‡åƒ¹
        if hasattr(kline, 'vwap'):
            indicators['vwap'] = float(kline.vwap)
        
        # æˆäº¤é‡ç•°å¸¸
        indicators['volume_anomaly'] = 1.0 if kline.volume_anomaly else 0.0
        
        return indicators
    
    def _setup_routing_targets(self):
        """è¨­ç½®JSONè¦ç¯„è·¯ç”±ç›®æ¨™"""
        # Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆè·¯ç”±
        self.event_broadcaster.register_routing_target(
            "phase1a_basic_signal_generation", 
            self._handle_phase1a_signal_generation
        )
        
        # æŒ‡æ¨™ä¾è³´åœ–è·¯ç”±  
        self.event_broadcaster.register_routing_target(
            "indicator_dependency_graph",
            self._handle_indicator_dependency_update
        )
        
        # Phase1Bæ³¢å‹•ç‡é©æ‡‰è·¯ç”±
        self.event_broadcaster.register_routing_target(
            "phase1b_volatility_adaptation",
            self._handle_volatility_adaptation
        )
        
        # çµ±ä¸€ä¿¡è™Ÿå€™é¸æ± è·¯ç”±
        self.event_broadcaster.register_routing_target(
            "unified_signal_candidate_pool",
            self._handle_unified_signal_pool
        )
    
    async def _handle_phase1a_signal_generation(self, event_type: str, data: Dict[str, Any]):
        """è™•ç†Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆ"""
        try:
            if data.get('type') in ['kline_data', 'real_time_trades']:
                # è¨ˆç®—åŸºç¤æŒ‡æ¨™
                indicators = await self.basic_computation_engine.calculate_price_indicators(data)
                
                # ç”ŸæˆåŸºç¤ä¿¡è™Ÿ
                signal_data = {
                    "signal_type": "phase1a_basic",
                    "symbol": data.get('symbol'),
                    "timestamp": data.get('timestamp'),
                    "indicators": indicators,
                    "confidence": self._calculate_signal_confidence(indicators)
                }
                
                # ç™¼é€åˆ°çµ±ä¸€ä¿¡è™Ÿæ± 
                await self.event_broadcaster.broadcast("signal_generated", signal_data)
            
            # JSONè¦ç¯„: ç”Ÿæˆ real_time_price è¼¸å‡º
            real_time_price_data = {
                "type": "real_time_price",
                "symbol": data.get('symbol'),
                "price": data.get('close', data.get('price', 0)),
                "timestamp": data.get('timestamp'),
                "source_exchange": data.get('source_exchange'),
                "price_change": data.get('price_change', 0),
                "price_change_pct": data.get('price_change_pct', 0)
            }
            await self.event_broadcaster.broadcast("real_time_price", real_time_price_data)
                
        except Exception as e:
            self.logger.error(f"Phase1A signal generation error: {e}")
    
    async def _handle_indicator_dependency_update(self, event_type: str, data: Dict[str, Any]):
        """è™•ç†æŒ‡æ¨™ä¾è³´åœ–æ›´æ–°"""
        try:
            # æ›´æ–°æŒ‡æ¨™ä¾è³´é—œä¿‚
            indicator_update = {
                "dependency_type": "real_time_update",
                "source_data": data.get('type'),
                "affected_indicators": self._get_affected_indicators(data),
                "update_timestamp": time.time()
            }
            
            # å»£æ’­æŒ‡æ¨™æ›´æ–°
            await self.event_broadcaster.broadcast("indicator_dependency_updated", indicator_update)
            
        except Exception as e:
            self.logger.error(f"Indicator dependency update error: {e}")
    
    async def _handle_volatility_adaptation(self, event_type: str, data: Dict[str, Any]):
        """è™•ç†Phase1Bæ³¢å‹•ç‡é©æ‡‰"""
        try:
            if data.get('type') in ['orderbook_data', 'mark_price']:
                # è¨ˆç®—æ³¢å‹•ç‡æŒ‡æ¨™
                volatility_metrics = await self._calculate_volatility_metrics(data)
                
                # é©æ‡‰ä¿¡è™Ÿç”Ÿæˆåƒæ•¸
                adaptation_signal = {
                    "adaptation_type": "volatility_based",
                    "symbol": data.get('symbol'),
                    "volatility_level": volatility_metrics.get('volatility_level'),
                    "adaptation_params": self._generate_adaptation_params(volatility_metrics),
                    "timestamp": time.time()
                }
                
                await self.event_broadcaster.broadcast("volatility_adaptation", adaptation_signal)
                
        except Exception as e:
            self.logger.error(f"Volatility adaptation error: {e}")
    
    async def _handle_unified_signal_pool(self, event_type: str, data: Dict[str, Any]):
        """è™•ç†çµ±ä¸€ä¿¡è™Ÿå€™é¸æ± """
        try:
            # æ‰€æœ‰æ•¸æ“šéƒ½é€²å…¥çµ±ä¸€æ± é€²è¡Œèšåˆ
            pool_entry = {
                "entry_type": "raw_data",
                "data_source": data.get('type'),
                "symbol": data.get('symbol'),
                "timestamp": data.get('timestamp'),
                "processed_data": data,
                "quality_score": await self._calculate_data_quality(data)
            }
            
            await self.event_broadcaster.broadcast("unified_pool_entry", pool_entry)
            
        except Exception as e:
            self.logger.error(f"Unified signal pool error: {e}")
    
    def _calculate_signal_confidence(self, indicators: Dict[str, float]) -> float:
        """è¨ˆç®—ä¿¡è™Ÿç½®ä¿¡åº¦"""
        if not indicators:
            return 0.0
        
        # ç°¡åŒ–ç½®ä¿¡åº¦è¨ˆç®—
        confidence_factors = []
        
        if 'price_momentum' in indicators:
            momentum = abs(indicators['price_momentum'])
            confidence_factors.append(min(1.0, momentum * 10))  # å‹•é‡å¼·åº¦
        
        if 'volatility' in indicators:
            volatility = indicators['volatility']
            confidence_factors.append(max(0.3, 1.0 - volatility))  # ä½æ³¢å‹•ç‡=é«˜ç½®ä¿¡åº¦
        
        return sum(confidence_factors) / len(confidence_factors) if confidence_factors else 0.5
    
    def _get_affected_indicators(self, data: Dict[str, Any]) -> List[str]:
        """ç²å–å—å½±éŸ¿çš„æŒ‡æ¨™åˆ—è¡¨"""
        data_type = data.get('type', '')
        affected = []
        
        if data_type == 'kline_data':
            affected.extend(['price_momentum', 'volatility', 'price_range_pct'])
        elif data_type == 'real_time_trades':
            affected.extend(['volume_trend', 'money_flow'])
        elif data_type == 'orderbook_data':
            affected.extend(['bid_ask_spread', 'book_depth', 'liquidity_ratio'])
        elif data_type == 'mark_price':
            affected.extend(['mark_price_deviation', 'funding_rate_impact'])
        
        return affected
    
    async def _calculate_volatility_metrics(self, data: Dict[str, Any]) -> Dict[str, float]:
        """è¨ˆç®—æ³¢å‹•ç‡æŒ‡æ¨™"""
        try:
            metrics = {}
            
            if data.get('type') == 'orderbook_data':
                bids = data.get('bids', [])
                asks = data.get('asks', [])
                
                if bids and asks:
                    spread = float(asks[0][0]) - float(bids[0][0])
                    mid_price = (float(asks[0][0]) + float(bids[0][0])) / 2
                    metrics['spread_volatility'] = spread / mid_price if mid_price > 0 else 0.0
                    metrics['volatility_level'] = 'high' if metrics['spread_volatility'] > 0.001 else 'low'
            
            elif data.get('type') == 'mark_price':
                # æ¨™è¨˜åƒ¹æ ¼æ³¢å‹•ç‡è¨ˆç®—
                mark_price = float(data.get('mark_price', 0))
                metrics['mark_price_volatility'] = 0.01  # ç°¡åŒ–å¯¦ç¾
                metrics['volatility_level'] = 'medium'
            
            return metrics
        except:
            return {'volatility_level': 'unknown'}
    
    def _generate_adaptation_params(self, volatility_metrics: Dict[str, float]) -> Dict[str, Any]:
        """ç”Ÿæˆé©æ‡‰åƒæ•¸"""
        volatility_level = volatility_metrics.get('volatility_level', 'medium')
        
        params = {
            'signal_sensitivity': 0.5,
            'confidence_threshold': 0.6,
            'update_frequency': 'normal'
        }
        
        if volatility_level == 'high':
            params.update({
                'signal_sensitivity': 0.7,
                'confidence_threshold': 0.8,
                'update_frequency': 'fast'
            })
        elif volatility_level == 'low':
            params.update({
                'signal_sensitivity': 0.3,
                'confidence_threshold': 0.4,
                'update_frequency': 'slow'
            })
        
        return params
    
    async def _calculate_data_quality(self, data: Dict[str, Any]) -> float:
        """è¨ˆç®—æ•¸æ“šå“è³ªåˆ†æ•¸"""
        try:
            quality_score = 1.0
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_fields = ['symbol', 'timestamp']
            missing_fields = [field for field in required_fields if field not in data]
            quality_score -= len(missing_fields) * 0.2
            
            # æª¢æŸ¥æ•¸æ“šæ–°é®®åº¦
            if 'timestamp' in data:
                data_age = time.time() - float(data['timestamp'])
                if data_age > 5:  # 5ç§’ä»¥ä¸Šèªç‚ºæ•¸æ“šé™³èˆŠ
                    quality_score -= 0.1
            
            # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
            if await self.data_validator.validate_data_integrity(data, data.get('type', '')):
                quality_score += 0.1
            else:
                quality_score -= 0.3
            
            return max(0.0, min(1.0, quality_score))
        except:
            return 0.5

# å…¨å±€å¯¦ä¾‹
websocket_realtime_driver = WebSocketRealtimeDriver()

# ä¾¿æ·å‡½æ•¸
async def start_realtime_driver(symbols: List[str] = None):
    """å•Ÿå‹•å¯¦æ™‚æ•¸æ“šé©…å‹•å™¨"""
    await websocket_realtime_driver.start(symbols)

async def stop_realtime_driver():
    """åœæ­¢å¯¦æ™‚æ•¸æ“šé©…å‹•å™¨"""
    await websocket_realtime_driver.stop()

def subscribe_to_realtime_data(callback: Callable):
    """è¨‚é–±å¯¦æ™‚æ•¸æ“š"""
    websocket_realtime_driver.subscribe("data", callback)

async def get_latest_market_data(symbol: str) -> Optional[MarketDataSnapshot]:
    """ç²å–æœ€æ–°å¸‚å ´æ•¸æ“š"""
    return await websocket_realtime_driver.get_latest_data(symbol)
