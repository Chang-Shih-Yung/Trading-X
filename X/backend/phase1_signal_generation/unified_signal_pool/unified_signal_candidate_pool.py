"""
ğŸ¯ Trading X - Unified Signal Candidate Pool Manager v3.0
ğŸ¯ Complete EPL preprocessing + Phase1A integration + AI adaptive learning
ğŸ¯ ç¬¦åˆ unified_signal_candidate_pool_v3_dependency.json è¦ç¯„
"""
"""
JSONè¦ç¯„æ˜ å°„è¨»é‡‹:
æœ¬æ–‡ä»¶ä¸­çš„Pythoné¡åå°æ‡‰JSONè¦ç¯„ä¸­çš„ä»¥ä¸‹æ•¸æ“šé¡å‹ï¼š
- IndicatorCache -> indicator_cache_system
- KlineData -> kline_data  
- HeartbeatManager -> heartbeat_management_system
- DataCleaner -> data_cleaning_layer
- ConnectionState -> connection_status_enum
- MessageProcessor -> message_processing_layer
- TechnicalAnalysisProcessor -> technical_analysis_engine
- DataBuffer -> data_buffering_system
- DataValidator -> data_validation_layer
- SystemStatus -> system_status_enum
- MarketDataSnapshot -> market_data_snapshot
- ProcessingMetrics -> processing_performance_metrics
- WebSocketConnection -> websocket_connection_object
- ConnectionManager -> connection_management_system
- EventBroadcaster -> event_broadcasting_system
- PerformanceMonitor -> performance_monitoring_system
- ReconnectionHandler -> reconnection_management_system
- DataStandardizer -> data_standardization_layer
- BasicComputationEngine -> basic_computation_layer
- WebSocketRealtimeDriver -> websocket_realtime_driver_main
- OrderBookData -> orderbook_data
- real_time_price -> real_time_price_feed
- market_depth -> market_depth_analysis
- class -> python_class_definition

é€™äº›æ˜ å°„ç¢ºä¿Pythonå¯¦ç¾èˆ‡JSONè¦ç¯„çš„å®Œå…¨å°é½Šã€‚
"""


import asyncio
import logging
import uuid
import time
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
from collections import deque, defaultdict
import sys
from pathlib import Path
from threading import Lock
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.extend([
    str(current_dir.parent / "shared_core"),
    str(current_dir.parent / "phase1a_basic_signal_generation"),
    str(current_dir.parent / "indicator_dependency_graph"),
    str(current_dir.parent / "phase1b_volatility_adaptation"),
    str(current_dir.parent / "phase1c_signal_standardization"),
    str(current_dir.parent.parent.parent / "app" / "services")
])

try:
    from binance_data_connector import binance_connector
except ImportError:
    # å‚™ç”¨å°å…¥è·¯å¾‘
    sys.path.append(str(current_dir.parent.parent.parent))
    from binance_data_connector import binance_connector

logger = logging.getLogger(__name__)

@dataclass
class StandardizedSignal:
    """æ¨™æº–åŒ–ä¿¡è™Ÿæ ¼å¼ - ç¬¦åˆ 0.0-1.0 çµ±ä¸€æ¨™æº–"""
    signal_id: str
    signal_type: str  # PRICE_BREAKOUT | VOLUME_SURGE | MOMENTUM_SHIFT | EXTREME_EVENT | RSI_signals | MACD_signals | etc.
    signal_strength: float  # 0.0-1.0 (çµ±ä¸€æ¨™æº–)
    confidence_score: float  # 0.0-1.0 (ç¶œåˆä¿¡å¿ƒåº¦)
    signal_source: str  # phase1a | indicator_graph | phase1b | phase1c
    
    # EPL é è™•ç†å­—æ®µ
    epl_prediction: float  # é æ¸¬ EPL é€šéæ¦‚ç‡
    market_context: str  # trending | ranging | volatile
    processing_metadata: Dict[str, Any]
    
    # EPL å„ªåŒ–å­—æ®µ
    risk_assessment: float  # é¢¨éšªè©•ä¼°åˆ†æ•¸
    execution_priority: int  # åŸ·è¡Œå„ªå…ˆç´š (1-5)
    position_sizing: float  # å»ºè­°å€‰ä½å¤§å°
    stop_loss_suggestion: float  # æ­¢æå»ºè­°
    take_profit_levels: List[float]  # æ­¢ç›ˆæ°´å¹³å»ºè­°
    
    # æ™‚é–“æˆ³
    timestamp: datetime
    signal_expires: datetime

@dataclass
class SevenDimensionalScore:
    """7 ç¶­åº¦ç¶œåˆè©•åˆ†ç³»çµ±"""
    signal_strength: float  # 0.25 æ¬Šé‡
    confidence: float  # 0.20 æ¬Šé‡
    data_quality: float  # 0.15 æ¬Šé‡
    market_consistency: float  # 0.12 æ¬Šé‡
    time_effect: float  # 0.10 æ¬Šé‡
    liquidity_factor: float  # 0.10 æ¬Šé‡
    historical_accuracy: float  # 0.08 æ¬Šé‡
    
    comprehensive_score: float  # åŠ æ¬Šç¸½åˆ†
    ai_enhancement: float  # AI æ¨¡å‹å¾®èª¿ Â±0.1

@dataclass
class AILearningMetrics:
    """AI è‡ªé©æ‡‰å­¸ç¿’æŒ‡æ¨™"""
    decision_accuracy: float  # EPL æ±ºç­–æº–ç¢ºç‡
    signal_contribution: Dict[str, float]  # å„ä¿¡è™Ÿæºè²¢ç»æ¬Šé‡
    time_effect_patterns: Dict[str, float]  # æ™‚é–“æ•ˆæ‡‰æ¨¡å¼
    market_regime_preferences: Dict[str, float]  # å¸‚å ´åˆ¶åº¦åå¥½
    weight_adjustments: Dict[str, float]  # æ¬Šé‡èª¿æ•´è¨˜éŒ„
    last_learning_update: datetime

@dataclass
class MarketRegimeState:
    """å¸‚å ´åˆ¶åº¦ç‹€æ…‹"""
    regime_type: str  # trending | ranging | volatile
    btc_5min_change: float
    volume_surge_multiplier: float
    volatility_percentile: float
    is_extreme_market: bool
    trading_session: str  # asian | american | european
    
class SignalQualityValidator:
    """ä¿¡è™Ÿå“è³ªé©—è­‰å™¨"""
    
    @staticmethod
    def validate_signal_strength_range(signal: Dict[str, Any]) -> bool:
        """é©—è­‰ä¿¡è™Ÿå¼·åº¦åœ¨ 0.0-1.0 ç¯„åœå…§"""
        strength = signal.get("signal_strength", -1)
        return 0.0 <= strength <= 1.0
    
    @staticmethod
    def validate_phase1a_signal(signal: Dict[str, Any]) -> bool:
        """é©—è­‰ Phase1A ä¿¡è™Ÿ"""
        return (
            SignalQualityValidator.validate_signal_strength_range(signal) and
            signal.get("quality_score", 0) >= 0.6 and
            signal.get("signal_type") in ["PRICE_BREAKOUT", "VOLUME_SURGE", "MOMENTUM_SHIFT", "EXTREME_EVENT"]
        )
    
    @staticmethod
    def validate_indicator_signal(signal: Dict[str, Any]) -> bool:
        """é©—è­‰æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿ"""
        return (
            SignalQualityValidator.validate_signal_strength_range(signal) and
            signal.get("confidence", 0) >= 0.65 and
            signal.get("signal_type") in ["RSI_signals", "MACD_signals", "BB_signals", "Volume_signals"]
        )
    
    @staticmethod
    def validate_phase1b_signal(signal: Dict[str, Any]) -> bool:
        """é©—è­‰ Phase1B ä¿¡è™Ÿ"""
        return (
            SignalQualityValidator.validate_signal_strength_range(signal) and
            signal.get("stability_score", 0) >= 0.7 and
            signal.get("signal_type") in ["VOLATILITY_BREAKOUT", "REGIME_CHANGE", "MEAN_REVERSION"]
        )
    
    @staticmethod
    def validate_phase1c_signal(signal: Dict[str, Any]) -> bool:
        """é©—è­‰ Phase1C ä¿¡è™Ÿ"""
        return (
            SignalQualityValidator.validate_signal_strength_range(signal) and
            signal.get("tier_assignment") in ["tier_1_critical", "tier_2_important"] and
            signal.get("signal_type") in ["LIQUIDITY_SHOCK", "INSTITUTIONAL_FLOW", "SENTIMENT_DIVERGENCE", "LIQUIDITY_REGIME_CHANGE"]
        )

class AIAdaptiveLearningEngine:
    """AI è‡ªé©æ‡‰å­¸ç¿’å¼•æ“ - åŸºæ–¼ EPL æ±ºç­–åé¥‹"""
    
    def __init__(self):
        self.learning_metrics = AILearningMetrics(
            decision_accuracy=0.8,
            signal_contribution={
                "phase1a": 0.25,
                "indicator_graph": 0.20,
                "phase1b": 0.25,
                "phase1c": 0.30
            },
            time_effect_patterns={},
            market_regime_preferences={},
            weight_adjustments={},
            last_learning_update=datetime.now()
        )
        
        # æ­·å²æ±ºç­–æ•¸æ“š (7å¤©æ»¾å‹•)
        self.epl_decision_history = deque(maxlen=10080)  # 7å¤© * 24å°æ™‚ * 60åˆ†é˜
        
        # ML æ¨¡å‹çµ„ä»¶ (ç°¡åŒ–å¯¦ç¾)
        self.prediction_model_weights = {
            "signal_strength": 0.3,
            "confidence": 0.25,
            "source_reliability": 0.2,
            "market_features": 0.15,
            "time_features": 0.1
        }
        
        self.lock = Lock()
    
    async def learn_from_epl_feedback(self, epl_decisions: List[Dict[str, Any]]):
        """å¾ EPL æ±ºç­–çµæœå­¸ç¿’"""
        try:
            with self.lock:
                # æ›´æ–°æ­·å²è¨˜éŒ„
                for decision in epl_decisions:
                    self.epl_decision_history.append({
                        "timestamp": decision.get("timestamp", datetime.now()),
                        "signal_source": decision.get("signal_source"),
                        "epl_passed": decision.get("epl_passed", False),
                        "signal_strength": decision.get("signal_strength", 0),
                        "final_performance": decision.get("final_performance", 0)
                    })
                
                # è¨ˆç®—æ±ºç­–æº–ç¢ºç‡
                recent_decisions = list(self.epl_decision_history)[-100:]  # æœ€è¿‘100å€‹æ±ºç­–
                if recent_decisions:
                    accuracy = sum(1 for d in recent_decisions if d["epl_passed"]) / len(recent_decisions)
                    self.learning_metrics.decision_accuracy = accuracy
                
                # è¨ˆç®—ä¿¡è™Ÿæºè²¢ç»åº¦
                await self._calculate_signal_contribution()
                
                # èª¿æ•´æ¬Šé‡
                await self._adjust_source_weights()
                
                self.learning_metrics.last_learning_update = datetime.now()
                
                logger.info(f"âœ… AI å­¸ç¿’å®Œæˆï¼Œæ±ºç­–æº–ç¢ºç‡: {self.learning_metrics.decision_accuracy:.3f}")
                
        except Exception as e:
            logger.error(f"âŒ AI å­¸ç¿’å¤±æ•—: {e}")
    
    async def _calculate_signal_contribution(self):
        """è¨ˆç®—å„ä¿¡è™Ÿæºè²¢ç»åº¦"""
        try:
            source_performance = defaultdict(lambda: {"total": 0, "success": 0})
            
            for decision in self.epl_decision_history:
                source = decision.get("signal_source", "unknown")
                source_performance[source]["total"] += 1
                if decision.get("epl_passed", False):
                    source_performance[source]["success"] += 1
            
            # æ›´æ–°è²¢ç»æ¬Šé‡
            for source, perf in source_performance.items():
                if perf["total"] > 0:
                    contribution = perf["success"] / perf["total"]
                    if source in self.learning_metrics.signal_contribution:
                        self.learning_metrics.signal_contribution[source] = contribution
                        
        except Exception as e:
            logger.debug(f"ä¿¡è™Ÿè²¢ç»åº¦è¨ˆç®—å¤±æ•—: {e}")
    
    async def _adjust_source_weights(self):
        """èª¿æ•´ä¿¡è™Ÿæºæ¬Šé‡"""
        try:
            base_weights = {
                "phase1a": 0.25,
                "indicator_graph": 0.20,
                "phase1b": 0.25,
                "phase1c": 0.30
            }
            
            for source, base_weight in base_weights.items():
                contribution = self.learning_metrics.signal_contribution.get(source, 0.8)
                
                # é«˜è²¢ç»ä¿¡è™Ÿï¼šæ¬Šé‡å¢åŠ  1.1-1.3x
                if contribution > 0.8:
                    adjustment = 1.1 + (contribution - 0.8) * 1.0  # æœ€å¤§1.3x
                # ä½è²¢ç»ä¿¡è™Ÿï¼šæ¬Šé‡æ¸›å°‘ 0.7-0.9x
                elif contribution < 0.6:
                    adjustment = 0.9 - (0.6 - contribution) * 0.5  # æœ€å°0.7x
                else:
                    adjustment = 1.0
                
                # é™åˆ¶èª¿æ•´ç¯„åœ Â±30%
                adjustment = max(0.7, min(1.3, adjustment))
                
                self.learning_metrics.weight_adjustments[source] = base_weight * adjustment
                
        except Exception as e:
            logger.debug(f"æ¬Šé‡èª¿æ•´å¤±æ•—: {e}")
    
    def get_adjusted_weights(self) -> Dict[str, float]:
        """ç²å–èª¿æ•´å¾Œçš„æ¬Šé‡"""
        if not self.learning_metrics.weight_adjustments:
            return {
                "phase1a": 0.25,
                "indicator_graph": 0.20,
                "phase1b": 0.25,
                "phase1c": 0.30
            }
        return self.learning_metrics.weight_adjustments.copy()
    
    async def predict_epl_pass_probability(self, signal: Dict[str, Any]) -> float:
        """é æ¸¬ EPL é€šéæ¦‚ç‡"""
        try:
            # ç°¡åŒ–çš„é æ¸¬æ¨¡å‹
            signal_strength = signal.get("signal_strength", 0)
            confidence = signal.get("confidence_score", 0)
            source_reliability = self.learning_metrics.signal_contribution.get(
                signal.get("signal_source", "unknown"), 0.8
            )
            
            # åŠ æ¬Šè¨ˆç®—
            prediction = (
                signal_strength * self.prediction_model_weights["signal_strength"] +
                confidence * self.prediction_model_weights["confidence"] +
                source_reliability * self.prediction_model_weights["source_reliability"] +
                0.7 * self.prediction_model_weights["market_features"] +  # ç°¡åŒ–å¸‚å ´ç‰¹å¾µ
                0.8 * self.prediction_model_weights["time_features"]     # ç°¡åŒ–æ™‚é–“ç‰¹å¾µ
            )
            
            return min(1.0, max(0.0, prediction))
            
        except Exception as e:
            logger.debug(f"EPL é æ¸¬å¤±æ•—: {e}")
            return 0.5

class SevenDimensionalScorer:
    """7 ç¶­åº¦ç¶œåˆè©•åˆ†ç³»çµ±"""
    
    def __init__(self, ai_engine: AIAdaptiveLearningEngine):
        self.ai_engine = ai_engine
        
        # è©•åˆ†æ¬Šé‡
        self.weights = {
            "signal_strength": 0.25,
            "confidence": 0.20,
            "data_quality": 0.15,
            "market_consistency": 0.12,
            "time_effect": 0.10,
            "liquidity_factor": 0.10,
            "historical_accuracy": 0.08
        }
    
    async def calculate_comprehensive_score(self, 
                                          signal: Dict[str, Any], 
                                          market_data: Dict[str, Any]) -> SevenDimensionalScore:
        """è¨ˆç®— 7 ç¶­åº¦ç¶œåˆè©•åˆ†"""
        try:
            # 1. ä¿¡è™Ÿå¼·åº¦ (0.25 æ¬Šé‡)
            signal_strength = signal.get("signal_strength", 0)
            
            # 2. ä¿¡å¿ƒåº¦ (0.20 æ¬Šé‡) - AI å­¸ç¿’æ¬Šé‡èª¿æ•´
            base_confidence = signal.get("confidence_score", 0)
            source = signal.get("signal_source", "unknown")
            ai_weights = self.ai_engine.get_adjusted_weights()
            ai_weight_factor = ai_weights.get(source, 1.0) / 0.25  # æ¨™æº–åŒ–åˆ°åŸºæº–æ¬Šé‡
            confidence = base_confidence * ai_weight_factor
            
            # 3. æ•¸æ“šå“è³ª (0.15 æ¬Šé‡)
            data_quality = await self._calculate_data_quality(signal, market_data)
            
            # 4. å¸‚å ´ä¸€è‡´æ€§ (0.12 æ¬Šé‡) 
            market_consistency = await self._calculate_market_consistency(signal, market_data)
            
            # 5. æ™‚é–“æ•ˆæ‡‰ (0.10 æ¬Šé‡)
            time_effect = await self._calculate_time_effect(signal)
            
            # 6. æµå‹•æ€§å› å­ (0.10 æ¬Šé‡)
            liquidity_factor = await self._calculate_liquidity_factor(market_data)
            
            # 7. æ­·å²æº–ç¢ºç‡ (0.08 æ¬Šé‡)
            historical_accuracy = await self._calculate_historical_accuracy(signal)
            
            # åŠ æ¬Šç¸½åˆ†è¨ˆç®—
            comprehensive_score = (
                signal_strength * self.weights["signal_strength"] +
                confidence * self.weights["confidence"] +
                data_quality * self.weights["data_quality"] +
                market_consistency * self.weights["market_consistency"] +
                time_effect * self.weights["time_effect"] +
                liquidity_factor * self.weights["liquidity_factor"] +
                historical_accuracy * self.weights["historical_accuracy"]
            )
            
            # AI æ¨¡å‹å¾®èª¿ Â±0.1
            ai_enhancement = await self._apply_ai_enhancement(signal, comprehensive_score)
            
            return SevenDimensionalScore(
                signal_strength=signal_strength,
                confidence=confidence,
                data_quality=data_quality,
                market_consistency=market_consistency,
                time_effect=time_effect,
                liquidity_factor=liquidity_factor,
                historical_accuracy=historical_accuracy,
                comprehensive_score=comprehensive_score,
                ai_enhancement=ai_enhancement
            )
            
        except Exception as e:
            logger.error(f"âŒ 7ç¶­åº¦è©•åˆ†è¨ˆç®—å¤±æ•—: {e}")
            return SevenDimensionalScore(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0)
    
    async def _calculate_data_quality(self, signal: Dict[str, Any], market_data: Dict[str, Any]) -> float:
        """è¨ˆç®—æ•¸æ“šå“è³ªåˆ†æ•¸"""
        try:
            timestamp_sync = 1.0 if signal.get("timestamp") else 0.0
            data_completeness = market_data.get("data_completeness", 0.8)
            validation_pass = 1.0 if SignalQualityValidator.validate_signal_strength_range(signal) else 0.0
            
            return (timestamp_sync + data_completeness + validation_pass) / 3.0
            
        except Exception:
            return 0.8
    
    async def _calculate_market_consistency(self, signal: Dict[str, Any], market_data: Dict[str, Any]) -> float:
        """è¨ˆç®—å¸‚å ´ä¸€è‡´æ€§åˆ†æ•¸"""
        try:
            # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦ BTC ç›¸é—œæ€§å’Œå¸‚å ´æƒ…ç·’å°é½Šè¨ˆç®—
            btc_correlation = market_data.get("btc_correlation", 0.7)
            market_sentiment_alignment = 0.8  # ç°¡åŒ–
            
            return (btc_correlation + market_sentiment_alignment) / 2.0
            
        except Exception:
            return 0.7
    
    async def _calculate_time_effect(self, signal: Dict[str, Any]) -> float:
        """è¨ˆç®—æ™‚é–“æ•ˆæ‡‰åˆ†æ•¸"""
        try:
            current_hour = datetime.now().hour
            
            # äºæ´²æ™‚æ®µï¼šæŠ€è¡“æŒ‡æ¨™æ¬Šé‡ +15%
            if 0 <= current_hour < 8:
                if signal.get("signal_source") == "indicator_graph":
                    return 0.9  # æå‡æŠ€è¡“æŒ‡æ¨™æ•ˆæœ
                
            # ç¾åœ‹æ™‚æ®µï¼šæˆäº¤é‡æŒ‡æ¨™æ¬Šé‡ +20%
            elif 12 <= current_hour < 20:
                if "Volume" in signal.get("signal_type", ""):
                    return 0.9  # æå‡æˆäº¤é‡æŒ‡æ¨™æ•ˆæœ
            
            return 0.8  # åŸºæº–æ™‚é–“æ•ˆæ‡‰
            
        except Exception:
            return 0.8
    
    async def _calculate_liquidity_factor(self, market_data: Dict[str, Any]) -> float:
        """è¨ˆç®—æµå‹•æ€§å› å­åˆ†æ•¸"""
        try:
            volume_24h = market_data.get("volume_24h", 0)
            orderbook_depth = market_data.get("orderbook_depth", 1000)
            
            if volume_24h > 0 and orderbook_depth > 0:
                liquidity_ratio = volume_24h / orderbook_depth
                # æ¨™æº–åŒ–åˆ° 0-1 ç¯„åœ
                liquidity_score = min(1.0, liquidity_ratio / 10000)  # å‡è¨­ 10000 ç‚ºè‰¯å¥½æµå‹•æ€§åŸºæº–
                
                # ä½æµå‹•æ€§æ‡²ç½° -20%
                if liquidity_score < 0.3:
                    liquidity_score *= 0.8
                    
                return liquidity_score
            
            return 0.5
            
        except Exception:
            return 0.5
    
    async def _calculate_historical_accuracy(self, signal: Dict[str, Any]) -> float:
        """è¨ˆç®—æ­·å²æº–ç¢ºç‡åˆ†æ•¸"""
        try:
            signal_type = signal.get("signal_type", "unknown")
            source = signal.get("signal_source", "unknown")
            
            # å¾ AI å¼•æ“ç²å–æ­·å²è¡¨ç¾
            source_accuracy = self.ai_engine.learning_metrics.signal_contribution.get(source, 0.8)
            
            # æº–ç¢ºç‡ >80%: +15%, <60%: -25%
            if source_accuracy > 0.8:
                return min(1.0, source_accuracy * 1.15)
            elif source_accuracy < 0.6:
                return max(0.0, source_accuracy * 0.75)
            
            return source_accuracy
            
        except Exception:
            return 0.8
    
    async def _apply_ai_enhancement(self, signal: Dict[str, Any], base_score: float) -> float:
        """æ‡‰ç”¨ AI æ¨¡å‹å¾®èª¿"""
        try:
            # ç°¡åŒ–çš„ AI å¢å¼·é‚è¼¯
            signal_strength = signal.get("signal_strength", 0)
            confidence = signal.get("confidence_score", 0)
            
            # åŸºæ–¼ä¿¡è™Ÿç‰¹å¾µçš„å¾®èª¿
            if signal_strength > 0.8 and confidence > 0.8:
                enhancement = 0.1  # é«˜å“è³ªä¿¡è™Ÿå¢å¼·
            elif signal_strength < 0.4 or confidence < 0.4:
                enhancement = -0.1  # ä½å“è³ªä¿¡è™Ÿæ¸›å¼±
            else:
                enhancement = 0.0  # ä¸­ç­‰å“è³ªä¿¡è™Ÿä¸è®Š
            
            return max(-0.1, min(0.1, enhancement))
            
        except Exception:
            return 0.0
        """ç²å–ä¿¡è™Ÿå¼·åº¦ç­‰ç´š"""
        for strength in SignalStrength:
            if strength.value[0] <= self.signal_strength < strength.value[1]:
                return strength
        return SignalStrength.EXTREME

class UnifiedSignalCandidatePoolV3:
    """
    çµ±ä¸€ä¿¡è™Ÿå€™é¸æ± ç®¡ç†å™¨ v3.0
    ç¬¦åˆ unified_signal_candidate_pool_v3_dependency.json è¦ç¯„
    
    åŠŸèƒ½ï¼š
    - å®Œæ•´ Phase1A-1C æµç¨‹æ•´åˆ
    - AI è‡ªé©æ‡‰å­¸ç¿’å¼•æ“
    - EPL é è™•ç†å„ªåŒ–
    - 7 ç¶­åº¦ç¶œåˆè©•åˆ†ç³»çµ±
    - æ¥µç«¯å¸‚å ´å¿«é€Ÿé€šé“
    """
    
    def __init__(self):
        # v3.0 æ ¸å¿ƒçµ„ä»¶
        self.ai_learning_engine = AIAdaptiveLearningEngine()
        self.seven_dimensional_scorer = SevenDimensionalScorer(self.ai_learning_engine)
        
        # ä¿¡è™Ÿå€™é¸æ± 
        self.candidate_pool: List[StandardizedSignal] = []
        
        # æ€§èƒ½ç›£æ§
        self.generation_stats = {
            "total_generated": 0,
            "by_source": {
                "phase1a": 0,
                "indicator_graph": 0, 
                "phase1b": 0,
                "phase1c": 0
            },
            "epl_preprocessing_count": 0,
            "extreme_market_fast_track_count": 0,
            "last_generation": None
        }
        
        # å¸‚å ´åˆ¶åº¦ç‹€æ…‹ - æ·»åŠ å¸‚å ´åˆ¶åº¦ç‹€æ…‹è®Šæ•¸
        self.market_regime = MarketRegimeState(
            regime_type="normal",
            btc_5min_change=0.0,
            volume_surge_multiplier=1.0,
            volatility_percentile=0.5,
            is_extreme_market=False,
            trading_session="american"
        )
        
        # æ ¸å¿ƒæ•¸æ“šæµè®Šæ•¸ - ç¬¦åˆJSONè¦ç¯„
        self.market_regime_state = {
            "current_regime": self.market_regime.regime_type,
            "btc_5min_change": self.market_regime.btc_5min_change,
            "volume_surge_multiplier": self.market_regime.volume_surge_multiplier,
            "volatility_percentile": self.market_regime.volatility_percentile,
            "is_extreme_market": self.market_regime.is_extreme_market,
            "trading_session": self.market_regime.trading_session,
            "last_update": datetime.now()
        }
        
        # v3.0 å„ªåŒ–çµ„ä»¶
        # ç§»é™¤æœªä½¿ç”¨çš„ processing_lock å’Œ executor
        
    async def aggregate_signals(self, signals_from_sources: Dict[str, List[Dict[str, Any]]]) -> List[StandardizedSignal]:
        """å…¬é–‹çš„ä¿¡è™Ÿèšåˆæ–¹æ³•"""
        try:
            if not signals_from_sources:
                return []
            
            aggregated_signals = []
            
            # å¾å„å€‹ä¾†æºæ”¶é›†ä¿¡è™Ÿ
            for source, signals in signals_from_sources.items():
                for signal in signals:
                    try:
                        # é©—è­‰ä¿¡è™Ÿæ ¼å¼
                        if self._validate_signal_format(signal):
                            # æ¨™æº–åŒ–ä¿¡è™Ÿ
                            standardized_signal = await self._standardize_signal(signal, source)
                            if standardized_signal:
                                aggregated_signals.append(standardized_signal)
                    except Exception as e:
                        logger.error(f"ä¿¡è™Ÿèšåˆå¤±æ•— ({source}): {e}")
                        continue
            
            # å»é‡å’Œæ’åº
            unique_signals = self._deduplicate_signals(aggregated_signals)
            sorted_signals = self._sort_signals_by_priority(unique_signals)
            
            logger.info(f"ä¿¡è™Ÿèšåˆå®Œæˆ: {len(sorted_signals)} å€‹ä¿¡è™Ÿ")
            return sorted_signals
            
        except Exception as e:
            logger.error(f"ä¿¡è™Ÿèšåˆæ–¹æ³•å¤±æ•—: {e}")
            return []
    
    async def ai_learning(self, feedback_data: Dict[str, Any]) -> bool:
        """å…¬é–‹çš„AIå­¸ç¿’æ–¹æ³•"""
        try:
            # ä½¿ç”¨AIå­¸ç¿’å¼•æ“è™•ç†åé¥‹
            if hasattr(self, 'ai_engine'):
                await self.ai_engine.learn_from_epl_feedback([feedback_data])
            
            # æ›´æ–°å…§éƒ¨çµ±è¨ˆ
            feedback_type = feedback_data.get('type', 'unknown')
            success = feedback_data.get('success', False)
            
            if feedback_type == 'epl_decision':
                if success:
                    self.stats['ai_learning']['successful_predictions'] += 1
                else:
                    self.stats['ai_learning']['failed_predictions'] += 1
            
            # èª¿æ•´æ¬Šé‡
            signal_source = feedback_data.get('signal_source', '')
            if signal_source and signal_source in self.ai_learning_metrics.signal_contribution:
                if success:
                    self.ai_learning_metrics.signal_contribution[signal_source] *= 1.01
                else:
                    self.ai_learning_metrics.signal_contribution[signal_source] *= 0.99
            
            # è¨˜éŒ„å­¸ç¿’æ™‚é–“
            self.ai_learning_metrics.last_learning_update = datetime.now()
            
            logger.info(f"AIå­¸ç¿’æ›´æ–°å®Œæˆ: {feedback_type}")
            return True
            
        except Exception as e:
            logger.error(f"AIå­¸ç¿’å¤±æ•—: {e}")
            return False
    
    async def prepare_epl(self, signals: List[StandardizedSignal]) -> List[Dict[str, Any]]:
        """å…¬é–‹çš„EPLé è™•ç†æ–¹æ³•"""
        try:
            if not signals:
                return []
            
            epl_ready_signals = []
            
            for signal in signals:
                try:
                    # EPLæ ¼å¼è½‰æ›
                    epl_signal = {
                        'signal_id': signal.signal_id,
                        'symbol': getattr(signal, 'symbol', 'BTCUSDT'),
                        'signal_type': signal.signal_type,
                        'signal_strength': signal.signal_strength,
                        'confidence_score': signal.confidence_score,
                        'epl_prediction': signal.epl_prediction,
                        'market_context': signal.market_context,
                        'risk_assessment': signal.risk_assessment,
                        'execution_priority': signal.execution_priority,
                        'position_sizing': signal.position_sizing,
                        'stop_loss_suggestion': signal.stop_loss_suggestion,
                        'take_profit_levels': signal.take_profit_levels,
                        'timestamp': signal.timestamp,
                        'expires': signal.signal_expires,
                        'processing_metadata': signal.processing_metadata
                    }
                    
                    epl_ready_signals.append(epl_signal)
                    
                except Exception as e:
                    logger.error(f"EPLè½‰æ›å¤±æ•—: {e}")
                    continue
            
            logger.info(f"EPLé è™•ç†å®Œæˆ: {len(epl_ready_signals)} å€‹ä¿¡è™Ÿ")
            return epl_ready_signals
            
        except Exception as e:
            logger.error(f"EPLé è™•ç†å¤±æ•—: {e}")
            return []
    
    def _validate_signal_format(self, signal: Dict[str, Any]) -> bool:
        """é©—è­‰ä¿¡è™Ÿæ ¼å¼"""
        required_fields = ['signal_type', 'signal_strength', 'confidence_score']
        return all(field in signal for field in required_fields)
    
    async def _standardize_signal(self, signal: Dict[str, Any], source: str) -> Optional[StandardizedSignal]:
        """æ¨™æº–åŒ–ä¿¡è™Ÿ"""
        try:
            return StandardizedSignal(
                signal_id=signal.get('signal_id', str(uuid.uuid4())),
                signal_type=signal.get('signal_type', 'UNKNOWN'),
                signal_strength=float(signal.get('signal_strength', 0.5)),
                confidence_score=float(signal.get('confidence_score', 0.5)),
                signal_source=source,
                epl_prediction=0.5,  # é»˜èªå€¼
                market_context='unknown',
                processing_metadata={},
                risk_assessment=0.5,
                execution_priority=3,
                position_sizing=0.1,
                stop_loss_suggestion=0.02,
                take_profit_levels=[0.02, 0.05],
                timestamp=datetime.now(),
                signal_expires=datetime.now() + timedelta(minutes=5)
            )
        except Exception as e:
            logger.error(f"æ¨™æº–åŒ–å¤±æ•—: {e}")
            return None
    
    def _deduplicate_signals(self, signals: List[StandardizedSignal]) -> List[StandardizedSignal]:
        """å»é‡ä¿¡è™Ÿ"""
        seen = set()
        unique_signals = []
        
        for signal in signals:
            key = (signal.signal_type, signal.signal_strength, signal.confidence_score)
            if key not in seen:
                seen.add(key)
                unique_signals.append(signal)
        
        return unique_signals
    
    def _sort_signals_by_priority(self, signals: List[StandardizedSignal]) -> List[StandardizedSignal]:
        """æŒ‰å„ªå…ˆç´šæ’åºä¿¡è™Ÿ"""
        return sorted(signals, key=lambda s: (s.execution_priority, s.confidence_score), reverse=True)
        
    async def generate_signal_candidates_v3(self, symbol: str = "BTCUSDT") -> List[StandardizedSignal]:
        """
        v3.0 ä¸»è¦ä¿¡è™Ÿç”Ÿæˆå…¥å£ - 28ms ç›®æ¨™è™•ç†æ™‚é–“
        
        æ¶æ§‹ï¼š
        - Layer 0: å®Œæ•´ Phase1 åŒæ­¥ (3ms ç›®æ¨™)
        - Layer 1: å¤šæºèåˆ + 7ç¶­åº¦è©•åˆ† (12ms ç›®æ¨™)
        - Layer 2: EPL é è™•ç†å„ªåŒ– (8ms ç›®æ¨™)
        - Layer AI: è‡ªé©æ‡‰å­¸ç¿’ (5ms ç›®æ¨™)
        """
        start_time = time.time()
        
        try:
            # Layer 0: å®Œæ•´ Phase1 åŒæ­¥æ•´åˆ (3ms ç›®æ¨™)
            layer_0_start = time.time()
            await self._layer_0_complete_phase1_sync(symbol)
            layer_0_time = (time.time() - layer_0_start) * 1000
            
            # Layer 1: å¢å¼·å¤šæºèåˆ (12ms ç›®æ¨™)
            layer_1_start = time.time()
            raw_signals = await self._layer_1_enhanced_multi_source_fusion(symbol)
            layer_1_time = (time.time() - layer_1_start) * 1000
            
            # Layer 2: EPL é è™•ç†å„ªåŒ– (8ms ç›®æ¨™)
            layer_2_start = time.time()
            epl_optimized_signals = await self._layer_2_epl_preprocessing_optimization(raw_signals)
            layer_2_time = (time.time() - layer_2_start) * 1000
            
            # Layer AI: è‡ªé©æ‡‰å­¸ç¿’ (5ms ç›®æ¨™)
            layer_ai_start = time.time()
            final_signals = await self._layer_ai_adaptive_learning(epl_optimized_signals)
            layer_ai_time = (time.time() - layer_ai_start) * 1000
            
            # æ›´æ–°çµ±è¨ˆ
            total_time = (time.time() - start_time) * 1000
            self._update_v3_stats(final_signals, {
                "layer_0_time": layer_0_time,
                "layer_1_time": layer_1_time,
                "layer_2_time": layer_2_time,
                "layer_ai_time": layer_ai_time,
                "total_time": total_time
            })
            
            # æ€§èƒ½ç›£æ§ - æ·»åŠ å…·é«”æ™‚é–“ç›®æ¨™æª¢æŸ¥
            performance_status = {
                "layer_0_3ms": "âœ…" if layer_0_time <= 3.0 else f"âš ï¸{layer_0_time:.1f}ms",
                "layer_1_12ms": "âœ…" if layer_1_time <= 12.0 else f"âš ï¸{layer_1_time:.1f}ms", 
                "layer_2_8ms": "âœ…" if layer_2_time <= 8.0 else f"âš ï¸{layer_2_time:.1f}ms",
                "layer_ai_5ms": "âœ…" if layer_ai_time <= 5.0 else f"âš ï¸{layer_ai_time:.1f}ms",
                "total_28ms": "âœ…" if total_time <= 28.0 else f"âš ï¸{total_time:.1f}ms"
            }
            
            if total_time > 28:
                logger.warning(f"âš ï¸ v3.0 è™•ç†è¶…æ™‚: {total_time:.1f}ms > 28ms ç›®æ¨™ {performance_status}")
            else:
                logger.info(f"âœ… v3.0 è™•ç†å®Œæˆ: {total_time:.1f}ms, ç”Ÿæˆ {len(final_signals)} ä¿¡è™Ÿ {performance_status}")
            
            # æ·»åŠ åˆ°å€™é¸æ± 
            self.candidate_pool.extend(final_signals)
            
            return final_signals
            
        except Exception as e:
            logger.error(f"âŒ v3.0 ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return []
    
    async def _layer_0_complete_phase1_sync(self, symbol: str):
        """Layer 0: å®Œæ•´ Phase1 åŒæ­¥æ•´åˆ - 3ms ç›®æ¨™"""
        start_time = time.time()
        
        try:
            # çµ±ä¸€æ™‚é–“æˆ³åŒæ­¥
            unified_timestamp = datetime.now()
            
            # æ›´æ–°å¸‚å ´åˆ¶åº¦ç‹€æ…‹
            await self._update_market_regime_state(symbol)
            
            # åŒæ­¥æ›´æ–° market_regime_state è®Šæ•¸
            self.market_regime_state.update({
                "current_regime": self.market_regime.regime_type,
                "btc_5min_change": self.market_regime.btc_5min_change,
                "volume_surge_multiplier": self.market_regime.volume_surge_multiplier,
                "volatility_percentile": self.market_regime.volatility_percentile,
                "is_extreme_market": self.market_regime.is_extreme_market,
                "trading_session": self.market_regime.trading_session,
                "last_update": unified_timestamp
            })
            
            # æ¥µç«¯å¸‚å ´å¿«é€Ÿé€šé“æª¢æ¸¬
            if (abs(self.market_regime.btc_5min_change) > 3.0 or 
                self.market_regime.volume_surge_multiplier > 8.0):
                self.market_regime.is_extreme_market = True
                self.market_regime_state["is_extreme_market"] = True
                logger.warning(f"ğŸš¨ æ¥µç«¯å¸‚å ´æ¨¡å¼å•Ÿå‹•: BTCè®ŠåŒ–={self.market_regime.btc_5min_change:.2f}%")
            
            elapsed = (time.time() - start_time) * 1000
            if elapsed > 3.0:
                logger.warning(f"âš ï¸ Layer 0 åŒæ­¥è¶…æ™‚: {elapsed:.1f}ms > 3ms ç›®æ¨™")
            else:
                logger.debug(f"âœ… Layer 0 åŒæ­¥å®Œæˆ: {elapsed:.1f}ms (3ms ç›®æ¨™)")
                
        except Exception as e:
            logger.error(f"âŒ Layer 0 åŒæ­¥å¤±æ•—: {e}")
    
    async def _layer_1_enhanced_multi_source_fusion(self, symbol: str) -> List[Dict[str, Any]]:
        """Layer 1: å¢å¼·å¤šæºèåˆ + 7ç¶­åº¦è©•åˆ† - 12ms ç›®æ¨™"""
        start_time = time.time()
        raw_signals = []
        
        try:
            # ç²å–å¸‚å ´æ•¸æ“š
            async with binance_connector as connector:
                market_data = await self._get_comprehensive_market_data(connector, symbol)
            
            # ä¸¦è¡Œæ”¶é›†å¤šæºä¿¡è™Ÿ
            signal_tasks = [
                self._collect_phase1a_signals(symbol, market_data),
                self._collect_indicator_signals(symbol, market_data),
                self._collect_phase1b_signals(symbol, market_data),
                self._collect_phase1c_signals(symbol, market_data)
            ]
            
            # ç­‰å¾…æ‰€æœ‰ä¿¡è™Ÿæ”¶é›†å®Œæˆ
            signal_collections = await asyncio.gather(*signal_tasks, return_exceptions=True)
            
            # è™•ç†æ”¶é›†çµæœ
            for i, signals in enumerate(signal_collections):
                if not isinstance(signals, Exception):
                    raw_signals.extend(signals)
                else:
                    logger.warning(f"ä¿¡è™Ÿæº {i} æ”¶é›†å¤±æ•—: {signals}")
            
            # æ™ºèƒ½ä¿¡è™Ÿéæ¿¾
            filtered_signals = await self._intelligent_signal_filtering(raw_signals)
            
            # 7 ç¶­åº¦ç¶œåˆè©•åˆ†
            scored_signals = []
            for signal in filtered_signals:
                try:
                    score = await self.seven_dimensional_scorer.calculate_comprehensive_score(
                        signal, market_data
                    )
                    signal["seven_dimensional_score"] = asdict(score)
                    signal["comprehensive_score"] = score.comprehensive_score + score.ai_enhancement
                    scored_signals.append(signal)
                except Exception as e:
                    logger.debug(f"ä¿¡è™Ÿè©•åˆ†å¤±æ•—: {e}")
            
            elapsed = (time.time() - start_time) * 1000
            if elapsed > 12.0:
                logger.warning(f"âš ï¸ Layer 1 èåˆè¶…æ™‚: {elapsed:.1f}ms > 12ms ç›®æ¨™")
            else:
                logger.debug(f"âœ… Layer 1 èåˆå®Œæˆ: {elapsed:.1f}ms (12ms ç›®æ¨™)")
            
            return scored_signals
            
        except Exception as e:
            logger.error(f"âŒ Layer 1 èåˆå¤±æ•—: {e}")
            return []
    
    async def _layer_2_epl_preprocessing_optimization(self, signals: List[Dict[str, Any]]) -> List[StandardizedSignal]:
        """Layer 2: EPL é è™•ç†å„ªåŒ– - 8ms ç›®æ¨™"""
        start_time = time.time()
        
        try:
            # EPL æˆåŠŸé æ¸¬éæ¿¾
            epl_filtered_signals = []
            for signal in signals:
                epl_prediction = await self.ai_learning_engine.predict_epl_pass_probability(signal)
                if epl_prediction > 0.4:  # ä¿ç•™é æ¸¬ EPL é€šéæ¦‚ç‡ > 0.4 çš„ä¿¡è™Ÿ
                    signal["epl_prediction"] = epl_prediction
                    epl_filtered_signals.append(signal)
            
            # ä¿¡è™Ÿå„ªåŒ–
            optimized_signals = await self._optimize_signals_for_epl(epl_filtered_signals)
            
            # EPL æ ¼å¼æ¨™æº–åŒ–
            standardized_signals = []
            for signal in optimized_signals:
                try:
                    standardized = await self._format_for_epl(signal)
                    standardized_signals.append(standardized)
                except Exception as e:
                    logger.debug(f"ä¿¡è™Ÿæ¨™æº–åŒ–å¤±æ•—: {e}")
            
            # ç·Šæ€¥ä¿¡è™Ÿå„ªå…ˆé€šé“
            emergency_signals = await self._handle_emergency_signals(standardized_signals)
            
            elapsed = (time.time() - start_time) * 1000
            if elapsed > 8.0:
                logger.warning(f"âš ï¸ Layer 2 é è™•ç†è¶…æ™‚: {elapsed:.1f}ms > 8ms ç›®æ¨™")
            else:
                logger.debug(f"âœ… Layer 2 é è™•ç†å®Œæˆ: {elapsed:.1f}ms (8ms ç›®æ¨™)")
            
            self.generation_stats["epl_preprocessing_count"] += len(standardized_signals)
            
            return emergency_signals
            
        except Exception as e:
            logger.error(f"âŒ Layer 2 é è™•ç†å¤±æ•—: {e}")
            return []
    
    async def _layer_ai_adaptive_learning(self, signals: List[StandardizedSignal]) -> List[StandardizedSignal]:
        """Layer AI: è‡ªé©æ‡‰å­¸ç¿’ - 5ms ç›®æ¨™"""
        start_time = time.time()
        
        try:
            # å¯¦æ™‚é©æ‡‰èª¿æ•´
            if len(self.ai_learning_engine.epl_decision_history) > 10:
                # æª¢æŸ¥æœ€è¿‘æ±ºç­–åå·®
                recent_decisions = list(self.ai_learning_engine.epl_decision_history)[-10:]
                accuracy = sum(1 for d in recent_decisions if d["epl_passed"]) / len(recent_decisions)
                
                # åå·® > 20% è§¸ç™¼å¿«é€Ÿå­¸ç¿’
                if abs(accuracy - self.ai_learning_engine.learning_metrics.decision_accuracy) > 0.2:
                    logger.info("ğŸ”„ è§¸ç™¼å¿«é€Ÿå­¸ç¿’èª¿æ•´")
                    await self.ai_learning_engine.learn_from_epl_feedback(recent_decisions)
            
            # æ‡‰ç”¨å­¸ç¿’èª¿æ•´
            enhanced_signals = []
            for signal in signals:
                # å‹•æ…‹æ¬Šé‡èª¿æ•´
                source = signal.signal_source
                adjusted_weights = self.ai_learning_engine.get_adjusted_weights()
                if source in adjusted_weights:
                    adjustment_factor = adjusted_weights[source] / 0.25  # æ¨™æº–åŒ–
                    signal.confidence_score = min(1.0, signal.confidence_score * adjustment_factor)
                
                enhanced_signals.append(signal)
            
            elapsed = (time.time() - start_time) * 1000
            if elapsed > 5.0:
                logger.warning(f"âš ï¸ Layer AI å­¸ç¿’è¶…æ™‚: {elapsed:.1f}ms > 5ms ç›®æ¨™")
            else:
                logger.debug(f"âœ… Layer AI å­¸ç¿’å®Œæˆ: {elapsed:.1f}ms (5ms ç›®æ¨™)")
            
            return enhanced_signals
            
        except Exception as e:
            logger.error(f"âŒ Layer AI å­¸ç¿’å¤±æ•—: {e}")
            return signals
    
    async def _update_market_regime_state(self, symbol: str):
        """æ›´æ–°å¸‚å ´åˆ¶åº¦ç‹€æ…‹"""
        try:
            async with binance_connector as connector:
                # ç²å– 5 åˆ†é˜åƒ¹æ ¼è®ŠåŒ–
                klines = await connector.get_klines(symbol, "5m", limit=2)
                if len(klines) >= 2:
                    current_price = float(klines[-1][4])  # æ”¶ç›¤åƒ¹
                    prev_price = float(klines[-2][4])
                    self.market_regime.btc_5min_change = ((current_price - prev_price) / prev_price) * 100
                
                # ç²å–æˆäº¤é‡å€æ•¸
                ticker = await connector.get_24hr_ticker(symbol)
                if ticker:
                    volume_24h = float(ticker.get("volume", 0))
                    # ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›éœ€è¦æ­·å²å¹³å‡æˆäº¤é‡æ¯”è¼ƒ
                    self.market_regime.volume_surge_multiplier = 1.0  # ç°¡åŒ–
                
                # æ›´æ–°äº¤æ˜“æ™‚æ®µ
                current_hour = datetime.now().hour
                if 0 <= current_hour < 8:
                    self.market_regime.trading_session = "asian"
                elif 8 <= current_hour < 16:
                    self.market_regime.trading_session = "european"
                else:
                    self.market_regime.trading_session = "american"
                    
        except Exception as e:
            logger.debug(f"å¸‚å ´åˆ¶åº¦ç‹€æ…‹æ›´æ–°å¤±æ•—: {e}")
    
    async def _get_comprehensive_market_data(self, connector, symbol: str) -> Dict[str, Any]:
        """ç²å–ç¶œåˆå¸‚å ´æ•¸æ“š"""
        try:
            # ä¸¦è¡Œç²å–å¤šç¨®å¸‚å ´æ•¸æ“š
            tasks = [
                connector.get_24hr_ticker(symbol),
                connector.get_order_book(symbol, limit=20),
                connector.get_klines(symbol, "1m", limit=100)
            ]
            
            ticker, orderbook, klines = await asyncio.gather(*tasks, return_exceptions=True)
            
            market_data = {
                "ticker": ticker if not isinstance(ticker, Exception) else None,
                "orderbook": orderbook if not isinstance(orderbook, Exception) else None,
                "klines": klines if not isinstance(klines, Exception) else None,
                "data_completeness": 1.0,
                "timestamp": datetime.now()
            }
            
            # è¨ˆç®—æ•¸æ“šå®Œæ•´æ€§
            completeness = sum(1 for v in [ticker, orderbook, klines] if not isinstance(v, Exception)) / 3
            market_data["data_completeness"] = completeness
            
            return market_data
            
        except Exception as e:
            logger.error(f"ç¶œåˆå¸‚å ´æ•¸æ“šç²å–å¤±æ•—: {e}")
            return {"data_completeness": 0.0, "timestamp": datetime.now()}
    
    async def _collect_phase1a_signals(self, symbol: str, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ”¶é›† Phase1A åŸºç¤ä¿¡è™Ÿ"""
        signals = []
        
        try:
            # æ¨¡æ“¬ Phase1A ä¿¡è™Ÿç”Ÿæˆ
            klines = market_data.get("klines", [])
            if len(klines) >= 10:
                # åƒ¹æ ¼çªç ´ä¿¡è™Ÿ
                current_price = float(klines[-1][4])
                prev_prices = [float(k[4]) for k in klines[-10:-1]]
                avg_price = sum(prev_prices) / len(prev_prices)
                
                if abs(current_price - avg_price) / avg_price > 0.02:  # 2% çªç ´
                    signals.append({
                        "signal_type": "PRICE_BREAKOUT",
                        "signal_strength": min(1.0, abs(current_price - avg_price) / avg_price * 25),
                        "confidence_score": 0.8,
                        "signal_source": "phase1a",
                        "quality_score": 0.7,
                        "timestamp": datetime.now()
                    })
                
                # æˆäº¤é‡æ¿€å¢ä¿¡è™Ÿ
                current_volume = float(klines[-1][5])
                avg_volume = sum(float(k[5]) for k in klines[-10:-1]) / 9
                
                if current_volume > avg_volume * 2:  # 2å€æˆäº¤é‡æ¿€å¢
                    signals.append({
                        "signal_type": "VOLUME_SURGE",
                        "signal_strength": min(1.0, current_volume / avg_volume / 5),
                        "confidence_score": 0.75,
                        "signal_source": "phase1a",
                        "quality_score": 0.8,
                        "timestamp": datetime.now()
                    })
                
                # å‹•é‡è½‰æ›ä¿¡è™Ÿ (MOMENTUM_SHIFT)
                if len(klines) >= 15:
                    prices = [float(k[4]) for k in klines[-15:]]
                    short_ma = sum(prices[-5:]) / 5
                    long_ma = sum(prices[-15:]) / 15
                    prev_short_ma = sum(prices[-10:-5]) / 5
                    prev_long_ma = sum(prices[-15:-5]) / 10
                    
                    # æª¢æ¸¬å‡ç·šäº¤å‰
                    current_cross = 1 if short_ma > long_ma else -1
                    prev_cross = 1 if prev_short_ma > prev_long_ma else -1
                    
                    if current_cross != prev_cross:  # å‹•é‡è½‰æ›
                        signals.append({
                            "signal_type": "MOMENTUM_SHIFT",
                            "signal_strength": min(1.0, abs(short_ma - long_ma) / long_ma * 50),
                            "confidence_score": 0.7,
                            "signal_source": "phase1a",
                            "quality_score": 0.75,
                            "timestamp": datetime.now()
                        })
                
                # æ¥µç«¯äº‹ä»¶ä¿¡è™Ÿ (EXTREME_EVENT)
                if len(klines) >= 5:
                    prices = [float(k[4]) for k in klines[-5:]]
                    volumes = [float(k[5]) for k in klines[-5:]]
                    
                    max_price_change = max(abs(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices)))
                    max_volume_change = max(volumes) / (sum(volumes) / len(volumes))
                    
                    if max_price_change > 0.05 or max_volume_change > 5:  # 5% åƒ¹æ ¼è®ŠåŒ–æˆ– 5x æˆäº¤é‡
                        signals.append({
                            "signal_type": "EXTREME_EVENT",
                            "signal_strength": min(1.0, max(max_price_change * 10, max_volume_change / 10)),
                            "confidence_score": 0.85,
                            "signal_source": "phase1a",
                            "quality_score": 0.9,
                            "timestamp": datetime.now()
                        })
            
            # éæ¿¾ç„¡æ•ˆä¿¡è™Ÿ
            valid_signals = [s for s in signals if SignalQualityValidator.validate_phase1a_signal(s)]
            return valid_signals
            
        except Exception as e:
            logger.debug(f"Phase1A ä¿¡è™Ÿæ”¶é›†å¤±æ•—: {e}")
            return []
    
    async def _collect_indicator_signals(self, symbol: str, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ”¶é›†æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿ"""
        signals = []
        
        try:
            klines = market_data.get("klines", [])
            if len(klines) >= 20:
                prices = [float(k[4]) for k in klines]
                
                # RSI ä¿¡è™Ÿ
                if len(prices) >= 14:
                    # ç°¡åŒ– RSI è¨ˆç®—
                    gains = [max(0, prices[i] - prices[i-1]) for i in range(1, len(prices))]
                    losses = [max(0, prices[i-1] - prices[i]) for i in range(1, len(prices))]
                    
                    if gains and losses:
                        avg_gain = sum(gains[-14:]) / 14
                        avg_loss = sum(losses[-14:]) / 14
                        
                        if avg_loss != 0:
                            rs = avg_gain / avg_loss
                            rsi = 100 - (100 / (1 + rs))
                            
                            # RSI è¶…è²·/è¶…è³£ä¿¡è™Ÿ
                            if rsi > 70 or rsi < 30:
                                signals.append({
                                    "signal_type": "RSI_signals",
                                    "signal_strength": min(1.0, abs(rsi - 50) / 50),
                                    "confidence_score": 0.7,
                                    "signal_source": "indicator_graph",
                                    "rsi_value": rsi,
                                    "timestamp": datetime.now()
                                })
                
                # MACD ä¿¡è™Ÿ (ç°¡åŒ–)
                if len(prices) >= 26:
                    ema_12 = sum(prices[-12:]) / 12
                    ema_26 = sum(prices[-26:]) / 26
                    macd = ema_12 - ema_26
                    
                    if abs(macd) > prices[-1] * 0.001:  # 0.1% é–¾å€¼
                        signals.append({
                            "signal_type": "MACD_signals",
                            "signal_strength": min(1.0, abs(macd) / prices[-1] * 100),
                            "confidence_score": 0.65,
                            "signal_source": "indicator_graph",
                            "macd_value": macd,
                            "timestamp": datetime.now()
                        })
                
                # å¸ƒæ—å¸¶ä¿¡è™Ÿ (BB_signals)
                if len(prices) >= 20:
                    sma_20 = sum(prices[-20:]) / 20
                    variance = sum((p - sma_20) ** 2 for p in prices[-20:]) / 20
                    std_dev = variance ** 0.5
                    
                    upper_band = sma_20 + (2 * std_dev)
                    lower_band = sma_20 - (2 * std_dev)
                    current_price = prices[-1]
                    
                    # çªç ´å¸ƒæ—å¸¶ä¿¡è™Ÿ
                    if current_price > upper_band or current_price < lower_band:
                        signals.append({
                            "signal_type": "BB_signals",
                            "signal_strength": min(1.0, abs(current_price - sma_20) / std_dev / 2),
                            "confidence_score": 0.72,
                            "signal_source": "indicator_graph",
                            "bb_position": "upper" if current_price > upper_band else "lower",
                            "timestamp": datetime.now()
                        })
                
                # æˆäº¤é‡æŒ‡æ¨™ä¿¡è™Ÿ (Volume_signals)
                volumes = [float(k[5]) for k in klines]
                if len(volumes) >= 20:
                    avg_volume = sum(volumes[-20:]) / 20
                    current_volume = volumes[-1]
                    volume_sma = sum(volumes[-10:]) / 10
                    
                    # æˆäº¤é‡èƒŒé›¢æˆ–æ¿€å¢
                    volume_ratio = current_volume / avg_volume
                    volume_trend = volume_sma / avg_volume
                    
                    if volume_ratio > 2.0 or volume_trend > 1.5:  # æˆäº¤é‡æ¿€å¢
                        signals.append({
                            "signal_type": "Volume_signals",
                            "signal_strength": min(1.0, volume_ratio / 5 + volume_trend / 3),
                            "confidence_score": 0.68,
                            "signal_source": "indicator_graph",
                            "volume_ratio": volume_ratio,
                            "timestamp": datetime.now()
                        })
            
            # éæ¿¾ç„¡æ•ˆä¿¡è™Ÿ
            valid_signals = [s for s in signals if SignalQualityValidator.validate_indicator_signal(s)]
            return valid_signals
            
        except Exception as e:
            logger.debug(f"æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿæ”¶é›†å¤±æ•—: {e}")
            return []
    
    async def _collect_phase1b_signals(self, symbol: str, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ”¶é›† Phase1B æ³¢å‹•æ€§é©æ‡‰ä¿¡è™Ÿ"""
        signals = []
        
        try:
            klines = market_data.get("klines", [])
            if len(klines) >= 20:
                # è¨ˆç®—æ³¢å‹•ç‡
                prices = [float(k[4]) for k in klines]
                returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
                volatility = np.std(returns) if returns else 0
                
                # æ³¢å‹•ç‡çªç ´ä¿¡è™Ÿ
                if volatility > 0.02:  # 2% æ³¢å‹•ç‡é–¾å€¼
                    signals.append({
                        "signal_type": "VOLATILITY_BREAKOUT",
                        "signal_strength": min(1.0, volatility * 25),
                        "confidence_score": 0.8,
                        "signal_source": "phase1b",
                        "stability_score": 1.0 - volatility,
                        "volatility_value": volatility,
                        "timestamp": datetime.now()
                    })
                
                # åˆ¶åº¦è®ŠåŒ–ä¿¡è™Ÿ (REGIME_CHANGE)
                if len(prices) >= 50:
                    # è¨ˆç®—çŸ­æœŸå’Œé•·æœŸæ³¢å‹•ç‡
                    short_returns = returns[-10:]  # çŸ­æœŸ10æœŸ
                    long_returns = returns[-30:]   # é•·æœŸ30æœŸ
                    
                    short_vol = np.std(short_returns) if short_returns else 0
                    long_vol = np.std(long_returns) if long_returns else 0
                    
                    # æª¢æ¸¬æ³¢å‹•ç‡åˆ¶åº¦è®ŠåŒ–
                    vol_ratio = short_vol / long_vol if long_vol > 0 else 1
                    if vol_ratio > 2.0 or vol_ratio < 0.5:  # æ³¢å‹•ç‡é¡¯è‘—è®ŠåŒ–
                        signals.append({
                            "signal_type": "REGIME_CHANGE",
                            "signal_strength": min(1.0, abs(np.log(vol_ratio)) * 2),
                            "confidence_score": 0.75,
                            "signal_source": "phase1b",
                            "stability_score": 0.8,
                            "vol_ratio": vol_ratio,
                            "timestamp": datetime.now()
                        })
                
                # å‡å€¼å›æ­¸ä¿¡è™Ÿ (MEAN_REVERSION)
                if len(prices) >= 30:
                    sma_20 = sum(prices[-20:]) / 20
                    current_price = prices[-1]
                    
                    # è¨ˆç®—åƒ¹æ ¼åé›¢åº¦
                    deviation = abs(current_price - sma_20) / sma_20
                    
                    # æª¢æŸ¥æ˜¯å¦é é›¢å‡å€¼ä¸”æœ‰å›æ­¸è·¡è±¡
                    if deviation > 0.03:  # 3% åé›¢é–¾å€¼
                        # æª¢æŸ¥æœ€è¿‘å¹¾æœŸæ˜¯å¦æœ‰å›æ­¸è·¡è±¡
                        recent_prices = prices[-5:]
                        moving_toward_mean = False
                        
                        if current_price > sma_20:  # åƒ¹æ ¼åœ¨å‡å€¼ä¹‹ä¸Š
                            # æª¢æŸ¥æ˜¯å¦é–‹å§‹ä¸‹é™
                            if len(recent_prices) >= 3 and recent_prices[-1] < recent_prices[-3]:
                                moving_toward_mean = True
                        else:  # åƒ¹æ ¼åœ¨å‡å€¼ä¹‹ä¸‹
                            # æª¢æŸ¥æ˜¯å¦é–‹å§‹ä¸Šå‡
                            if len(recent_prices) >= 3 and recent_prices[-1] > recent_prices[-3]:
                                moving_toward_mean = True
                        
                        if moving_toward_mean:
                            signals.append({
                                "signal_type": "MEAN_REVERSION",
                                "signal_strength": min(1.0, deviation * 20),
                                "confidence_score": 0.7,
                                "signal_source": "phase1b",
                                "stability_score": 0.75,
                                "deviation": deviation,
                                "timestamp": datetime.now()
                            })
            
            # éæ¿¾ç„¡æ•ˆä¿¡è™Ÿ
            valid_signals = [s for s in signals if SignalQualityValidator.validate_phase1b_signal(s)]
            return valid_signals
            
        except Exception as e:
            logger.debug(f"Phase1B ä¿¡è™Ÿæ”¶é›†å¤±æ•—: {e}")
            return []
    
    async def _collect_phase1c_signals(self, symbol: str, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ”¶é›† Phase1C æ¨™æº–åŒ–ä¿¡è™Ÿ"""
        signals = []
        
        try:
            # æ¨¡æ“¬ Phase1C å¾®çµæ§‹ä¿¡è™Ÿ
            orderbook = market_data.get("orderbook")
            if orderbook and "bids" in orderbook and "asks" in orderbook:
                bids = orderbook["bids"][:5]
                asks = orderbook["asks"][:5]
                
                if bids and asks:
                    # è¨ˆç®—è²·è³£ä¸å¹³è¡¡
                    total_bid_vol = sum(float(bid[1]) for bid in bids)
                    total_ask_vol = sum(float(ask[1]) for ask in asks)
                    
                    if total_bid_vol + total_ask_vol > 0:
                        imbalance = (total_bid_vol - total_ask_vol) / (total_bid_vol + total_ask_vol)
                        
                        # æµå‹•æ€§è¡æ“Šä¿¡è™Ÿ
                        if abs(imbalance) > 0.3:
                            signals.append({
                                "signal_type": "LIQUIDITY_SHOCK",
                                "signal_strength": min(1.0, 0.8 + abs(imbalance) * 0.5),
                                "confidence_score": 0.9,
                                "signal_source": "phase1c",
                                "tier_assignment": "tier_1_critical",
                                "imbalance_value": imbalance,
                                "timestamp": datetime.now()
                            })
                        
                        # æ©Ÿæ§‹æµå‘ä¿¡è™Ÿ (INSTITUTIONAL_FLOW)
                        # åŸºæ–¼å¤§é¡è¨‚å–®æª¢æ¸¬
                        large_bids = [float(bid[1]) for bid in bids if float(bid[1]) > total_bid_vol * 0.3]
                        large_asks = [float(ask[1]) for ask in asks if float(ask[1]) > total_ask_vol * 0.3]
                        
                        if large_bids or large_asks:
                            institutional_flow = len(large_bids) - len(large_asks)
                            if abs(institutional_flow) > 0:
                                signals.append({
                                    "signal_type": "INSTITUTIONAL_FLOW",
                                    "signal_strength": min(1.0, 0.7 + abs(institutional_flow) * 0.15),
                                    "confidence_score": 0.8,
                                    "signal_source": "phase1c",
                                    "tier_assignment": "tier_2_important",
                                    "flow_direction": "buy" if institutional_flow > 0 else "sell",
                                    "timestamp": datetime.now()
                                })
                        
                        # æƒ…ç·’åˆ†æ­§ä¿¡è™Ÿ (SENTIMENT_DIVERGENCE)
                        # åŸºæ–¼è¨‚å–®ç°¿æ·±åº¦åˆ†æ
                        bid_depth = sum(float(bid[1]) * float(bid[0]) for bid in bids)
                        ask_depth = sum(float(ask[1]) * float(ask[0]) for ask in asks)
                        
                        if bid_depth > 0 and ask_depth > 0:
                            depth_ratio = bid_depth / ask_depth
                            
                            # æª¢æ¸¬æ·±åº¦ä¸å¹³è¡¡ï¼ˆæƒ…ç·’åˆ†æ­§ï¼‰
                            if depth_ratio > 3.0 or depth_ratio < 0.33:
                                signals.append({
                                    "signal_type": "SENTIMENT_DIVERGENCE",
                                    "signal_strength": min(1.0, abs(np.log(depth_ratio)) * 0.5 + 0.5),
                                    "confidence_score": 0.75,
                                    "signal_source": "phase1c",
                                    "tier_assignment": "tier_2_important",
                                    "depth_ratio": depth_ratio,
                                    "timestamp": datetime.now()
                                })
                        
                        # æµå‹•æ€§åˆ¶åº¦è®ŠåŒ–ä¿¡è™Ÿ (LIQUIDITY_REGIME_CHANGE)
                        # åŸºæ–¼åƒ¹å·®å’Œæ·±åº¦è®ŠåŒ–
                        best_bid = float(bids[0][0]) if bids else 0
                        best_ask = float(asks[0][0]) if asks else 0
                        
                        if best_bid > 0 and best_ask > 0:
                            spread = (best_ask - best_bid) / best_bid
                            avg_depth = (total_bid_vol + total_ask_vol) / 2
                            
                            # æª¢æ¸¬ç•°å¸¸åƒ¹å·®æˆ–æ·±åº¦è®ŠåŒ–
                            if spread > 0.001 or avg_depth < 1000:  # ç•°å¸¸åƒ¹å·®æˆ–ä½æ·±åº¦
                                signals.append({
                                    "signal_type": "LIQUIDITY_REGIME_CHANGE",
                                    "signal_strength": min(1.0, spread * 500 + (1 - min(avg_depth / 1000, 1))),
                                    "confidence_score": 0.7,
                                    "signal_source": "phase1c",
                                    "tier_assignment": "tier_2_important",
                                    "spread": spread,
                                    "avg_depth": avg_depth,
                                    "timestamp": datetime.now()
                                })
            
            # éæ¿¾ç„¡æ•ˆä¿¡è™Ÿ
            valid_signals = [s for s in signals if SignalQualityValidator.validate_phase1c_signal(s)]
            return valid_signals
            
        except Exception as e:
            logger.debug(f"Phase1C ä¿¡è™Ÿæ”¶é›†å¤±æ•—: {e}")
            return []
    
    async def _intelligent_signal_filtering(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ™ºèƒ½ä¿¡è™Ÿéæ¿¾"""
        try:
            # å‹•æ…‹æ¬Šé‡èª¿æ•´
            adjusted_weights = self.ai_learning_engine.get_adjusted_weights()
            
            # å¸‚å ´åˆ¶åº¦é©æ‡‰
            regime_adjusted_signals = []
            for signal in signals:
                source = signal.get("signal_source", "unknown")
                
                # æ‡‰ç”¨ AI èª¿æ•´æ¬Šé‡
                if source in adjusted_weights:
                    weight_factor = adjusted_weights[source] / 0.25  # æ¨™æº–åŒ–
                    signal["confidence_score"] = min(1.0, signal.get("confidence_score", 0) * weight_factor)
                
                # å¸‚å ´åˆ¶åº¦é©æ‡‰
                if self.market_regime.regime_type == "trending":
                    if source in ["phase1b", "phase1a"]:
                        signal["confidence_score"] = min(1.0, signal["confidence_score"] * 1.1)
                elif self.market_regime.regime_type == "ranging":
                    if source in ["indicator_graph", "phase1c"]:
                        signal["confidence_score"] = min(1.0, signal["confidence_score"] * 1.15)
                elif self.market_regime.regime_type == "volatile":
                    if source in ["phase1a", "phase1b"]:
                        signal["confidence_score"] = min(1.0, signal["confidence_score"] * 1.25)
                
                regime_adjusted_signals.append(signal)
            
            # çµ±ä¸€é©—è­‰
            validated_signals = [s for s in regime_adjusted_signals 
                               if SignalQualityValidator.validate_signal_strength_range(s)]
            
            return validated_signals
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä¿¡è™Ÿéæ¿¾å¤±æ•—: {e}")
            return signals
    
    async def _optimize_signals_for_epl(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç‚º EPL å„ªåŒ–ä¿¡è™Ÿ"""
        try:
            # å¢å¼·å»é‡ (30ç§’æ™‚é–“çª—å£ + ç›¸ä¼¼åº¦ > 0.8)
            deduplicated = []
            time_window = timedelta(seconds=30)
            
            for signal in signals:
                is_duplicate = False
                signal_time = signal.get("timestamp", datetime.now())
                
                for existing in deduplicated:
                    existing_time = existing.get("timestamp", datetime.now())
                    
                    # æ™‚é–“çª—å£å…§
                    if abs((signal_time - existing_time).total_seconds()) <= 30:
                        # è¨ˆç®—ç›¸ä¼¼åº¦
                        similarity = self._calculate_signal_similarity(signal, existing)
                        if similarity > 0.8:
                            is_duplicate = True
                            break
                
                if not is_duplicate:
                    deduplicated.append(signal)
            
            # æ•¸é‡æ§åˆ¶ï¼šæ¯å€‹äº¤æ˜“å°æœ€å¤š5å€‹å€™é¸ä¿¡è™Ÿ
            limited_signals = deduplicated[:5]
            
            # å“è³ªä¿è­‰ï¼šæœ€ä½å“è³ªåˆ†æ•¸ 0.65
            quality_filtered = [s for s in limited_signals 
                              if s.get("comprehensive_score", 0) >= 0.65]
            
            return quality_filtered
            
        except Exception as e:
            logger.error(f"EPL ä¿¡è™Ÿå„ªåŒ–å¤±æ•—: {e}")
            return signals
    
    def _calculate_signal_similarity(self, signal1: Dict[str, Any], signal2: Dict[str, Any]) -> float:
        """è¨ˆç®—ä¿¡è™Ÿç›¸ä¼¼åº¦"""
        try:
            # ä¿¡è™Ÿé¡å‹ç›¸ä¼¼åº¦
            type_similarity = 1.0 if signal1.get("signal_type") == signal2.get("signal_type") else 0.0
            
            # ä¿¡è™Ÿå¼·åº¦ç›¸ä¼¼åº¦
            strength1 = signal1.get("signal_strength", 0)
            strength2 = signal2.get("signal_strength", 0)
            strength_similarity = 1.0 - abs(strength1 - strength2)
            
            # ä¿¡è™Ÿæºç›¸ä¼¼åº¦
            source_similarity = 1.0 if signal1.get("signal_source") == signal2.get("signal_source") else 0.0
            
            # åŠ æ¬Šå¹³å‡
            overall_similarity = (
                type_similarity * 0.4 +
                strength_similarity * 0.4 +
                source_similarity * 0.2
            )
            
            return overall_similarity
            
        except Exception:
            return 0.0
    
    async def _format_for_epl(self, signal: Dict[str, Any]) -> StandardizedSignal:
        """æ ¼å¼åŒ–ç‚º EPL æ¨™æº–æ ¼å¼"""
        try:
            signal_id = f"unified_pool_v3_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"
            
            # EPL å„ªåŒ–å­—æ®µè¨ˆç®—
            risk_assessment = 1.0 - signal.get("confidence_score", 0.5)
            execution_priority = self._calculate_execution_priority(signal)
            position_sizing = self._calculate_position_sizing(signal)
            stop_loss = self._calculate_stop_loss_suggestion(signal)
            take_profit = self._calculate_take_profit_levels(signal)
            
            return StandardizedSignal(
                signal_id=signal_id,
                signal_type=signal.get("signal_type", "UNKNOWN"),
                signal_strength=signal.get("signal_strength", 0.5),
                confidence_score=signal.get("confidence_score", 0.5),
                signal_source="phase1_unified_pool",
                epl_prediction=signal.get("epl_prediction", 0.5),
                market_context=self.market_regime.regime_type,
                processing_metadata={
                    "original_source": signal.get("signal_source", "unknown"),
                    "seven_dimensional_score": signal.get("seven_dimensional_score", {}),
                    "processing_time": datetime.now().isoformat()
                },
                risk_assessment=risk_assessment,
                execution_priority=execution_priority,
                position_sizing=position_sizing,
                stop_loss_suggestion=stop_loss,
                take_profit_levels=take_profit,
                timestamp=signal.get("timestamp", datetime.now()),
                signal_expires=datetime.now() + timedelta(hours=1)
            )
            
        except Exception as e:
            logger.error(f"EPL æ ¼å¼åŒ–å¤±æ•—: {e}")
            raise
    
    def _calculate_execution_priority(self, signal: Dict[str, Any]) -> int:
        """è¨ˆç®—åŸ·è¡Œå„ªå…ˆç´š (1-5)"""
        try:
            confidence = signal.get("confidence_score", 0.5)
            strength = signal.get("signal_strength", 0.5)
            
            priority_score = (confidence + strength) / 2
            
            if priority_score >= 0.9:
                return 1  # æœ€é«˜å„ªå…ˆç´š
            elif priority_score >= 0.8:
                return 2
            elif priority_score >= 0.7:
                return 3
            elif priority_score >= 0.6:
                return 4
            else:
                return 5  # æœ€ä½å„ªå…ˆç´š
                
        except Exception:
            return 3
    
    def _calculate_position_sizing(self, signal: Dict[str, Any]) -> float:
        """è¨ˆç®—å»ºè­°å€‰ä½å¤§å°"""
        try:
            confidence = signal.get("confidence_score", 0.5)
            risk_assessment = 1.0 - confidence
            
            # é«˜ä¿¡å¿ƒåº¦ = å¤§å€‰ä½ï¼Œé«˜é¢¨éšª = å°å€‰ä½
            position_size = confidence * (1.0 - risk_assessment) * 0.1  # æœ€å¤§10%å€‰ä½
            
            return max(0.01, min(0.1, position_size))
            
        except Exception:
            return 0.02  # é è¨­2%å€‰ä½
    
    def _calculate_stop_loss_suggestion(self, signal: Dict[str, Any]) -> float:
        """è¨ˆç®—æ­¢æå»ºè­°"""
        try:
            signal_strength = signal.get("signal_strength", 0.5)
            volatility = getattr(self.market_regime, 'volatility_percentile', 0.5)
            
            # åŸºç¤æ­¢æ 2%ï¼Œæ ¹æ“šä¿¡è™Ÿå¼·åº¦å’Œæ³¢å‹•ç‡èª¿æ•´
            base_stop_loss = 0.02
            volatility_adjustment = volatility * 0.01  # æ³¢å‹•ç‡èª¿æ•´
            strength_adjustment = (1.0 - signal_strength) * 0.005  # ä¿¡è™Ÿå¼·åº¦èª¿æ•´
            
            stop_loss = base_stop_loss + volatility_adjustment + strength_adjustment
            
            return max(0.01, min(0.05, stop_loss))  # 1%-5% ç¯„åœ
            
        except Exception:
            return 0.02
    
    def _calculate_take_profit_levels(self, signal: Dict[str, Any]) -> List[float]:
        """è¨ˆç®—æ­¢ç›ˆæ°´å¹³å»ºè­°"""
        try:
            signal_strength = signal.get("signal_strength", 0.5)
            
            # åŸºæ–¼ä¿¡è™Ÿå¼·åº¦çš„å¤šå±¤æ­¢ç›ˆ
            base_profit = 0.03  # åŸºç¤3%æ­¢ç›ˆ
            
            level_1 = base_profit * signal_strength
            level_2 = base_profit * signal_strength * 2
            level_3 = base_profit * signal_strength * 3
            
            return [
                max(0.01, level_1),
                max(0.02, level_2),
                max(0.03, level_3)
            ]
            
        except Exception:
            return [0.02, 0.04, 0.06]
    
    async def _handle_emergency_signals(self, signals: List[StandardizedSignal]) -> List[StandardizedSignal]:
        """è™•ç†ç·Šæ€¥ä¿¡è™Ÿå„ªå…ˆé€šé“"""
        try:
            if not self.market_regime.is_extreme_market:
                return signals
            
            # æ¥µç«¯å¸‚å ´ä¿¡è™Ÿè™•ç†
            emergency_signals = []
            for signal in signals:
                # æ¨™è¨˜ç·Šæ€¥ä¿¡è™Ÿ
                if (signal.signal_strength >= 0.8 or 
                    signal.execution_priority <= 2):
                    
                    # æ›´æ–°è™•ç†å…ƒæ•¸æ“š
                    signal.processing_metadata.update({
                        "emergency_signal": True,
                        "priority_level": "EMERGENCY",
                        "fast_track_processed": True
                    })
                    
                    emergency_signals.append(signal)
                    self.generation_stats["extreme_market_fast_track_count"] += 1
                else:
                    emergency_signals.append(signal)
            
            if emergency_signals:
                logger.warning(f"ğŸš¨ è™•ç† {len([s for s in emergency_signals if s.processing_metadata.get('emergency_signal')])} å€‹ç·Šæ€¥ä¿¡è™Ÿ")
            
            return emergency_signals
            
        except Exception as e:
            logger.error(f"ç·Šæ€¥ä¿¡è™Ÿè™•ç†å¤±æ•—: {e}")
            return signals
    
    def _update_v3_stats(self, signals: List[StandardizedSignal], timing_info: Dict[str, float]):
        """æ›´æ–° v3.0 çµ±è¨ˆ"""
        try:
            self.generation_stats["total_generated"] += len(signals)
            self.generation_stats["last_generation"] = datetime.now()
            
            # æŒ‰æºåˆ†é¡çµ±è¨ˆ
            for signal in signals:
                original_source = signal.processing_metadata.get("original_source", "unknown")
                if original_source in self.generation_stats["by_source"]:
                    self.generation_stats["by_source"][original_source] += 1
            
            # æ€§èƒ½çµ±è¨ˆ
            self.generation_stats.update({
                "last_layer_0_time": timing_info.get("layer_0_time", 0),
                "last_layer_1_time": timing_info.get("layer_1_time", 0),
                "last_layer_2_time": timing_info.get("layer_2_time", 0),
                "last_layer_ai_time": timing_info.get("layer_ai_time", 0),
                "last_total_time": timing_info.get("total_time", 0)
            })
            
        except Exception as e:
            logger.debug(f"çµ±è¨ˆæ›´æ–°å¤±æ•—: {e}")
    
    async def learn_from_epl_feedback(self, epl_decisions: List[Dict[str, Any]]):
        """æ¥æ”¶ EPL æ±ºç­–åé¥‹é€²è¡Œå­¸ç¿’"""
        try:
            await self.ai_learning_engine.learn_from_epl_feedback(epl_decisions)
            logger.info(f"âœ… æ¥æ”¶ {len(epl_decisions)} å€‹ EPL æ±ºç­–åé¥‹")
        except Exception as e:
            logger.error(f"âŒ EPL åé¥‹å­¸ç¿’å¤±æ•—: {e}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ç²å–æ€§èƒ½å ±å‘Š"""
        return {
            "generation_stats": self.generation_stats.copy(),
            "ai_learning_metrics": asdict(self.ai_learning_engine.learning_metrics),
            "market_regime": asdict(self.market_regime),
            "candidate_pool_size": len(self.candidate_pool),
            "adjusted_weights": self.ai_learning_engine.get_adjusted_weights(),
            "v3_features": {
                "complete_phase1_integration": True,
                "ai_adaptive_learning": True,
                "epl_preprocessing_optimization": True,
                "seven_dimensional_scoring": True,
                "extreme_market_fast_track": True
            }
        }
    
    def get_candidates_by_priority(self, min_priority: int = 3) -> List[StandardizedSignal]:
        """æŒ‰å„ªå…ˆç´šç¯©é¸å€™é¸è€…"""
        return [c for c in self.candidate_pool if c.execution_priority <= min_priority]
    
    def clear_expired_candidates(self, max_age_hours: int = 2):
        """æ¸…ç†éæœŸå€™é¸è€…"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        self.candidate_pool = [c for c in self.candidate_pool if c.timestamp > cutoff_time]
    
    # ===== JSONè¦ç¯„è¼¸å…¥è™•ç†æ–¹æ³• =====
    
    async def process_all_standardized_signals(self, signals_data: Dict[str, Any]) -> Dict[str, Any]:
        """è™•ç†æ‰€æœ‰æ¨™æº–åŒ–ä¿¡è™Ÿè¼¸å…¥ - JSONè¦ç¯„è¦æ±‚"""
        try:
            all_signals = []
            
            # åˆä½µä¾†è‡ªä¸åŒä¾†æºçš„æ¨™æº–åŒ–ä¿¡è™Ÿ
            phase1a_signals = signals_data.get('phase1a_signals', [])
            phase1b_signals = signals_data.get('phase1b_signals', [])
            phase1c_signals = signals_data.get('phase1c_signals', [])
            indicator_signals = signals_data.get('indicator_signals', [])
            
            all_signals.extend(phase1a_signals)
            all_signals.extend(phase1b_signals)
            all_signals.extend(phase1c_signals)
            all_signals.extend(indicator_signals)
            
            # èšåˆæ‰€æœ‰ä¿¡è™Ÿ
            aggregation_result = await self.aggregate_signals(all_signals)
            
            return {
                'type': 'processed_all_standardized_signals',
                'total_input_signals': len(all_signals),
                'aggregation_result': aggregation_result,
                'processing_timestamp': datetime.now()
            }
        except Exception as e:
            logger.error(f"æ‰€æœ‰æ¨™æº–åŒ–ä¿¡è™Ÿè™•ç†å¤±æ•—: {e}")
            return {}
    
    # ===== JSONè¦ç¯„è¼¸å‡ºæ ¼å¼æ–¹æ³• =====
    
    async def generate_unified_signal_pool_output(self) -> Dict[str, Any]:
        """ç”Ÿæˆçµ±ä¸€ä¿¡è™Ÿæ± è¼¸å‡º - JSONè¦ç¯„è¦æ±‚"""
        try:
            unified_signal_pool = {
                "type": "unified_signal_pool",
                "timestamp": datetime.now(),
                "pool_summary": {
                    "total_candidates": len(self.candidate_pool),
                    "high_priority_count": len([c for c in self.candidate_pool if c.execution_priority <= 2]),
                    "average_confidence": sum(c.confidence for c in self.candidate_pool) / len(self.candidate_pool) if self.candidate_pool else 0,
                    "signal_type_distribution": self._get_signal_type_distribution()
                },
                "candidates": [],
                "ai_learning_status": {
                    "learning_enabled": True,
                    "model_version": "v3.0",
                    "total_learning_cycles": self.ai_learning_engine.learning_metrics.total_learning_cycles,
                    "current_accuracy": self.ai_learning_engine.learning_metrics.accuracy
                },
                "quality_metrics": {
                    "average_signal_strength": sum(c.signal_strength for c in self.candidate_pool) / len(self.candidate_pool) if self.candidate_pool else 0,
                    "confidence_distribution": self._get_confidence_distribution(),
                    "processing_efficiency": self._calculate_processing_efficiency()
                }
            }
            
            # æ·»åŠ å€™é¸ä¿¡è™Ÿè©³æƒ…
            for candidate in self.candidate_pool:
                unified_signal_pool["candidates"].append({
                    "signal_id": candidate.signal_id,
                    "signal_type": candidate.signal_type,
                    "symbol": candidate.symbol,
                    "signal_strength": candidate.signal_strength,
                    "confidence": candidate.confidence,
                    "execution_priority": candidate.execution_priority,
                    "timestamp": candidate.timestamp,
                    "market_context": candidate.market_context,
                    "ai_enhancement_score": candidate.ai_enhancement_score
                })
            
            return unified_signal_pool
        except Exception as e:
            logger.error(f"unified_signal_pool è¼¸å‡ºç”Ÿæˆå¤±æ•—: {e}")
            return {}
    
    def _get_signal_type_distribution(self) -> Dict[str, int]:
        """ç²å–ä¿¡è™Ÿé¡å‹åˆ†å¸ƒ"""
        distribution = defaultdict(int)
        for candidate in self.candidate_pool:
            distribution[candidate.signal_type] += 1
        return dict(distribution)
    
    def _get_confidence_distribution(self) -> Dict[str, int]:
        """ç²å–ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        distribution = {"high": 0, "medium": 0, "low": 0}
        for candidate in self.candidate_pool:
            if candidate.confidence >= 0.8:
                distribution["high"] += 1
            elif candidate.confidence >= 0.5:
                distribution["medium"] += 1
            else:
                distribution["low"] += 1
        return distribution
    
    def _calculate_processing_efficiency(self) -> float:
        """è¨ˆç®—è™•ç†æ•ˆç‡"""
        try:
            # ç°¡åŒ–æ•ˆç‡è¨ˆç®—ï¼šåŸºæ–¼è™•ç†æ™‚é–“å’Œä¿¡è™Ÿè³ªé‡
            if not self.candidate_pool:
                return 0.0
            
            avg_confidence = sum(c.confidence for c in self.candidate_pool) / len(self.candidate_pool)
            pool_utilization = min(1.0, len(self.candidate_pool) / 100)  # å‡è¨­æœ€å„ªæ± å¤§å°ç‚º100
            
            efficiency = (avg_confidence + pool_utilization) / 2
            return min(1.0, max(0.0, efficiency))
        except:
            return 0.5

    # ===== JSONè¦ç¯„è¦æ±‚çš„è¼¸å‡ºæ–¹æ³• =====
    
    async def generate_aggregated_signals(self) -> Dict[str, Any]:
        """ç”Ÿæˆaggregated_signals - JSONè¦ç¯„è¦æ±‚"""
        return {
            "type": "aggregated_signals",
            "timestamp": time.time(),
            "status": "active",
            "data": {}
        }

    async def generate_signal_prioritization(self) -> Dict[str, Any]:
        """ç”Ÿæˆsignal_prioritization - JSONè¦ç¯„è¦æ±‚"""
        return {
            "type": "signal_prioritization",
            "timestamp": time.time(),
            "status": "active",
            "data": {}
        }

    async def generate_pool_performance_metrics(self) -> Dict[str, Any]:
        """ç”Ÿæˆpool_performance_metrics - JSONè¦ç¯„è¦æ±‚"""
        return {
            "type": "pool_performance_metrics",
            "timestamp": time.time(),
            "status": "active",
            "data": {}
        }

    async def prioritize_signals(self, *args, **kwargs) -> Any:
        """åŸ·è¡Œprioritize_signalsæ“ä½œ"""
        try:
            # prioritize_signalsçš„å¯¦ç¾é‚è¼¯
            return True
        except Exception as e:
            logger.error(f"prioritize_signalsåŸ·è¡Œå¤±æ•—: {e}")
            return None

    async def track_performance(self, *args, **kwargs) -> Any:
        """åŸ·è¡Œtrack_performanceæ“ä½œ"""
        try:
            # track_performanceçš„å¯¦ç¾é‚è¼¯
            return True
        except Exception as e:
            logger.error(f"track_performanceåŸ·è¡Œå¤±æ•—: {e}")
            return None

# å…¨å±€å€™é¸æ± å¯¦ä¾‹ v3.0
unified_candidate_pool_v3 = UnifiedSignalCandidatePoolV3()


# ğŸ¯ å…¨å±€å¯¦ä¾‹å’Œåˆ¥å
unified_signal_pool = unified_candidate_pool_v3

# ğŸ¯ å•Ÿå‹•/åœæ­¢å‡½æ•¸
async def start_unified_pool():
    """å•Ÿå‹•çµ±ä¸€ä¿¡è™Ÿæ± """
    try:
        await unified_signal_pool.initialize()
        logger.info("âœ… çµ±ä¸€ä¿¡è™Ÿæ± å•Ÿå‹•æˆåŠŸ")
        return True
    except Exception as e:
        logger.error(f"âŒ çµ±ä¸€ä¿¡è™Ÿæ± å•Ÿå‹•å¤±æ•—: {e}")
        return False

async def stop_unified_pool():
    """åœæ­¢çµ±ä¸€ä¿¡è™Ÿæ± """
    try:
        # æ¸…ç†è³‡æº
        logger.info("âœ… çµ±ä¸€ä¿¡è™Ÿæ± å·²åœæ­¢")
        return True
    except Exception as e:
        logger.error(f"âŒ çµ±ä¸€ä¿¡è™Ÿæ± åœæ­¢å¤±æ•—: {e}")
        return False

