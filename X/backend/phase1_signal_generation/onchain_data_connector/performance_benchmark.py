"""
âš¡ æ™ºèƒ½æ··åˆç³»çµ±æ•ˆèƒ½åŸºæº–æ¸¬è©¦
Performance Benchmark for Smart Hybrid System
æ¸¬è©¦ WebSocket + Multicall å„ªåŒ–æ•ˆæœ
"""

import asyncio
import time
import statistics
from datetime import datetime
from typing import List, Dict

class PerformanceBenchmark:
    """æ™ºèƒ½æ··åˆç³»çµ±æ•ˆèƒ½åŸºæº–æ¸¬è©¦"""
    
    def __init__(self):
        self.results = {}
        
    async def benchmark_price_fetching(self, connector, symbols: List[str], iterations: int = 10):
        """åŸºæº–æ¸¬è©¦åƒ¹æ ¼ç²å–æ€§èƒ½"""
        print(f"âš¡ åŸºæº–æ¸¬è©¦åƒ¹æ ¼ç²å–æ€§èƒ½ ({iterations} æ¬¡è¿­ä»£)")
        
        latencies = []
        success_count = 0
        
        for i in range(iterations):
            start_time = time.time()
            
            try:
                # éš¨æ©Ÿé¸æ“‡æ¸¬è©¦ç¬¦è™Ÿ
                test_symbol = symbols[i % len(symbols)]
                price = await connector.get_price(test_symbol)
                
                end_time = time.time()
                latency = (end_time - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’
                
                if price:
                    latencies.append(latency)
                    success_count += 1
                    print(f"   ç¬¬{i+1}æ¬¡ {test_symbol}: {latency:.2f}ms -> ${price:.4f}")
                else:
                    print(f"   ç¬¬{i+1}æ¬¡ {test_symbol}: å¤±æ•—")
                    
            except Exception as e:
                print(f"   ç¬¬{i+1}æ¬¡: éŒ¯èª¤ - {e}")
            
            # é¿å…éæ–¼é »ç¹çš„è«‹æ±‚
            if i < iterations - 1:
                await asyncio.sleep(0.1)
        
        if latencies:
            avg_latency = statistics.mean(latencies)
            min_latency = min(latencies)
            max_latency = max(latencies)
            median_latency = statistics.median(latencies)
            
            print(f"\nğŸ“Š å»¶é²çµ±è¨ˆ:")
            print(f"   å¹³å‡å»¶é²: {avg_latency:.2f}ms")
            print(f"   æœ€å°å»¶é²: {min_latency:.2f}ms")
            print(f"   æœ€å¤§å»¶é²: {max_latency:.2f}ms") 
            print(f"   ä¸­ä½å»¶é²: {median_latency:.2f}ms")
            print(f"   æˆåŠŸç‡: {success_count}/{iterations} ({success_count/iterations*100:.1f}%)")
            
            # è©•ä¼°æ•ˆèƒ½ç­‰ç´š
            if avg_latency < 500:
                print("   ğŸ¯ æ•ˆèƒ½ç­‰ç´š: å„ªç§€ (<500ms)")
            elif avg_latency < 1000:
                print("   âœ… æ•ˆèƒ½ç­‰ç´š: è‰¯å¥½ (<1000ms)")
            elif avg_latency < 2000:
                print("   âš ï¸ æ•ˆèƒ½ç­‰ç´š: å¯æ¥å— (<2000ms)")
            else:
                print("   âŒ æ•ˆèƒ½ç­‰ç´š: éœ€è¦å„ªåŒ– (>2000ms)")
                
            return {
                'avg_latency': avg_latency,
                'min_latency': min_latency,
                'max_latency': max_latency,
                'median_latency': median_latency,
                'success_rate': success_count/iterations,
                'total_iterations': iterations
            }
        else:
            print("   âŒ æ²’æœ‰æˆåŠŸçš„æ¸¬è©¦")
            return None
    
    async def benchmark_batch_fetching(self, connector, iterations: int = 5):
        """åŸºæº–æ¸¬è©¦æ‰¹é‡ç²å–æ€§èƒ½"""
        print(f"\nğŸ”¥ åŸºæº–æ¸¬è©¦æ‰¹é‡ç²å–æ€§èƒ½ ({iterations} æ¬¡è¿­ä»£)")
        
        batch_latencies = []
        
        for i in range(iterations):
            start_time = time.time()
            
            try:
                all_prices = await connector.get_all_prices()
                end_time = time.time()
                
                batch_latency = (end_time - start_time) * 1000
                batch_latencies.append(batch_latency)
                
                print(f"   ç¬¬{i+1}æ¬¡æ‰¹é‡: {batch_latency:.2f}ms -> {len(all_prices)} å€‹åƒ¹æ ¼")
                
            except Exception as e:
                print(f"   ç¬¬{i+1}æ¬¡æ‰¹é‡: éŒ¯èª¤ - {e}")
            
            if i < iterations - 1:
                await asyncio.sleep(0.5)
        
        if batch_latencies:
            avg_batch_latency = statistics.mean(batch_latencies)
            min_batch_latency = min(batch_latencies)
            max_batch_latency = max(batch_latencies)
            
            print(f"\nğŸ“Š æ‰¹é‡å»¶é²çµ±è¨ˆ:")
            print(f"   å¹³å‡æ‰¹é‡å»¶é²: {avg_batch_latency:.2f}ms")
            print(f"   æœ€å°æ‰¹é‡å»¶é²: {min_batch_latency:.2f}ms")
            print(f"   æœ€å¤§æ‰¹é‡å»¶é²: {max_batch_latency:.2f}ms")
            
            # WebSocket + Multicall æ•ˆèƒ½ç›®æ¨™
            if avg_batch_latency < 1000:
                print("   ğŸš€ æ‰¹é‡æ•ˆèƒ½: å„ªç§€ (<1000ms)")
            elif avg_batch_latency < 2000:
                print("   âœ… æ‰¹é‡æ•ˆèƒ½: è‰¯å¥½ (<2000ms)")
            else:
                print("   âš ï¸ æ‰¹é‡æ•ˆèƒ½: éœ€è¦å„ªåŒ– (>2000ms)")
                
            return {
                'avg_batch_latency': avg_batch_latency,
                'min_batch_latency': min_batch_latency,
                'max_batch_latency': max_batch_latency
            }
        else:
            return None
    
    async def benchmark_fallback_mechanism(self, connector, symbols: List[str]):
        """åŸºæº–æ¸¬è©¦å›é€€æ©Ÿåˆ¶æ€§èƒ½"""
        print(f"\nğŸ”„ åŸºæº–æ¸¬è©¦å›é€€æ©Ÿåˆ¶æ€§èƒ½")
        
        fallback_count = 0
        fallback_latencies = []
        
        # ç²å–ç³»çµ±ç‹€æ…‹
        status = await connector.get_system_status()
        symbols_on_fallback = status.get('symbols_on_fallback', [])
        
        if symbols_on_fallback:
            print(f"   æª¢æ¸¬åˆ° {len(symbols_on_fallback)} å€‹å¹£ç¨®æ­£åœ¨ä½¿ç”¨å›é€€æ©Ÿåˆ¶:")
            
            for symbol in symbols_on_fallback:
                start_time = time.time()
                try:
                    price = await connector.get_price(symbol)
                    end_time = time.time()
                    
                    if price:
                        fallback_latency = (end_time - start_time) * 1000
                        fallback_latencies.append(fallback_latency)
                        fallback_count += 1
                        print(f"      {symbol}: {fallback_latency:.2f}ms (å›é€€)")
                        
                except Exception as e:
                    print(f"      {symbol}: å›é€€å¤±æ•— - {e}")
            
            if fallback_latencies:
                avg_fallback_latency = statistics.mean(fallback_latencies)
                print(f"\n   å›é€€æ©Ÿåˆ¶å¹³å‡å»¶é²: {avg_fallback_latency:.2f}ms")
                print(f"   å›é€€æ©Ÿåˆ¶æˆåŠŸç‡: {fallback_count}/{len(symbols_on_fallback)}")
                
                return {
                    'avg_fallback_latency': avg_fallback_latency,
                    'fallback_success_rate': fallback_count/len(symbols_on_fallback),
                    'symbols_on_fallback': len(symbols_on_fallback)
                }
        else:
            print("   âœ… æ²’æœ‰å¹£ç¨®ä½¿ç”¨å›é€€æ©Ÿåˆ¶ - éˆä¸Šæ•¸æ“šé‹è¡Œè‰¯å¥½")
            return {'all_onchain': True}

async def run_performance_benchmark():
    """é‹è¡Œå®Œæ•´çš„æ•ˆèƒ½åŸºæº–æ¸¬è©¦"""
    
    print("âš¡ æ™ºèƒ½æ··åˆç³»çµ±æ•ˆèƒ½åŸºæº–æ¸¬è©¦")
    print("=" * 70)
    
    try:
        # å‰µå»ºæ¨¡æ“¬å¹£å®‰å›é€€
        class MockBinanceFallback:
            async def get_price(self, symbol: str) -> float:
                mock_prices = {
                    'BTC': 43500.0, 'ETH': 2650.0, 'BNB': 310.0,
                    'ADA': 0.45, 'DOGE': 0.08, 'XRP': 0.52, 'SOL': 98.0
                }
                await asyncio.sleep(0.05)  # æ¨¡æ“¬ç¶²è·¯å»¶é²
                return mock_prices.get(symbol, 100.0)
        
        # å°å…¥æ™ºèƒ½æ··åˆé€£æ¥å™¨
        from smart_hybrid_connector import SmartHybridPriceConnector
        
        mock_binance = MockBinanceFallback()
        connector = SmartHybridPriceConnector(binance_fallback=mock_binance)
        
        print("ğŸš€ åˆå§‹åŒ–æ™ºèƒ½æ··åˆé€£æ¥å™¨...")
        await connector.initialize()
        
        print("âš¡ å•Ÿå‹•åƒ¹æ ¼æµ...")
        await connector.start_price_streaming()
        
        print("â³ ç³»çµ±ç©©å®šç­‰å¾…...")
        await asyncio.sleep(3)
        
        # å‰µå»ºåŸºæº–æ¸¬è©¦å¯¦ä¾‹
        benchmark = PerformanceBenchmark()
        
        # æ¸¬è©¦ç¬¦è™Ÿ
        test_symbols = ['BTC', 'ETH', 'BNB', 'ADA', 'DOGE', 'XRP', 'SOL']
        
        # 1. å–®æ¬¡åƒ¹æ ¼ç²å–æ•ˆèƒ½æ¸¬è©¦
        print("\n" + "="*50)
        single_results = await benchmark.benchmark_price_fetching(
            connector, test_symbols, iterations=15
        )
        
        # 2. æ‰¹é‡ç²å–æ•ˆèƒ½æ¸¬è©¦
        print("\n" + "="*50)
        batch_results = await benchmark.benchmark_batch_fetching(
            connector, iterations=5
        )
        
        # 3. å›é€€æ©Ÿåˆ¶æ•ˆèƒ½æ¸¬è©¦
        print("\n" + "="*50)
        fallback_results = await benchmark.benchmark_fallback_mechanism(
            connector, test_symbols
        )
        
        # æœ€çµ‚æ•ˆèƒ½å ±å‘Š
        print("\n" + "="*70)
        print("ğŸ† æœ€çµ‚æ•ˆèƒ½å ±å‘Š")
        print("="*70)
        
        if single_results:
            print(f"ğŸ“ˆ å–®æ¬¡ç²å–å¹³å‡å»¶é²: {single_results['avg_latency']:.2f}ms")
            print(f"ğŸ“ˆ å–®æ¬¡ç²å–æˆåŠŸç‡: {single_results['success_rate']*100:.1f}%")
        
        if batch_results:
            print(f"ğŸ”¥ æ‰¹é‡ç²å–å¹³å‡å»¶é²: {batch_results['avg_batch_latency']:.2f}ms")
        
        if fallback_results and not fallback_results.get('all_onchain'):
            print(f"ğŸ”„ å›é€€æ©Ÿåˆ¶å¹³å‡å»¶é²: {fallback_results['avg_fallback_latency']:.2f}ms")
        
        # ç³»çµ±æ•´é«”è©•ä¼°
        print("\nğŸ¯ ç³»çµ±æ•´é«”è©•ä¼°:")
        
        performance_score = 0
        
        if single_results and single_results['avg_latency'] < 1000:
            performance_score += 30
            print("   âœ… å–®æ¬¡ç²å–æ•ˆèƒ½: å„ªç§€")
        elif single_results and single_results['avg_latency'] < 2000:
            performance_score += 20
            print("   âš ï¸ å–®æ¬¡ç²å–æ•ˆèƒ½: è‰¯å¥½")
        else:
            print("   âŒ å–®æ¬¡ç²å–æ•ˆèƒ½: éœ€è¦å„ªåŒ–")
        
        if batch_results and batch_results['avg_batch_latency'] < 2000:
            performance_score += 35
            print("   âœ… æ‰¹é‡ç²å–æ•ˆèƒ½: å„ªç§€")
        elif batch_results and batch_results['avg_batch_latency'] < 3000:
            performance_score += 25
            print("   âš ï¸ æ‰¹é‡ç²å–æ•ˆèƒ½: è‰¯å¥½")
        else:
            print("   âŒ æ‰¹é‡ç²å–æ•ˆèƒ½: éœ€è¦å„ªåŒ–")
        
        if fallback_results:
            if fallback_results.get('all_onchain'):
                performance_score += 35
                print("   âœ… å›é€€æ©Ÿåˆ¶: éˆä¸Šæ•¸æ“šç©©å®šï¼Œç„¡éœ€å›é€€")
            elif fallback_results.get('fallback_success_rate', 0) > 0.8:
                performance_score += 30
                print("   âœ… å›é€€æ©Ÿåˆ¶: é‹è¡Œæ­£å¸¸")
            else:
                performance_score += 15
                print("   âš ï¸ å›é€€æ©Ÿåˆ¶: éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸")
        
        print(f"\nğŸ† ç¸½é«”æ•ˆèƒ½è©•åˆ†: {performance_score}/100")
        
        if performance_score >= 80:
            print("ğŸ‰ ç³»çµ±æ•ˆèƒ½å„ªç§€ï¼Œç”Ÿç”¢ç’°å¢ƒå°±ç·’!")
        elif performance_score >= 60:
            print("âœ… ç³»çµ±æ•ˆèƒ½è‰¯å¥½ï¼Œå¯ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ")
        else:
            print("âš ï¸ ç³»çµ±æ•ˆèƒ½éœ€è¦é€²ä¸€æ­¥å„ªåŒ–")
        
        print("\nğŸ§¹ æ¸…ç†æ¸¬è©¦è³‡æº...")
        await connector.stop()
        
    except Exception as e:
        print(f"\nâŒ åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(run_performance_benchmark())
