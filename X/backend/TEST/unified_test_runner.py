#!/usr/bin/env python3
"""
çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨ - Phase1-4 ç¶œåˆæ¸¬è©¦æ¡†æ¶
åŠŸèƒ½ï¼š
1. é †åºåŸ·è¡Œæ‰€æœ‰éšæ®µæ¸¬è©¦
2. ç”Ÿæˆæ•´åˆæ¸¬è©¦å ±å‘Š
3. æ€§èƒ½åŸºæº–æ¸¬è©¦å’Œæ¯”è¼ƒ
4. éŒ¯èª¤åˆ†æå’Œå»ºè­°
5. æ¸¬è©¦çµæœå°å‡ºå’Œæ­¸æª”
"""

import asyncio
import time
import json
import logging
import os
import sys
from datetime import datetime
from typing import Dict, List, Any
import numpy as np

# å°å…¥å„éšæ®µæ¸¬è©¦æ¨¡çµ„
from test_websocket_realtime_driver import WebSocketDataLayerTest
from test_phase1_comprehensive import Phase1ComprehensiveTest
from test_phase2_strategy_level import Phase2StrategyLevelTest
from test_phase3_cross_integration import Phase3CrossPhaseIntegrationTest
from test_phase4_frontend_e2e import Phase4FrontendEndToEndTest

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test_execution.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UnifiedTestRunner:
    """çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨"""
    
    def __init__(self):
        self.test_results = {}
        self.execution_start_time = None
        self.execution_end_time = None
        self.performance_benchmarks = {
            'websocket_layer': {'target_latency_ms': 10.0, 'target_throughput': 10000},
            'phase1_processing': {'target_latency_ms': 150.0, 'target_accuracy': 90.0},
            'phase2_strategy': {'target_latency_ms': 200.0, 'target_accuracy': 85.0},
            'phase3_integration': {'target_latency_ms': 100.0, 'target_reliability': 95.0},
            'phase4_frontend': {'target_latency_ms': 200.0, 'target_ux_score': 8.0}
        }
        
    async def run_complete_test_suite(self, test_phases: List[str] = None) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶"""
        
        if test_phases is None:
            test_phases = [
                "websocket_data_layer",
                "phase1_comprehensive", 
                "phase2_strategy_level",
                "phase3_cross_integration",
                "phase4_frontend_e2e"
            ]
        
        logger.info("ğŸš€ é–‹å§‹åŸ·è¡Œçµ±ä¸€æ¸¬è©¦å¥—ä»¶...")
        logger.info(f"ğŸ“‹ æ¸¬è©¦éšæ®µ: {', '.join(test_phases)}")
        
        self.execution_start_time = datetime.now()
        overall_start_time = time.time()
        
        # åŸ·è¡Œå„éšæ®µæ¸¬è©¦
        for phase in test_phases:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ”„ åŸ·è¡Œéšæ®µ: {phase}")
            logger.info(f"{'='*60}")
            
            phase_start_time = time.time()
            
            try:
                if phase == "websocket_data_layer":
                    result = await self._run_websocket_tests()
                elif phase == "phase1_comprehensive":
                    result = await self._run_phase1_tests()
                elif phase == "phase2_strategy_level":
                    result = await self._run_phase2_tests()
                elif phase == "phase3_cross_integration":
                    result = await self._run_phase3_tests()
                elif phase == "phase4_frontend_e2e":
                    result = await self._run_phase4_tests()
                else:
                    logger.warning(f"âš ï¸ æœªçŸ¥æ¸¬è©¦éšæ®µ: {phase}")
                    continue
                
                phase_duration = time.time() - phase_start_time
                result['phase_duration_s'] = phase_duration
                
                self.test_results[phase] = result
                
                status = "âœ… PASSED" if result.get("success", False) or result.get("overall_success_rate", 0) >= 80.0 else "âŒ FAILED"
                logger.info(f"\n{status} {phase} å®Œæˆ - è€—æ™‚: {phase_duration:.2f}ç§’")
                
            except Exception as e:
                logger.error(f"âŒ {phase} åŸ·è¡Œå¤±æ•—: {e}")
                self.test_results[phase] = {
                    "success": False,
                    "error": str(e),
                    "phase_duration_s": time.time() - phase_start_time
                }
        
        self.execution_end_time = datetime.now()
        total_duration = time.time() - overall_start_time
        
        # ç”Ÿæˆç¶œåˆå ±å‘Š
        comprehensive_report = await self._generate_comprehensive_report(total_duration)
        
        logger.info(f"\nğŸ¯ çµ±ä¸€æ¸¬è©¦å¥—ä»¶å®Œæˆ - ç¸½è€—æ™‚: {total_duration:.2f}ç§’")
        logger.info(f"ğŸ“Š æ•´é«”ç‹€æ…‹: {comprehensive_report['execution_summary']['overall_status']}")
        
        return comprehensive_report
    
    async def _run_websocket_tests(self) -> Dict[str, Any]:
        """åŸ·è¡ŒWebSocketæ•¸æ“šå±¤æ¸¬è©¦"""
        tester = WebSocketDataLayerTest()
        return await tester.run_all_tests()
    
    async def _run_phase1_tests(self) -> Dict[str, Any]:
        """åŸ·è¡ŒPhase1ç¶œåˆæ¸¬è©¦"""
        tester = Phase1ComprehensiveTest()
        return await tester.run_all_tests()
    
    async def _run_phase2_tests(self) -> Dict[str, Any]:
        """åŸ·è¡ŒPhase2ç­–ç•¥å±¤ç´šæ¸¬è©¦"""
        tester = Phase2StrategyLevelTest()
        return await tester.run_all_tests()
    
    async def _run_phase3_tests(self) -> Dict[str, Any]:
        """åŸ·è¡ŒPhase3è·¨éšæ®µæ•´åˆæ¸¬è©¦"""
        tester = Phase3CrossPhaseIntegrationTest()
        return await tester.run_all_tests()
    
    async def _run_phase4_tests(self) -> Dict[str, Any]:
        """åŸ·è¡ŒPhase4å‰ç«¯ç«¯åˆ°ç«¯æ¸¬è©¦"""
        tester = Phase4FrontendEndToEndTest()
        return await tester.run_all_tests()
    
    async def _generate_comprehensive_report(self, total_duration: float) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆæ¸¬è©¦å ±å‘Š"""
        
        # è¨ˆç®—æ•´é«”çµ±è¨ˆ
        total_phases = len(self.test_results)
        successful_phases = sum(
            1 for result in self.test_results.values() 
            if result.get("success", False) or result.get("overall_success_rate", 0) >= 80.0
        )
        
        overall_success_rate = (successful_phases / total_phases) * 100 if total_phases > 0 else 0
        
        # æ€§èƒ½åˆ†æ
        performance_analysis = await self._analyze_performance_metrics()
        
        # éŒ¯èª¤åˆ†æ
        error_analysis = await self._analyze_errors_and_failures()
        
        # åŸºæº–æ¸¬è©¦æ¯”è¼ƒ
        benchmark_comparison = await self._compare_with_benchmarks()
        
        # æ”¹é€²å»ºè­°
        improvement_recommendations = await self._generate_improvement_recommendations()
        
        comprehensive_report = {
            "execution_summary": {
                "start_time": self.execution_start_time.isoformat(),
                "end_time": self.execution_end_time.isoformat(),
                "total_duration_s": total_duration,
                "total_phases": total_phases,
                "successful_phases": successful_phases,
                "failed_phases": total_phases - successful_phases,
                "overall_success_rate": overall_success_rate,
                "overall_status": "âœ… PASSED" if overall_success_rate >= 80.0 else "âŒ FAILED"
            },
            "phase_results": self.test_results,
            "performance_analysis": performance_analysis,
            "error_analysis": error_analysis,
            "benchmark_comparison": benchmark_comparison,
            "improvement_recommendations": improvement_recommendations,
            "test_environment": {
                "timestamp": datetime.now().isoformat(),
                "python_version": sys.version,
                "platform": sys.platform
            }
        }
        
        # ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶
        await self._save_report_to_file(comprehensive_report)
        
        return comprehensive_report
    
    async def _analyze_performance_metrics(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æŒ‡æ¨™"""
        
        performance_data = {}
        
        for phase_name, result in self.test_results.items():
            if not result.get("success") and result.get("overall_success_rate", 0) < 80.0:
                continue
            
            phase_metrics = {
                "duration_s": result.get("phase_duration_s", 0),
                "success_rate": result.get("overall_success_rate", 0),
                "performance_stats": result.get("performance_statistics", {})
            }
            
            # æå–å…·é«”æ€§èƒ½æ•¸æ“š
            if "performance_statistics" in result:
                stats = result["performance_statistics"]
                
                if phase_name == "websocket_data_layer":
                    phase_metrics["avg_latency_ms"] = stats.get("latency", {}).get("avg", 0)
                    phase_metrics["throughput"] = stats.get("throughput", {}).get("avg", 0)
                
                elif phase_name in ["phase1_comprehensive", "phase2_strategy_level"]:
                    # è¨ˆç®—å„çµ„ä»¶å¹³å‡å»¶é²
                    latencies = []
                    for key, value in stats.items():
                        if "latency" in key and isinstance(value, dict):
                            latencies.append(value.get("avg_ms", 0))
                    
                    phase_metrics["avg_component_latency_ms"] = np.mean(latencies) if latencies else 0
                
                elif phase_name == "phase3_cross_integration":
                    phase_metrics["end_to_end_latency_ms"] = stats.get("end_to_end_latency", {}).get("avg", 0)
                    phase_metrics["error_recovery_time_ms"] = stats.get("error_recovery_time", {}).get("avg", 0)
                
                elif phase_name == "phase4_frontend_e2e":
                    phase_metrics["ui_response_time_ms"] = stats.get("ui_update_latency", {}).get("avg", 0)
                    phase_metrics["user_interaction_latency_ms"] = stats.get("user_interaction_latency", {}).get("avg", 0)
            
            performance_data[phase_name] = phase_metrics
        
        # è¨ˆç®—æ•´é«”æ€§èƒ½åˆ†æ•¸
        overall_performance_score = self._calculate_overall_performance_score(performance_data)
        
        return {
            "phase_performance": performance_data,
            "overall_performance_score": overall_performance_score,
            "performance_trends": self._identify_performance_trends(performance_data)
        }
    
    def _calculate_overall_performance_score(self, performance_data: Dict[str, Any]) -> float:
        """è¨ˆç®—æ•´é«”æ€§èƒ½åˆ†æ•¸"""
        
        scores = []
        
        for phase_name, metrics in performance_data.items():
            phase_score = 0
            
            # åŸºæ–¼æˆåŠŸç‡çš„åˆ†æ•¸
            success_rate = metrics.get("success_rate", 0)
            phase_score += success_rate * 0.4
            
            # åŸºæ–¼å»¶é²çš„åˆ†æ•¸
            if phase_name in self.performance_benchmarks:
                benchmark = self.performance_benchmarks[phase_name]
                
                if "target_latency_ms" in benchmark:
                    if phase_name == "websocket_data_layer":
                        actual_latency = metrics.get("avg_latency_ms", float('inf'))
                    elif phase_name in ["phase1_comprehensive", "phase2_strategy_level"]:
                        actual_latency = metrics.get("avg_component_latency_ms", float('inf'))
                    elif phase_name == "phase3_cross_integration":
                        actual_latency = metrics.get("end_to_end_latency_ms", float('inf'))
                    else:  # phase4
                        actual_latency = metrics.get("ui_response_time_ms", float('inf'))
                    
                    target_latency = benchmark["target_latency_ms"]
                    
                    if actual_latency <= target_latency:
                        latency_score = 100
                    else:
                        latency_score = max(0, 100 - ((actual_latency - target_latency) / target_latency * 100))
                    
                    phase_score += latency_score * 0.6
                else:
                    phase_score += 60  # é»˜èªåˆ†æ•¸å¦‚æœæ²’æœ‰å»¶é²åŸºæº–
            
            scores.append(min(100, phase_score))
        
        return np.mean(scores) if scores else 0
    
    def _identify_performance_trends(self, performance_data: Dict[str, Any]) -> List[str]:
        """è­˜åˆ¥æ€§èƒ½è¶¨å‹¢"""
        
        trends = []
        
        # åˆ†æå»¶é²è¶¨å‹¢
        latencies = []
        phase_order = ["websocket_data_layer", "phase1_comprehensive", "phase2_strategy_level", 
                      "phase3_cross_integration", "phase4_frontend_e2e"]
        
        for phase in phase_order:
            if phase in performance_data:
                metrics = performance_data[phase]
                
                if phase == "websocket_data_layer":
                    latency = metrics.get("avg_latency_ms", 0)
                elif phase in ["phase1_comprehensive", "phase2_strategy_level"]:
                    latency = metrics.get("avg_component_latency_ms", 0)
                elif phase == "phase3_cross_integration":
                    latency = metrics.get("end_to_end_latency_ms", 0)
                else:
                    latency = metrics.get("ui_response_time_ms", 0)
                
                latencies.append(latency)
        
        if len(latencies) >= 3:
            # æª¢æŸ¥å»¶é²æ˜¯å¦é€æ­¥å¢åŠ 
            increasing_trend = all(latencies[i] <= latencies[i+1] for i in range(len(latencies)-1))
            if increasing_trend:
                trends.append("å»¶é²éš¨è™•ç†éšæ®µé€æ­¥å¢åŠ ï¼Œç¬¦åˆé æœŸ")
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ç•°å¸¸é«˜å»¶é²
            avg_latency = np.mean(latencies)
            for i, latency in enumerate(latencies):
                if latency > avg_latency * 2:
                    trends.append(f"{phase_order[i]} éšæ®µå»¶é²ç•°å¸¸åé«˜")
        
        # åˆ†ææˆåŠŸç‡è¶¨å‹¢
        success_rates = [metrics.get("success_rate", 0) for metrics in performance_data.values()]
        if success_rates:
            min_success_rate = min(success_rates)
            if min_success_rate >= 95:
                trends.append("æ‰€æœ‰éšæ®µæˆåŠŸç‡å„ªç§€ (>=95%)")
            elif min_success_rate >= 80:
                trends.append("æ•´é«”æˆåŠŸç‡è‰¯å¥½ï¼Œéƒ¨åˆ†éšæ®µå¯å„ªåŒ–")
            else:
                trends.append("å­˜åœ¨æˆåŠŸç‡åä½çš„éšæ®µï¼Œéœ€è¦é‡é»é—œæ³¨")
        
        return trends
    
    async def _analyze_errors_and_failures(self) -> Dict[str, Any]:
        """åˆ†æéŒ¯èª¤å’Œå¤±æ•—"""
        
        error_summary = {
            "total_errors": 0,
            "error_categories": {},
            "critical_failures": [],
            "failure_patterns": []
        }
        
        for phase_name, result in self.test_results.items():
            if "error" in result:
                error_summary["total_errors"] += 1
                error_summary["critical_failures"].append({
                    "phase": phase_name,
                    "error": result["error"],
                    "impact": "critical"
                })
            
            # åˆ†æè©³ç´°çµæœä¸­çš„éŒ¯èª¤
            if "detailed_results" in result:
                for test_name, test_result in result["detailed_results"].items():
                    if not test_result.get("success", True):
                        error_summary["total_errors"] += 1
                        
                        # åˆ†é¡éŒ¯èª¤é¡å‹
                        if "timeout" in test_result.get("error", "").lower():
                            category = "timeout_errors"
                        elif "connection" in test_result.get("error", "").lower():
                            category = "connection_errors"
                        elif "validation" in test_result.get("error", "").lower():
                            category = "validation_errors"
                        else:
                            category = "other_errors"
                        
                        error_summary["error_categories"][category] = error_summary["error_categories"].get(category, 0) + 1
        
        # è­˜åˆ¥å¤±æ•—æ¨¡å¼
        if error_summary["total_errors"] > 0:
            if error_summary["error_categories"].get("timeout_errors", 0) > 2:
                error_summary["failure_patterns"].append("æ€§èƒ½ç›¸é—œè¶…æ™‚å•é¡Œ")
            
            if error_summary["error_categories"].get("connection_errors", 0) > 1:
                error_summary["failure_patterns"].append("ç¶²è·¯é€£æ¥ç©©å®šæ€§å•é¡Œ")
            
            if len(error_summary["critical_failures"]) > 1:
                error_summary["failure_patterns"].append("å¤šå€‹é—œéµéšæ®µå¤±æ•—")
        
        return error_summary
    
    async def _compare_with_benchmarks(self) -> Dict[str, Any]:
        """èˆ‡åŸºæº–æ¸¬è©¦æ¯”è¼ƒ"""
        
        benchmark_results = {}
        
        for phase_name, result in self.test_results.items():
            if phase_name not in self.performance_benchmarks:
                continue
            
            benchmark = self.performance_benchmarks[phase_name]
            actual_metrics = {}
            
            # æå–å¯¦éš›æŒ‡æ¨™
            if phase_name == "websocket_data_layer":
                # WebSocketå±¤åŸºæº–æ¯”è¼ƒ
                if "performance_statistics" in result:
                    stats = result["performance_statistics"]
                    actual_metrics["latency_ms"] = stats.get("latency", {}).get("avg", 0)
                    actual_metrics["throughput"] = stats.get("throughput", {}).get("avg", 0)
            
            elif phase_name in ["phase1_comprehensive", "phase2_strategy_level"]:
                # Phase1/2åŸºæº–æ¯”è¼ƒ
                actual_metrics["success_rate"] = result.get("overall_success_rate", 0)
                
                if "performance_statistics" in result:
                    stats = result["performance_statistics"]
                    latencies = []
                    for key, value in stats.items():
                        if "latency" in key and isinstance(value, dict):
                            latencies.append(value.get("avg_ms", 0))
                    actual_metrics["avg_latency_ms"] = np.mean(latencies) if latencies else 0
            
            elif phase_name == "phase3_cross_integration":
                # Phase3åŸºæº–æ¯”è¼ƒ
                actual_metrics["success_rate"] = result.get("overall_success_rate", 0)
                if "performance_statistics" in result:
                    stats = result["performance_statistics"]
                    actual_metrics["end_to_end_latency_ms"] = stats.get("end_to_end_latency", {}).get("avg", 0)
            
            elif phase_name == "phase4_frontend_e2e":
                # Phase4åŸºæº–æ¯”è¼ƒ
                actual_metrics["success_rate"] = result.get("overall_success_rate", 0)
                
                # å°‹æ‰¾ç”¨æˆ¶é«”é©—åˆ†æ•¸
                if "detailed_results" in result:
                    for test_result in result["detailed_results"].values():
                        if "avg_satisfaction_score" in test_result:
                            actual_metrics["ux_score"] = test_result["avg_satisfaction_score"]
                            break
            
            # è¨ˆç®—åŸºæº–é”æˆæƒ…æ³
            benchmark_achievement = {}
            for metric_name, target_value in benchmark.items():
                actual_value = actual_metrics.get(metric_name.replace("target_", ""), 0)
                
                if "latency" in metric_name:
                    # å»¶é²è¶Šä½è¶Šå¥½
                    achievement = min(100, (target_value / actual_value) * 100) if actual_value > 0 else 0
                else:
                    # å…¶ä»–æŒ‡æ¨™è¶Šé«˜è¶Šå¥½
                    achievement = min(100, (actual_value / target_value) * 100) if target_value > 0 else 0
                
                benchmark_achievement[metric_name] = {
                    "target": target_value,
                    "actual": actual_value,
                    "achievement_percentage": achievement,
                    "status": "âœ… é”æˆ" if achievement >= 90 else "âš ï¸ éƒ¨åˆ†é”æˆ" if achievement >= 70 else "âŒ æœªé”æˆ"
                }
            
            benchmark_results[phase_name] = benchmark_achievement
        
        return benchmark_results
    
    async def _generate_improvement_recommendations(self) -> List[Dict[str, str]]:
        """ç”Ÿæˆæ”¹é€²å»ºè­°"""
        
        recommendations = []
        
        # åˆ†ææ•´é«”çµæœ
        overall_success_rate = sum(
            1 for result in self.test_results.values() 
            if result.get("success", False) or result.get("overall_success_rate", 0) >= 80.0
        ) / len(self.test_results) * 100
        
        if overall_success_rate < 80:
            recommendations.append({
                "category": "æ•´é«”æ€§èƒ½",
                "priority": "é«˜",
                "description": "æ•´é«”æ¸¬è©¦æˆåŠŸç‡åä½ï¼Œå»ºè­°é‡é»å„ªåŒ–å¤±æ•—çš„æ¸¬è©¦éšæ®µ",
                "action": "æª¢æŸ¥å¤±æ•—æ¸¬è©¦çš„è©³ç´°éŒ¯èª¤æ—¥èªŒï¼Œå„ªå…ˆä¿®å¾©é—œéµè·¯å¾‘å•é¡Œ"
            })
        
        # åˆ†æå„éšæ®µå…·é«”å•é¡Œ
        for phase_name, result in self.test_results.items():
            phase_success = result.get("success", False) or result.get("overall_success_rate", 0) >= 80.0
            
            if not phase_success:
                if phase_name == "websocket_data_layer":
                    recommendations.append({
                        "category": "WebSocketæ•¸æ“šå±¤",
                        "priority": "æ¥µé«˜",
                        "description": "WebSocketæ•¸æ“šå±¤æ˜¯æ•´å€‹ç³»çµ±çš„åŸºç¤ï¼Œå¿…é ˆå„ªå…ˆä¿®å¾©",
                        "action": "æª¢æŸ¥WebSocketé€£æ¥ç©©å®šæ€§ã€æ•¸æ“šè™•ç†ç®¡é“ã€é«˜å‹ç‡æª¢æ¸¬å¼•æ“"
                    })
                
                elif phase_name == "phase1_comprehensive":
                    recommendations.append({
                        "category": "Phase1ä¿¡è™Ÿç”Ÿæˆ",
                        "priority": "é«˜",
                        "description": "ä¿¡è™Ÿç”Ÿæˆç³»çµ±å­˜åœ¨å•é¡Œï¼Œå½±éŸ¿å¾ŒçºŒæ‰€æœ‰éšæ®µ",
                        "action": "å„ªåŒ–æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã€æ³¢å‹•ç‡é©æ‡‰æ©Ÿåˆ¶ã€ä¿¡è™Ÿæ¨™æº–åŒ–æµç¨‹"
                    })
                
                elif phase_name == "phase2_strategy_level":
                    recommendations.append({
                        "category": "Phase2ç­–ç•¥å¼•æ“",
                        "priority": "é«˜",
                        "description": "ç­–ç•¥å¼•æ“æ€§èƒ½ä¸é”æ¨™ï¼Œå½±éŸ¿äº¤æ˜“æ±ºç­–è³ªé‡",
                        "action": "å„ªåŒ–ç­–ç•¥é‚è¼¯ã€å¤šæ™‚é–“æ¡†æ¶åˆ†æã€é¢¨éšªç®¡ç†ç®—æ³•"
                    })
                
                elif phase_name == "phase3_cross_integration":
                    recommendations.append({
                        "category": "è·¨éšæ®µæ•´åˆ",
                        "priority": "ä¸­",
                        "description": "è·¨çµ„ä»¶æ•´åˆå­˜åœ¨å•é¡Œï¼Œå¯èƒ½å½±éŸ¿ç³»çµ±ç©©å®šæ€§",
                        "action": "æª¢æŸ¥çµ„ä»¶é–“æ¥å£ã€éŒ¯èª¤è™•ç†æ©Ÿåˆ¶ã€è² è¼‰å‡è¡¡"
                    })
                
                elif phase_name == "phase4_frontend_e2e":
                    recommendations.append({
                        "category": "å‰ç«¯ç”¨æˆ¶é«”é©—",
                        "priority": "ä¸­",
                        "description": "å‰ç«¯é«”é©—å•é¡Œå½±éŸ¿ç”¨æˆ¶æ»¿æ„åº¦",
                        "action": "å„ªåŒ–UIéŸ¿æ‡‰é€Ÿåº¦ã€æ•¸æ“šåŒæ­¥æ©Ÿåˆ¶ã€ç”¨æˆ¶äº¤äº’æµç¨‹"
                    })
        
        # æ€§èƒ½å„ªåŒ–å»ºè­°
        performance_analysis = await self._analyze_performance_metrics()
        if performance_analysis["overall_performance_score"] < 75:
            recommendations.append({
                "category": "æ€§èƒ½å„ªåŒ–",
                "priority": "ä¸­",
                "description": "æ•´é«”æ€§èƒ½åˆ†æ•¸åä½ï¼Œå»ºè­°é€²è¡Œç³»çµ±æ€§èƒ½èª¿å„ª",
                "action": "åˆ†ææ€§èƒ½ç“¶é ¸ã€å„ªåŒ–ç®—æ³•æ•ˆç‡ã€è€ƒæ…®ç¡¬é«”å‡ç´š"
            })
        
        return recommendations
    
    async def _save_report_to_file(self, report: Dict[str, Any]) -> None:
        """ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶"""
        
        # å‰µå»ºå ±å‘Šç›®éŒ„
        report_dir = "test_reports"
        os.makedirs(report_dir, exist_ok=True)
        
        # ç”Ÿæˆå ±å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"{report_dir}/comprehensive_test_report_{timestamp}.json"
        
        # ä¿å­˜JSONå ±å‘Š
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å ±å‘Šå¤±æ•—: {e}")
        
        # ç”Ÿæˆç°¡åŒ–çš„æ‘˜è¦å ±å‘Š
        summary_filename = f"{report_dir}/test_summary_{timestamp}.txt"
        try:
            with open(summary_filename, 'w', encoding='utf-8') as f:
                f.write("=== Trading-X Phase1-4 æ¸¬è©¦æ‘˜è¦å ±å‘Š ===\n\n")
                
                exec_summary = report["execution_summary"]
                f.write(f"åŸ·è¡Œæ™‚é–“: {exec_summary['start_time']} - {exec_summary['end_time']}\n")
                f.write(f"ç¸½è€—æ™‚: {exec_summary['total_duration_s']:.2f} ç§’\n")
                f.write(f"æ¸¬è©¦éšæ®µ: {exec_summary['total_phases']}\n")
                f.write(f"æˆåŠŸéšæ®µ: {exec_summary['successful_phases']}\n")
                f.write(f"æ•´é«”æˆåŠŸç‡: {exec_summary['overall_success_rate']:.1f}%\n")
                f.write(f"ç‹€æ…‹: {exec_summary['overall_status']}\n\n")
                
                f.write("=== å„éšæ®µçµæœ ===\n")
                for phase_name, result in report["phase_results"].items():
                    success = result.get("success", False) or result.get("overall_success_rate", 0) >= 80.0
                    status = "âœ… PASSED" if success else "âŒ FAILED"
                    duration = result.get("phase_duration_s", 0)
                    f.write(f"{phase_name}: {status} ({duration:.2f}s)\n")
                
                f.write(f"\n=== æ€§èƒ½åˆ†æ ===\n")
                perf_analysis = report["performance_analysis"]
                f.write(f"æ•´é«”æ€§èƒ½åˆ†æ•¸: {perf_analysis['overall_performance_score']:.1f}/100\n")
                
                f.write(f"\n=== æ”¹é€²å»ºè­° ===\n")
                for i, rec in enumerate(report["improvement_recommendations"], 1):
                    f.write(f"{i}. [{rec['priority']}] {rec['category']}: {rec['description']}\n")
            
            logger.info(f"ğŸ“‹ æ¸¬è©¦æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_filename}")
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ‘˜è¦å¤±æ•—: {e}")

# ä¸»åŸ·è¡Œå‡½æ•¸
async def main():
    """ä¸»æ¸¬è©¦åŸ·è¡Œå‡½æ•¸"""
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    import argparse
    parser = argparse.ArgumentParser(description='Trading-X çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨')
    parser.add_argument('--phases', nargs='*', 
                       choices=['websocket_data_layer', 'phase1_comprehensive', 
                               'phase2_strategy_level', 'phase3_cross_integration', 
                               'phase4_frontend_e2e'],
                       help='æŒ‡å®šè¦åŸ·è¡Œçš„æ¸¬è©¦éšæ®µ')
    parser.add_argument('--quick', action='store_true', 
                       help='å¿«é€Ÿæ¸¬è©¦æ¨¡å¼ï¼ˆè·³ééƒ¨åˆ†è€—æ™‚æ¸¬è©¦ï¼‰')
    
    args = parser.parse_args()
    
    # å‰µå»ºæ¸¬è©¦åŸ·è¡Œå™¨
    runner = UnifiedTestRunner()
    
    # åŸ·è¡Œæ¸¬è©¦
    try:
        logger.info("ğŸ¯ Trading-X çµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨å•Ÿå‹•")
        
        report = await runner.run_complete_test_suite(args.phases)
        
        # è¼¸å‡ºæœ€çµ‚çµæœ
        print("\n" + "="*80)
        print("ğŸ† Trading-X Phase1-4 ç¶œåˆæ¸¬è©¦å®Œæˆ")
        print("="*80)
        
        exec_summary = report["execution_summary"]
        print(f"ğŸ“Š æ•´é«”æˆåŠŸç‡: {exec_summary['overall_success_rate']:.1f}%")
        print(f"â±ï¸  ç¸½è€—æ™‚: {exec_summary['total_duration_s']:.2f} ç§’")
        print(f"ğŸ¯ æœ€çµ‚ç‹€æ…‹: {exec_summary['overall_status']}")
        
        print(f"\nğŸ“ˆ æ€§èƒ½åˆ†æ•¸: {report['performance_analysis']['overall_performance_score']:.1f}/100")
        
        if report["improvement_recommendations"]:
            print(f"\nğŸ’¡ æ”¹é€²å»ºè­°æ•¸é‡: {len(report['improvement_recommendations'])}")
            for rec in report["improvement_recommendations"][:3]:  # é¡¯ç¤ºå‰3å€‹å»ºè­°
                print(f"   â€¢ [{rec['priority']}] {rec['category']}: {rec['description']}")
        
        # æ ¹æ“šçµæœæ±ºå®šé€€å‡ºä»£ç¢¼
        exit_code = 0 if exec_summary['overall_success_rate'] >= 80.0 else 1
        return exit_code
        
    except Exception as e:
        logger.error(f"âŒ æ¸¬è©¦åŸ·è¡Œå™¨ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        return 1

if __name__ == "__main__":
    # é‹è¡Œçµ±ä¸€æ¸¬è©¦åŸ·è¡Œå™¨
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
