#!/usr/bin/env python3
"""
Phase1ä¿¡è™Ÿç”Ÿæˆç³»çµ±ç¶œåˆæ¸¬è©¦
æ¸¬è©¦ç›®æ¨™ï¼š
1. Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆç®—æ³•
2. æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æº–ç¢ºæ€§
3. Phase1Bæ³¢å‹•ç‡é©æ‡‰æ©Ÿåˆ¶
4. Phase1Cä¿¡è™Ÿæ¨™æº–åŒ–æµç¨‹
5. çµ±ä¸€ä¿¡è™Ÿæ± èšåˆé‚è¼¯
"""

import asyncio
import time
import pytest
import json
import logging
import numpy as np
from datetime import datetime
from typing import Dict, List, Any
from unittest.mock import Mock, patch

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Phase1ComprehensiveTest:
    """Phase1å„çµ„ä»¶ç¶œåˆæ¸¬è©¦"""
    
    def __init__(self):
        self.test_results = {}
        self.performance_metrics = {
            'phase1a_latency': [],
            'phase1b_latency': [],
            'phase1c_latency': [],
            'unified_pool_latency': [],
            'indicator_calculation_latency': []
        }
        
    async def test_phase1a_signal_generation(self) -> Dict[str, Any]:
        """æ¸¬è©¦Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆç®—æ³•"""
        logger.info("ğŸ”„ æ¸¬è©¦Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆ...")
        
        try:
            # æ¨¡æ“¬å¸‚å ´æ•¸æ“š
            market_data = {
                "symbol": "BTCUSDT",
                "timestamp": time.time(),
                "klines": [
                    {"open": 45000, "high": 45500, "low": 44800, "close": 45200, "volume": 1500},
                    {"open": 45200, "high": 45800, "low": 45100, "close": 45600, "volume": 1800},
                    {"open": 45600, "high": 46000, "low": 45400, "close": 45800, "volume": 2100}
                ],
                "orderbook": {
                    "bids": [[45750, 100], [45700, 200], [45650, 300]],
                    "asks": [[45850, 150], [45900, 180], [45950, 220]]
                }
            }
            
            start_time = time.time()
            
            # æ¨¡æ“¬Phase1Aä¿¡è™Ÿç”Ÿæˆ
            phase1a_signals = await self._simulate_phase1a_generation(market_data)
            
            processing_time = (time.time() - start_time) * 1000
            self.performance_metrics['phase1a_latency'].append(processing_time)
            
            # é©—è­‰ä¿¡è™Ÿè³ªé‡
            signal_quality_checks = await self._validate_phase1a_signals(phase1a_signals)
            
            # æ€§èƒ½æª¢æŸ¥
            performance_target = 25.0  # ç›®æ¨™<25ms
            performance_pass = processing_time < performance_target
            
            overall_success = (
                len(phase1a_signals) > 0 and
                signal_quality_checks["all_valid"] and
                performance_pass
            )
            
            result = {
                "test_name": "Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆæ¸¬è©¦",
                "success": overall_success,
                "processing_time_ms": processing_time,
                "performance_target_ms": performance_target,
                "performance_pass": performance_pass,
                "signals_generated": len(phase1a_signals),
                "signal_quality": signal_quality_checks,
                "generated_signals": phase1a_signals[:3],  # åªä¿å­˜å‰3å€‹ä½œç‚ºç¤ºä¾‹
                "status": "âœ… PASSED" if overall_success else "âŒ FAILED"
            }
            
            logger.info(f"{'âœ…' if overall_success else 'âŒ'} Phase1A: {len(phase1a_signals)}å€‹ä¿¡è™Ÿ, {processing_time:.2f}ms")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Phase1Aæ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "Phase1AåŸºç¤ä¿¡è™Ÿç”Ÿæˆæ¸¬è©¦",
                "success": False,
                "error": str(e),
                "status": "âŒ ERROR"
            }
    
    async def test_technical_indicator_calculation(self) -> Dict[str, Any]:
        """æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æº–ç¢ºæ€§"""
        logger.info("ğŸ”„ æ¸¬è©¦æŠ€è¡“æŒ‡æ¨™è¨ˆç®—...")
        
        try:
            # æº–å‚™æ¸¬è©¦åƒ¹æ ¼æ•¸æ“š
            price_data = [45000, 45200, 45600, 45800, 46000, 45700, 45500, 45900, 46200, 46100]
            volume_data = [1500, 1800, 2100, 1900, 2200, 1700, 1600, 2000, 2300, 2100]
            
            start_time = time.time()
            
            # è¨ˆç®—å„ç¨®æŠ€è¡“æŒ‡æ¨™
            indicators_result = await self._calculate_technical_indicators(price_data, volume_data)
            
            processing_time = (time.time() - start_time) * 1000
            self.performance_metrics['indicator_calculation_latency'].append(processing_time)
            
            # é©—è­‰æŒ‡æ¨™è¨ˆç®—çµæœ
            validation_results = await self._validate_technical_indicators(indicators_result)
            
            # æª¢æŸ¥è¨ˆç®—æº–ç¢ºæ€§
            accuracy_checks = {
                "rsi_range_valid": 0 <= indicators_result.get("rsi", -1) <= 100,
                "macd_exists": "macd" in indicators_result,
                "ema_exists": "ema_12" in indicators_result and "ema_26" in indicators_result,
                "volume_indicators_exist": "volume_trend" in indicators_result
            }
            
            all_indicators_valid = all(accuracy_checks.values())
            performance_target = 45.0  # ç›®æ¨™<45ms
            performance_pass = processing_time < performance_target
            
            overall_success = (
                all_indicators_valid and
                validation_results["validation_pass"] and
                performance_pass
            )
            
            result = {
                "test_name": "æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¸¬è©¦",
                "success": overall_success,
                "processing_time_ms": processing_time,
                "performance_target_ms": performance_target,
                "performance_pass": performance_pass,
                "calculated_indicators": indicators_result,
                "accuracy_checks": accuracy_checks,
                "validation_results": validation_results,
                "all_indicators_valid": all_indicators_valid,
                "status": "âœ… PASSED" if overall_success else "âŒ FAILED"
            }
            
            logger.info(f"{'âœ…' if overall_success else 'âŒ'} æŠ€è¡“æŒ‡æ¨™: {len(indicators_result)}å€‹æŒ‡æ¨™, {processing_time:.2f}ms")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "æŠ€è¡“æŒ‡æ¨™è¨ˆç®—æ¸¬è©¦",
                "success": False,
                "error": str(e),
                "status": "âŒ ERROR"
            }
    
    async def test_phase1b_volatility_adaptation(self) -> Dict[str, Any]:
        """æ¸¬è©¦Phase1Bæ³¢å‹•ç‡é©æ‡‰æ©Ÿåˆ¶"""
        logger.info("ğŸ”„ æ¸¬è©¦Phase1Bæ³¢å‹•ç‡é©æ‡‰...")
        
        try:
            # æ¨¡æ“¬ä¸åŒæ³¢å‹•ç‡æƒ…æ³
            volatility_scenarios = [
                {
                    "name": "é«˜æ³¢å‹•ç‡",
                    "volatility_level": 0.08,  # 8%
                    "expected_adaptation": "increased_sensitivity"
                },
                {
                    "name": "ä¸­ç­‰æ³¢å‹•ç‡",
                    "volatility_level": 0.04,  # 4%
                    "expected_adaptation": "normal_sensitivity"
                },
                {
                    "name": "ä½æ³¢å‹•ç‡",
                    "volatility_level": 0.015,  # 1.5%
                    "expected_adaptation": "decreased_sensitivity"
                }
            ]
            
            # æ¨¡æ“¬åŸºç¤ä¿¡è™Ÿ
            base_signals = [
                {
                    "signal_type": "PRICE_BREAKOUT",
                    "signal_strength": 0.7,
                    "confidence_score": 0.8,
                    "timestamp": time.time()
                },
                {
                    "signal_type": "VOLUME_SURGE",
                    "signal_strength": 0.6,
                    "confidence_score": 0.75,
                    "timestamp": time.time()
                }
            ]
            
            adaptation_results = []
            
            for scenario in volatility_scenarios:
                start_time = time.time()
                
                # æ¨¡æ“¬æ³¢å‹•ç‡é©æ‡‰
                adapted_signals = await self._simulate_volatility_adaptation(
                    base_signals, 
                    scenario["volatility_level"]
                )
                
                processing_time = (time.time() - start_time) * 1000
                self.performance_metrics['phase1b_latency'].append(processing_time)
                
                # é©—è­‰é©æ‡‰æ•ˆæœ
                adaptation_effective = await self._validate_adaptation_effectiveness(
                    adapted_signals, 
                    scenario["expected_adaptation"]
                )
                
                scenario_result = {
                    "scenario_name": scenario["name"],
                    "volatility_level": scenario["volatility_level"],
                    "processing_time_ms": processing_time,
                    "signals_adapted": len(adapted_signals),
                    "adaptation_effective": adaptation_effective,
                    "adapted_signals": adapted_signals
                }
                
                adaptation_results.append(scenario_result)
            
            # è©•ä¼°æ•´é«”é©æ‡‰æ€§èƒ½
            avg_processing_time = np.mean([r["processing_time_ms"] for r in adaptation_results])
            all_adaptations_effective = all(r["adaptation_effective"] for r in adaptation_results)
            performance_target = 45.0  # ç›®æ¨™<45ms
            performance_pass = avg_processing_time < performance_target
            
            overall_success = all_adaptations_effective and performance_pass
            
            result = {
                "test_name": "Phase1Bæ³¢å‹•ç‡é©æ‡‰æ¸¬è©¦",
                "success": overall_success,
                "avg_processing_time_ms": avg_processing_time,
                "performance_target_ms": performance_target,
                "performance_pass": performance_pass,
                "scenarios_tested": len(volatility_scenarios),
                "adaptation_results": adaptation_results,
                "all_adaptations_effective": all_adaptations_effective,
                "status": "âœ… PASSED" if overall_success else "âŒ FAILED"
            }
            
            logger.info(f"{'âœ…' if overall_success else 'âŒ'} Phase1B: {len(volatility_scenarios)}å€‹å ´æ™¯, {avg_processing_time:.2f}ms")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Phase1Bæ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "Phase1Bæ³¢å‹•ç‡é©æ‡‰æ¸¬è©¦",
                "success": False,
                "error": str(e),
                "status": "âŒ ERROR"
            }
    
    async def test_phase1c_signal_standardization(self) -> Dict[str, Any]:
        """æ¸¬è©¦Phase1Cä¿¡è™Ÿæ¨™æº–åŒ–æµç¨‹"""
        logger.info("ğŸ”„ æ¸¬è©¦Phase1Cä¿¡è™Ÿæ¨™æº–åŒ–...")
        
        try:
            # æ¨¡æ“¬æœªæ¨™æº–åŒ–çš„ä¿¡è™Ÿ
            raw_signals = [
                {
                    "signal_type": "BREAKOUT",
                    "value": 0.85,
                    "confidence": 0.7,
                    "source": "phase1a",
                    "timestamp": time.time(),
                    "symbol": "BTCUSDT"
                },
                {
                    "signal_type": "MOMENTUM",
                    "value": 0.65,
                    "confidence": 0.8,
                    "source": "phase1b",
                    "timestamp": time.time(),
                    "symbol": "BTCUSDT"
                },
                {
                    "signal_type": "VOLUME_ANOMALY",
                    "value": 0.9,
                    "confidence": 0.75,
                    "source": "indicator_graph",
                    "timestamp": time.time(),
                    "symbol": "BTCUSDT"
                }
            ]
            
            start_time = time.time()
            
            # æ¨¡æ“¬æ¨™æº–åŒ–è™•ç†
            standardized_signals = await self._simulate_signal_standardization(raw_signals)
            
            processing_time = (time.time() - start_time) * 1000
            self.performance_metrics['phase1c_latency'].append(processing_time)
            
            # é©—è­‰æ¨™æº–åŒ–æ•ˆæœ
            standardization_checks = await self._validate_signal_standardization(
                raw_signals, 
                standardized_signals
            )
            
            # æª¢æŸ¥æ¨™æº–åŒ–å®Œæ•´æ€§
            completeness_checks = {
                "all_signals_processed": len(standardized_signals) == len(raw_signals),
                "tier_assignment_complete": all(
                    hasattr(signal, 'tier_assignment') or 'tier_assignment' in signal 
                    for signal in standardized_signals
                ),
                "priority_assignment_complete": all(
                    hasattr(signal, 'execution_priority') or 'execution_priority' in signal 
                    for signal in standardized_signals
                ),
                "standardization_applied": all(
                    hasattr(signal, 'standardized') or 'standardized' in signal 
                    for signal in standardized_signals
                )
            }
            
            all_checks_pass = all(completeness_checks.values())
            performance_target = 25.0  # ç›®æ¨™<25ms
            performance_pass = processing_time < performance_target
            
            overall_success = (
                all_checks_pass and
                standardization_checks["validation_pass"] and
                performance_pass
            )
            
            result = {
                "test_name": "Phase1Cä¿¡è™Ÿæ¨™æº–åŒ–æ¸¬è©¦",
                "success": overall_success,
                "processing_time_ms": processing_time,
                "performance_target_ms": performance_target,
                "performance_pass": performance_pass,
                "raw_signals_count": len(raw_signals),
                "standardized_signals_count": len(standardized_signals),
                "completeness_checks": completeness_checks,
                "standardization_checks": standardization_checks,
                "all_checks_pass": all_checks_pass,
                "sample_standardized_signals": standardized_signals[:2],  # å‰2å€‹ä½œç‚ºç¤ºä¾‹
                "status": "âœ… PASSED" if overall_success else "âŒ FAILED"
            }
            
            logger.info(f"{'âœ…' if overall_success else 'âŒ'} Phase1C: {len(standardized_signals)}å€‹æ¨™æº–åŒ–ä¿¡è™Ÿ, {processing_time:.2f}ms")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Phase1Cæ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "Phase1Cä¿¡è™Ÿæ¨™æº–åŒ–æ¸¬è©¦",
                "success": False,
                "error": str(e),
                "status": "âŒ ERROR"
            }
    
    async def test_unified_signal_pool_aggregation(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ±ä¸€ä¿¡è™Ÿæ± èšåˆé‚è¼¯"""
        logger.info("ğŸ”„ æ¸¬è©¦çµ±ä¸€ä¿¡è™Ÿæ± èšåˆ...")
        
        try:
            # æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„ä¿¡è™Ÿ
            signals_from_sources = {
                "phase1a": [
                    {"signal_type": "BREAKOUT", "strength": 0.8, "confidence": 0.75},
                    {"signal_type": "REVERSAL", "strength": 0.7, "confidence": 0.7}
                ],
                "phase1b": [
                    {"signal_type": "VOLATILITY_ADAPTED", "strength": 0.85, "confidence": 0.8}
                ],
                "phase1c": [
                    {"signal_type": "STANDARDIZED_MOMENTUM", "strength": 0.9, "confidence": 0.85}
                ],
                "indicator_graph": [
                    {"signal_type": "RSI_OVERSOLD", "strength": 0.75, "confidence": 0.8},
                    {"signal_type": "MACD_BULLISH", "strength": 0.8, "confidence": 0.75}
                ]
            }
            
            start_time = time.time()
            
            # æ¨¡æ“¬çµ±ä¸€æ± èšåˆ
            aggregated_signals = await self._simulate_unified_pool_aggregation(signals_from_sources)
            
            processing_time = (time.time() - start_time) * 1000
            self.performance_metrics['unified_pool_latency'].append(processing_time)
            
            # é©—è­‰èšåˆæ•ˆæœ
            aggregation_checks = await self._validate_signal_aggregation(
                signals_from_sources, 
                aggregated_signals
            )
            
            # æª¢æŸ¥èšåˆå®Œæ•´æ€§
            total_input_signals = sum(len(signals) for signals in signals_from_sources.values())
            
            aggregation_metrics = {
                "input_signals_total": total_input_signals,
                "output_signals_count": len(aggregated_signals),
                "deduplication_effective": aggregation_checks.get("duplicates_removed", False),
                "quality_filtering_applied": aggregation_checks.get("quality_filtered", False),
                "source_diversity_maintained": len(set(
                    signal.get("source", "unknown") for signal in aggregated_signals
                )) > 1
            }
            
            performance_target = 28.0  # ç›®æ¨™<28ms
            performance_pass = processing_time < performance_target
            
            overall_success = (
                len(aggregated_signals) > 0 and
                aggregation_checks["validation_pass"] and
                aggregation_metrics["source_diversity_maintained"] and
                performance_pass
            )
            
            result = {
                "test_name": "çµ±ä¸€ä¿¡è™Ÿæ± èšåˆæ¸¬è©¦",
                "success": overall_success,
                "processing_time_ms": processing_time,
                "performance_target_ms": performance_target,
                "performance_pass": performance_pass,
                "aggregation_metrics": aggregation_metrics,
                "aggregation_checks": aggregation_checks,
                "sample_aggregated_signals": aggregated_signals[:3],  # å‰3å€‹ä½œç‚ºç¤ºä¾‹
                "status": "âœ… PASSED" if overall_success else "âŒ FAILED"
            }
            
            logger.info(f"{'âœ…' if overall_success else 'âŒ'} çµ±ä¸€æ± : {len(aggregated_signals)}å€‹èšåˆä¿¡è™Ÿ, {processing_time:.2f}ms")
            return result
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€ä¿¡è™Ÿæ± æ¸¬è©¦å¤±æ•—: {e}")
            return {
                "test_name": "çµ±ä¸€ä¿¡è™Ÿæ± èšåˆæ¸¬è©¦",
                "success": False,
                "error": str(e),
                "status": "âŒ ERROR"
            }
    
    # === æ¨¡æ“¬æ–¹æ³• ===
    
    async def _simulate_phase1a_generation(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬Phase1Aä¿¡è™Ÿç”Ÿæˆ"""
        await asyncio.sleep(0.02)  # æ¨¡æ“¬è™•ç†æ™‚é–“
        
        signals = []
        
        # åŸºæ–¼Kç·šæ•¸æ“šç”Ÿæˆä¿¡è™Ÿ
        klines = market_data.get("klines", [])
        if klines:
            last_kline = klines[-1]
            price_change = (last_kline["close"] - last_kline["open"]) / last_kline["open"]
            
            if abs(price_change) > 0.01:  # 1%ä»¥ä¸Šåƒ¹æ ¼è®ŠåŒ–
                signals.append({
                    "signal_type": "PRICE_BREAKOUT" if price_change > 0 else "PRICE_BREAKDOWN",
                    "signal_strength": min(0.9, abs(price_change) * 50),
                    "confidence_score": 0.7 + min(0.2, abs(price_change) * 10),
                    "source": "phase1a",
                    "timestamp": time.time(),
                    "price_change": price_change
                })
        
        # åŸºæ–¼è¨‚å–®ç°¿ç”Ÿæˆä¿¡è™Ÿ
        orderbook = market_data.get("orderbook", {})
        if orderbook:
            bids = orderbook.get("bids", [])
            asks = orderbook.get("asks", [])
            
            if bids and asks:
                spread = (asks[0][0] - bids[0][0]) / bids[0][0]
                if spread < 0.001:  # ç·Šå¯†åƒ¹å·®
                    signals.append({
                        "signal_type": "TIGHT_SPREAD",
                        "signal_strength": 0.6,
                        "confidence_score": 0.8,
                        "source": "phase1a",
                        "timestamp": time.time(),
                        "spread": spread
                    })
        
        return signals
    
    async def _validate_phase1a_signals(self, signals: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é©—è­‰Phase1Aä¿¡è™Ÿè³ªé‡"""
        await asyncio.sleep(0.001)
        
        if not signals:
            return {"all_valid": False, "error": "no_signals_generated"}
        
        validation_checks = []
        
        for signal in signals:
            checks = {
                "has_signal_type": "signal_type" in signal,
                "has_strength": "signal_strength" in signal and 0 <= signal.get("signal_strength", -1) <= 1,
                "has_confidence": "confidence_score" in signal and 0 <= signal.get("confidence_score", -1) <= 1,
                "has_source": "source" in signal,
                "has_timestamp": "timestamp" in signal
            }
            validation_checks.append(all(checks.values()))
        
        return {
            "all_valid": all(validation_checks),
            "valid_signals": sum(validation_checks),
            "total_signals": len(signals),
            "validation_rate": sum(validation_checks) / len(signals) * 100
        }
    
    async def _calculate_technical_indicators(self, price_data: List[float], volume_data: List[float]) -> Dict[str, Any]:
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™"""
        await asyncio.sleep(0.04)  # æ¨¡æ“¬æŒ‡æ¨™è¨ˆç®—æ™‚é–“
        
        # ç°¡åŒ–çš„æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
        prices = np.array(price_data)
        volumes = np.array(volume_data)
        
        # RSIè¨ˆç®— (ç°¡åŒ–ç‰ˆ)
        price_changes = np.diff(prices)
        gains = np.where(price_changes > 0, price_changes, 0)
        losses = np.where(price_changes < 0, -price_changes, 0)
        
        avg_gain = np.mean(gains) if len(gains) > 0 else 0
        avg_loss = np.mean(losses) if len(losses) > 0 else 0
        
        if avg_loss == 0:
            rsi = 100
        else:
            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs))
        
        # EMAè¨ˆç®— (ç°¡åŒ–ç‰ˆ)
        ema_12 = np.mean(prices[-12:]) if len(prices) >= 12 else np.mean(prices)
        ema_26 = np.mean(prices[-26:]) if len(prices) >= 26 else np.mean(prices)
        
        # MACDè¨ˆç®—
        macd = ema_12 - ema_26
        
        # æˆäº¤é‡æŒ‡æ¨™
        volume_trend = np.mean(volumes[-5:]) / np.mean(volumes[:-5]) if len(volumes) > 5 else 1.0
        
        return {
            "rsi": float(rsi),
            "ema_12": float(ema_12),
            "ema_26": float(ema_26),
            "macd": float(macd),
            "volume_trend": float(volume_trend),
            "calculation_timestamp": time.time()
        }
    
    async def _validate_technical_indicators(self, indicators: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰æŠ€è¡“æŒ‡æ¨™è¨ˆç®—çµæœ"""
        await asyncio.sleep(0.001)
        
        required_indicators = ["rsi", "ema_12", "ema_26", "macd", "volume_trend"]
        
        validation_results = {
            "required_indicators_present": all(ind in indicators for ind in required_indicators),
            "rsi_in_valid_range": 0 <= indicators.get("rsi", -1) <= 100,
            "ema_values_positive": indicators.get("ema_12", 0) > 0 and indicators.get("ema_26", 0) > 0,
            "volume_trend_reasonable": 0.1 <= indicators.get("volume_trend", 0) <= 10.0
        }
        
        return {
            "validation_pass": all(validation_results.values()),
            "validation_details": validation_results,
            "indicators_count": len(indicators)
        }
    
    async def _simulate_volatility_adaptation(self, base_signals: List[Dict[str, Any]], volatility_level: float) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬æ³¢å‹•ç‡é©æ‡‰"""
        await asyncio.sleep(0.03)  # æ¨¡æ“¬é©æ‡‰è™•ç†æ™‚é–“
        
        adapted_signals = []
        
        for signal in base_signals:
            adapted_signal = signal.copy()
            
            # æ ¹æ“šæ³¢å‹•ç‡èª¿æ•´ä¿¡è™Ÿå¼·åº¦
            if volatility_level > 0.06:  # é«˜æ³¢å‹•ç‡
                adapted_signal["signal_strength"] *= 1.2  # å¢å¼·ä¿¡è™Ÿ
                adapted_signal["adaptation_type"] = "high_volatility_boost"
            elif volatility_level < 0.02:  # ä½æ³¢å‹•ç‡
                adapted_signal["signal_strength"] *= 0.8  # æ¸›å¼±ä¿¡è™Ÿ
                adapted_signal["adaptation_type"] = "low_volatility_dampening"
            else:  # ä¸­ç­‰æ³¢å‹•ç‡
                adapted_signal["adaptation_type"] = "normal_volatility"
            
            # ç¢ºä¿ä¿¡è™Ÿå¼·åº¦åœ¨æœ‰æ•ˆç¯„åœå…§
            adapted_signal["signal_strength"] = min(1.0, max(0.0, adapted_signal["signal_strength"]))
            
            # æ·»åŠ é©æ‡‰å…ƒæ•¸æ“š
            adapted_signal["volatility_adapted"] = True
            adapted_signal["original_strength"] = signal["signal_strength"]
            adapted_signal["volatility_level"] = volatility_level
            adapted_signal["adaptation_timestamp"] = time.time()
            
            adapted_signals.append(adapted_signal)
        
        return adapted_signals
    
    async def _validate_adaptation_effectiveness(self, adapted_signals: List[Dict[str, Any]], expected_adaptation: str) -> bool:
        """é©—è­‰é©æ‡‰æ•ˆæœ"""
        await asyncio.sleep(0.001)
        
        if not adapted_signals:
            return False
        
        # æª¢æŸ¥é©æ‡‰æ¨™è¨˜
        all_adapted = all(signal.get("volatility_adapted", False) for signal in adapted_signals)
        
        # æª¢æŸ¥é©æ‡‰é¡å‹
        adaptation_types = [signal.get("adaptation_type", "") for signal in adapted_signals]
        
        if expected_adaptation == "increased_sensitivity":
            return all_adapted and any("high_volatility" in atype for atype in adaptation_types)
        elif expected_adaptation == "decreased_sensitivity":
            return all_adapted and any("low_volatility" in atype for atype in adaptation_types)
        else:  # normal_sensitivity
            return all_adapted and any("normal_volatility" in atype for atype in adaptation_types)
    
    async def _simulate_signal_standardization(self, raw_signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬ä¿¡è™Ÿæ¨™æº–åŒ–"""
        await asyncio.sleep(0.02)  # æ¨¡æ“¬æ¨™æº–åŒ–è™•ç†æ™‚é–“
        
        standardized_signals = []
        
        for i, signal in enumerate(raw_signals):
            standardized_signal = signal.copy()
            
            # åˆ†é…å±¤ç´š
            signal_strength = signal.get("value", signal.get("signal_strength", 0.5))
            
            if signal_strength >= 0.8:
                tier = "tier_1_critical"
                priority = 1
            elif signal_strength >= 0.6:
                tier = "tier_2_important"
                priority = 2
            else:
                tier = "tier_3_standard"
                priority = 3
            
            # æ¨™æº–åŒ–å­—æ®µ
            standardized_signal.update({
                "standardized": True,
                "tier_assignment": tier,
                "execution_priority": priority,
                "normalized_strength": min(1.0, max(0.0, signal_strength)),
                "quality_score": signal.get("confidence", 0.7),
                "standardization_timestamp": time.time(),
                "processing_order": i + 1
            })
            
            standardized_signals.append(standardized_signal)
        
        return standardized_signals
    
    async def _validate_signal_standardization(self, raw_signals: List[Dict[str, Any]], standardized_signals: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é©—è­‰ä¿¡è™Ÿæ¨™æº–åŒ–"""
        await asyncio.sleep(0.001)
        
        if len(raw_signals) != len(standardized_signals):
            return {"validation_pass": False, "error": "signal_count_mismatch"}
        
        validation_checks = []
        
        for std_signal in standardized_signals:
            checks = {
                "has_standardized_flag": std_signal.get("standardized", False),
                "has_tier_assignment": "tier_assignment" in std_signal,
                "has_execution_priority": "execution_priority" in std_signal,
                "has_normalized_strength": "normalized_strength" in std_signal,
                "normalized_strength_valid": 0 <= std_signal.get("normalized_strength", -1) <= 1
            }
            validation_checks.append(all(checks.values()))
        
        return {
            "validation_pass": all(validation_checks),
            "standardized_count": sum(validation_checks),
            "total_count": len(standardized_signals),
            "standardization_rate": sum(validation_checks) / len(standardized_signals) * 100
        }
    
    async def _simulate_unified_pool_aggregation(self, signals_from_sources: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """æ¨¡æ“¬çµ±ä¸€æ± èšåˆ"""
        await asyncio.sleep(0.025)  # æ¨¡æ“¬èšåˆè™•ç†æ™‚é–“
        
        aggregated_signals = []
        signal_id = 1
        
        # èšåˆæ‰€æœ‰ä¾†æºçš„ä¿¡è™Ÿ
        for source, signals in signals_from_sources.items():
            for signal in signals:
                aggregated_signal = signal.copy()
                aggregated_signal.update({
                    "signal_id": f"unified_{signal_id:04d}",
                    "source": source,
                    "aggregation_timestamp": time.time(),
                    "unified_pool_processed": True,
                    "quality_score": signal.get("confidence", 0.7),
                    "source_weight": self._get_source_weight(source)
                })
                
                aggregated_signals.append(aggregated_signal)
                signal_id += 1
        
        # æ¨¡æ“¬å»é‡å’Œè³ªé‡éæ¿¾
        filtered_signals = []
        seen_types = set()
        
        # æŒ‰è³ªé‡åˆ†æ•¸æ’åº
        aggregated_signals.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
        
        for signal in aggregated_signals:
            signal_type = signal.get("signal_type", "unknown")
            
            # ç°¡å–®å»é‡ï¼šæ¯ç¨®ä¿¡è™Ÿé¡å‹åªä¿ç•™æœ€é«˜è³ªé‡çš„
            if signal_type not in seen_types and signal.get("quality_score", 0) >= 0.6:
                seen_types.add(signal_type)
                signal["deduplication_applied"] = True
                signal["quality_filtering_applied"] = True
                filtered_signals.append(signal)
        
        return filtered_signals
    
    def _get_source_weight(self, source: str) -> float:
        """ç²å–ä¾†æºæ¬Šé‡"""
        weights = {
            "phase1a": 0.3,
            "phase1b": 0.25,
            "phase1c": 0.25,
            "indicator_graph": 0.2
        }
        return weights.get(source, 0.1)
    
    async def _validate_signal_aggregation(self, input_sources: Dict[str, List], aggregated_signals: List[Dict[str, Any]]) -> Dict[str, Any]:
        """é©—è­‰ä¿¡è™Ÿèšåˆ"""
        await asyncio.sleep(0.001)
        
        total_input = sum(len(signals) for signals in input_sources.values())
        
        # æª¢æŸ¥èšåˆè³ªé‡
        aggregation_checks = {
            "signals_aggregated": len(aggregated_signals) > 0,
            "duplicates_removed": len(aggregated_signals) <= total_input,
            "quality_filtered": all(signal.get("quality_score", 0) >= 0.6 for signal in aggregated_signals),
            "source_attribution_maintained": all("source" in signal for signal in aggregated_signals),
            "unified_processing_applied": all(signal.get("unified_pool_processed", False) for signal in aggregated_signals)
        }
        
        return {
            "validation_pass": all(aggregation_checks.values()),
            "aggregation_details": aggregation_checks,
            "input_signals_total": total_input,
            "output_signals_count": len(aggregated_signals),
            "reduction_ratio": (total_input - len(aggregated_signals)) / total_input * 100 if total_input > 0 else 0
        }
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰Phase1çµ„ä»¶æ¸¬è©¦"""
        logger.info("ğŸš€ é–‹å§‹Phase1ä¿¡è™Ÿç”Ÿæˆç³»çµ±ç¶œåˆæ¸¬è©¦...")
        
        test_methods = [
            self.test_phase1a_signal_generation,
            self.test_technical_indicator_calculation,
            self.test_phase1b_volatility_adaptation,
            self.test_phase1c_signal_standardization,
            self.test_unified_signal_pool_aggregation
        ]
        
        all_results = {}
        start_time = time.time()
        
        for test_method in test_methods:
            test_name = test_method.__name__
            logger.info(f"\nğŸ“‹ åŸ·è¡Œæ¸¬è©¦: {test_name}")
            
            try:
                result = await test_method()
                all_results[test_name] = result
                
                status = "âœ…" if result.get("success", False) else "âŒ"
                logger.info(f"{status} {test_name}: {result.get('status', 'UNKNOWN')}")
                
            except Exception as e:
                logger.error(f"âŒ {test_name} åŸ·è¡Œå¤±æ•—: {e}")
                all_results[test_name] = {
                    "success": False,
                    "error": str(e),
                    "status": "âŒ EXCEPTION"
                }
        
        # è¨ˆç®—ç¸½é«”çµæœ
        total_tests = len(test_methods)
        passed_tests = sum(1 for result in all_results.values() if result.get("success", False))
        overall_success_rate = (passed_tests / total_tests) * 100
        
        # è¨ˆç®—æ€§èƒ½çµ±è¨ˆ
        performance_stats = {}
        for metric_name, latencies in self.performance_metrics.items():
            if latencies:
                performance_stats[metric_name] = {
                    "avg_ms": np.mean(latencies),
                    "max_ms": np.max(latencies),
                    "min_ms": np.min(latencies)
                }
        
        total_time = time.time() - start_time
        
        summary = {
            "test_type": "Phase1ä¿¡è™Ÿç”Ÿæˆç³»çµ±ç¶œåˆæ¸¬è©¦",
            "start_time": datetime.fromtimestamp(start_time).isoformat(),
            "total_duration_s": total_time,
            "total_tests": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": total_tests - passed_tests,
            "overall_success_rate": overall_success_rate,
            "performance_statistics": performance_stats,
            "status": "âœ… PASSED" if overall_success_rate >= 80.0 else "âŒ FAILED",
            "detailed_results": all_results
        }
        
        logger.info(f"\nğŸ¯ Phase1ç¶œåˆæ¸¬è©¦å®Œæˆ:")
        logger.info(f"   ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        logger.info(f"   é€šéæ¸¬è©¦: {passed_tests}")
        logger.info(f"   æˆåŠŸç‡: {overall_success_rate:.1f}%")
        logger.info(f"   ç¸½è€—æ™‚: {total_time:.2f}ç§’")
        logger.info(f"   ç‹€æ…‹: {summary['status']}")
        
        return summary

# ä¸»åŸ·è¡Œå‡½æ•¸
async def main():
    """ä¸»æ¸¬è©¦åŸ·è¡Œå‡½æ•¸"""
    tester = Phase1ComprehensiveTest()
    results = await tester.run_all_tests()
    
    # è¼¸å‡ºæ¸¬è©¦å ±å‘Š
    print("\n" + "="*80)
    print("ğŸ“Š Phase1ä¿¡è™Ÿç”Ÿæˆç³»çµ±ç¶œåˆæ¸¬è©¦å ±å‘Š")
    print("="*80)
    print(json.dumps(results, indent=2, ensure_ascii=False))
    
    return results

if __name__ == "__main__":
    # é‹è¡Œæ¸¬è©¦
    results = asyncio.run(main())
    
    # æ ¹æ“šçµæœæ±ºå®šé€€å‡ºä»£ç¢¼
    exit_code = 0 if results.get("overall_success_rate", 0) >= 80.0 else 1
    exit(exit_code)
