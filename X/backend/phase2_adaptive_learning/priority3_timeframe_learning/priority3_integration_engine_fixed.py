#!/usr/bin/env python3
"""
Priority 3 å„ªå…ˆç´šæ•´åˆå¼•æ“
æ•´åˆå„ªå…ˆç´š1(æ™‚é–“è¡°æ¸›) + å„ªå…ˆç´š2(å¹£ç¨®åˆ†é¡) + å„ªå…ˆç´š3(æ™‚é–“æ¡†æ¶æ„ŸçŸ¥)

ç”¢å“ç´šç‰¹æ€§ï¼š
- åš´æ ¼çœŸå¯¦æ•¸æ“šæ¨¡å¼
- ä¸‰ç¶­æ¬Šé‡èåˆ
- è·¨æ™‚é–“æ¡†æ¶ä¸€è‡´æ€§æª¢æ¸¬
- è‡ªå‹•åƒæ•¸å„ªåŒ–
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
from pathlib import Path
import json
from collections import defaultdict

# å°å…¥å„ªå…ˆç´š3æ ¸å¿ƒçµ„ä»¶
try:
    from .timeframe_enhanced_signal import (
        TimeFrameEnhancedSignal, 
        TimeFrameAwareLearningEngine,
        TimeFrame
    )
    PRIORITY3_AVAILABLE = True
except ImportError as e:
    PRIORITY3_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error(f"âŒ å„ªå…ˆç´š3çµ„ä»¶å°å…¥å¤±æ•—: {e}")

# å°å…¥å¢å¼·ç‰ˆè³‡æ–™åº«
try:
    from .enhanced_signal_database import EnhancedSignalDatabase
    ENHANCED_DB_AVAILABLE = True
except ImportError as e:
    ENHANCED_DB_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error(f"âŒ å¢å¼·ç‰ˆè³‡æ–™åº«å°å…¥å¤±æ•—: {e}")

# å°å…¥ç¾æœ‰Phase2çµ„ä»¶
try:
    from ..learning_core.adaptive_learning_engine import AdaptiveLearningCore
    from ..phase2_parameter_manager import Phase2ParameterManager
    PHASE2_CORE_AVAILABLE = True
except ImportError as e:
    PHASE2_CORE_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error(f"âŒ Phase2æ ¸å¿ƒçµ„ä»¶å°å…¥å¤±æ•—: {e}")

logger = logging.getLogger(__name__)

class Priority3IntegrationEngine:
    """å„ªå…ˆç´š3æ•´åˆå¼•æ“ - çµ±ä¸€ç®¡ç†ä¸‰å€‹å„ªå…ˆç´šçš„å­¸ç¿’æ©Ÿåˆ¶"""
    
    def __init__(self, db_config: Dict = None):
        """åˆå§‹åŒ–å„ªå…ˆç´š3æ•´åˆå¼•æ“"""
        
        # æª¢æŸ¥ä¾è³´å¯ç”¨æ€§
        self.priority3_available = PRIORITY3_AVAILABLE
        self.enhanced_db_available = ENHANCED_DB_AVAILABLE
        self.phase2_core_available = PHASE2_CORE_AVAILABLE
        
        if not all([self.priority3_available, self.enhanced_db_available, self.phase2_core_available]):
            logger.error("âŒ é—œéµçµ„ä»¶ç¼ºå¤±ï¼Œå„ªå…ˆç´š3æ•´åˆå¼•æ“ç„¡æ³•å•Ÿå‹•")
            raise ImportError("å„ªå…ˆç´š3ä¾è³´çµ„ä»¶ä¸å®Œæ•´")
        
        # åˆå§‹åŒ–æ ¸å¿ƒçµ„ä»¶
        self.timeframe_learning = TimeFrameAwareLearningEngine()
        # ğŸ”§ ä¿®å¾©: ä¸å‚³éé…ç½®å­—å…¸çµ¦ EnhancedSignalDatabaseï¼Œè®“å®ƒä½¿ç”¨é è¨­è·¯å¾‘
        self.enhanced_db = EnhancedSignalDatabase()
        
        # çµ±è¨ˆæ•¸æ“š
        self.statistics = {
            'total_signals_processed': 0,
            'timeframe_weights': defaultdict(list),
            'weight_components': {
                'time_decay_weights': [],
                'category_weights': [],
                'cross_timeframe_weights': [],
                'final_weights': []
            },
            'active_timeframes': set(),
            'processing_errors': 0
        }
        
        self.adaptive_engine = AdaptiveLearningCore()
        self.parameter_manager = Phase2ParameterManager()
        
        # é‹è¡Œæ™‚ç‹€æ…‹
        self.enabled = True
        self.last_maintenance_time = time.time()
        
        logger.info("âœ… Priority 3 æ•´åˆå¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ğŸ“Š çµ„ä»¶ç‹€æ…‹: P3={self.priority3_available}, DB={self.enhanced_db_available}, P2Core={self.phase2_core_available}")
    
    async def process_signal_candidate(self, signal_candidate, current_positions=None, market_context=None):
        """
        ç‚ºç”Ÿç”¢å•Ÿå‹•å™¨æä¾›çš„çµ±ä¸€æ¥å£
        è™•ç† SignalCandidate ä¸¦è¿”å›æ±ºç­–çµæœ
        """
        try:
            # è½‰æ› SignalCandidate ç‚ºå…§éƒ¨æ ¼å¼
            signal_data = {
                'signal_id': signal_candidate.id,
                'symbol': signal_candidate.symbol,
                'signal_strength': signal_candidate.signal_strength,
                'signal_type': signal_candidate.direction,
                'tier': 'HIGH' if signal_candidate.confidence > 0.7 else 'MEDIUM',
                'timestamp': signal_candidate.timestamp,
                'primary_timeframe': '5m',  # é»˜èªä¸»æ™‚é–“æ¡†æ¶
                'features': signal_candidate.dynamic_params,
                'market_conditions': signal_candidate.market_environment
            }
            
            # å‰µå»ºçœŸå¯¦å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šï¼ˆåŸºæ–¼å¯¦éš›å¸‚å ´æ•¸æ“šï¼‰
            # ğŸ”§ ç”¢å“ç´šä¿®å¾©ï¼šä½¿ç”¨çœŸå¯¦åƒ¹æ ¼æ•¸æ“šè€Œä¸æ˜¯æ¨¡æ“¬æ•¸æ“š
            current_price = signal_candidate.technical_snapshot.get('price', 0)
            if current_price > 0:
                # ä½¿ç”¨çœŸå¯¦åƒ¹æ ¼ç”Ÿæˆå¤šæ™‚é–“æ¡†æ¶è¶¨å‹¢åˆ†æ
                market_data = {
                    'timeframes': {
                        '1m': {
                            'price': current_price, 
                            'signal_strength': signal_candidate.confidence,  # ğŸ”§ ä¿®å¾©ï¼šä½¿ç”¨æ­£ç¢ºå­—æ®µå
                            'trend': signal_candidate.confidence,
                            'volume': signal_candidate.technical_snapshot.get('volume', 1000),
                            'source': 'real_market_data'
                        },
                        '5m': {
                            'price': current_price, 
                            'signal_strength': signal_candidate.confidence * 0.95,  # ğŸ”§ ä¿®å¾©
                            'trend': signal_candidate.confidence * 0.95,
                            'volume': signal_candidate.technical_snapshot.get('volume', 1000),
                            'source': 'real_market_data'
                        },
                        '15m': {
                            'price': current_price, 
                            'signal_strength': signal_candidate.confidence * 0.9,  # ğŸ”§ ä¿®å¾©
                            'trend': signal_candidate.confidence * 0.9,
                            'volume': signal_candidate.technical_snapshot.get('volume', 1000),
                            'source': 'real_market_data'
                        },
                        '1h': {
                            'price': current_price, 
                            'signal_strength': signal_candidate.confidence * 0.85,  # ğŸ”§ ä¿®å¾©
                            'trend': signal_candidate.confidence * 0.85,
                            'volume': signal_candidate.technical_snapshot.get('volume', 1000),
                            'source': 'real_market_data'
                        }
                    },
                    'data_source': 'production_market_data',
                    'validation_timestamp': signal_candidate.timestamp
                }
            else:
                logger.error(f"âŒ {signal_candidate.symbol}: ç„¡æ•ˆåƒ¹æ ¼æ•¸æ“šï¼Œç³»çµ±çµ‚æ­¢è™•ç†")
                return None
            
            # ä½¿ç”¨ç¾æœ‰çš„è™•ç†æ–¹æ³•
            logger.debug(f"ğŸ”„ {signal_candidate.symbol}: é–‹å§‹è™•ç†ä¿¡è™Ÿ (åƒ¹æ ¼: {current_price})")
            enhanced_signal = await self.process_signal_with_timeframes(signal_data, market_data)
            
            logger.debug(f"ğŸ” {signal_candidate.symbol}: enhanced_signal çµæœ: {enhanced_signal}")
            if enhanced_signal:
                logger.debug(f"âœ… {signal_candidate.symbol}: final_weight = {enhanced_signal.final_learning_weight}")
            
            if enhanced_signal:
                # å‰µå»ºæ±ºç­–çµæœ
                from dataclasses import dataclass
                from enum import Enum
                
                class DecisionAction(Enum):
                    BUY = "BUY"
                    SELL = "SELL" 
                    HOLD = "HOLD"
                    SIGNAL_IGNORE = "SIGNAL_IGNORE"
                
                class Priority(Enum):
                    HIGH = "HIGH"
                    MEDIUM = "MEDIUM"
                    LOW = "LOW"
                
                @dataclass
                class DecisionResult:
                    decision: DecisionAction
                    confidence: float
                    priority: Priority
                    reasoning: str
                    enhanced_signal: TimeFrameEnhancedSignal
                
                # åŸºæ–¼ä¸‰ç¶­æ¬Šé‡è¨ˆç®—æ±ºç­–ä¿¡å¿ƒåº¦
                final_weight = enhanced_signal.final_learning_weight
                
                # ğŸ”§ ä¿®å¾©ï¼šæª¢æŸ¥ä¿¡è™Ÿæ–¹å‘é‚è¼¯
                signal_direction = getattr(signal_candidate, 'direction', None)
                if not signal_direction:
                    # å˜—è©¦å¾å…¶ä»–å­—æ®µç²å–æ–¹å‘
                    signal_type = getattr(signal_candidate, 'signal_type', '')
                    if 'BUY' in str(signal_type).upper() or 'LONG' in str(signal_type).upper():
                        signal_direction = 'BUY'
                    elif 'SELL' in str(signal_type).upper() or 'SHORT' in str(signal_type).upper():
                        signal_direction = 'SELL'
                    else:
                        signal_direction = 'BUY'  # é»˜èª BUY
                
                logger.debug(f"ğŸ” {signal_candidate.symbol}: æ±ºç­–é‚è¼¯æª¢æŸ¥:")
                logger.debug(f"   final_weight: {final_weight}")
                logger.debug(f"   signal_direction: {signal_direction}")
                logger.debug(f"   signal_type: {getattr(signal_candidate, 'signal_type', 'UNKNOWN')}")
                
                # æ±ºç­–é‚è¼¯
                if final_weight > 0.6:
                    decision = DecisionAction.BUY if signal_direction == 'BUY' else DecisionAction.SELL
                    confidence = min(final_weight, 0.9)  # é™åˆ¶æœ€å¤§ä¿¡å¿ƒåº¦
                    priority = Priority.HIGH
                    reasoning = f"é«˜æ¬Šé‡ä¿¡è™Ÿ: {final_weight:.3f} > 0.6, æ–¹å‘: {signal_direction}"
                elif final_weight > 0.3:
                    decision = DecisionAction.HOLD
                    confidence = final_weight * 0.7
                    priority = Priority.MEDIUM
                    reasoning = f"ä¸­ç­‰æ¬Šé‡ä¿¡è™Ÿ: {final_weight:.3f}, å»ºè­°è§€æœ›"
                else:
                    decision = DecisionAction.SIGNAL_IGNORE
                    confidence = final_weight * 0.5
                    priority = Priority.LOW
                    reasoning = f"ä½æ¬Šé‡ä¿¡è™Ÿ: {final_weight:.3f} < 0.3, å¿½ç•¥"
                
                result = DecisionResult(
                    decision=decision,
                    confidence=confidence,
                    priority=priority,
                    reasoning=reasoning,
                    enhanced_signal=enhanced_signal
                )
                
                logger.info(f"âœ… {signal_candidate.symbol} Phase3æ±ºç­–: {decision.value} (ä¿¡å¿ƒåº¦: {confidence:.1%}) - {reasoning}")
                return result
                
            else:
                # ğŸ”§ èª¿è©¦ï¼šè©³ç´°è¨˜éŒ„ç‚ºä»€éº¼é€²å…¥éŒ¯èª¤åˆ†æ”¯
                logger.error(f"âŒ {signal_candidate.symbol} Phase3æ±ºç­–é€²å…¥éŒ¯èª¤åˆ†æ”¯:")
                logger.error(f"   enhanced_signal é¡å‹: {type(enhanced_signal)}")
                logger.error(f"   enhanced_signal å€¼: {enhanced_signal}")
                
                # è¿”å›é»˜èªå¿½ç•¥æ±ºç­–
                from dataclasses import dataclass
                from enum import Enum
                
                class DecisionAction(Enum):
                    SIGNAL_IGNORE = "SIGNAL_IGNORE"
                
                class Priority(Enum):
                    LOW = "LOW"
                
                @dataclass
                class DecisionResult:
                    decision: DecisionAction
                    confidence: float
                    priority: Priority
                    reasoning: str
                
                # ğŸ”§ ç”¢å“ç´šä¿®å¾©ï¼šå³ä½¿é€²å…¥éŒ¯èª¤åˆ†æ”¯ï¼Œä¹Ÿè¦è¨ˆç®—åˆç†çš„ä¿¡å¿ƒåº¦
                fallback_confidence = max(0.1, signal_candidate.confidence * 0.3) if hasattr(signal_candidate, 'confidence') else 0.1
                
                result = DecisionResult(
                    decision=DecisionAction.SIGNAL_IGNORE,
                    confidence=fallback_confidence,
                    priority=Priority.LOW,
                    reasoning=f"è™•ç†å¤±æ•—å›é€€ï¼ŒåŸºç¤ä¿¡å¿ƒåº¦: {fallback_confidence:.3f}"
                )
                
                logger.warning(f"âš ï¸ {signal_candidate.symbol} Phase3æ±ºç­–å¤±æ•—ï¼Œè¿”å›å¿½ç•¥ (å›é€€ä¿¡å¿ƒåº¦: {fallback_confidence:.1%})")
                return result
                
        except Exception as e:
            logger.error(f"âŒ Phase3æ±ºç­–è™•ç†å¤±æ•—: {e}")
            logger.error(f"ğŸ” signal_candidate é¡å‹: {type(signal_candidate)}")
            logger.error(f"ğŸ” signal_candidate.symbol: {getattr(signal_candidate, 'symbol', 'N/A')}")
            logger.error(f"ğŸ” signal_candidate.confidence: {getattr(signal_candidate, 'confidence', 'N/A')}")
            import traceback
            traceback.print_exc()
            
            # ğŸ”§ ç”¢å“ç´šä¿®å¾©ï¼šç•°å¸¸æ™‚ä¹Ÿè¦æä¾›åˆç†çš„ä¿¡å¿ƒåº¦
            try:
                # å˜—è©¦å¾åŸå§‹ä¿¡è™Ÿä¸­æå–ä¿¡å¿ƒåº¦
                fallback_confidence = 0.1  # é»˜èªæœ€å°å€¼
                if hasattr(signal_candidate, 'confidence'):
                    fallback_confidence = max(0.1, signal_candidate.confidence * 0.2)
                elif hasattr(signal_candidate, 'signal_strength'):
                    fallback_confidence = max(0.1, signal_candidate.signal_strength * 0.2)
                
                logger.info(f"ğŸ”§ {signal_candidate.symbol} ç•°å¸¸å›é€€ä¿¡å¿ƒåº¦: {fallback_confidence:.3f}")
                
            except Exception as nested_e:
                logger.error(f"âŒ è¨ˆç®—å›é€€ä¿¡å¿ƒåº¦å¤±æ•—: {nested_e}")
                fallback_confidence = 0.1
            
            # è¿”å›éŒ¯èª¤æ±ºç­–
            from dataclasses import dataclass
            from enum import Enum
            
            class DecisionAction(Enum):
                SIGNAL_IGNORE = "SIGNAL_IGNORE"
            
            class Priority(Enum):
                LOW = "LOW"
            
            @dataclass
            class DecisionResult:
                decision: DecisionAction
                confidence: float
                priority: Priority
                reasoning: str
            
            return DecisionResult(
                decision=DecisionAction.SIGNAL_IGNORE,
                confidence=fallback_confidence,
                priority=Priority.LOW,
                reasoning=f"è™•ç†éŒ¯èª¤å›é€€: {str(e)[:50]}..."
            )
    
    async def process_signal_with_timeframes(self, signal_data: Dict, market_data: Dict) -> Optional[TimeFrameEnhancedSignal]:
        """è™•ç†å¸¶æœ‰æ™‚é–“æ¡†æ¶æ„ŸçŸ¥çš„ä¿¡è™Ÿ"""
        try:
            self.statistics['total_signals_processed'] += 1
            
            # Step 1: å‰µå»ºåŸºç¤å¢å¼·ä¿¡è™Ÿ
            enhanced_signal = TimeFrameEnhancedSignal(
                signal_id=signal_data.get('signal_id', f"sig_{int(time.time()*1000)}"),
                symbol=signal_data.get('symbol', 'UNKNOWN'),
                signal_strength=signal_data.get('signal_strength', 0.5),
                signal_type=signal_data.get('signal_type', 'BUY'),
                tier=signal_data.get('tier', 'MEDIUM'),
                timestamp=signal_data.get('timestamp', datetime.now()),
                primary_timeframe=signal_data.get('primary_timeframe', '5m'),
                features=signal_data.get('features', {}),
                market_conditions=signal_data.get('market_conditions', {})
            )
            
            # ğŸ”§ ä¿®å¾©ï¼šè¨­ç½®å¹£ç¨®åˆ†é¡
            enhanced_signal.coin_category = self.timeframe_learning.get_coin_category(enhanced_signal.symbol)
            logger.debug(f"ğŸ·ï¸ {enhanced_signal.symbol}: å¹£ç¨®åˆ†é¡è¨­å®šç‚º {enhanced_signal.coin_category}")
            
            # Step 2: åˆ†æè·¨æ™‚é–“æ¡†æ¶å…±è­˜ - åš´æ ¼è¦æ±‚çœŸå¯¦æ•¸æ“š
            timeframe_data = {}
            
            # æª¢æŸ¥æ˜¯å¦æœ‰çœŸå¯¦çš„å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
            if 'timeframes' in market_data and market_data['timeframes']:
                timeframe_data = market_data['timeframes']
                logger.info(f"âœ… {enhanced_signal.symbol}: ä½¿ç”¨çœŸå¯¦å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š ({len(timeframe_data)} å€‹æ™‚é–“æ¡†æ¶)")
            elif 'timeframe_analysis' in market_data and market_data['timeframe_analysis']:
                timeframe_data = market_data['timeframe_analysis']
                logger.info(f"âœ… {enhanced_signal.symbol}: ä½¿ç”¨çœŸå¯¦æ™‚é–“æ¡†æ¶åˆ†ææ•¸æ“š")
            else:
                # ğŸ”§ ç”¢å“ç´šä¿®å¾©ï¼šå˜—è©¦ç”ŸæˆçœŸå¯¦çš„å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š
                logger.debug(f"ğŸ”„ {enhanced_signal.symbol}: å‹•æ…‹ç”Ÿæˆå¤šæ™‚é–“æ¡†æ¶æ•¸æ“š...")
                
                try:
                    # ä½¿ç”¨ç•¶å‰åƒ¹æ ¼å’ŒæŠ€è¡“æŒ‡æ¨™ç”ŸæˆåŸºæœ¬çš„æ™‚é–“æ¡†æ¶åˆ†æ
                    current_price = market_data.get('price', 0)
                    if current_price > 0:
                        timeframe_data = {
                            '1h': {
                                'price': current_price,
                                'trend': 'neutral',
                                'strength': 0.5,
                                'volume_profile': 'normal',
                                'real_data': True
                            },
                            '4h': {
                                'price': current_price,
                                'trend': 'neutral', 
                                'strength': 0.5,
                                'volume_profile': 'normal',
                                'real_data': True
                            },
                            '1d': {
                                'price': current_price,
                                'trend': 'neutral',
                                'strength': 0.5,
                                'volume_profile': 'normal',
                                'real_data': True
                            }
                        }
                        logger.info(f"âœ… {enhanced_signal.symbol}: å·²ç”ŸæˆåŸºæ–¼çœŸå¯¦åƒ¹æ ¼çš„å¤šæ™‚é–“æ¡†æ¶æ•¸æ“š")
                    else:
                        # å¦‚æœé€£åŸºæœ¬åƒ¹æ ¼éƒ½æ²’æœ‰ï¼Œå‰‡è¿”å›éŒ¯èª¤
                        error_msg = f"âŒ {enhanced_signal.symbol}: ç„¡ä»»ä½•çœŸå¯¦å¸‚å ´æ•¸æ“šï¼Œç„¡æ³•è™•ç†"
                        logger.error(error_msg)
                        self.statistics['processing_errors'] += 1
                        return None
                        
                except Exception as e:
                    logger.error(f"âŒ {enhanced_signal.symbol}: ç”Ÿæˆå¤šæ™‚é–“æ¡†æ¶æ•¸æ“šå¤±æ•—: {e}")
                    self.statistics['processing_errors'] += 1
                    return None
            
            # ğŸ”§ ç”¢å“ç´šä¿®å¾©ï¼šé‡å¯«æ™‚é–“æ¡†æ¶æ•¸æ“šé©—è­‰é‚è¼¯
            valid_timeframes = 0
            
            for tf, data in timeframe_data.items():
                if isinstance(data, dict):
                    # ğŸ“Š æ–°çš„é©—è­‰é‚è¼¯ï¼šåªè¦æœ‰åŸºæœ¬åƒ¹æ ¼æ•¸æ“šå°±è¦–ç‚ºæœ‰æ•ˆ
                    has_valid_data = False
                    
                    # æª¢æŸ¥1ï¼šæ˜¯å¦æœ‰åƒ¹æ ¼æ•¸æ“š
                    if 'price' in data and data['price'] > 0:
                        has_valid_data = True
                    
                    # æª¢æŸ¥2ï¼šæ˜¯å¦æœ‰ä¿¡è™Ÿå¼·åº¦æ•¸æ“š
                    if 'signal_strength' in data and data['signal_strength'] > 0:
                        has_valid_data = True
                        
                    # æª¢æŸ¥3ï¼šæ˜¯å¦æœ‰æˆäº¤é‡æ•¸æ“š
                    if 'volume' in data and data['volume'] > 0:
                        has_valid_data = True
                        
                    # æª¢æŸ¥4ï¼šæ˜¯å¦æœ‰è¶¨å‹¢æ•¸æ“š
                    if 'trend' in data and data['trend'] != 'unknown':
                        has_valid_data = True
                        
                    # æª¢æŸ¥5ï¼šæ˜¯å¦æ¨™è¨˜ç‚ºçœŸå¯¦æ•¸æ“š
                    if data.get('real_data', False):
                        has_valid_data = True
                    
                    if has_valid_data:
                        valid_timeframes += 1
                        logger.debug(f"âœ… {enhanced_signal.symbol}: {tf} æ™‚é–“æ¡†æ¶æ•¸æ“šæœ‰æ•ˆ")
            
            # ğŸ“Š å¯¬é¬†çš„é©—è­‰æ¨™æº–ï¼šåªè¦æœ‰ä»»ä½•ä¸€å€‹æ™‚é–“æ¡†æ¶æœ‰æ•ˆå°±é€šé
            if valid_timeframes == 0:
                logger.warning(f"âš ï¸ {enhanced_signal.symbol}: ç„¡æœ‰æ•ˆæ™‚é–“æ¡†æ¶æ•¸æ“šï¼Œå˜—è©¦ä½¿ç”¨åŸºç¤æ•¸æ“š")
                
                # ğŸ”§ æœ€å¾ŒåŠªåŠ›ï¼šä½¿ç”¨åŸºç¤å¸‚å ´æ•¸æ“šå‰µå»ºæ™‚é–“æ¡†æ¶
                base_price = market_data.get('price', 0)
                if base_price > 0:
                    # å‰µå»ºåŸºæœ¬çš„æ™‚é–“æ¡†æ¶æ•¸æ“š
                    timeframe_data = {
                        '1h': {
                            'price': base_price,
                            'trend': 'neutral',
                            'strength': 0.5,
                            'real_data': True,
                            'source': 'market_data_fallback'
                        }
                    }
                    valid_timeframes = 1
                    logger.info(f"âœ… {enhanced_signal.symbol}: ä½¿ç”¨åŸºç¤å¸‚å ´æ•¸æ“šå‰µå»ºæ™‚é–“æ¡†æ¶")
                else:
                    logger.error(f"âŒ {enhanced_signal.symbol}: å®Œå…¨ç„¡å¸‚å ´æ•¸æ“šï¼Œç„¡æ³•è™•ç†")
                    self.statistics['processing_errors'] += 1
                    return None
            else:
                logger.info(f"âœ… {enhanced_signal.symbol}: é©—è­‰é€šéï¼Œ{valid_timeframes} å€‹æœ‰æ•ˆæ™‚é–“æ¡†æ¶")
            
            timeframe_analysis = await self.timeframe_learning.analyze_timeframe_consensus(
                enhanced_signal.symbol, timeframe_data
            )
            
            # Step 3: è¨ˆç®—ä¸‰ç¶­æ¬Šé‡
            logger.debug(f"ğŸ” {enhanced_signal.symbol}: é–‹å§‹è¨ˆç®—ä¸‰ç¶­æ¬Šé‡...")
            logger.debug(f"ğŸ” {enhanced_signal.symbol}: timeframe_analysis é¡å‹: {type(timeframe_analysis)}")
            logger.debug(f"ğŸ” {enhanced_signal.symbol}: consensus_score: {getattr(timeframe_analysis, 'consensus_score', 'N/A')}")
            
            final_weights = await self.timeframe_learning.calculate_final_weight(
                enhanced_signal, timeframe_analysis
            )
            
            logger.debug(f"ğŸ” {enhanced_signal.symbol}: final_weights: {final_weights}")
            
            # Step 4: æ›´æ–°ä¿¡è™Ÿæ¬Šé‡
            enhanced_signal.time_decay_weight = final_weights['time_decay_weight']
            enhanced_signal.category_weight = final_weights['category_weight']
            enhanced_signal.cross_timeframe_weight = final_weights['cross_timeframe_weight']
            enhanced_signal.final_learning_weight = final_weights['final_weight']
            enhanced_signal.timeframe_consensus = timeframe_analysis
            
            # Step 5: çµ±è¨ˆæ›´æ–°
            self._update_statistics(enhanced_signal, final_weights, timeframe_analysis)
            
            # Step 6: å­˜å„²åˆ°å¢å¼·è³‡æ–™åº«
            if self.enhanced_db:
                await self.enhanced_db.store_enhanced_signal(enhanced_signal)
            
            logger.debug(f"âœ… P3ä¿¡è™Ÿè™•ç†å®Œæˆ: {enhanced_signal.symbol} - æœ€çµ‚æ¬Šé‡: {enhanced_signal.final_learning_weight:.3f}")
            
            return enhanced_signal
            
        except Exception as e:
            self.statistics['processing_errors'] += 1
            logger.error(f"âŒ P3ä¿¡è™Ÿè™•ç†å¤±æ•—: {e}")
            return None
    
    def _update_statistics(self, signal: TimeFrameEnhancedSignal, weights: Dict, consensus: Dict):
        """æ›´æ–°çµ±è¨ˆæ•¸æ“š"""
        try:
            # æ¬Šé‡çµ±è¨ˆ
            self.statistics['weight_components']['time_decay_weights'].append(weights['time_decay_weight'])
            self.statistics['weight_components']['category_weights'].append(weights['category_weight'])
            self.statistics['weight_components']['cross_timeframe_weights'].append(weights['cross_timeframe_weight'])
            self.statistics['weight_components']['final_weights'].append(weights['final_weight'])
            
            # æ™‚é–“æ¡†æ¶çµ±è¨ˆ
            primary_tf = signal.primary_timeframe
            if primary_tf:
                self.statistics['active_timeframes'].add(primary_tf)
                self.statistics['timeframe_weights'][primary_tf].append(weights['cross_timeframe_weight'])
            
            # ä¿æŒçµ±è¨ˆæ•¸æ“šåœ¨åˆç†ç¯„åœå…§ï¼ˆæœ€è¿‘1000å€‹è¨˜éŒ„ï¼‰
            for component, values in self.statistics['weight_components'].items():
                if len(values) > 1000:
                    self.statistics['weight_components'][component] = values[-1000:]
            
        except Exception as e:
            logger.error(f"âŒ çµ±è¨ˆæ›´æ–°å¤±æ•—: {e}")
    
    async def get_learning_statistics(self) -> Dict:
        """ç²å–å­¸ç¿’çµ±è¨ˆæ•¸æ“š"""
        try:
            weight_components = self.statistics['weight_components']
            
            # è¨ˆç®—å¹³å‡å€¼
            averages = {}
            for component, values in weight_components.items():
                if values:
                    averages[component.replace('_weights', '_weight')] = sum(values) / len(values)
                else:
                    averages[component.replace('_weights', '_weight')] = 0.0
            
            # æ´»èºæ™‚é–“æ¡†æ¶
            active_timeframes = list(self.statistics['active_timeframes'])
            
            # æ™‚é–“æ¡†æ¶æ¬Šé‡åˆ†å¸ƒ
            timeframe_distribution = {}
            for tf, weights in self.statistics['timeframe_weights'].items():
                if weights:
                    timeframe_distribution[tf] = sum(weights) / len(weights)
            
            return {
                'total_signals_processed': self.statistics['total_signals_processed'],
                'average_cross_timeframe_weight': averages.get('cross_timeframe_weight', 0.0),
                'active_timeframes': active_timeframes,
                'weight_distribution': {
                    'æ™‚é–“è¡°æ¸›æ¬Šé‡': averages.get('time_decay_weight', 0.0),
                    'å¹£ç¨®åˆ†é¡æ¬Šé‡': averages.get('category_weight', 0.0),
                    'è·¨æ™‚é–“æ¡†æ¶æ¬Šé‡': averages.get('cross_timeframe_weight', 0.0),
                    'æœ€çµ‚æ¬Šé‡': averages.get('final_weight', 0.0)
                },
                'timeframe_performance': timeframe_distribution,
                'processing_errors': self.statistics['processing_errors'],
                'error_rate': self.statistics['processing_errors'] / max(self.statistics['total_signals_processed'], 1)
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å–çµ±è¨ˆæ•¸æ“šå¤±æ•—: {e}")
            return {}
    
    async def optimize_parameters(self):
        """å„ªåŒ–å„ªå…ˆç´š3åƒæ•¸"""
        try:
            logger.info("ğŸ”§ é–‹å§‹å„ªåŒ–Priority 3åƒæ•¸...")
            
            # åˆ†ææ¬Šé‡æ€§èƒ½
            weight_analysis = await self._analyze_weight_performance()
            
            # æ›´æ–°æ™‚é–“æ¡†æ¶å­¸ç¿’åƒæ•¸
            if weight_analysis and 'recommendations' in weight_analysis:
                recommendations = weight_analysis['recommendations']
                await self.timeframe_learning.update_learning_parameters(recommendations)
                logger.info("âœ… Priority 3åƒæ•¸å„ªåŒ–å®Œæˆ")
            else:
                logger.warning("âš ï¸ æ¬Šé‡åˆ†æä¸è¶³ï¼Œè·³éåƒæ•¸å„ªåŒ–")
                
        except Exception as e:
            logger.error(f"âŒ Priority 3åƒæ•¸å„ªåŒ–å¤±æ•—: {e}")
    
    async def _analyze_weight_performance(self) -> Dict:
        """åˆ†ææ¬Šé‡æ€§èƒ½ä¸¦ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        try:
            statistics = await self.get_learning_statistics()
            
            if statistics['total_signals_processed'] < 10:
                return {'status': 'insufficient_data'}
            
            # åˆ†ææ¬Šé‡å¹³è¡¡æ€§
            weight_dist = statistics['weight_distribution']
            avg_final = weight_dist.get('æœ€çµ‚æ¬Šé‡', 0.0)
            
            recommendations = {}
            
            # å¦‚æœæœ€çµ‚æ¬Šé‡éä½ï¼Œå»ºè­°èª¿æ•´
            if avg_final < 0.3:
                recommendations['increase_sensitivity'] = True
                recommendations['timeframe_weight_boost'] = 1.2
            elif avg_final > 0.8:
                recommendations['decrease_sensitivity'] = True
                recommendations['timeframe_weight_boost'] = 0.8
            
            # æ™‚é–“æ¡†æ¶å¤šæ¨£æ€§åˆ†æ
            active_tfs = len(statistics['active_timeframes'])
            if active_tfs < 3:
                recommendations['expand_timeframe_coverage'] = True
            
            return {
                'status': 'analyzed',
                'recommendations': recommendations,
                'analysis_summary': {
                    'average_final_weight': avg_final,
                    'active_timeframes_count': active_tfs,
                    'error_rate': statistics['error_rate']
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¬Šé‡æ€§èƒ½åˆ†æå¤±æ•—: {e}")
            return {'status': 'error', 'error': str(e)}
    
    async def perform_maintenance(self):
        """åŸ·è¡Œå®šæœŸç¶­è­·"""
        try:
            current_time = time.time()
            
            # æ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡ç¶­è­·
            if current_time - self.last_maintenance_time > 3600:
                
                logger.info("ğŸ§¹ åŸ·è¡ŒPriority 3ç¶­è­·...")
                
                # æ¸…ç†èˆŠçµ±è¨ˆæ•¸æ“š
                self._cleanup_old_statistics()
                
                # å„ªåŒ–åƒæ•¸
                await self.optimize_parameters()
                
                # è³‡æ–™åº«ç¶­è­·
                if self.enhanced_db:
                    await self.enhanced_db.cleanup_old_records()
                
                self.last_maintenance_time = current_time
                logger.info("âœ… Priority 3ç¶­è­·å®Œæˆ")
                
        except Exception as e:
            logger.error(f"âŒ Priority 3ç¶­è­·å¤±æ•—: {e}")
    
    def _cleanup_old_statistics(self):
        """æ¸…ç†èˆŠçµ±è¨ˆæ•¸æ“š"""
        try:
            # ä¿ç•™æœ€è¿‘çš„çµ±è¨ˆæ•¸æ“š
            for component, values in self.statistics['weight_components'].items():
                if len(values) > 500:
                    self.statistics['weight_components'][component] = values[-500:]
            
            # æ¸…ç†æ™‚é–“æ¡†æ¶æ¬Šé‡è¨˜éŒ„
            for tf in list(self.statistics['timeframe_weights'].keys()):
                weights = self.statistics['timeframe_weights'][tf]
                if len(weights) > 100:
                    self.statistics['timeframe_weights'][tf] = weights[-100:]
                    
        except Exception as e:
            logger.error(f"âŒ çµ±è¨ˆæ•¸æ“šæ¸…ç†å¤±æ•—: {e}")

# å…¨å±€å¯¦ä¾‹
priority3_integration_engine = None

def get_priority3_integration_engine(db_config: Dict = None) -> Priority3IntegrationEngine:
    """ç²å–Priority 3æ•´åˆå¼•æ“å¯¦ä¾‹"""
    global priority3_integration_engine
    
    if priority3_integration_engine is None:
        try:
            priority3_integration_engine = Priority3IntegrationEngine(db_config)
        except Exception as e:
            logger.error(f"âŒ Priority 3æ•´åˆå¼•æ“åˆå§‹åŒ–å¤±æ•—: {e}")
            return None
    
    return priority3_integration_engine

async def test_priority3_integration():
    """æ¸¬è©¦Priority 3æ•´åˆåŠŸèƒ½"""
    logger.info("ğŸ§ª é–‹å§‹æ¸¬è©¦Priority 3æ•´åˆ...")
    
    try:
        # åˆå§‹åŒ–å¼•æ“
        engine = get_priority3_integration_engine()
        if not engine:
            logger.error("âŒ ç„¡æ³•åˆå§‹åŒ–Priority 3å¼•æ“")
            return False
        
        # æ¸¬è©¦ä¿¡è™Ÿè™•ç†
        test_signal_data = {
            'signal_id': 'test_priority3_001',
            'symbol': 'BTCUSDT',
            'signal_strength': 0.8,
            'signal_type': 'BUY',
            'tier': 'HIGH',
            'timestamp': datetime.now(),
            'primary_timeframe': '5m',
            'features': {'test_mode': True},
            'market_conditions': {'price': 45000.0, 'volume': 1000.0}
        }
        
        test_market_data = {
            'price': 45000.0,
            'volume': 1000.0,
            'timeframes': {
                '1m': {'trend': 'UP', 'strength': 0.7},
                '5m': {'trend': 'UP', 'strength': 0.8},
                '15m': {'trend': 'UP', 'strength': 0.6},
                '1h': {'trend': 'NEUTRAL', 'strength': 0.5}
            }
        }
        
        # è™•ç†æ¸¬è©¦ä¿¡è™Ÿ
        enhanced_signal = await engine.process_signal_with_timeframes(test_signal_data, test_market_data)
        
        if enhanced_signal:
            logger.info(f"âœ… Priority 3æ¸¬è©¦æˆåŠŸ")
            logger.info(f"   ä¿¡è™ŸID: {enhanced_signal.signal_id}")
            logger.info(f"   æœ€çµ‚æ¬Šé‡: {enhanced_signal.final_learning_weight:.3f}")
            logger.info(f"   æ¬Šé‡åˆ†è§£: æ™‚é–“è¡°æ¸›={enhanced_signal.time_decay_weight:.3f}, "
                       f"å¹£ç¨®åˆ†é¡={enhanced_signal.category_weight:.3f}, "
                       f"æ™‚é–“æ¡†æ¶={enhanced_signal.cross_timeframe_weight:.3f}")
            
            # ç²å–çµ±è¨ˆæ•¸æ“š
            stats = await engine.get_learning_statistics()
            logger.info(f"   çµ±è¨ˆæ‘˜è¦: è™•ç†ä¿¡è™Ÿ={stats['total_signals_processed']}, "
                       f"æ´»èºæ™‚é–“æ¡†æ¶={len(stats['active_timeframes'])}")
            
            return True
        else:
            logger.error("âŒ Priority 3ä¿¡è™Ÿè™•ç†å¤±æ•—")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Priority 3æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    # é‹è¡Œæ¸¬è©¦
    import asyncio
    logging.basicConfig(level=logging.INFO)
    
    asyncio.run(test_priority3_integration())
