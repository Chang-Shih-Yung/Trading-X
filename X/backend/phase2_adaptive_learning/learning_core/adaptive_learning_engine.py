#!/usr/bin/env python3
"""
ğŸ§  Adaptive Learning Core
è‡ªé©æ‡‰å­¸ç¿’æ ¸å¿ƒç³»çµ± - Step 2 çµ„ä»¶

Phase 2 - Step 2: è‡ªé©æ‡‰å­¸ç¿’æ ¸å¿ƒ
- ä¿¡è™Ÿè¡¨ç¾ç›£æ§ï¼šè¿½è¹¤æ¯å€‹ä¿¡è™Ÿçš„å¯¦éš›çµæœ
- åƒæ•¸å‹•æ…‹å„ªåŒ–ï¼šåŸºæ–¼è¡¨ç¾è‡ªå‹•èª¿æ•´ç³»çµ±åƒæ•¸
- æ¨¡å¼å­¸ç¿’ï¼šè­˜åˆ¥æˆåŠŸäº¤æ˜“çš„å…±åŒç‰¹å¾µ
- é€±æœŸæ€§é‡è¨“ç·´ï¼šå®šæœŸæ›´æ–°å­¸ç¿’æ¨¡å‹
"""

import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from pathlib import Path
import json
import pickle
from collections import defaultdict, deque

logger = logging.getLogger(__name__)

class LearningStatus(Enum):
    """å­¸ç¿’ç‹€æ…‹"""
    INITIALIZING = "INITIALIZING"
    COLLECTING_DATA = "COLLECTING_DATA"
    TRAINING = "TRAINING"
    OPTIMIZING = "OPTIMIZING"
    READY = "READY"
    ERROR = "ERROR"

@dataclass
class SignalPerformance:
    """ä¿¡è™Ÿè¡¨ç¾è¨˜éŒ„"""
    signal_id: str
    symbol: str
    signal_strength: float
    direction: str
    timestamp: datetime
    actual_outcome: Optional[float] = None
    performance_score: Optional[float] = None
    features: Dict[str, Any] = None
    market_conditions: Dict[str, Any] = None

@dataclass
class LearningPattern:
    """å­¸ç¿’æ¨¡å¼"""
    pattern_id: str
    pattern_type: str
    success_rate: float
    avg_return: float
    conditions: Dict[str, Any]
    sample_count: int
    confidence: float

@dataclass
class ParameterOptimization:
    """åƒæ•¸å„ªåŒ–è¨˜éŒ„"""
    parameter_name: str
    old_value: float
    new_value: float
    improvement_score: float
    optimization_time: datetime
    validation_results: Dict[str, float]

class AdaptiveLearningCore:
    """è‡ªé©æ‡‰å­¸ç¿’æ ¸å¿ƒ - Phase 2 Step 2"""
    
    def __init__(self):
        self.status = LearningStatus.INITIALIZING
        
        # æ•¸æ“šå­˜å„²
        self.signal_history = deque(maxlen=10000)  # ä¿æŒæœ€è¿‘10000å€‹ä¿¡è™Ÿ
        self.performance_db = {}  # ä¿¡è™ŸID -> SignalPerformance
        self.learning_patterns = {}  # æ¨¡å¼ID -> LearningPattern
        self.parameter_history = defaultdict(list)  # åƒæ•¸å -> æ­·å²å€¼åˆ—è¡¨
        
        # å­¸ç¿’é…ç½®
        self.learning_config = {
            'min_signals_for_learning': 50,
            'pattern_confidence_threshold': 0.65,
            'parameter_optimization_frequency': 100,  # æ¯100å€‹ä¿¡è™Ÿå„ªåŒ–ä¸€æ¬¡
            'success_rate_threshold': 0.55,
            'return_threshold': 0.01
        }
        
        # ç•¶å‰å„ªåŒ–åƒæ•¸
        self.current_parameters = {
            'signal_threshold': 0.6,
            'momentum_weight': 1.0,
            'volume_weight': 0.8,
            'volatility_adjustment': 1.0,
            'trend_sensitivity': 1.0,
            'risk_multiplier': 1.0
        }
        
        # æ€§èƒ½ç›£æ§
        self.performance_metrics = {
            'total_signals_tracked': 0,
            'successful_signals': 0,
            'total_return': 0.0,
            'average_return': 0.0,
            'success_rate': 0.0,
            'sharpe_ratio': 0.0,
            'max_drawdown': 0.0
        }
        
        # å­¸ç¿’çµ±è¨ˆ
        self.learning_stats = {
            'patterns_discovered': 0,
            'parameters_optimized': 0,
            'retraining_cycles': 0,
            'model_accuracy': 0.0
        }
        
        self.status = LearningStatus.COLLECTING_DATA
        logger.info("âœ… AdaptiveLearningCore åˆå§‹åŒ–å®Œæˆ")
    
    async def monitor_signal_performance(self, signal_data: Dict[str, Any], actual_outcome: Optional[float] = None) -> SignalPerformance:
        """ç›£æ§ä¿¡è™Ÿè¡¨ç¾"""
        try:
            # å‰µå»ºä¿¡è™Ÿè¡¨ç¾è¨˜éŒ„
            performance = SignalPerformance(
                signal_id=signal_data.get('signal_id', f"signal_{len(self.signal_history)}"),
                symbol=signal_data.get('symbol', 'UNKNOWN'),
                signal_strength=signal_data.get('signal_strength', 0.0),
                direction=signal_data.get('direction', 'HOLD'),
                timestamp=datetime.now(),
                actual_outcome=actual_outcome,
                features=signal_data.get('features', {}),
                market_conditions=signal_data.get('market_conditions', {})
            )
            
            # è¨ˆç®—è¡¨ç¾åˆ†æ•¸
            if actual_outcome is not None:
                performance.performance_score = self._calculate_performance_score(
                    signal_data.get('direction', 'HOLD'),
                    actual_outcome,
                    signal_data.get('signal_strength', 0.0)
                )
                
                # æ›´æ–°æ€§èƒ½æŒ‡æ¨™
                self._update_performance_metrics(performance)
            
            # å­˜å„²è¨˜éŒ„
            self.signal_history.append(performance)
            self.performance_db[performance.signal_id] = performance
            self.performance_metrics['total_signals_tracked'] += 1
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦å­¸ç¿’æ›´æ–°
            if len(self.signal_history) % self.learning_config['pattern_confidence_threshold'] == 0:
                await self._discover_patterns()
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦åƒæ•¸å„ªåŒ–
            if len(self.signal_history) % self.learning_config['parameter_optimization_frequency'] == 0:
                await self._optimize_parameters()
            
            logger.debug(f"ğŸ“Š ä¿¡è™Ÿè¡¨ç¾å·²è¨˜éŒ„: {performance.signal_id}, è¡¨ç¾åˆ†æ•¸: {performance.performance_score}")
            
            return performance
            
        except Exception as e:
            logger.error(f"âŒ ä¿¡è™Ÿè¡¨ç¾ç›£æ§å¤±æ•—: {e}")
            return SignalPerformance(
                signal_id="error",
                symbol="UNKNOWN",
                signal_strength=0.0,
                direction="HOLD",
                timestamp=datetime.now()
            )
    
    def _calculate_performance_score(self, direction: str, actual_outcome: float, signal_strength: float) -> float:
        """è¨ˆç®—ä¿¡è™Ÿè¡¨ç¾åˆ†æ•¸"""
        try:
            # åŸºç¤åˆ†æ•¸ï¼šæ–¹å‘æ­£ç¢ºæ€§
            direction_score = 0.0
            if direction == 'BUY' and actual_outcome > 0:
                direction_score = 1.0
            elif direction == 'SELL' and actual_outcome < 0:
                direction_score = 1.0
            elif direction == 'HOLD':
                direction_score = 0.5  # ä¸­æ€§åˆ†æ•¸
            
            # æ”¶ç›Šå€æ•¸
            return_multiplier = min(2.0, abs(actual_outcome) * 100)  # æ”¶ç›Šæ”¾å¤§ï¼Œæœ€å¤§2å€
            
            # ä¿¡è™Ÿå¼·åº¦åŠ æ¬Š
            strength_weight = 0.5 + signal_strength * 0.5
            
            # ç¶œåˆåˆ†æ•¸
            final_score = direction_score * return_multiplier * strength_weight
            
            return min(2.0, max(0.0, final_score))  # é™åˆ¶åœ¨0-2ç¯„åœ
            
        except Exception as e:
            logger.error(f"âŒ è¡¨ç¾åˆ†æ•¸è¨ˆç®—å¤±æ•—: {e}")
            return 0.0
    
    def _update_performance_metrics(self, performance: SignalPerformance):
        """æ›´æ–°æ€§èƒ½æŒ‡æ¨™"""
        try:
            if performance.actual_outcome is not None:
                # æ›´æ–°ç¸½æ”¶ç›Š
                self.performance_metrics['total_return'] += performance.actual_outcome
                
                # æ›´æ–°æˆåŠŸä¿¡è™Ÿæ•¸
                if performance.performance_score and performance.performance_score > 1.0:
                    self.performance_metrics['successful_signals'] += 1
                
                # è¨ˆç®—æˆåŠŸç‡
                total_with_outcome = len([s for s in self.signal_history if s.actual_outcome is not None])
                if total_with_outcome > 0:
                    self.performance_metrics['success_rate'] = self.performance_metrics['successful_signals'] / total_with_outcome
                
                # è¨ˆç®—å¹³å‡æ”¶ç›Š - é˜²æ­¢é™¤é›¶éŒ¯èª¤
                if total_with_outcome > 0:
                    self.performance_metrics['average_return'] = self.performance_metrics['total_return'] / total_with_outcome
                else:
                    self.performance_metrics['average_return'] = 0.0
                
                # è¨ˆç®—å¤æ™®æ¯”ç‡ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                returns = [s.actual_outcome for s in self.signal_history if s.actual_outcome is not None]
                if len(returns) > 5:
                    return_std = np.std(returns)
                    if return_std > 0:
                        self.performance_metrics['sharpe_ratio'] = np.mean(returns) / return_std
        
        except Exception as e:
            logger.error(f"âŒ æ€§èƒ½æŒ‡æ¨™æ›´æ–°å¤±æ•—: {e}")
    
    async def _discover_patterns(self):
        """ç™¼ç¾å­¸ç¿’æ¨¡å¼"""
        try:
            if len(self.signal_history) < self.learning_config['min_signals_for_learning']:
                return
            
            logger.info("ğŸ” é–‹å§‹æ¨¡å¼ç™¼ç¾...")
            
            # åˆ†ææˆåŠŸä¿¡è™Ÿçš„å…±åŒç‰¹å¾µ
            successful_signals = [
                s for s in self.signal_history 
                if s.performance_score and s.performance_score > 1.0
            ]
            
            if len(successful_signals) < 10:
                return
            
            # æŒ‰ç‰¹å¾µåˆ†çµ„åˆ†æ
            feature_patterns = defaultdict(list)
            
            for signal in successful_signals:
                if signal.features:
                    for feature_name, feature_value in signal.features.items():
                        if isinstance(feature_value, (int, float)):
                            feature_patterns[feature_name].append(feature_value)
            
            # è­˜åˆ¥æœ‰æ•ˆç‰¹å¾µç¯„åœ
            for feature_name, values in feature_patterns.items():
                if len(values) >= 5:
                    pattern_id = f"pattern_{feature_name}_{len(self.learning_patterns)}"
                    
                    # è¨ˆç®—çµ±è¨ˆç‰¹å¾µ
                    mean_value = np.mean(values)
                    std_value = np.std(values)
                    # é˜²æ­¢é™¤é›¶éŒ¯èª¤
                    success_rate = len(values) / len(successful_signals) if len(successful_signals) > 0 else 0.0
                    
                    # å‰µå»ºå­¸ç¿’æ¨¡å¼
                    pattern = LearningPattern(
                        pattern_id=pattern_id,
                        pattern_type=f"feature_{feature_name}",
                        success_rate=success_rate,
                        avg_return=np.mean([s.actual_outcome for s in successful_signals if s.actual_outcome]),
                        conditions={
                            'feature_name': feature_name,
                            'value_range': (mean_value - std_value, mean_value + std_value),
                            'optimal_value': mean_value
                        },
                        sample_count=len(values),
                        confidence=min(1.0, len(values) / 20)  # 20å€‹æ¨£æœ¬ç‚ºæ»¿ä¿¡å¿ƒ
                    )
                    
                    # åªä¿å­˜é«˜ä¿¡å¿ƒæ¨¡å¼
                    if pattern.confidence >= self.learning_config['pattern_confidence_threshold']:
                        self.learning_patterns[pattern_id] = pattern
                        self.learning_stats['patterns_discovered'] += 1
                        
                        logger.info(f"âœ… ç™¼ç¾æ–°æ¨¡å¼: {pattern_id}, æˆåŠŸç‡: {success_rate:.1%}")
        
        except Exception as e:
            logger.error(f"âŒ æ¨¡å¼ç™¼ç¾å¤±æ•—: {e}")
    
    async def _optimize_parameters(self):
        """å„ªåŒ–åƒæ•¸"""
        try:
            if len(self.signal_history) < self.learning_config['min_signals_for_learning']:
                return
            
            logger.info("âš™ï¸ é–‹å§‹åƒæ•¸å„ªåŒ–...")
            
            # è©•ä¼°ç•¶å‰åƒæ•¸è¡¨ç¾
            current_performance = self._evaluate_current_performance()
            
            # å˜—è©¦å„ªåŒ–æ¯å€‹åƒæ•¸
            optimization_results = []
            
            for param_name, current_value in self.current_parameters.items():
                # æ¸¬è©¦åƒæ•¸èª¿æ•´
                test_values = [
                    current_value * 0.9,
                    current_value * 1.1,
                    current_value * 0.8,
                    current_value * 1.2
                ]
                
                for test_value in test_values:
                    # æ¨¡æ“¬åƒæ•¸èª¿æ•´çš„å½±éŸ¿
                    simulated_performance = self._simulate_parameter_change(param_name, test_value)
                    
                    if simulated_performance > current_performance:
                        improvement = simulated_performance - current_performance
                        optimization_results.append({
                            'parameter': param_name,
                            'old_value': current_value,
                            'new_value': test_value,
                            'improvement': improvement
                        })
            
            # æ‡‰ç”¨æœ€ä½³å„ªåŒ–
            if optimization_results:
                best_optimization = max(optimization_results, key=lambda x: x['improvement'])
                
                # æ›´æ–°åƒæ•¸
                old_value = self.current_parameters[best_optimization['parameter']]
                self.current_parameters[best_optimization['parameter']] = best_optimization['new_value']
                
                # è¨˜éŒ„å„ªåŒ–
                optimization = ParameterOptimization(
                    parameter_name=best_optimization['parameter'],
                    old_value=old_value,
                    new_value=best_optimization['new_value'],
                    improvement_score=best_optimization['improvement'],
                    optimization_time=datetime.now(),
                    validation_results={'simulated_improvement': best_optimization['improvement']}
                )
                
                self.parameter_history[best_optimization['parameter']].append(optimization)
                self.learning_stats['parameters_optimized'] += 1
                
                logger.info(f"âœ… åƒæ•¸å„ªåŒ–: {best_optimization['parameter']} {old_value:.3f} â†’ {best_optimization['new_value']:.3f}")
        
        except Exception as e:
            logger.error(f"âŒ åƒæ•¸å„ªåŒ–å¤±æ•—: {e}")
    
    def _evaluate_current_performance(self) -> float:
        """è©•ä¼°ç•¶å‰åƒæ•¸è¡¨ç¾"""
        try:
            recent_signals = list(self.signal_history)[-50:]  # æœ€è¿‘50å€‹ä¿¡è™Ÿ
            if not recent_signals:
                return 0.0
            
            # è¨ˆç®—åŠ æ¬Šè¡¨ç¾åˆ†æ•¸
            performance_scores = []
            returns = []
            
            for signal in recent_signals:
                if signal.performance_score is not None:
                    performance_scores.append(signal.performance_score)
                if signal.actual_outcome is not None:
                    returns.append(signal.actual_outcome)
            
            if not performance_scores:
                return 0.0
            
            # ç¶œåˆè©•åˆ†ï¼šè¡¨ç¾åˆ†æ•¸ + æ”¶ç›Šç©©å®šæ€§
            avg_performance = np.mean(performance_scores)
            if returns:
                return_stability = 1.0 / (1.0 + np.std(returns))
                return avg_performance * 0.7 + return_stability * 0.3
            else:
                return avg_performance
        
        except Exception as e:
            logger.error(f"âŒ è¡¨ç¾è©•ä¼°å¤±æ•—: {e}")
            return 0.0
    
    def _simulate_parameter_change(self, param_name: str, new_value: float) -> float:
        """æ¨¡æ“¬åƒæ•¸æ”¹è®Šçš„å½±éŸ¿"""
        try:
            # ç°¡åŒ–çš„æ¨¡æ“¬ï¼šåŸºæ–¼æ­·å²æ¨¡å¼ä¼°ç®—å½±éŸ¿
            base_performance = self._evaluate_current_performance()
            
            # æ ¹æ“šåƒæ•¸é¡å‹ä¼°ç®—å½±éŸ¿
            if param_name == 'signal_threshold':
                # é–¾å€¼è¶Šä½ï¼Œä¿¡è™Ÿè¶Šå¤šä½†è³ªé‡å¯èƒ½ä¸‹é™
                if new_value < self.current_parameters[param_name]:
                    return base_performance * 0.95  # è¼•å¾®é™ä½
                else:
                    return base_performance * 1.02  # è¼•å¾®æå‡
            
            elif param_name in ['momentum_weight', 'volume_weight', 'trend_sensitivity']:
                # æ¬Šé‡èª¿æ•´çš„å½±éŸ¿ - é˜²æ­¢é™¤é›¶éŒ¯èª¤
                current_param_value = self.current_parameters[param_name]
                if current_param_value != 0:
                    change_ratio = new_value / current_param_value
                    if 0.9 <= change_ratio <= 1.1:
                        return base_performance * (1.0 + (change_ratio - 1.0) * 0.1)
                    else:
                        return base_performance * 0.98  # å¤§å¹…èª¿æ•´å¯èƒ½é™ä½æ€§èƒ½
                else:
                    # å¦‚æœç•¶å‰åƒæ•¸ç‚º0ï¼Œä½¿ç”¨é»˜èªå¢ç›Š
                    return base_performance * 1.05
            
            else:
                # å…¶ä»–åƒæ•¸çš„ä¸€èˆ¬æ€§å½±éŸ¿
                return base_performance * np.random.uniform(0.98, 1.05)
        
        except Exception as e:
            logger.error(f"âŒ åƒæ•¸æ¨¡æ“¬å¤±æ•—: {e}")
            return 0.0
    
    async def weekly_parameter_retrain(self) -> Dict[str, Any]:
        """é€±æœŸæ€§åƒæ•¸é‡è¨“ç·´"""
        try:
            logger.info("ğŸ”„ é–‹å§‹é€±æœŸæ€§åƒæ•¸é‡è¨“ç·´...")
            
            if len(self.signal_history) < self.learning_config['min_signals_for_learning']:
                return {
                    'status': 'insufficient_data',
                    'message': f'éœ€è¦è‡³å°‘ {self.learning_config["min_signals_for_learning"]} å€‹ä¿¡è™Ÿæ•¸æ“š'
                }
            
            self.status = LearningStatus.TRAINING
            
            # 1. åˆ†ææ­·å²è¡¨ç¾
            performance_analysis = self._analyze_historical_performance()
            
            # 2. é‡æ–°ç™¼ç¾æ¨¡å¼
            await self._discover_patterns()
            
            # 3. å…¨é¢åƒæ•¸å„ªåŒ–
            await self._comprehensive_parameter_optimization()
            
            # 4. é©—è­‰å„ªåŒ–çµæœ
            validation_results = self._validate_optimization()
            
            self.learning_stats['retraining_cycles'] += 1
            self.status = LearningStatus.READY
            
            logger.info("âœ… é€±æœŸæ€§é‡è¨“ç·´å®Œæˆ")
            
            return {
                'status': 'success',
                'retraining_cycle': self.learning_stats['retraining_cycles'],
                'performance_analysis': performance_analysis,
                'parameters_optimized': list(self.current_parameters.keys()),
                'new_patterns_applied': len(self.learning_patterns),
                'validation_results': validation_results,
                'improvement_summary': {
                    'patterns_discovered': self.learning_stats['patterns_discovered'],
                    'parameters_optimized': self.learning_stats['parameters_optimized'],
                    'current_success_rate': self.performance_metrics['success_rate'],
                    'current_avg_return': self.performance_metrics['average_return']
                }
            }
        
        except Exception as e:
            logger.error(f"âŒ é€±æœŸæ€§é‡è¨“ç·´å¤±æ•—: {e}")
            self.status = LearningStatus.ERROR
            return {
                'status': 'error',
                'error_message': str(e)
            }
    
    def _analyze_historical_performance(self) -> Dict[str, Any]:
        """åˆ†ææ­·å²è¡¨ç¾"""
        try:
            recent_signals = list(self.signal_history)[-200:]  # æœ€è¿‘200å€‹ä¿¡è™Ÿ
            
            # æŒ‰æ™‚é–“æ®µåˆ†æ
            time_segments = {
                'last_week': [],
                'last_month': [],
                'all_time': recent_signals
            }
            
            now = datetime.now()
            for signal in recent_signals:
                if signal.timestamp > now - timedelta(days=7):
                    time_segments['last_week'].append(signal)
                if signal.timestamp > now - timedelta(days=30):
                    time_segments['last_month'].append(signal)
            
            analysis = {}
            for period, signals in time_segments.items():
                if signals:
                    outcomes = [s.actual_outcome for s in signals if s.actual_outcome is not None]
                    performance_scores = [s.performance_score for s in signals if s.performance_score is not None]
                    
                    analysis[period] = {
                        'signal_count': len(signals),
                        'avg_return': np.mean(outcomes) if outcomes else 0.0,
                        'success_rate': len([o for o in outcomes if o > 0]) / len(outcomes) if outcomes else 0.0,
                        'avg_performance_score': np.mean(performance_scores) if performance_scores else 0.0
                    }
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ æ­·å²è¡¨ç¾åˆ†æå¤±æ•—: {e}")
            return {}
    
    async def _comprehensive_parameter_optimization(self):
        """å…¨é¢åƒæ•¸å„ªåŒ–"""
        try:
            # ä½¿ç”¨æ›´ç²¾ç´°çš„åƒæ•¸æœç´¢
            optimization_rounds = 3
            
            for round_num in range(optimization_rounds):
                logger.info(f"âš™ï¸ åƒæ•¸å„ªåŒ–è¼ªæ¬¡ {round_num + 1}/{optimization_rounds}")
                
                # å°æ¯å€‹åƒæ•¸é€²è¡Œç²¾ç´°èª¿å„ª
                for param_name in self.current_parameters.keys():
                    best_value = await self._optimize_single_parameter(param_name)
                    if best_value != self.current_parameters[param_name]:
                        old_value = self.current_parameters[param_name]
                        self.current_parameters[param_name] = best_value
                        logger.info(f"ğŸ”§ {param_name}: {old_value:.3f} â†’ {best_value:.3f}")
        
        except Exception as e:
            logger.error(f"âŒ å…¨é¢åƒæ•¸å„ªåŒ–å¤±æ•—: {e}")
    
    async def _optimize_single_parameter(self, param_name: str) -> float:
        """å„ªåŒ–å–®å€‹åƒæ•¸"""
        try:
            current_value = self.current_parameters[param_name]
            best_value = current_value
            best_performance = self._evaluate_current_performance()
            
            # æ¸¬è©¦ç¯„åœ
            test_multipliers = [0.7, 0.8, 0.9, 1.1, 1.2, 1.3]
            
            for multiplier in test_multipliers:
                test_value = current_value * multiplier
                simulated_performance = self._simulate_parameter_change(param_name, test_value)
                
                if simulated_performance > best_performance:
                    best_performance = simulated_performance
                    best_value = test_value
            
            return best_value
            
        except Exception as e:
            logger.error(f"âŒ å–®å€‹åƒæ•¸å„ªåŒ–å¤±æ•—: {e}")
            return self.current_parameters[param_name]
    
    def _validate_optimization(self) -> Dict[str, float]:
        """é©—è­‰å„ªåŒ–çµæœ"""
        try:
            # è¨ˆç®—å„ªåŒ–å‰å¾Œçš„æ€§èƒ½æŒ‡æ¨™
            return {
                'current_success_rate': self.performance_metrics['success_rate'],
                'current_avg_return': self.performance_metrics['average_return'],
                'current_sharpe_ratio': self.performance_metrics['sharpe_ratio'],
                'pattern_confidence': np.mean([p.confidence for p in self.learning_patterns.values()]) if self.learning_patterns else 0.0,
                'optimization_score': self._evaluate_current_performance()
            }
            
        except Exception as e:
            logger.error(f"âŒ å„ªåŒ–é©—è­‰å¤±æ•—: {e}")
            return {}
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """ç²å–å­¸ç¿’æ‘˜è¦"""
        try:
            return {
                'learning_status': self.status.value,
                'performance_metrics': self.performance_metrics,
                'learning_statistics': self.learning_stats,
                'current_parameters': self.current_parameters,
                'discovered_patterns': {
                    pattern_id: {
                        'type': pattern.pattern_type,
                        'success_rate': pattern.success_rate,
                        'confidence': pattern.confidence,
                        'sample_count': pattern.sample_count
                    }
                    for pattern_id, pattern in self.learning_patterns.items()
                },
                'recent_optimizations': {
                    param_name: [
                        {
                            'old_value': opt.old_value,
                            'new_value': opt.new_value,
                            'improvement': opt.improvement_score,
                            'time': opt.optimization_time.isoformat()
                        }
                        for opt in optimizations[-3:]  # æœ€è¿‘3æ¬¡å„ªåŒ–
                    ]
                    for param_name, optimizations in self.parameter_history.items()
                },
                'update_frequency': len(self.signal_history),
                'next_optimization_in': self.learning_config['parameter_optimization_frequency'] - (len(self.signal_history) % self.learning_config['parameter_optimization_frequency'])
            }
            
        except Exception as e:
            logger.error(f"âŒ å­¸ç¿’æ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}")
            return {
                'learning_status': 'error',
                'error': str(e)
            }
    
    async def update_from_feedback(self, symbol: str, feedback) -> Dict[str, Any]:
        """æ ¹æ“šäº¤æ˜“åé¥‹æ›´æ–°å­¸ç¿’åƒæ•¸ - ç”Ÿç”¢ç³»çµ±æ¥å£"""
        try:
            logger.info(f"ğŸ”„ è™•ç† {symbol} çš„å­¸ç¿’åé¥‹...")
            
            # å°‡åé¥‹æ•¸æ“šè½‰æ›ç‚ºå­¸ç¿’ç³»çµ±æ ¼å¼
            feedback_data = {
                'symbol': symbol,
                'win_rate': feedback.win_rate,
                'average_return': feedback.average_return,
                'sharpe_ratio': feedback.sharpe_ratio,
                'max_drawdown': feedback.max_drawdown,
                'total_signals': feedback.total_signals,
                'successful_trades': feedback.successful_trades,
                'tier_performance': feedback.tier_performance,
                'regime_performance': feedback.regime_performance,
                'parameter_effectiveness': feedback.parameter_effectiveness,
                'recommendations': feedback.recommendations
            }
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ¨™
            self.performance_metrics['success_rate'] = feedback.win_rate
            self.performance_metrics['average_return'] = feedback.average_return
            self.performance_metrics['total_signals_tracked'] += feedback.total_signals
            self.performance_metrics['successful_signals'] += feedback.successful_trades
            
            # æ ¹æ“šåé¥‹èª¿æ•´åƒæ•¸
            adjustments_made = {}
            
            # 1. æ ¹æ“šå‹ç‡èª¿æ•´ä¿¡è™Ÿé–¾å€¼
            if feedback.win_rate < 0.4:
                old_threshold = self.current_parameters['signal_threshold']
                self.current_parameters['signal_threshold'] = min(0.8, old_threshold * 1.1)
                adjustments_made['signal_threshold'] = {
                    'old': old_threshold,
                    'new': self.current_parameters['signal_threshold'],
                    'reason': f'ä½å‹ç‡ {feedback.win_rate:.2%} < 40%'
                }
            elif feedback.win_rate > 0.8:
                old_threshold = self.current_parameters['signal_threshold']
                self.current_parameters['signal_threshold'] = max(0.3, old_threshold * 0.95)
                adjustments_made['signal_threshold'] = {
                    'old': old_threshold,
                    'new': self.current_parameters['signal_threshold'],
                    'reason': f'é«˜å‹ç‡ {feedback.win_rate:.2%} > 80%'
                }
            
            # 2. æ ¹æ“šå¤æ™®æ¯”ç‡èª¿æ•´é¢¨éšªå€æ•¸
            if feedback.sharpe_ratio < 0.5:
                old_risk = self.current_parameters['risk_multiplier']
                self.current_parameters['risk_multiplier'] = min(2.0, old_risk * 1.05)
                adjustments_made['risk_multiplier'] = {
                    'old': old_risk,
                    'new': self.current_parameters['risk_multiplier'],
                    'reason': f'ä½å¤æ™®æ¯”ç‡ {feedback.sharpe_ratio:.3f} < 0.5'
                }
            elif feedback.sharpe_ratio > 1.5:
                old_risk = self.current_parameters['risk_multiplier']
                self.current_parameters['risk_multiplier'] = max(0.5, old_risk * 0.98)
                adjustments_made['risk_multiplier'] = {
                    'old': old_risk,
                    'new': self.current_parameters['risk_multiplier'],
                    'reason': f'é«˜å¤æ™®æ¯”ç‡ {feedback.sharpe_ratio:.3f} > 1.5'
                }
            
            # 3. æ ¹æ“šæœ€å¤§å›æ’¤èª¿æ•´æ³¢å‹•æ€§èª¿æ•´
            if feedback.max_drawdown > 0.15:
                old_vol = self.current_parameters['volatility_adjustment']
                self.current_parameters['volatility_adjustment'] = min(1.5, old_vol * 1.08)
                adjustments_made['volatility_adjustment'] = {
                    'old': old_vol,
                    'new': self.current_parameters['volatility_adjustment'],
                    'reason': f'é«˜å›æ’¤ {feedback.max_drawdown:.2%} > 15%'
                }
            
            # 4. æ ¹æ“šåˆ†å±¤è¡¨ç¾èª¿æ•´æ¬Šé‡
            if feedback.tier_performance:
                best_tier = max(feedback.tier_performance.keys(), 
                              key=lambda t: feedback.tier_performance[t].get('win_rate', 0))
                if feedback.tier_performance[best_tier].get('win_rate', 0) > 0.7:
                    # å¢å¼·æœ€ä½³å±¤ç´šçš„æ¬Šé‡
                    old_trend = self.current_parameters['trend_sensitivity']
                    self.current_parameters['trend_sensitivity'] = min(1.5, old_trend * 1.03)
                    adjustments_made['trend_sensitivity'] = {
                        'old': old_trend,
                        'new': self.current_parameters['trend_sensitivity'],
                        'reason': f'æœ€ä½³å±¤ç´š {best_tier} å‹ç‡ {feedback.tier_performance[best_tier]["win_rate"]:.2%}'
                    }
            
            # è¨˜éŒ„åƒæ•¸è®ŠåŒ–æ­·å²
            for param_name, adjustment in adjustments_made.items():
                self.parameter_history[param_name].append({
                    'timestamp': datetime.now(),
                    'old_value': adjustment['old'],
                    'new_value': adjustment['new'],
                    'reason': adjustment['reason'],
                    'feedback_source': symbol
                })
            
            # æ›´æ–°å­¸ç¿’çµ±è¨ˆ
            self.learning_stats['parameters_optimized'] += len(adjustments_made)
            
            logger.info(f"âœ… {symbol} å­¸ç¿’åé¥‹è™•ç†å®Œæˆ")
            if adjustments_made:
                logger.info(f"ğŸ”§ é€²è¡Œäº† {len(adjustments_made)} é …åƒæ•¸èª¿æ•´")
                for param, adj in adjustments_made.items():
                    logger.info(f"   ğŸ“Š {param}: {adj['old']:.3f} â†’ {adj['new']:.3f} ({adj['reason']})")
            
            return {
                'success': True,
                'adjustments_made': adjustments_made,
                'current_parameters': self.current_parameters,
                'total_adjustments': len(adjustments_made)
            }
            
        except Exception as e:
            logger.error(f"âŒ å­¸ç¿’åé¥‹è™•ç†å¤±æ•—: {e}")
            return {
                'success': False,
                'error': str(e),
                'adjustments_made': {},
                'current_parameters': self.current_parameters
            }
    
    async def track_signal_for_learning(self, signal_data: Dict[str, Any]) -> str:
        """è¿½è¹¤ä¿¡è™Ÿç”¨æ–¼å­¸ç¿’ - ç”Ÿç”¢ç³»çµ±æ¥å£"""
        try:
            signal_id = signal_data.get('signal_id', f"signal_{len(self.signal_history)}_{datetime.now().timestamp()}")
            
            # è¨˜éŒ„ä¿¡è™Ÿåˆ°å­¸ç¿’ç³»çµ±
            performance = await self.monitor_signal_performance(signal_data)
            
            logger.debug(f"ğŸ“Š ä¿¡è™Ÿå·²è¨˜éŒ„åˆ°å­¸ç¿’ç³»çµ±: {signal_id}")
            return signal_id
            
        except Exception as e:
            logger.error(f"âŒ ä¿¡è™Ÿå­¸ç¿’è¿½è¹¤å¤±æ•—: {e}")
            return ""
    
    def get_optimized_parameters(self) -> Dict[str, float]:
        """ç²å–ç•¶å‰å„ªåŒ–åƒæ•¸ - ä¾› Phase1A ä½¿ç”¨"""
        return self.current_parameters.copy()
    
    async def get_optimized_parameters_async(self) -> Dict[str, float]:
        """ç²å–ç•¶å‰å„ªåŒ–åƒæ•¸ - ç•°æ­¥ç‰ˆæœ¬ä¾›åƒæ•¸ç®¡ç†å™¨ä½¿ç”¨"""
        return self.current_parameters.copy()

async def main():
    """æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§  Adaptive Learning Core æ¸¬è©¦")
    
    # å‰µå»ºå¯¦ä¾‹é€²è¡Œæ¸¬è©¦
    learning_core = AdaptiveLearningCore()
    
    # æ¨¡æ“¬ä¿¡è™Ÿæ•¸æ“š
    test_signals = []
    for i in range(100):
        signal_data = {
            'signal_id': f'test_signal_{i}',
            'symbol': 'BTCUSDT',
            'signal_strength': np.random.uniform(0.3, 0.9),
            'direction': np.random.choice(['BUY', 'SELL']),
            'features': {
                'momentum': np.random.uniform(-1, 1),
                'volatility': np.random.uniform(0, 1),
                'volume_ratio': np.random.uniform(0.5, 2)
            }
        }
        
        # æ¨¡æ“¬å¯¦éš›çµæœ
        actual_outcome = np.random.uniform(-0.02, 0.03)
        
        # ç›£æ§è¡¨ç¾
        await learning_core.monitor_signal_performance(signal_data, actual_outcome)
        test_signals.append(signal_data)
    
    # åŸ·è¡Œé‡è¨“ç·´
    retrain_results = await learning_core.weekly_parameter_retrain()
    print(f"é‡è¨“ç·´çµæœ: {retrain_results['status']}")
    
    # ç²å–æ‘˜è¦
    summary = learning_core.get_learning_summary()
    print(f"å­¸ç¿’ç‹€æ…‹: {summary['learning_status']}")
    print(f"è·Ÿè¹¤ä¿¡è™Ÿæ•¸: {summary['performance_metrics']['total_signals_tracked']}")
    print(f"æˆåŠŸç‡: {summary['performance_metrics']['success_rate']:.1%}")
    
    print("\nâœ… æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(main())
