#!/usr/bin/env python3
"""
ğŸ”„ Phase2 åƒæ•¸è¼¸å‡ºç®¡ç†å™¨
å¯¦ç¾é¡ä¼¼ Phase5 çš„ JSON é…ç½®è¼¸å‡ºæ©Ÿåˆ¶
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
import numpy as np

logger = logging.getLogger(__name__)

@dataclass
class ParameterGenerationMetrics:
    """åƒæ•¸ç”ŸæˆæŒ‡æ¨™"""
    generation_time: datetime
    trigger_type: str  # "time_based" | "signal_based" | "performance_based"
    signal_count_since_last: int
    hours_since_last: float
    performance_improvement: float
    learning_confidence: float
    market_regime: str

@dataclass
class ParameterConflictResolution:
    """åƒæ•¸è¡çªè§£æ±ºè¨˜éŒ„"""
    parameter_name: str
    phase2_value: float
    phase5_value: float
    fusion_weight: float
    final_value: float
    resolution_method: str
    confidence_score: float

class Phase2ParameterManager:
    """Phase2 åƒæ•¸ç®¡ç†å™¨ - é¡ä¼¼ Phase5 çš„é…ç½®è¼¸å‡ºæ©Ÿåˆ¶"""
    
    def __init__(self, config_path: str = None):
        """åˆå§‹åŒ–åƒæ•¸ç®¡ç†å™¨"""
        self.config_path = Path(config_path) if config_path else Path(__file__).parent / "config" / "phase2_parameter_config.json"
        self.output_dir = Path(__file__).parent / "output"
        self.output_dir.mkdir(exist_ok=True)
        
        # è¼‰å…¥é…ç½®
        self.config = self._load_config()
        
        # ç‹€æ…‹è¿½è¹¤
        self.last_generation_time = None
        self.signal_count_since_last = 0
        self.current_parameters = {}
        self.generation_history = []
        self.conflict_history = []
        
        # æ€§èƒ½ç›£æ§
        self.performance_baseline = None
        self.performance_history = []
        self.rollback_stack = []
        
        logger.info("ğŸ“Š Phase2 åƒæ•¸ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _load_config(self) -> Dict[str, Any]:
        """è¼‰å…¥é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"âœ… è¼‰å…¥é…ç½®: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®è¼‰å…¥å¤±æ•—: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ç²å–é»˜èªé…ç½®"""
        return {
            "generation_frequency": {
                "interval_hours": 2,
                "signal_count": 200,
                "trigger_mode": "either"
            },
            "parameter_authority": {
                "phase2_dominant": {
                    "signal_threshold": {"base_value": 0.6, "adjustment_range": [0.4, 0.8], "fusion_weight": 0.8},
                    "momentum_weight": {"base_value": 1.0, "adjustment_range": [0.5, 2.0], "fusion_weight": 0.8},
                    "volatility_adjustment": {"base_value": 1.0, "adjustment_range": [0.3, 2.5], "fusion_weight": 0.8}
                }
            },
            "performance_monitoring": {
                "rollback_threshold": {"performance_drop_percent": 15},
                "warning_threshold": {"performance_drop_percent": 8}
            }
        }
    
    def should_generate_new_parameters(self) -> tuple[bool, str]:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²ç”Ÿæˆæ–°åƒæ•¸"""
        try:
            freq_config = self.config.get("generation_frequency", {})
            
            # æ™‚é–“æ¢ä»¶
            time_trigger = False
            if self.last_generation_time:
                interval_hours = freq_config.get("interval_hours", 2)
                hours_since = (datetime.now() - self.last_generation_time).total_seconds() / 3600
                time_trigger = hours_since >= interval_hours
            else:
                time_trigger = True  # é¦–æ¬¡ç”Ÿæˆ
            
            # ä¿¡è™Ÿæ•¸é‡æ¢ä»¶
            signal_count_threshold = freq_config.get("signal_count", 200)
            signal_trigger = self.signal_count_since_last >= signal_count_threshold
            
            # è§¸ç™¼æ¨¡å¼
            trigger_mode = freq_config.get("trigger_mode", "either")
            
            if trigger_mode == "either":
                should_trigger = time_trigger or signal_trigger
            elif trigger_mode == "both":
                should_trigger = time_trigger and signal_trigger
            else:
                should_trigger = time_trigger
            
            # ç¢ºå®šè§¸ç™¼åŸå› 
            if should_trigger:
                if time_trigger and signal_trigger:
                    reason = "time_and_signal"
                elif time_trigger:
                    reason = "time_based"
                else:
                    reason = "signal_based"
            else:
                reason = "no_trigger"
            
            return should_trigger, reason
            
        except Exception as e:
            logger.error(f"âŒ åƒæ•¸ç”Ÿæˆæª¢æŸ¥å¤±æ•—: {e}")
            return False, "error"
    
    async def generate_optimized_parameters(self, learning_engine, market_detector) -> Optional[Dict[str, Any]]:
        """ç”Ÿæˆå„ªåŒ–åƒæ•¸ - æ ¸å¿ƒé‚è¼¯"""
        try:
            logger.info("ğŸ”„ é–‹å§‹ç”Ÿæˆ Phase2 å„ªåŒ–åƒæ•¸...")
            
            # æª¢æŸ¥æ˜¯å¦æ‡‰è©²ç”Ÿæˆ
            should_generate, trigger_reason = self.should_generate_new_parameters()
            if not should_generate:
                logger.debug(f"â­ï¸ è·³éåƒæ•¸ç”Ÿæˆ: {trigger_reason}")
                return None
            
            # ç²å–ç•¶å‰å¸‚å ´ç‹€æ…‹
            try:
                if market_detector and hasattr(market_detector, 'detect_current_regime'):
                    market_regime = await market_detector.detect_current_regime()
                else:
                    market_regime = "NORMAL"  # é»˜èªå¸‚å ´ç‹€æ…‹
            except Exception as e:
                logger.warning(f"âš ï¸ å¸‚å ´ç‹€æ…‹æª¢æ¸¬å¤±æ•—: {e}ï¼Œä½¿ç”¨é»˜èªç‹€æ…‹")
                market_regime = "NORMAL"
            
            # ç²å–å­¸ç¿’å¼•æ“çš„å„ªåŒ–åƒæ•¸
            try:
                if learning_engine and hasattr(learning_engine, 'get_optimized_parameters_async'):
                    phase2_parameters = await learning_engine.get_optimized_parameters_async()
                elif learning_engine and hasattr(learning_engine, 'get_optimized_parameters'):
                    phase2_parameters = learning_engine.get_optimized_parameters()
                else:
                    # ä½¿ç”¨é»˜èªåƒæ•¸
                    phase2_parameters = {
                        'signal_threshold': 0.6,
                        'momentum_weight': 1.0,
                        'volatility_adjustment': 1.0,
                        'trend_sensitivity': 1.0,
                        'volume_weight': 0.8,
                        'risk_multiplier': 1.0
                    }
                    logger.warning("âš ï¸ ä½¿ç”¨é»˜èª Phase2 åƒæ•¸")
            except Exception as e:
                logger.error(f"âŒ ç²å–å­¸ç¿’åƒæ•¸å¤±æ•—: {e}")
                return None
            
            # è¼‰å…¥ Phase5 åƒæ•¸ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            phase5_parameters = await self._load_phase5_parameters()
            
            # åƒæ•¸èåˆ
            fused_parameters = await self._fuse_parameters(phase2_parameters, phase5_parameters)
            
            # é©—è­‰åƒæ•¸åˆç†æ€§
            validated_parameters = self._validate_parameters(fused_parameters)
            
            # ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶
            output_file = await self._save_parameter_file(validated_parameters, trigger_reason, market_regime)
            
            # æ›´æ–°ç‹€æ…‹
            self._update_generation_state(trigger_reason, market_regime)
            
            logger.info(f"âœ… åƒæ•¸ç”Ÿæˆå®Œæˆ: {output_file}")
            return validated_parameters
            
        except Exception as e:
            logger.error(f"âŒ åƒæ•¸ç”Ÿæˆå¤±æ•—: {e}")
            return None
    
    async def _load_phase5_parameters(self) -> Dict[str, Any]:
        """è¼‰å…¥ Phase5 åƒæ•¸"""
        try:
            # å°‹æ‰¾æœ€æ–°çš„ Phase5 é…ç½®æ–‡ä»¶
            phase5_dir = Path(__file__).parent.parent.parent / "phase5_backtesting" / "output"
            if not phase5_dir.exists():
                logger.warning("âš ï¸ Phase5 è¼¸å‡ºç›®éŒ„ä¸å­˜åœ¨")
                return {}
            
            # ç²å–æœ€æ–°æ–‡ä»¶
            phase5_files = list(phase5_dir.glob("optimized_config_*.json"))
            if not phase5_files:
                logger.warning("âš ï¸ æœªæ‰¾åˆ° Phase5 é…ç½®æ–‡ä»¶")
                return {}
            
            latest_file = max(phase5_files, key=lambda f: f.stat().st_mtime)
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                phase5_config = json.load(f)
            
            logger.info(f"ğŸ“ è¼‰å…¥ Phase5 åƒæ•¸: {latest_file.name}")
            return phase5_config.get("parameters", {})
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥ Phase5 åƒæ•¸å¤±æ•—: {e}")
            return {}
    
    async def _fuse_parameters(self, phase2_params: Dict, phase5_params: Dict) -> Dict[str, Any]:
        """èåˆ Phase2 å’Œ Phase5 åƒæ•¸"""
        fused_params = {}
        conflict_resolutions = []
        
        authority_config = self.config["parameter_authority"]
        
        # è™•ç† Phase2 ä¸»å°åƒæ•¸
        for param_name, param_config in authority_config.get("phase2_dominant", {}).items():
            phase2_value = phase2_params.get(param_name, param_config["base_value"])
            phase5_value = phase5_params.get(param_name, param_config["base_value"])
            fusion_weight = param_config["fusion_weight"]
            
            # åŠ æ¬Šå¹³å‡
            final_value = phase2_value * fusion_weight + phase5_value * (1 - fusion_weight)
            
            # ç¯„åœæª¢æŸ¥
            value_range = param_config["adjustment_range"]
            final_value = np.clip(final_value, value_range[0], value_range[1])
            
            fused_params[param_name] = final_value
            
            # è¨˜éŒ„è¡çªè§£æ±º
            if abs(phase2_value - phase5_value) > 0.1:  # æœ‰é¡¯è‘—å·®ç•°
                conflict_resolutions.append(ParameterConflictResolution(
                    parameter_name=param_name,
                    phase2_value=phase2_value,
                    phase5_value=phase5_value,
                    fusion_weight=fusion_weight,
                    final_value=final_value,
                    resolution_method="weighted_average",
                    confidence_score=fusion_weight
                ))
        
        # è™•ç† Phase5 ä¸»å°åƒæ•¸
        for param_name, param_config in authority_config.get("phase5_dominant", {}).items():
            phase2_value = phase2_params.get(param_name, param_config["base_value"])
            phase5_value = phase5_params.get(param_name, param_config["base_value"])
            fusion_weight = param_config["fusion_weight"]  # Phase2 çš„æ¬Šé‡
            
            # Phase5 ä¸»å°ï¼Œæ‰€ä»¥ Phase5 æ¬Šé‡æ›´é«˜
            final_value = phase2_value * fusion_weight + phase5_value * (1 - fusion_weight)
            
            value_range = param_config["adjustment_range"]
            final_value = np.clip(final_value, value_range[0], value_range[1])
            
            fused_params[param_name] = final_value
        
        # è™•ç†å¹³è¡¡åƒæ•¸
        for param_name, param_config in authority_config.get("balanced", {}).items():
            phase2_value = phase2_params.get(param_name, param_config["base_value"])
            phase5_value = phase5_params.get(param_name, param_config["base_value"])
            
            # 50-50 å¹³è¡¡
            final_value = (phase2_value + phase5_value) / 2
            
            value_range = param_config["adjustment_range"]
            final_value = np.clip(final_value, value_range[0], value_range[1])
            
            fused_params[param_name] = final_value
        
        # ä¿å­˜è¡çªè§£æ±ºè¨˜éŒ„
        self.conflict_history.extend(conflict_resolutions)
        
        if conflict_resolutions:
            logger.info(f"âš–ï¸ è§£æ±º {len(conflict_resolutions)} å€‹åƒæ•¸è¡çª")
        
        return fused_params
    
    def _validate_parameters(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰åƒæ•¸åˆç†æ€§"""
        validated = {}
        authority_config = self.config["parameter_authority"]
        
        # æ”¶é›†æ‰€æœ‰åƒæ•¸é…ç½®
        all_param_configs = {}
        for category in ["phase2_dominant", "phase5_dominant", "balanced"]:
            all_param_configs.update(authority_config.get(category, {}))
        
        for param_name, value in parameters.items():
            if param_name in all_param_configs:
                param_config = all_param_configs[param_name]
                value_range = param_config["adjustment_range"]
                
                # ç¯„åœé©—è­‰
                validated_value = np.clip(value, value_range[0], value_range[1])
                
                # é¡å‹é©—è­‰
                if isinstance(param_config["base_value"], int):
                    validated_value = int(validated_value)
                else:
                    validated_value = float(validated_value)
                
                validated[param_name] = validated_value
                
                if validated_value != value:
                    logger.warning(f"âš ï¸ åƒæ•¸ {param_name} è¢«èª¿æ•´: {value:.4f} -> {validated_value:.4f}")
            else:
                # æœªçŸ¥åƒæ•¸ä¿æŒåŸå€¼
                validated[param_name] = value
        
        return validated
    
    async def _save_parameter_file(self, parameters: Dict, trigger_reason: str, market_regime: str) -> str:
        """ä¿å­˜åƒæ•¸æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"phase2_optimized_params_{timestamp}.json"
        filepath = self.output_dir / filename
        
        # ç”ŸæˆæŒ‡æ¨™
        metrics = ParameterGenerationMetrics(
            generation_time=datetime.now(),
            trigger_type=trigger_reason,
            signal_count_since_last=self.signal_count_since_last,
            hours_since_last=self._get_hours_since_last(),
            performance_improvement=self._calculate_performance_improvement(),
            learning_confidence=0.75,  # æš«æ™‚å›ºå®šï¼Œå¾ŒçºŒå¯ä»¥å¾å­¸ç¿’å¼•æ“ç²å–
            market_regime=market_regime
        )
        
        # æ§‹å»ºè¼¸å‡ºæ•¸æ“š
        output_data = {
            "version": "2.0.0",
            "generation_time": timestamp,
            "config_name": "Phase2 è‡ªé©æ‡‰å„ªåŒ–åƒæ•¸",
            "description": "Phase2 å­¸ç¿’å¼•æ“ç”Ÿæˆçš„å„ªåŒ–åƒæ•¸",
            "parameters": parameters,
            "generation_metrics": asdict(metrics),
            "conflict_resolutions": [asdict(cr) for cr in self.conflict_history[-10:]],  # æœ€è¿‘10å€‹è¡çª
            "validation_status": {
                "validated": True,
                "parameter_count": len(parameters),
                "range_violations": 0
            },
            "integration_info": {
                "phase1a_compatible": True,
                "phase5_conflicts_resolved": len(self.conflict_history),
                "recommended_validation_signals": 50
            }
        }
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"ğŸ’¾ åƒæ•¸æ–‡ä»¶å·²ä¿å­˜: {filename}")
        
        # æ¸…ç†èˆŠæ–‡ä»¶
        await self._cleanup_old_files()
        
        return str(filepath)
    
    def _get_hours_since_last(self) -> float:
        """ç²å–è·é›¢ä¸Šæ¬¡ç”Ÿæˆçš„å°æ™‚æ•¸"""
        if self.last_generation_time:
            return (datetime.now() - self.last_generation_time).total_seconds() / 3600
        return 0.0
    
    def _calculate_performance_improvement(self) -> float:
        """è¨ˆç®—æ€§èƒ½æ”¹å–„"""
        if len(self.performance_history) < 2:
            return 0.0
        
        current = self.performance_history[-1]
        previous = self.performance_history[-2]
        
        return (current - previous) / previous * 100 if previous != 0 else 0.0
    
    def _update_generation_state(self, trigger_reason: str, market_regime: str):
        """æ›´æ–°ç”Ÿæˆç‹€æ…‹"""
        self.last_generation_time = datetime.now()
        self.signal_count_since_last = 0
        
        # è¨˜éŒ„ç”Ÿæˆæ­·å²
        self.generation_history.append({
            "timestamp": datetime.now(),
            "trigger_reason": trigger_reason,
            "market_regime": market_regime
        })
        
        # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§
        if len(self.generation_history) > 100:
            self.generation_history = self.generation_history[-50:]
    
    async def _cleanup_old_files(self):
        """æ¸…ç†èˆŠçš„åƒæ•¸æ–‡ä»¶"""
        try:
            retention_hours = self.config.get("output_schema", {}).get("backup_retention_hours", 168)
            cutoff_time = datetime.now() - timedelta(hours=retention_hours)
            
            for file in self.output_dir.glob("phase2_optimized_params_*.json"):
                if file.stat().st_mtime < cutoff_time.timestamp():
                    file.unlink()
                    logger.debug(f"ğŸ—‘ï¸ æ¸…ç†èˆŠæ–‡ä»¶: {file.name}")
        
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†èˆŠæ–‡ä»¶å¤±æ•—: {e}")
    
    def increment_signal_count(self):
        """å¢åŠ ä¿¡è™Ÿè¨ˆæ•¸"""
        self.signal_count_since_last += 1
    
    def report_performance(self, performance_score: float):
        """å ±å‘Šæ€§èƒ½åˆ†æ•¸"""
        self.performance_history.append(performance_score)
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦å›æ»¾
        if self._should_rollback(performance_score):
            asyncio.create_task(self._perform_rollback())
    
    def _should_rollback(self, current_performance: float) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²å›æ»¾"""
        if not self.performance_baseline or len(self.performance_history) < 2:
            return False
        
        rollback_threshold = self.config["performance_monitoring"]["rollback_threshold"]["performance_drop_percent"]
        performance_drop = (self.performance_baseline - current_performance) / self.performance_baseline * 100
        
        return performance_drop >= rollback_threshold
    
    async def _perform_rollback(self):
        """åŸ·è¡Œåƒæ•¸å›æ»¾"""
        if not self.rollback_stack:
            logger.warning("âš ï¸ ç„¡æ³•å›æ»¾ï¼šæ²’æœ‰æ­·å²åƒæ•¸")
            return
        
        previous_params = self.rollback_stack[-1]
        logger.warning(f"ğŸ”™ åŸ·è¡Œç·Šæ€¥å›æ»¾åˆ°: {previous_params['timestamp']}")
        
        # å‰µå»ºå›æ»¾æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        rollback_file = self.output_dir / f"phase2_rollback_params_{timestamp}.json"
        
        rollback_data = {
            "version": "2.0.0",
            "generation_time": timestamp,
            "config_name": "Phase2 ç·Šæ€¥å›æ»¾åƒæ•¸",
            "description": "ç”±æ–¼æ€§èƒ½ä¸‹é™è§¸ç™¼çš„ç·Šæ€¥åƒæ•¸å›æ»¾",
            "parameters": previous_params["parameters"],
            "rollback_info": {
                "trigger_reason": "performance_degradation",
                "rollback_timestamp": timestamp,
                "original_timestamp": previous_params["timestamp"]
            }
        }
        
        with open(rollback_file, 'w', encoding='utf-8') as f:
            json.dump(rollback_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… å›æ»¾åƒæ•¸å·²ä¿å­˜: {rollback_file.name}")

# å…¨å±€å¯¦ä¾‹
phase2_parameter_manager = Phase2ParameterManager()
