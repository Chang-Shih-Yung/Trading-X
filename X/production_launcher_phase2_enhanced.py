"""
ğŸš€ Trading X ç”Ÿç”¢ç’°å¢ƒå•Ÿå‹•å™¨ - Phase2 åƒæ•¸ç®¡ç†å¢å¼·ç‰ˆ
çœŸæ­£å•Ÿå‹•å®Œæ•´çš„ Phase1A + Phase2 æ•´åˆç³»çµ±ï¼ŒåŒ…å«è‡ªå‹•åƒæ•¸å„ªåŒ–
"""

import asyncio
import logging
import sys
import time
import gc
import aiohttp
import importlib.util
from pathlib import Path
from datetime import datetime
import json

# ç¢ºä¿å¯ä»¥å°å…¥æ‰€æœ‰æ¨¡çµ„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))
sys.path.insert(0, str(current_dir / "backend"))

# è¨­å®šè©³ç´°æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'production_trading_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ğŸ§  ç°¡åŒ–ç‰ˆå…§å­˜ç®¡ç†ï¼ˆä¸ä¾è³´psutilï¼‰
class SimpleMemoryManager:
    """ç°¡åŒ–ç‰ˆå…§å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.last_cleanup = time.time()
        self.cleanup_interval = 300  # 5åˆ†é˜
        
    async def check_and_cleanup(self):
        """æª¢æŸ¥ä¸¦åŸ·è¡Œå…§å­˜æ¸…ç†"""
        current_time = time.time()
        if current_time - self.last_cleanup > self.cleanup_interval:
            logger.info("ğŸ§¹ åŸ·è¡Œå®šæœŸå…§å­˜æ¸…ç†...")
            
            # å¼·åˆ¶åƒåœ¾å›æ”¶
            collected = gc.collect()
            
            self.last_cleanup = current_time
            logger.info(f"âœ… å…§å­˜æ¸…ç†å®Œæˆï¼Œå›æ”¶ {collected} å€‹å°è±¡")
            
    async def memory_monitoring_loop(self):
        """å…§å­˜ç›£æ§å¾ªç’°"""
        while True:
            try:
                await self.check_and_cleanup()
                await asyncio.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"âŒ å…§å­˜ç›£æ§éŒ¯èª¤: {e}")
                await asyncio.sleep(60)

# ğŸš€ å°å…¥æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ± - å¢å¼·é‡è©¦æ©Ÿåˆ¶
HYBRID_PRICE_SYSTEM_AVAILABLE = False
HYBRID_RETRY_COUNT = 0
MAX_HYBRID_RETRIES = 3

def attempt_hybrid_import():
    """å˜—è©¦å°å…¥æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±ï¼Œæ”¯æ´é‡è©¦"""
    global HYBRID_PRICE_SYSTEM_AVAILABLE, HYBRID_RETRY_COUNT
    
    try:
        # æ¸…é™¤æ¨¡çµ„å¿«å–ï¼Œå¼·åˆ¶é‡æ–°å°å…¥
        import sys
        modules_to_clear = [mod for mod in sys.modules.keys() if 'pool_discovery' in mod or 'production_price_integration' in mod]
        for mod in modules_to_clear:
            del sys.modules[mod]
        
        # é‡æ–°å˜—è©¦å°å…¥
        from backend.phase1_signal_generation.onchain_data_connector.production_price_integration import get_real_market_data
        HYBRID_PRICE_SYSTEM_AVAILABLE = True
        HYBRID_RETRY_COUNT = 0  # é‡ç½®è¨ˆæ•¸å™¨
        logger.info("âœ… æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±å°å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        HYBRID_RETRY_COUNT += 1
        logger.warning(f"âš ï¸ æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±å°å…¥å¤±æ•— (å˜—è©¦ {HYBRID_RETRY_COUNT}/{MAX_HYBRID_RETRIES}): {e}")
        
        if HYBRID_RETRY_COUNT < MAX_HYBRID_RETRIES:
            logger.info("ğŸ”„ å°‡åœ¨ç¨å¾Œé‡è©¦æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±é€£æ¥...")
            return False
        else:
            logger.warning("ğŸ”„ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œå°‡ä½¿ç”¨å‚³çµ±å¹£å®‰APIä½œç‚ºå‚™ç”¨æ–¹æ¡ˆ")
            HYBRID_PRICE_SYSTEM_AVAILABLE = False
            return False
    except Exception as e:
        HYBRID_RETRY_COUNT += 1
        logger.error(f"âŒ æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±å°å…¥éŒ¯èª¤ (å˜—è©¦ {HYBRID_RETRY_COUNT}/{MAX_HYBRID_RETRIES}): {e}")
        return False

# åˆå§‹å˜—è©¦å°å…¥
attempt_hybrid_import()

# ğŸ”’ åš´æ ¼ç³»çµ±é©—è­‰ - å¿…é ˆåœ¨ç³»çµ±å•Ÿå‹•å‰å®Œæˆ
def strict_system_validation():
    """åš´æ ¼ç³»çµ±é©—è­‰ - ä»»ä½•çµ„ä»¶ç¼ºå¤±éƒ½çµ‚æ­¢ç³»çµ±"""
    logger.info("ğŸ”’ åŸ·è¡Œåš´æ ¼ç³»çµ±é©—è­‰...")
    
    try:
        from system_strict_validator import validate_system_strict
        result = validate_system_strict()
        
        if not result.get("can_proceed", False):
            logger.error("âŒ ç³»çµ±é©—è­‰å¤±æ•—ï¼Œç³»çµ±å°‡çµ‚æ­¢")
            sys.exit(1)
        
        logger.info("âœ… æ‰€æœ‰çµ„ä»¶é©—è­‰é€šéï¼Œç³»çµ±å¯ä»¥å®‰å…¨å•Ÿå‹•")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ç³»çµ±é©—è­‰éç¨‹å¤±æ•—: {e}")
        logger.error("ç³»çµ±å°‡çµ‚æ­¢ä»¥ç¢ºä¿å®‰å…¨æ€§")
        sys.exit(1)

# åŸ·è¡Œåš´æ ¼é©—è­‰
validation_result = strict_system_validation()

class ProductionTradingSystemPhase2Enhanced:
    """ç”Ÿç”¢ç’°å¢ƒäº¤æ˜“ç³»çµ± - Phase2 åƒæ•¸ç®¡ç†å¢å¼·ç‰ˆ"""
    
    def __init__(self):
        self.phase1a_generator = None
        self.phase3_decision_engine = None
        self.phase3_enabled = False
        self.monitoring_manager = None
        self.running = False
        
        # Phase2 å„ªåŒ–çµ„ä»¶
        self.adaptive_learning_engine = None
        self.learning_enabled = False
        
        # å„ªå…ˆç´š3ï¼šæ™‚é–“æ¡†æ¶æ„ŸçŸ¥å­¸ç¿’å¼•æ“
        self.priority3_enabled = False
        self.priority3_integration = None
        self.timeframe_learning_available = False
        
        # ğŸ§  å…§å­˜ç®¡ç†å™¨
        self.memory_manager = SimpleMemoryManager()
        
        # ğŸš¨ ç³»çµ±å¥åº·ç‹€æ…‹ç›£æ§
        self.system_health = {
            'critical_errors': 0,
            'max_critical_errors': 10,  # å…è¨±çš„æœ€å¤§åš´é‡éŒ¯èª¤æ•¸
            'data_quality_failures': 0,
            'max_data_failures': 5,  # å…è¨±çš„æœ€å¤§æ•¸æ“šè³ªé‡å¤±æ•—æ•¸
            'last_health_check': time.time()
        }
        
        # ä¿¡è™Ÿå¾ªç’°èª¿åº¦é–“éš” - å„ªåŒ–ç‚ºç¬¦åˆBinanceå…è²»APIé™åˆ¶
        self.signal_loop_interval = 90  # ä¿¡è™Ÿç”Ÿæˆå¾ªç’°é–“éš”ï¼ˆç§’ï¼‰- å¾15ç§’å¢åŠ åˆ°90ç§’
        self.symbol_processing_interval = 12  # äº¤æ˜“å°è™•ç†é–“éš”ï¼ˆç§’ï¼‰- å¾3ç§’å¢åŠ åˆ°12ç§’é¿å…APIé™åˆ¶
        self.phase2_last_parameter_check = 0
        
        # Phase5 å®šæ™‚è§¸ç™¼é…ç½® - å•Ÿå‹•è…³æœ¬èª¿åº¦é‚è¼¯
        self.phase5_enabled = True
        self.phase5_interval_hours = 24  # Phase5 å¤§å‹å›æ¸¬èª¿åº¦é–“éš”
        self.phase5_last_run = None
        self.phase5_running = False
        
        # Phase2 åƒæ•¸ç®¡ç†å™¨ - èª¿åº¦é–“éš”å¾Phase2å…§éƒ¨è®€å–
        self.phase2_parameter_manager = None
        self.phase2_parameter_check_interval = None  # å°‡å¾Phase2å…§éƒ¨é…ç½®è®€å–
        
        # å­¸ç¿’åé¥‹æ©Ÿåˆ¶èª¿åº¦é…ç½® - å¾Phase2å…§éƒ¨è®€å–
        self.learning_feedback_enabled = True
        self.learning_feedback_last_run = 0
        self.learning_feedback_interval = None  # å°‡å¾Phase2å…§éƒ¨é…ç½®è®€å–
        
        # æ–‡ä»¶æ¸…ç†èª¿åº¦é…ç½®
        self.file_cleanup_manager = None
        self.last_cleanup_time = 0
        self.cleanup_interval = 3600  # 1å°æ™‚æ¸…ç†ä¸€æ¬¡ï¼ˆèª¿åº¦é‚è¼¯ï¼‰
        
        # äº¤æ˜“å°åˆ—è¡¨ - èª¿åº¦å™¨éœ€è¦çŸ¥é“è¦è™•ç†å“ªäº›äº¤æ˜“å°
        self.trading_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT", "XRPUSDT", "DOGEUSDT"]
        
        # Binance API é™åˆ¶ç®¡ç†
        self.api_call_times = []  # è¨˜éŒ„APIå‘¼å«æ™‚é–“
        self.api_rate_limit_window = 60  # é™åˆ¶çª—å£ï¼ˆç§’ï¼‰
        self.api_max_calls_per_minute = 50  # ä¿å®ˆçš„æ¯åˆ†é˜æœ€å¤§å‘¼å«æ•¸ï¼ˆé ä½æ–¼1200é™åˆ¶ï¼‰
        self.api_pause_duration = 60  # APIé™åˆ¶è§¸ç™¼å¾Œçš„æš«åœæ™‚é–“ï¼ˆç§’ï¼‰
        self.last_api_pause = 0
        
        # ä¿¡è™Ÿçµ±è¨ˆ
        self.signal_stats = {
            'total_signals_generated': 0,
            'signals_per_symbol': {},
            'signals_per_session': 0,
            'last_reset_time': time.time()
        }
        
        # ğŸ¯ éšæ®µ1ï¼šè·¨é–‰ç’°ä¿¡è™Ÿå»é‡æ©Ÿåˆ¶ - é–‰ç’°å¤–å„ªåŒ–
        self.signal_deduplication_enabled = True
        self.signal_history_cache = {}  # {symbol: [signal_records]}
        self.signal_cache_max_size = 50  # æ¯å€‹äº¤æ˜“å°æœ€å¤šç·©å­˜50å€‹æ­·å²ä¿¡è™Ÿ
        self.signal_similarity_threshold = 0.65  # ç›¸ä¼¼åº¦é–¾å€¼ (å¯å‹•æ…‹èª¿æ•´)
        self.signal_time_decay_hours = 2  # ä¿¡è™Ÿæ™‚é–“è¡°æ¸›çª—å£ï¼ˆå°æ™‚ï¼‰
        
        # ğŸ¯ éšæ®µ2ï¼šé«˜æ³¢å‹•é©æ‡‰åƒæ•¸ (é è¨­å€¼ï¼Œå¾ŒçºŒå‹•æ…‹èª¿æ•´)
        self.volatility_adaptive_enabled = True
        self.high_volatility_threshold = 0.05  # 5% é«˜æ³¢å‹•é–¾å€¼
        self.volatility_similarity_relaxation = 0.15  # é«˜æ³¢å‹•æ™‚æ”¾å¯¬ç›¸ä¼¼åº¦
        
        # ğŸ¯ éšæ®µ3ï¼šæ™ºèƒ½è§¸ç™¼å„ªåŒ–åƒæ•¸
        self.intelligent_trigger_enabled = True
        self.last_price_update_times = {}  # {symbol: timestamp}
        self.price_update_threshold_seconds = 3  # æ™ºèƒ½æ··åˆç³»çµ±æ›´æ–°é–“éš”
        self.fallback_api_interval_seconds = 60  # å¹£å®‰APIå›é€€é–“éš”
        
        # å•Ÿå‹•è…³æœ¬åƒ…è² è²¬èª¿åº¦ï¼Œå¾å„Phaseè®€å–å…§éƒ¨è¨­å®š
        self._load_phase_internal_settings()
    
    def _load_phase_internal_settings(self):
        """å¾å„Phaseè®€å–å…§éƒ¨è¨­å®š - å•Ÿå‹•è…³æœ¬åªè² è²¬èª¿åº¦å”èª¿"""
        logger.info("ğŸ“‹ è¼‰å…¥å„Phaseå…§éƒ¨è¨­å®š...")
        
        # å¾Phase2è®€å–å…§éƒ¨è¨­å®š
        try:
            # ä½¿ç”¨Phase2çš„é»˜èªé…ç½®
            phase2_default_config = {
                "generation_frequency": {
                    "interval_hours": 2,  # Phase2å…§éƒ¨é è¨­2å°æ™‚
                    "signal_count": 200,
                    "trigger_mode": "either"
                }
            }
            
            freq_config = phase2_default_config.get("generation_frequency", {})
            self.phase2_parameter_check_interval = freq_config.get("interval_hours", 2) * 3600  # è½‰æ›ç‚ºç§’
            self.learning_feedback_interval = 3600  # å­¸ç¿’åé¥‹é–“éš”1å°æ™‚
            
            logger.info(f"âœ… Phase2 è¨­å®šè¼‰å…¥: åƒæ•¸æª¢æŸ¥é–“éš” {self.phase2_parameter_check_interval/3600} å°æ™‚")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥Phase2è¨­å®šå¤±æ•—: {e}")
            # ä½¿ç”¨å®‰å…¨çš„é»˜èªå€¼
            self.phase2_parameter_check_interval = 7200  # 2å°æ™‚
            self.learning_feedback_interval = 3600  # 1å°æ™‚
        
        # å¾Phase5è®€å–å…§éƒ¨è¨­å®šï¼ˆauto_backtest_config.jsonï¼‰
        try:
            config_path = Path(__file__).parent / "backend" / "phase5_backtest_validation" / "auto_backtest_validator" / "auto_backtest_config.json"
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    phase5_config = json.load(f)
                
                # è®€å–Phase5çš„6å°æ™‚é–¾å€¼èª¿æ•´è¨­å®š
                threshold_system = phase5_config.get('dynamic_threshold_system', {})
                phase5_adjustment_hours = threshold_system.get('adjustment_frequency_hours', 6)
                
                logger.info(f"âœ… Phase5 è¨­å®šè¼‰å…¥: é–¾å€¼èª¿æ•´é–“éš” {phase5_adjustment_hours} å°æ™‚")
                
        except Exception as e:
            logger.warning(f"âš ï¸ è¼‰å…¥Phase5è¨­å®šå¤±æ•—: {e}")
    
    def get_trading_symbols(self):
        """ç²å–äº¤æ˜“å°åˆ—è¡¨ - èª¿åº¦å™¨ä½¿ç”¨"""
        return self.trading_symbols
        
    async def initialize_systems(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç³»çµ±çµ„ä»¶"""
        logger.info("ğŸš€ åˆå§‹åŒ–ç”Ÿç”¢ç’°å¢ƒäº¤æ˜“ç³»çµ±...")
        
        try:
            # 1. åˆå§‹åŒ– Phase1A ä¿¡è™Ÿç”Ÿæˆå™¨ï¼ˆå·²æ•´åˆ Phase2ï¼‰
            from backend.phase1_signal_generation.phase1a_basic_signal_generation.phase1a_basic_signal_generation import Phase1ABasicSignalGeneration
            
            self.phase1a_generator = Phase1ABasicSignalGeneration()
            # ç›´æ¥è¨­ç½®é‹è¡Œç‹€æ…‹ï¼ˆä¸ä½¿ç”¨éœ€è¦ WebSocket çš„ start() æ–¹æ³•ï¼‰
            self.phase1a_generator.is_running = True
            logger.info("âœ… Phase1A ä¿¡è™Ÿç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # æª¢æŸ¥ Phase2 è‡ªé©æ‡‰å­¸ç¿’æ˜¯å¦å•Ÿç”¨
            if self.phase1a_generator.adaptive_mode:
                logger.info("ğŸ§  Phase2 è‡ªé©æ‡‰å­¸ç¿’æ¨¡å¼ï¼šå·²å•Ÿç”¨")
                logger.info(f"ğŸ“Š å¸‚å ´æª¢æ¸¬å™¨ï¼š{type(self.phase1a_generator.regime_detector).__name__}")
                logger.info(f"ğŸ“ å­¸ç¿’å¼•æ“ï¼š{type(self.phase1a_generator.learning_core).__name__}")
            else:
                logger.warning("âš ï¸ Phase2 è‡ªé©æ‡‰å­¸ç¿’æ¨¡å¼ï¼šæœªå•Ÿç”¨ï¼Œä½¿ç”¨åŸºç¤æ¨¡å¼")
            
            # 2. åˆå§‹åŒ–å„ªå…ˆç´š3æ™‚é–“æ¡†æ¶æ„ŸçŸ¥å­¸ç¿’
            try:
                from backend.phase2_adaptive_learning.priority3_timeframe_learning.priority3_integration_engine_fixed import get_priority3_integration_engine
                
                # åˆå§‹åŒ–å„ªå…ˆç´š3æ•´åˆå¼•æ“ - ğŸ”§ ç§»é™¤ç„¡æ•ˆé…ç½®
                self.priority3_integration = get_priority3_integration_engine()
                
                if self.priority3_integration:
                    self.priority3_enabled = True
                    self.timeframe_learning_available = True
                    logger.info("âœ… å„ªå…ˆç´š3æ™‚é–“æ¡†æ¶æ„ŸçŸ¥å­¸ç¿’ï¼šå·²å•Ÿç”¨")
                    logger.info("   ğŸ“Š æ”¯æ´åŠŸèƒ½: è·¨æ™‚é–“æ¡†æ¶å…±è­˜åˆ†æã€ä¸‰ç¶­æ¬Šé‡èåˆ")
                    logger.info("   ğŸ•’ æ”¯æ´åŠŸèƒ½ï¼šæ™‚é–“è¡°æ¸› + å¹£ç¨®åˆ†é¡ + æ™‚é–“æ¡†æ¶æ„ŸçŸ¥")
                else:
                    logger.warning("âš ï¸ å„ªå…ˆç´š3åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤å­¸ç¿’æ¨¡å¼")
                    self.priority3_enabled = False
                    self.timeframe_learning_available = False
                    
            except Exception as e:
                logger.error(f"âŒ å„ªå…ˆç´š3åˆå§‹åŒ–éŒ¯èª¤: {e}")
                logger.warning("âš ï¸ å„ªå…ˆç´š3åˆå§‹åŒ–å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤å­¸ç¿’æ¨¡å¼")
                self.priority3_enabled = False
                self.timeframe_learning_available = False
            
            # 3. åˆå§‹åŒ– Phase3 æ±ºç­–ç³»çµ±
            try:
                from backend.phase3_execution_policy.epl_intelligent_decision_engine import initialize_epl_system
                self.phase3_decision_engine = await initialize_epl_system()
                logger.info("âœ… Phase3 æ±ºç­–ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
                self.phase3_enabled = True
            except ImportError as e:
                logger.warning(f"âš ï¸ Phase3 æ±ºç­–ç³»çµ±æœªå•Ÿç”¨: {e}")
                self.phase3_decision_engine = None
                self.phase3_enabled = False
            
            # 3. åˆå§‹åŒ–ç›£æ§ç³»çµ±ï¼ˆå¯é¸ï¼‰
            try:
                from backend.phase4_output_monitoring.real_time_unified_monitoring_manager import unified_monitoring_manager
                self.monitoring_manager = unified_monitoring_manager
                logger.info("âœ… ç›£æ§ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
            except ImportError as e:
                logger.warning(f"âš ï¸ ç›£æ§ç³»çµ±æœªå•Ÿç”¨: {e}")
                self.monitoring_manager = None
            
            # 4. åˆå§‹åŒ– Phase2 å„ªåŒ–çµ„ä»¶
            await self._initialize_phase2_optimization_components()
            
            # 5. åˆå§‹åŒ– Phase2 åƒæ•¸ç®¡ç†å™¨
            try:
                from backend.phase2_adaptive_learning.phase2_parameter_manager import phase2_parameter_manager
                self.phase2_parameter_manager = phase2_parameter_manager
                logger.info("âœ… Phase2 åƒæ•¸ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                
                # è¨­ç½®æ€§èƒ½åŸºç·š
                if hasattr(self.phase2_parameter_manager, 'performance_baseline'):
                    self.phase2_parameter_manager.performance_baseline = 0.55  # 55% å‹ç‡åŸºç·š
                    
            except ImportError as e:
                logger.warning(f"âš ï¸ Phase2 åƒæ•¸ç®¡ç†å™¨æœªå•Ÿç”¨: {e}")
                self.phase2_parameter_manager = None
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
            return False
    
    async def _initialize_phase2_optimization_components(self):
        """åˆå§‹åŒ– Phase2 å„ªåŒ–çµ„ä»¶"""
        logger.info("ğŸ”§ åˆå§‹åŒ– Phase2 å„ªåŒ–çµ„ä»¶...")
        
        # 1. åˆå§‹åŒ– Adaptive Learning Engine
        try:
            from backend.phase2_adaptive_learning.learning_core.adaptive_learning_engine import AdaptiveLearningCore
            self.adaptive_learning_engine = AdaptiveLearningCore()
            self.learning_enabled = True
            logger.info("âœ… Adaptive Learning Engine åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Adaptive Learning Engine åˆå§‹åŒ–å¤±æ•—: {e}")
            self.learning_enabled = False
        
        # 2. åˆå§‹åŒ–æ–‡ä»¶æ¸…ç†ç®¡ç†å™¨
        try:
            from backend.phase2_adaptive_learning.storage.file_cleanup_manager import FileCleanupManager
            self.file_cleanup_manager = FileCleanupManager()
            logger.info("âœ… æ–‡ä»¶æ¸…ç†ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ æ–‡ä»¶æ¸…ç†ç®¡ç†å™¨åˆå§‹åŒ–å¤±æ•—: {e}")
    
    async def start_signal_generation_loop(self):
        """å•Ÿå‹•ä¿¡è™Ÿç”Ÿæˆå¾ªç’°"""
        logger.info("ğŸ¯ å•Ÿå‹•ä¿¡è™Ÿç”Ÿæˆå¾ªç’°...")
        
        # ä½¿ç”¨å…§å»ºäº¤æ˜“å°åˆ—è¡¨
        symbols = self.trading_symbols
        
        while self.running:
            try:
                # ğŸš¨ ç³»çµ±å¥åº·æª¢æŸ¥
                if not await self.check_system_health():
                    logger.critical("ğŸ›‘ ç³»çµ±å¥åº·æª¢æŸ¥å¤±æ•—ï¼Œåœæ­¢ä¿¡è™Ÿç”Ÿæˆå¾ªç’°")
                    break
                
                # ğŸ¯ Phase5 å®šæ™‚æª¢æŸ¥ï¼ˆæ¯24å°æ™‚ï¼‰
                await self.check_phase5_schedule()
                
                # ç•¶å‰æ™‚é–“
                current_time = time.time()
                
                # ğŸ”§ Phase2 å„ªåŒ–çµ„ä»¶å®šæœŸç¶­è­·
                await self._perform_phase2_maintenance(current_time)
                
                # ğŸ”§ Phase2 åƒæ•¸æª¢æŸ¥å’Œç”Ÿæˆï¼ˆæ¯2å°æ™‚ï¼Œèˆ‡Phase2å…§éƒ¨åŒæ­¥ï¼‰
                if (self.phase2_parameter_manager and 
                    current_time - self.phase2_last_parameter_check > self.phase2_parameter_check_interval):
                    
                    # ğŸš¨ å”èª¿æ©Ÿåˆ¶ï¼šå¦‚æœPhase5æ­£åœ¨é‹è¡Œï¼Œå»¶é²Phase2åŸ·è¡Œ
                    if self.phase5_running:
                        logger.info("â³ Phase5é‹è¡Œä¸­ï¼Œå»¶é²Phase2åƒæ•¸æª¢æŸ¥ï¼ˆé¿å…è¡çªï¼‰")
                    else:
                        try:
                            await self._check_and_generate_phase2_parameters()
                            self.phase2_last_parameter_check = current_time
                        except Exception as e:
                            logger.error(f"âŒ Phase2 åƒæ•¸æª¢æŸ¥å¤±æ•—: {e}")
                
                for symbol in symbols:
                    logger.info(f"ğŸ“Š ç”Ÿæˆ {symbol} ä¿¡è™Ÿ...")
                    
                    # ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š
                    try:
                        # ä½¿ç”¨çœŸå¯¦æ•¸æ“šæº
                        market_data = await self._get_real_market_data(symbol)
                        if not market_data:
                            logger.error(f"âŒ {symbol} ç„¡æ³•ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š")
                            logger.error("ğŸ›‘ ç”Ÿç”¢ç³»çµ±å¿…é ˆä½¿ç”¨çœŸå¯¦æ•¸æ“šï¼Œç³»çµ±å°‡é—œé–‰")
                            self.running = False
                            return
                            
                    except Exception as e:
                        logger.error(f"âŒ {symbol} çœŸå¯¦æ•¸æ“šç²å–å¤±æ•—: {e}")
                        logger.error("ğŸ›‘ ç”Ÿç”¢ç³»çµ±æ•¸æ“šæºå¤±æ•ˆï¼Œç³»çµ±å°‡é—œé–‰")
                        self.running = False
                        return
                    
                    # ğŸš€ ç›´æ¥ä½¿ç”¨Phase1Aç”Ÿæˆä¿¡è™Ÿï¼ˆæ–°æ¶æ§‹ï¼Œä¸ä¾è³´èˆŠç³»çµ±ï¼‰
                    try:
                        # ğŸ¯ ç›´æ¥ä½¿ç”¨Phase1Aç”Ÿæˆå™¨ç”Ÿæˆä¿¡è™Ÿ
                        logger.info(f"ğŸ“Š é–‹å§‹ç‚º {symbol} ç”Ÿæˆä¿¡è™Ÿï¼ˆPhase1Aç›´æ¥èª¿ç”¨ï¼‰...")
                        
                        # ä½¿ç”¨Phase1Aç”ŸæˆåŸºç¤ä¿¡è™Ÿ - ä¿®æ­£æ–¹æ³•åç¨±
                        base_signals = await self.phase1a_generator.generate_signals(symbol, market_data)
                        
                        logger.info(f"ğŸ” {symbol} Phase1Aä¿¡è™Ÿç”Ÿæˆçµæœ: {type(base_signals)} - æ•¸é‡: {len(base_signals) if base_signals else 0}")
                        
                        signals = base_signals  # å°‡Phase1Açš„çµæœä½œç‚ºæœ€çµ‚ä¿¡è™Ÿ
                        
                        if signals:
                            signal_count = len(signals) if isinstance(signals, list) else 1
                            
                            # æ›´æ–°ä¿¡è™Ÿçµ±è¨ˆ
                            self.signal_stats['total_signals_generated'] += signal_count
                            self.signal_stats['signals_per_session'] += signal_count
                            if symbol not in self.signal_stats['signals_per_symbol']:
                                self.signal_stats['signals_per_symbol'][symbol] = 0
                            self.signal_stats['signals_per_symbol'][symbol] += signal_count
                            
                            logger.info(f"âœ… {symbol} ä¿¡è™Ÿç”ŸæˆæˆåŠŸ: {signal_count} å€‹ä¿¡è™Ÿ")
                            logger.info(f"ğŸ“ˆ ç´¯ç©çµ±è¨ˆ: ç¸½ä¿¡è™Ÿ {self.signal_stats['total_signals_generated']} | æœ¬è¼ª {self.signal_stats['signals_per_session']} | {symbol}: {self.signal_stats['signals_per_symbol'][symbol]}")
                            
                            # ğŸ§  Phase2 å­¸ç¿’å¼•æ“ç›£æ§ä¿¡è™Ÿ
                            await self._monitor_signals_with_learning_engine(signals, symbol, market_data)
                        else:
                            logger.info(f"â„¹ï¸ {symbol} æœªç”Ÿæˆä¿¡è™Ÿ - price_buffer æ•¸é‡: {len(self.phase1a_generator.price_buffer[symbol]) if hasattr(self.phase1a_generator, 'price_buffer') and symbol in self.phase1a_generator.price_buffer else 0}")
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ {symbol} ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
                        signals = None
                    
                    # ğŸ“Š å°‡ä¿¡è™Ÿå‚³éçµ¦ Phase2 å­¸ç¿’ç³»çµ±é€²è¡Œè¿½è¹¤
                    if signals and self.phase1a_generator.adaptive_mode:
                        try:
                            # å¢åŠ ä¿¡è™Ÿè¨ˆæ•¸
                            if self.phase2_parameter_manager:
                                self.phase2_parameter_manager.increment_signal_count()
                                
                            # ç‚ºä¿¡è™Ÿå»ºç«‹å­¸ç¿’è¿½è¹¤ï¼ˆç°¡åŒ–ç‰ˆï¼‰
                            if isinstance(signals, list):
                                for signal in signals:
                                    if hasattr(signal, 'signal_type') and hasattr(signal, 'strength'):
                                        learning_data = {
                                            'signal_id': f"{symbol}_{datetime.now().timestamp()}",
                                            'symbol': symbol,
                                            'signal_strength': signal.strength,
                                            'direction': signal.signal_type,
                                            'features': {
                                                'price': market_data.get('close', 0),
                                                'volume': market_data.get('volume', 0)
                                            },
                                            'market_conditions': market_data
                                        }
                                        
                                        # è¿½è¹¤ä¿¡è™Ÿåˆ°å­¸ç¿’ç³»çµ±
                                        if hasattr(self.phase1a_generator.learning_core, 'track_signal_for_learning'):
                                            await self.phase1a_generator.learning_core.track_signal_for_learning(learning_data)
                            elif isinstance(signals, dict) and hasattr(signals, 'signal_type'):
                                # å–®å€‹ä¿¡è™Ÿ
                                learning_data = {
                                    'signal_id': f"{symbol}_{datetime.now().timestamp()}",
                                    'symbol': symbol,
                                    'signal_strength': signals.get('strength', 0),
                                    'direction': signals.get('signal_type', 'NEUTRAL'),
                                    'features': {
                                        'price': market_data.get('close', 0),
                                        'volume': market_data.get('volume', 0)
                                    },
                                    'market_conditions': market_data
                                }
                                
                                if hasattr(self.phase1a_generator.learning_core, 'track_signal_for_learning'):
                                    await self.phase1a_generator.learning_core.track_signal_for_learning(learning_data)
                                    
                        except Exception as e:
                            logger.debug(f"å­¸ç¿’è¿½è¹¤éŒ¯èª¤: {e}")
                    
                    # Phase3 æ±ºç­–è™•ç† - ä½¿ç”¨æ­£ç¢ºçš„API
                    if self.phase3_enabled and signals:
                        try:
                            # å°‡æ¯å€‹ä¿¡è™Ÿå‚³éçµ¦ Phase3 æ±ºç­–å¼•æ“é€²è¡Œå–®ç¨è™•ç†
                            decisions = []
                            for i, signal in enumerate(signals):
                                try:
                                    # ğŸ”§ çµ±ä¸€å°å…¥è·¯å¾‘ç­–ç•¥ - æ”¯æ´å¤šç¨®å°å…¥æ–¹å¼
                                    import sys
                                    from pathlib import Path
                                    
                                    SignalCandidate = None
                                    
                                    # å˜—è©¦æ–¹å¼1: ç›¸å°å°å…¥
                                    try:
                                        from backend.phase2_pre_evaluation.epl_pre_processing_system.epl_pre_processing_system import SignalCandidate
                                        logger.debug("âœ… SignalCandidate ç›¸å°å°å…¥æˆåŠŸ")
                                    except ImportError:
                                        # å˜—è©¦æ–¹å¼2: çµ•å°å°å…¥
                                        try:
                                            current_path = Path(__file__).parent
                                            sys.path.append(str(current_path))
                                            from backend.phase2_pre_evaluation.epl_pre_processing_system.epl_pre_processing_system import SignalCandidate
                                            logger.debug("âœ… SignalCandidate çµ•å°å°å…¥æˆåŠŸ")
                                        except ImportError:
                                            # å˜—è©¦æ–¹å¼3: å‹•æ…‹å°å…¥
                                            try:
                                                import importlib.util
                                                module_path = current_path / "backend" / "phase2_pre_evaluation" / "epl_pre_processing_system" / "epl_pre_processing_system.py"
                                                spec = importlib.util.spec_from_file_location("epl_module", module_path)
                                                module = importlib.util.module_from_spec(spec)
                                                spec.loader.exec_module(module)
                                                SignalCandidate = module.SignalCandidate
                                                logger.debug("âœ… SignalCandidate å‹•æ…‹å°å…¥æˆåŠŸ")
                                            except Exception as dynamic_error:
                                                logger.warning(f"âš ï¸ SignalCandidate æ‰€æœ‰å°å…¥æ–¹å¼å¤±æ•—: {dynamic_error}")
                                                raise ImportError("ç„¡æ³•å°å…¥ SignalCandidate")
                                    
                                    # å‰µå»ºæ­£ç¢ºçš„ SignalCandidate å°è±¡ï¼ŒæŒ‰ç…§ @dataclass å®šç¾©
                                    signal_candidate = SignalCandidate(
                                        id=f"{symbol}_{int(datetime.now().timestamp())}_{i}",
                                        symbol=symbol,
                                        signal_strength=getattr(signal, 'signal_strength', 0.7),
                                        confidence=signal.confidence if hasattr(signal, 'confidence') else 0.5,
                                        direction=signal.direction if hasattr(signal, 'direction') else 'BUY',
                                        timestamp=datetime.now(),
                                        source="Phase1A_ProductionLauncher",
                                        data_completeness=0.8,
                                        signal_clarity=0.8,
                                        dynamic_params=getattr(signal, 'parameters', {}),
                                        market_environment={},
                                        technical_snapshot=getattr(signal, 'technical_analysis', {})
                                    )
                                    
                                    # èª¿ç”¨æ­£ç¢ºçš„Phase3æ–¹æ³•
                                    decision_result = await self.phase3_decision_engine.process_signal_candidate(
                                        signal_candidate, 
                                        current_positions=[],
                                        market_context={}
                                    )
                                    
                                except ImportError as import_error:
                                    logger.error(f"âŒ SignalCandidate å°å…¥å¤±æ•—: {import_error}")
                                    logger.error("ğŸ›‘ ç”Ÿç”¢ç³»çµ±å¿…é ˆæœ‰å®Œæ•´çš„ä¾è³´æ¨¡çµ„ï¼Œç„¡æ³•ç¹¼çºŒPhase3æ±ºç­–")
                                    logger.error("ğŸ”§ è«‹ä¿®å¾©å°å…¥å•é¡Œæˆ–æª¢æŸ¥ç³»çµ±æ¶æ§‹å®Œæ•´æ€§")
                                    # ç”¢å“åŒ–è¦æ±‚ï¼šå°å…¥å¤±æ•—ç›´æ¥å ±éŒ¯ï¼Œä¸ä½¿ç”¨è™›å‡æ•¸æ“š
                                    decision_result = None
                                    
                                except Exception as signal_error:
                                    # ä½¿ç”¨æ¨¡çµ„ç´š logger ç¢ºä¿è®Šæ•¸å¯ç”¨
                                    import logging
                                    module_logger = logging.getLogger(__name__)
                                    module_logger.warning(f"âš ï¸ {symbol} ä¿¡è™Ÿ {i} Phase3 è™•ç†å¤±æ•—: {signal_error}")
                                    decision_result = None
                                
                                if decision_result:
                                    decisions.append(decision_result)
                            
                            if decisions:
                                logger.info(f"ğŸ¯ {symbol} Phase3 æ±ºç­–å®Œæˆ: {len(decisions)} å€‹æ±ºç­–")
                                
                                # è¨˜éŒ„æ±ºç­–è©³æƒ…
                                for i, decision in enumerate(decisions):
                                    if hasattr(decision, 'decision') and hasattr(decision, 'priority'):
                                        logger.info(f"   æ±ºç­– {i+1}: {decision.decision.value} | å„ªå…ˆç´š: {decision.priority.name}")
                                    else:
                                        logger.info(f"   æ±ºç­– {i+1}: {decision}")
                                        
                            else:
                                logger.info(f"ğŸš« {symbol} Phase3 æ±ºç­–ï¼šç„¡æœ‰æ•ˆæ±ºç­–ç”Ÿæˆ")
                                
                        except Exception as e:
                            logger.error(f"âŒ {symbol} Phase3 æ±ºç­–è™•ç†éŒ¯èª¤: {e}")
                            decisions = []
                    
                    if signals:
                        # signalsæ˜¯dicté¡å‹ï¼Œéœ€è¦è½‰æ›ç‚ºlist
                        signal_list = []
                        if isinstance(signals, dict):
                            # æå–ä¿¡è™Ÿå°è±¡
                            for tier, signal_data in signals.items():
                                if signal_data and isinstance(signal_data, list):
                                    signal_list.extend(signal_data)
                                elif signal_data:
                                    signal_list.append(signal_data)
                        else:
                            signal_list = signals if isinstance(signals, list) else [signals]
                        
                        logger.info(f"âœ… {symbol} ä¿¡è™Ÿç”ŸæˆæˆåŠŸ: {len(signal_list)} å€‹ä¿¡è™Ÿ")
                        
                        # ğŸ¯ ===== éšæ®µ1+2: æ‡‰ç”¨è·¨é–‰ç’°ä¿¡è™Ÿå»é‡æ©Ÿåˆ¶ (é–‰ç’°å¤–å„ªåŒ–) =====
                        # é‡è¦ï¼šé€™å€‹å»é‡æ˜¯åœ¨é¡¯ç¤ºçµ¦ç”¨æˆ¶ä¹‹å‰é€²è¡Œï¼Œä¸å½±éŸ¿é–‰ç’°å…§çš„å­¸ç¿’å’Œå›æ¸¬
                        original_count = len(signal_list)
                        signal_list = await self._apply_signal_deduplication(signal_list, symbol, market_data)
                        
                        if len(signal_list) != original_count:
                            logger.info(f"ğŸ¯ {symbol} å»é‡çµæœ: {original_count} â†’ {len(signal_list)} å€‹ä¿¡è™Ÿ")
                        
                        # ğŸ¯ ä¿¡è™Ÿæœƒè‡ªå‹•å­˜å„²åˆ°æ¨™æº–ä¸‰åˆ†é¡è³‡æ–™åº«ï¼š
                        # â€¢ Phase1A åŸºç¤ä¿¡è™Ÿ â†’ market_data.db (ç”± Phase1A è‡ªå‹•è™•ç†)
                        # â€¢ Priority3 å¢å¼·ä¿¡è™Ÿ â†’ learning_records.db (ç”± Priority3 è‡ªå‹•è™•ç†)
                        # â€¢ ç³»çµ±ä¿è­·äº‹ä»¶ â†’ extreme_events.db (ç”±ç³»çµ±ä¿è­·æ¨¡çµ„è‡ªå‹•è™•ç†)
                        
                        # ğŸ¯ å‘ç”¨æˆ¶å±•ç¤ºå®Œæ•´äº¤æ˜“ä¿¡è™Ÿ (ç¶“éå»é‡çš„ä¿¡è™Ÿ)
                        decision_list = decisions if self.phase3_enabled and 'decisions' in locals() else None
                        await self._display_user_signals(symbol, signal_list, decision_list)
                        
                        # é¡¯ç¤ºæŠ€è¡“ä¿¡è™Ÿè©³æƒ…
                        for i, signal in enumerate(signal_list[:3]):  # åªé¡¯ç¤ºå‰3å€‹
                            if hasattr(signal, 'signal_type') and hasattr(signal, 'signal_strength'):
                                tier_info = signal.tier.value if hasattr(signal, 'tier') and hasattr(signal.tier, 'value') else 'N/A'
                                logger.info(f"   ğŸ“ˆ ä¿¡è™Ÿ{i+1}: {signal.signal_type} | å¼·åº¦: {signal.signal_strength:.3f} | å±¤ç´š: {tier_info}")
                    else:
                        logger.info(f"ğŸ“Š {symbol} ç•¶å‰ç„¡äº¤æ˜“ä¿¡è™Ÿ")
                    
                    # è¨˜éŒ„å­¸ç¿’ç³»çµ±ç‹€æ…‹
                    await self._log_learning_status()
                    
                    await asyncio.sleep(self.symbol_processing_interval)  # äº¤æ˜“å°è™•ç†é–“éš”
                
                # å¾ªç’°çµæŸï¼Œé¡¯ç¤ºæœ¬è¼ªçµ±è¨ˆ
                await self._display_round_summary()
                
                # ğŸ¯ éšæ®µ4: æ€§èƒ½é©—è­‰ - ç¢ºä¿é–‰ç’°å…§æ©Ÿåˆ¶æœªå—å½±éŸ¿
                if not await self._validate_learning_integrity():
                    logger.warning("âš ï¸ å­¸ç¿’æ©Ÿåˆ¶å®Œæ•´æ€§æª¢æŸ¥å¤±æ•—ï¼Œä½†ç³»çµ±å°‡ç¹¼çºŒé‹è¡Œ")
                
                if not await self._validate_backtest_data_integrity():
                    logger.warning("âš ï¸ å›æ¸¬æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥å¤±æ•—ï¼Œä½†ç³»çµ±å°‡ç¹¼çºŒé‹è¡Œ")
                
                await asyncio.sleep(self.signal_loop_interval)  # ä¿¡è™Ÿå¾ªç’°é–“éš”
                
            except Exception as e:
                logger.error(f"âŒ ä¿¡è™Ÿç”Ÿæˆå¾ªç’°éŒ¯èª¤: {e}")
                await asyncio.sleep(30)  # éŒ¯èª¤å¾Œç­‰å¾…æ›´é•·æ™‚é–“
    
    async def _check_and_generate_phase2_parameters(self):
        """æª¢æŸ¥ä¸¦ç”Ÿæˆ Phase2 åƒæ•¸"""
        try:
            logger.debug("ğŸ”§ æª¢æŸ¥ Phase2 åƒæ•¸ç”Ÿæˆæ¢ä»¶...")
            
            if not self.phase1a_generator or not self.phase1a_generator.adaptive_mode:
                logger.debug("â­ï¸ Phase2 è‡ªé©æ‡‰æ¨¡å¼æœªå•Ÿç”¨ï¼Œè·³éåƒæ•¸ç”Ÿæˆ")
                return
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°åƒæ•¸
            should_generate, trigger_reason = self.phase2_parameter_manager.should_generate_new_parameters()
            
            if should_generate:
                logger.info(f"ğŸ”„ è§¸ç™¼ Phase2 åƒæ•¸ç”Ÿæˆ: {trigger_reason}")
                
                # ç²å–å­¸ç¿’å¼•æ“å’Œå¸‚å ´æª¢æ¸¬å™¨
                learning_engine = self.phase1a_generator.learning_core
                market_detector = self.phase1a_generator.regime_detector
                
                # ç”Ÿæˆå„ªåŒ–åƒæ•¸
                new_parameters = await self.phase2_parameter_manager.generate_optimized_parameters(
                    learning_engine=learning_engine,
                    market_detector=market_detector
                )
                
                if new_parameters:
                    logger.info("âœ… Phase2 åƒæ•¸ç”ŸæˆæˆåŠŸ")
                    logger.info(f"ğŸ“Š æ–°åƒæ•¸æ•¸é‡: {len(new_parameters)}")
                    
                    # è¨˜éŒ„é—œéµåƒæ•¸è®ŠåŒ–
                    key_params = ["signal_threshold", "momentum_weight", "volatility_adjustment"]
                    for param in key_params:
                        if param in new_parameters:
                            logger.info(f"   ğŸ”§ {param}: {new_parameters[param]:.3f}")
                    
                    # é€šçŸ¥ Phase1A é‡è¼‰åƒæ•¸ï¼ˆå¦‚æœæ”¯æŒï¼‰
                    if hasattr(self.phase1a_generator, 'reload_configuration'):
                        try:
                            await self.phase1a_generator.reload_configuration()
                            logger.info("ğŸ”„ Phase1A åƒæ•¸å·²é‡è¼‰")
                        except Exception as e:
                            logger.warning(f"âš ï¸ Phase1A åƒæ•¸é‡è¼‰å¤±æ•—: {e}")
                    
                    # å ±å‘Šæ€§èƒ½
                    if hasattr(self.phase2_parameter_manager, 'report_performance'):
                        # ç”Ÿç”¢ç’°å¢ƒæ€§èƒ½è©•ä¼° (å¾çœŸå¯¦äº¤æ˜“çµæœç²å–)
                        current_performance = await self._estimate_current_performance()
                        self.phase2_parameter_manager.report_performance(current_performance)
                        
                else:
                    logger.warning("âš ï¸ Phase2 åƒæ•¸ç”Ÿæˆå¤±æ•—")
            else:
                logger.debug(f"â­ï¸ è·³é Phase2 åƒæ•¸ç”Ÿæˆ: {trigger_reason}")
        
        except Exception as e:
            logger.error(f"âŒ Phase2 åƒæ•¸æª¢æŸ¥å¤±æ•—: {e}")
    
    async def _estimate_current_performance(self) -> float:
        """ä¼°ç®—ç•¶å‰ç³»çµ±æ€§èƒ½"""
        try:
            if (self.phase1a_generator and 
                hasattr(self.phase1a_generator, 'learning_core') and
                hasattr(self.phase1a_generator.learning_core, 'performance_metrics')):
                
                metrics = self.phase1a_generator.learning_core.performance_metrics
                success_rate = metrics.get('success_rate', 0.5)
                return success_rate
            else:
                # é»˜èªæ€§èƒ½è©•ä¼°
                return 0.55
        except Exception as e:
            logger.debug(f"æ€§èƒ½ä¼°ç®—éŒ¯èª¤: {e}")
            return 0.55
    
    async def _log_learning_status(self):
        """è¨˜éŒ„å­¸ç¿’ç³»çµ±ç‹€æ…‹"""
        try:
            if not (self.phase1a_generator and self.phase1a_generator.adaptive_mode):
                return
            
            # === åŸºç¤å­¸ç¿’ç‹€æ…‹ (å„ªå…ˆç´š1+2) ===
            if hasattr(self.phase1a_generator.learning_core, 'get_learning_summary'):
                learning_summary = self.phase1a_generator.learning_core.get_learning_summary()
                
                # è¨˜éŒ„é—œéµå­¸ç¿’æŒ‡æ¨™
                status = learning_summary.get('learning_status', 'UNKNOWN')
                total_signals = learning_summary.get('performance_metrics', {}).get('total_signals_tracked', 0)
                success_rate = learning_summary.get('performance_metrics', {}).get('success_rate', 0)
                
                if total_signals > 0:
                    logger.info(f"ğŸ§  å­¸ç¿’ç‹€æ…‹: {status} | è¿½è¹¤ä¿¡è™Ÿ: {total_signals} | æˆåŠŸç‡: {success_rate:.1%}")
                
                # ä¸‹æ¬¡å„ªåŒ–å€’è¨ˆæ™‚
                next_opt = learning_summary.get('next_optimization_in', 0)
                if next_opt > 0:
                    logger.info(f"   â³ ä¸‹æ¬¡åƒæ•¸å„ªåŒ–: {next_opt} å€‹ä¿¡è™Ÿå¾Œ")
            
            # === å„ªå…ˆç´š3æ™‚é–“æ¡†æ¶æ„ŸçŸ¥ç‹€æ…‹ ===
            if self.priority3_enabled and self.priority3_integration:
                try:
                    # ç²å–å„ªå…ˆç´š3å­¸ç¿’çµ±è¨ˆ
                    p3_stats = await self.priority3_integration.get_learning_statistics()
                    
                    if p3_stats:
                        total_enhanced = p3_stats.get('total_signals_processed', 0)
                        avg_cross_tf_weight = p3_stats.get('average_cross_timeframe_weight', 0)
                        active_timeframes = p3_stats.get('active_timeframes', [])
                        weight_distribution = p3_stats.get('weight_distribution', {})
                        
                        logger.info(f"âš¡ å„ªå…ˆç´š3ç‹€æ…‹: å·²è™•ç† {total_enhanced} å€‹å¢å¼·ä¿¡è™Ÿ")
                        logger.info(f"   ğŸ¯ å¹³å‡è·¨æ™‚é–“æ¡†æ¶æ¬Šé‡: {avg_cross_tf_weight:.3f}")
                        logger.info(f"   ğŸ“Š æ´»èºæ™‚é–“æ¡†æ¶: {', '.join(active_timeframes)}")
                        
                        # é¡¯ç¤ºæ¬Šé‡åˆ†å¸ƒ
                        if weight_distribution:
                            logger.info(f"   âš–ï¸ ä¸‰ç¶­æ¬Šé‡åˆ†å¸ƒ:")
                            for component, avg_weight in weight_distribution.items():
                                logger.info(f"      â€¢ {component}: {avg_weight:.3f}")
                        
                except Exception as e:
                    logger.debug(f"å„ªå…ˆç´š3ç‹€æ…‹è¨˜éŒ„éŒ¯èª¤: {e}")
                    
            if hasattr(self.phase1a_generator, 'regime_detector') and self.phase1a_generator.regime_detector:
                # é€™è£¡éœ€è¦å¸‚å ´æ•¸æ“šæ‰èƒ½æª¢æ¸¬ï¼Œæš«æ™‚è·³é
                pass
                
        except Exception as e:
            logger.debug(f"å­¸ç¿’ç‹€æ…‹è¨˜éŒ„éŒ¯èª¤: {e}")
    
    # ğŸ¯ ===== éšæ®µ1: è·¨é–‰ç’°ä¿¡è™Ÿå»é‡æ©Ÿåˆ¶ (é–‰ç’°å¤–å„ªåŒ–) =====
    
    def _initialize_signal_cache(self, symbol: str):
        """åˆå§‹åŒ–ä¿¡è™Ÿç·©å­˜"""
        if symbol not in self.signal_history_cache:
            self.signal_history_cache[symbol] = []
    
    def _calculate_signal_signature(self, signal, symbol: str, market_data: dict) -> dict:
        """è¨ˆç®—ä¿¡è™Ÿç‰¹å¾µç°½åç”¨æ–¼ç›¸ä¼¼åº¦æ¯”è¼ƒ"""
        try:
            signature = {
                'symbol': symbol,
                'signal_type': getattr(signal, 'signal_type', 'UNKNOWN'),
                'direction': getattr(signal, 'direction', 'NEUTRAL'),
                'tier': getattr(signal, 'tier', {}).get('value', 'MEDIUM') if hasattr(signal, 'tier') else 'MEDIUM',
                'strength': getattr(signal, 'signal_strength', 0.5),
                'confidence': getattr(signal, 'confidence', 0.5),
                'price_range': self._discretize_price(market_data.get('price', 0)),
                'timestamp': time.time()
            }
            
            # åŠ å…¥æŠ€è¡“æŒ‡æ¨™ç‹€æ…‹ (å¦‚æœå­˜åœ¨)
            if hasattr(signal, 'technical_analysis'):
                tech_analysis = signal.technical_analysis
                signature.update({
                    'rsi_zone': self._discretize_rsi(tech_analysis.get('rsi', 50)),
                    'trend_direction': tech_analysis.get('trend', 'NEUTRAL'),
                    'volume_state': self._discretize_volume(market_data.get('volume', 0))
                })
                
            return signature
            
        except Exception as e:
            logger.debug(f"ä¿¡è™Ÿç°½åè¨ˆç®—éŒ¯èª¤: {e}")
            return {
                'symbol': symbol,
                'signal_type': 'UNKNOWN',
                'timestamp': time.time()
            }
    
    def _discretize_price(self, price: float) -> str:
        """å°‡åƒ¹æ ¼é›¢æ•£åŒ–åˆ°å€é–“ï¼Œç”¨æ–¼ç›¸ä¼¼åº¦æ¯”è¼ƒ"""
        if price == 0:
            return "UNKNOWN"
        
        # ä½¿ç”¨2%çš„åƒ¹æ ¼å€é–“é€²è¡Œé›¢æ•£åŒ–
        price_bucket = int(price / (price * 0.02))
        return f"PRICE_BUCKET_{price_bucket}"
    
    def _discretize_rsi(self, rsi: float) -> str:
        """RSIé›¢æ•£åŒ–"""
        if rsi < 30:
            return "OVERSOLD"
        elif rsi > 70:
            return "OVERBOUGHT"
        else:
            return "NEUTRAL"
    
    def _discretize_volume(self, volume: float) -> str:
        """æˆäº¤é‡é›¢æ•£åŒ– (ç°¡åŒ–ç‰ˆ)"""
        if volume == 0:
            return "UNKNOWN"
        # å¯ä»¥æ ¹æ“šæ­·å²æ•¸æ“šé€²è¡Œæ›´ç²¾ç¢ºçš„åˆ†é¡
        return "NORMAL"  # æš«æ™‚ç°¡åŒ–
    
    def _calculate_signal_similarity(self, sig1: dict, sig2: dict) -> float:
        """è¨ˆç®—å…©å€‹ä¿¡è™Ÿçš„ç›¸ä¼¼åº¦ (0-1)"""
        try:
            similarity_score = 0.0
            weight_sum = 0.0
            
            # æ ¸å¿ƒç‰¹å¾µæ¬Šé‡é…ç½®
            feature_weights = {
                'signal_type': 0.3,     # ä¿¡è™Ÿé¡å‹æœ€é‡è¦
                'direction': 0.25,      # æ–¹å‘æ¬¡é‡è¦
                'tier': 0.15,          # å±¤ç´š
                'price_range': 0.1,     # åƒ¹æ ¼å€é–“
                'rsi_zone': 0.1,       # RSIç‹€æ…‹
                'trend_direction': 0.1  # è¶¨å‹¢æ–¹å‘
            }
            
            for feature, weight in feature_weights.items():
                if feature in sig1 and feature in sig2:
                    if sig1[feature] == sig2[feature]:
                        similarity_score += weight
                    weight_sum += weight
            
            # æ•¸å€¼ç‰¹å¾µç›¸ä¼¼åº¦ (strength, confidence)
            numerical_features = ['strength', 'confidence']
            numerical_weight = 0.2
            
            for feature in numerical_features:
                if feature in sig1 and feature in sig2:
                    val1, val2 = sig1[feature], sig2[feature]
                    numerical_similarity = 1.0 - abs(val1 - val2)  # å·®ç•°è¶Šå°ç›¸ä¼¼åº¦è¶Šé«˜
                    similarity_score += numerical_similarity * (numerical_weight / len(numerical_features))
                    weight_sum += (numerical_weight / len(numerical_features))
            
            # æ­£è¦åŒ–ç›¸ä¼¼åº¦åˆ†æ•¸
            if weight_sum > 0:
                return similarity_score / weight_sum
            else:
                return 0.0
                
        except Exception as e:
            logger.debug(f"ç›¸ä¼¼åº¦è¨ˆç®—éŒ¯èª¤: {e}")
            return 0.0
    
    def _calculate_time_decay_weight(self, signal_timestamp: float) -> float:
        """è¨ˆç®—æ™‚é–“è¡°æ¸›æ¬Šé‡"""
        try:
            current_time = time.time()
            time_diff_hours = (current_time - signal_timestamp) / 3600
            
            if time_diff_hours >= self.signal_time_decay_hours:
                return 0.0  # è¶…éè¡°æ¸›çª—å£ï¼Œæ¬Šé‡æ­¸é›¶
            
            # ç·šæ€§è¡°æ¸›ï¼šå¾1.0è¡°æ¸›åˆ°0.0
            decay_weight = 1.0 - (time_diff_hours / self.signal_time_decay_hours)
            return max(0.0, decay_weight)
            
        except Exception as e:
            logger.debug(f"æ™‚é–“è¡°æ¸›è¨ˆç®—éŒ¯èª¤: {e}")
            return 0.0
    
    async def _apply_signal_deduplication(self, signals: list, symbol: str, market_data: dict) -> list:
        """æ‡‰ç”¨ä¿¡è™Ÿå»é‡é‚è¼¯ - é–‰ç’°å¤–å„ªåŒ–ï¼Œä¸å½±éŸ¿å­¸ç¿’æ©Ÿåˆ¶"""
        if not self.signal_deduplication_enabled or not signals:
            return signals
        
        try:
            # åˆå§‹åŒ–ä¿¡è™Ÿç·©å­˜
            self._initialize_signal_cache(symbol)
            
            # ğŸ¯ éšæ®µ2: è¨ˆç®—å¸‚å ´æ³¢å‹•åº¦ä»¥å‹•æ…‹èª¿æ•´é–¾å€¼
            current_volatility = await self._calculate_market_volatility(symbol, market_data)
            dynamic_threshold = await self._get_dynamic_similarity_threshold(current_volatility)
            
            filtered_signals = []
            current_time = time.time()
            
            # æ¸…ç†éæœŸçš„æ­·å²ä¿¡è™Ÿ
            self._cleanup_expired_signals(symbol, current_time)
            
            for signal in signals:
                signal_signature = self._calculate_signal_signature(signal, symbol, market_data)
                is_duplicate = False
                
                # èˆ‡æ­·å²ä¿¡è™Ÿæ¯”è¼ƒ
                for historical_record in self.signal_history_cache[symbol]:
                    historical_signature = historical_record['signature']
                    time_weight = self._calculate_time_decay_weight(historical_signature['timestamp'])
                    
                    if time_weight > 0:  # åªæ¯”è¼ƒæœªéæœŸçš„ä¿¡è™Ÿ
                        similarity = self._calculate_signal_similarity(signal_signature, historical_signature)
                        adjusted_similarity = similarity * time_weight
                        
                        if adjusted_similarity >= dynamic_threshold:
                            is_duplicate = True
                            logger.debug(f"ğŸ”„ {symbol} ä¿¡è™Ÿå»é‡: ç›¸ä¼¼åº¦ {similarity:.3f} * æ™‚é–“æ¬Šé‡ {time_weight:.3f} = {adjusted_similarity:.3f} >= é–¾å€¼ {dynamic_threshold:.3f}")
                            break
                
                if not is_duplicate:
                    filtered_signals.append(signal)
                    
                    # ğŸš¨ é‡è¦ï¼šç„¡è«–æ˜¯å¦é‡è¤‡ï¼Œéƒ½å°‡ä¿¡è™Ÿæ·»åŠ åˆ°æ­·å²ç·©å­˜ä¾›å¾ŒçºŒæ¯”è¼ƒ
                    # é€™ç¢ºä¿äº†å»é‡æ©Ÿåˆ¶çš„é€£çºŒæ€§ï¼Œä½†ä¸å½±éŸ¿é–‰ç’°å…§çš„å­¸ç¿’
                    self._add_to_signal_cache(symbol, signal_signature)
                else:
                    logger.info(f"ğŸš« {symbol} ä¿¡è™Ÿå·²éæ¿¾ (é‡è¤‡): {signal_signature['signal_type']} | ç›¸ä¼¼åº¦è¶…éé–¾å€¼")
            
            # çµ±è¨ˆå»é‡æ•ˆæœ
            if len(signals) != len(filtered_signals):
                removed_count = len(signals) - len(filtered_signals)
                logger.info(f"âœ… {symbol} ä¿¡è™Ÿå»é‡å®Œæˆ: åŸå§‹ {len(signals)} â†’ éæ¿¾å¾Œ {len(filtered_signals)} (ç§»é™¤ {removed_count} é‡è¤‡)")
                logger.info(f"ğŸ“Š ç•¶å‰æ³¢å‹•åº¦: {current_volatility:.3%} | å‹•æ…‹é–¾å€¼: {dynamic_threshold:.3f}")
            
            return filtered_signals
            
        except Exception as e:
            logger.error(f"âŒ {symbol} ä¿¡è™Ÿå»é‡å¤±æ•—: {e}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å›åŸå§‹ä¿¡è™Ÿï¼Œç¢ºä¿ç³»çµ±ç©©å®šæ€§
            return signals
    
    def _cleanup_expired_signals(self, symbol: str, current_time: float):
        """æ¸…ç†éæœŸçš„æ­·å²ä¿¡è™Ÿ"""
        if symbol not in self.signal_history_cache:
            return
        
        # ç§»é™¤éæœŸä¿¡è™Ÿ
        expiry_time = current_time - (self.signal_time_decay_hours * 3600)
        self.signal_history_cache[symbol] = [
            record for record in self.signal_history_cache[symbol]
            if record['signature']['timestamp'] > expiry_time
        ]
        
        # é™åˆ¶ç·©å­˜å¤§å°
        if len(self.signal_history_cache[symbol]) > self.signal_cache_max_size:
            # ä¿ç•™æœ€æ–°çš„ä¿¡è™Ÿè¨˜éŒ„
            self.signal_history_cache[symbol].sort(key=lambda x: x['signature']['timestamp'], reverse=True)
            self.signal_history_cache[symbol] = self.signal_history_cache[symbol][:self.signal_cache_max_size]
    
    def _add_to_signal_cache(self, symbol: str, signature: dict):
        """æ·»åŠ ä¿¡è™Ÿåˆ°ç·©å­˜"""
        if symbol not in self.signal_history_cache:
            self.signal_history_cache[symbol] = []
        
        signal_record = {
            'signature': signature,
            'added_time': time.time()
        }
        
        self.signal_history_cache[symbol].append(signal_record)
    
    # ğŸ¯ ===== éšæ®µ2: é«˜æ³¢å‹•é©æ‡‰æ©Ÿåˆ¶ =====
    
    async def _calculate_market_volatility(self, symbol: str, market_data: dict) -> float:
        """è¨ˆç®—å¸‚å ´æ³¢å‹•åº¦"""
        try:
            # å¾åƒ¹æ ¼ç·©å­˜ç²å–æ­·å²åƒ¹æ ¼è¨ˆç®—æ³¢å‹•åº¦
            if (hasattr(self.phase1a_generator, 'price_buffer') and 
                symbol in self.phase1a_generator.price_buffer):
                
                price_buffer = self.phase1a_generator.price_buffer[symbol]
                if len(price_buffer) >= 10:  # è‡³å°‘éœ€è¦10å€‹åƒ¹æ ¼é»
                    # è¨ˆç®—æœ€è¿‘10å€‹åƒ¹æ ¼é»çš„æ¨™æº–å·®
                    recent_prices = [entry['price'] for entry in price_buffer[-10:]]
                    if len(recent_prices) > 1:
                        mean_price = sum(recent_prices) / len(recent_prices)
                        variance = sum((price - mean_price) ** 2 for price in recent_prices) / len(recent_prices)
                        volatility = (variance ** 0.5) / mean_price  # æ­£è¦åŒ–æ³¢å‹•åº¦
                        return volatility
            
            # å›é€€ï¼šä½¿ç”¨ç•¶å‰åƒ¹æ ¼çš„ç°¡åŒ–æ³¢å‹•åº¦ä¼°ç®—
            current_price = market_data.get('price', 0)
            high_price = market_data.get('high', current_price)
            low_price = market_data.get('low', current_price)
            
            if current_price > 0:
                price_range_volatility = (high_price - low_price) / current_price
                return price_range_volatility
            
            return 0.02  # é»˜èª2%æ³¢å‹•åº¦
            
        except Exception as e:
            logger.debug(f"æ³¢å‹•åº¦è¨ˆç®—éŒ¯èª¤: {e}")
            return 0.02  # ä¿å®ˆçš„é»˜èªæ³¢å‹•åº¦
    
    async def _get_dynamic_similarity_threshold(self, volatility: float) -> float:
        """æ ¹æ“šå¸‚å ´æ³¢å‹•åº¦å‹•æ…‹èª¿æ•´ç›¸ä¼¼åº¦é–¾å€¼"""
        try:
            base_threshold = self.signal_similarity_threshold
            
            if not self.volatility_adaptive_enabled:
                return base_threshold
            
            if volatility >= self.high_volatility_threshold:
                # é«˜æ³¢å‹•æ™‚æ”¾å¯¬é–¾å€¼ï¼Œå…è¨±æ›´å¤šä¿¡è™Ÿé€šé
                relaxed_threshold = base_threshold - self.volatility_similarity_relaxation
                relaxed_threshold = max(0.3, relaxed_threshold)  # æœ€ä½é–¾å€¼ä¿è­·
                
                logger.debug(f"ğŸŒŠ é«˜æ³¢å‹•æ¨¡å¼: {volatility:.3%} >= {self.high_volatility_threshold:.3%}, é–¾å€¼ {base_threshold:.3f} â†’ {relaxed_threshold:.3f}")
                return relaxed_threshold
            else:
                # æ­£å¸¸æ³¢å‹•æ™‚ä½¿ç”¨åŸºç¤é–¾å€¼
                return base_threshold
                
        except Exception as e:
            logger.debug(f"å‹•æ…‹é–¾å€¼è¨ˆç®—éŒ¯èª¤: {e}")
            return self.signal_similarity_threshold
    
    async def _initialize_historical_data(self):
        """åˆå§‹åŒ–æ­·å²æ•¸æ“šä»¥æ”¯æ´æŠ€è¡“åˆ†æ - ç”¢å“ç´šå¯¦ç¾"""
        logger.info("ğŸ“Š åˆå§‹åŒ–æ­·å²æ•¸æ“š...")
        
        # ä½¿ç”¨å…§å»ºäº¤æ˜“å°åˆ—è¡¨
        symbols = self.trading_symbols
        
        for symbol in symbols:
            try:
                # ç²å–çœŸå¯¦æ­·å²Kç·šæ•¸æ“š
                historical_data = await self._fetch_historical_klines(symbol, limit=500)
                if not historical_data:
                    logger.warning(f"âš ï¸ {symbol} ç„¡æ³•ç²å–æ­·å²æ•¸æ“šï¼Œè·³éåˆå§‹åŒ–")
                    continue
                
                # å°‡æ­·å²æ•¸æ“šæ·»åŠ åˆ°ç³»çµ±
                if hasattr(self.phase1a_generator, 'price_buffer'):
                    for data_point in historical_data:
                        price_entry = {
                            'price': data_point['close'],
                            'volume': data_point['volume'],
                            'high': data_point['high'],
                            'low': data_point['low'],
                            'timestamp': data_point['timestamp']
                        }
                        self.phase1a_generator.price_buffer[symbol].append(price_entry)
                        
                        # åŒæ™‚æ·»åŠ åˆ° intelligent_trigger_engine çš„ price_cache
                        if hasattr(self.phase1a_generator, 'intelligent_trigger_engine'):
                            from backend.phase1_signal_generation.intelligent_trigger_engine.intelligent_trigger_engine import PriceData
                            
                            price_data = PriceData(
                                symbol=symbol,
                                price=data_point['close'],
                                volume=data_point['volume'],
                                timestamp=datetime.fromtimestamp(data_point['timestamp'])
                            )
                            
                            # ç¢ºä¿ symbol åœ¨ price_cache ä¸­æœ‰æ¢ç›®
                            if symbol not in self.phase1a_generator.intelligent_trigger_engine.price_cache:
                                self.phase1a_generator.intelligent_trigger_engine.price_cache[symbol] = []
                            
                            self.phase1a_generator.intelligent_trigger_engine.price_cache[symbol].append(price_data)
                
                # è§¸ç™¼æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
                if hasattr(self.phase1a_generator, 'intelligent_trigger_engine') and self.phase1a_generator.intelligent_trigger_engine:
                    try:
                        await self.phase1a_generator.intelligent_trigger_engine._update_technical_indicators(symbol)
                        logger.info(f"âœ… {symbol} æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å®Œæˆ")
                    except Exception as indicator_error:
                        logger.warning(f"âš ï¸ {symbol} æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {indicator_error}")
                
                logger.info(f"âœ… {symbol} æ­·å²æ•¸æ“šåˆå§‹åŒ–å®Œæˆ: {len(historical_data)} æ¢è¨˜éŒ„")
                
            except Exception as e:
                logger.error(f"âŒ {symbol} æ­·å²æ•¸æ“šåˆå§‹åŒ–å¤±æ•—: {e}")
        
        logger.info("âœ… æ­·å²æ•¸æ“šåˆå§‹åŒ–å®Œæˆ")

    async def _fetch_historical_klines(self, symbol: str, limit: int = 500) -> list:
        """ç²å–çœŸå¯¦çš„æ­·å²Kç·šæ•¸æ“š - å¸¶é‡è©¦æ©Ÿåˆ¶å’ŒAPIé™åˆ¶æª¢æŸ¥"""
        try:
            # æª¢æŸ¥APIé »ç‡é™åˆ¶
            if not self._check_api_rate_limit():
                logger.warning(f"â¸ï¸ {symbol} æ­·å²æ•¸æ“šAPIé™åˆ¶ï¼Œç­‰å¾…é‡ç½®...")
                await self._wait_for_api_limit_reset()
            
            import aiohttp
            import time
            import asyncio
            
            url = f"https://api.binance.com/api/v3/klines"
            params = {
                'symbol': symbol,
                'interval': '1m',  # 1åˆ†é˜Kç·š
                'limit': limit
            }
            
            # é‡è©¦æ©Ÿåˆ¶
            for retry in range(3):
                try:
                    async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                        # è¨˜éŒ„APIå‘¼å«
                        self.api_call_times.append(time.time())
                        
                        async with session.get(url, params=params) as response:
                            if response.status == 429:  # APIé™åˆ¶
                                logger.warning(f"â¸ï¸ {symbol} æ­·å²æ•¸æ“šAPIé™åˆ¶ (429)ï¼Œç­‰å¾…30ç§’...")
                                await asyncio.sleep(30)
                                continue
                            elif response.status != 200:
                                logger.error(f"âŒ ç²å– {symbol} æ­·å²æ•¸æ“šå¤±æ•—: HTTP {response.status}")
                                if retry < 2:
                                    await asyncio.sleep(5 * (retry + 1))  # æŒ‡æ•¸é€€é¿
                                    continue
                                return []
                            
                            klines = await response.json()
                            
                            historical_data = []
                            for kline in klines:
                                historical_data.append({
                                    'timestamp': kline[0] / 1000,  # è½‰æ›ç‚ºç§’
                                    'open': float(kline[1]),
                                    'high': float(kline[2]),
                                    'low': float(kline[3]),
                                    'close': float(kline[4]),
                                    'volume': float(kline[5])
                                })
                            
                            logger.debug(f"âœ… {symbol} æ­·å²æ•¸æ“šç²å–æˆåŠŸ: {len(historical_data)} ç­†")
                            return historical_data
                            
                except aiohttp.ClientError as e:
                    logger.warning(f"âš ï¸ {symbol} æ­·å²æ•¸æ“šç¶²è·¯éŒ¯èª¤ (é‡è©¦ {retry+1}/3): {e}")
                    if retry < 2:
                        await asyncio.sleep(10 * (retry + 1))  # ç¶²è·¯éŒ¯èª¤ç­‰å¾…æ›´ä¹…
                    else:
                        logger.error(f"âŒ {symbol} æ­·å²æ•¸æ“šç¶²è·¯é€£æ¥å¤±æ•—")
                        return []
                        
            return []  # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
                        
        except Exception as e:
            logger.error(f"âŒ ç²å– {symbol} æ­·å²æ•¸æ“šç•°å¸¸: {e}")
            return []

    def _check_api_rate_limit(self) -> bool:
        """æª¢æŸ¥APIé »ç‡é™åˆ¶"""
        import time
        current_time = time.time()
        
        # æ¸…ç†è¶…éçª—å£æ™‚é–“çš„è¨˜éŒ„
        self.api_call_times = [
            call_time for call_time in self.api_call_times 
            if current_time - call_time < self.api_rate_limit_window
        ]
        
        # æª¢æŸ¥æ˜¯å¦è¶…éé™åˆ¶
        if len(self.api_call_times) >= self.api_max_calls_per_minute:
            logger.warning(f"ğŸš¨ APIé »ç‡é™åˆ¶è§¸ç™¼ï¼š{len(self.api_call_times)}æ¬¡/{self.api_rate_limit_window}ç§’")
            self.last_api_pause = current_time
            return False
        
        # è¨˜éŒ„é€™æ¬¡APIå‘¼å«
        self.api_call_times.append(current_time)
        return True
    
    async def _wait_for_api_limit_reset(self):
        """ç­‰å¾…APIé™åˆ¶é‡ç½®"""
        import time
        if time.time() - self.last_api_pause < self.api_pause_duration:
            wait_time = self.api_pause_duration - (time.time() - self.last_api_pause)
            logger.info(f"â³ APIé™åˆ¶æš«åœä¸­ï¼Œç­‰å¾… {wait_time:.1f} ç§’...")
            await asyncio.sleep(wait_time)

    async def _get_real_market_data(self, symbol: str) -> dict:
        """ğŸš€ ä½¿ç”¨æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±ç²å–çœŸå¯¦å¸‚å ´æ•¸æ“š - éšæ®µ3å„ªåŒ–ï¼šæ™ºèƒ½è§¸ç™¼æ©Ÿåˆ¶"""
        try:
            # ğŸ¯ éšæ®µ3: æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ•¸æ“šï¼ˆé¿å…éåº¦é »ç¹çš„APIèª¿ç”¨ï¼‰
            if not await self._should_update_market_data(symbol):
                # ä½¿ç”¨ç·©å­˜çš„æ•¸æ“šï¼ˆå¦‚æœå¯ç”¨ï¼‰
                cached_data = await self._get_cached_market_data(symbol)
                if cached_data:
                    logger.debug(f"ğŸ”„ {symbol}: ä½¿ç”¨ç·©å­˜æ•¸æ“š (è§¸ç™¼é–“éš”æœªé”åˆ°)")
                    return cached_data
            
            # å„ªå…ˆä½¿ç”¨æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if HYBRID_PRICE_SYSTEM_AVAILABLE:
                try:
                    # å‹•æ…‹å°å…¥ä»¥é¿å…å…¨å±€å°å…¥å•é¡Œ
                    from backend.phase1_signal_generation.onchain_data_connector.production_price_integration import get_real_market_data
                    
                    # ä½¿ç”¨æ–°çš„æ™ºèƒ½æ··åˆåƒ¹æ ¼ç³»çµ±ï¼ˆéˆä¸Šæ•¸æ“šç‚ºä¸»ï¼ŒWebSocket å¹£å®‰API ç‚ºå›é€€ï¼‰
                    market_data = await get_real_market_data(symbol)
                    
                    if market_data:
                        logger.info(f"âœ… {symbol}: æ™ºèƒ½æ··åˆç³»çµ±ç²å–æˆåŠŸ - åƒ¹æ ¼: ${market_data['price']:.4f} (ä¾†æº: {market_data.get('source', 'æœªçŸ¥')})")
                        if market_data.get('is_fallback'):
                            logger.info(f"ğŸ”„ {symbol}: ä½¿ç”¨ WebSocket å¹£å®‰API å›é€€æ©Ÿåˆ¶")
                        
                        # ğŸ¯ éšæ®µ3: æ›´æ–°åƒ¹æ ¼æ›´æ–°æ™‚é–“æˆ³
                        self._update_price_timestamp(symbol, market_data.get('is_fallback', False))
                        
                        # ç·©å­˜æ•¸æ“š
                        await self._cache_market_data(symbol, market_data)
                        
                        return market_data
                except ImportError as e:
                    logger.warning(f"âš ï¸ {symbol}: æ™ºèƒ½æ··åˆç³»çµ±å‹•æ…‹å°å…¥å¤±æ•—: {e}")
                    # å˜—è©¦é‡æ–°å•Ÿç”¨å°å…¥
                    if attempt_hybrid_import():
                        logger.info(f"ğŸ”„ {symbol}: æ™ºèƒ½æ··åˆç³»çµ±é‡æ–°é€£æ¥æˆåŠŸï¼Œé‡è©¦ä¸­...")
                        # éæ­¸é‡è©¦ä¸€æ¬¡
                        return await self._get_real_market_data(symbol)
                else:
                    logger.warning(f"âš ï¸ {symbol}: æ™ºèƒ½æ··åˆç³»çµ±ç²å–å¤±æ•—ï¼Œå˜—è©¦å‚³çµ±æ–¹æ³•")
            
            # å¦‚æœæ™ºèƒ½æ··åˆç³»çµ±ä¸å¯ç”¨æˆ–å¤±æ•—ï¼Œä½¿ç”¨å‚³çµ±å¹£å®‰API
            logger.info(f"ğŸ”„ {symbol}: ä½¿ç”¨å‚³çµ±å¹£å®‰APIæ–¹æ³•")
            fallback_data = await self._get_traditional_binance_data(symbol)
            
            if fallback_data:
                # ğŸ¯ éšæ®µ3: æ›´æ–°å›é€€APIæ™‚é–“æˆ³
                self._update_price_timestamp(symbol, is_fallback=True)
                await self._cache_market_data(symbol, fallback_data)
            
            return fallback_data
                
        except Exception as e:
            logger.error(f"âŒ {symbol} åƒ¹æ ¼ç³»çµ±éŒ¯èª¤: {e}")
            # å˜—è©¦å‚³çµ±æ–¹æ³•ä½œç‚ºæœ€å¾Œçš„å›é€€
            return await self._get_traditional_binance_data(symbol)
    
    # ğŸ¯ ===== éšæ®µ3: æ™ºèƒ½è§¸ç™¼å„ªåŒ–æ–¹æ³• =====
    
    async def _should_update_market_data(self, symbol: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦æ‡‰è©²æ›´æ–°å¸‚å ´æ•¸æ“š"""
        try:
            current_time = time.time()
            
            if symbol not in self.last_price_update_times:
                return True  # é¦–æ¬¡ç²å–æ•¸æ“š
            
            last_update_info = self.last_price_update_times[symbol]
            last_update_time = last_update_info['timestamp']
            was_fallback = last_update_info.get('was_fallback', False)
            
            # æ ¹æ“šæ•¸æ“šæºé¡å‹ä½¿ç”¨ä¸åŒçš„æ›´æ–°é–“éš”
            if was_fallback:
                # ä½¿ç”¨å¹£å®‰APIå›é€€æ™‚ï¼Œä½¿ç”¨è¼ƒé•·é–“éš”
                update_interval = self.fallback_api_interval_seconds
            else:
                # ä½¿ç”¨æ™ºèƒ½æ··åˆç³»çµ±æ™‚ï¼Œä½¿ç”¨è¼ƒçŸ­é–“éš”
                update_interval = self.price_update_threshold_seconds
            
            time_since_update = current_time - last_update_time
            should_update = time_since_update >= update_interval
            
            if should_update:
                logger.debug(f"â° {symbol}: è§¸ç™¼æ•¸æ“šæ›´æ–° - è·é›¢ä¸Šæ¬¡æ›´æ–° {time_since_update:.1f}s >= é–“éš” {update_interval}s")
            
            return should_update
            
        except Exception as e:
            logger.debug(f"è§¸ç™¼æª¢æŸ¥éŒ¯èª¤: {e}")
            return True  # å‡ºéŒ¯æ™‚ä¿å®ˆåœ°å…è¨±æ›´æ–°
    
    def _update_price_timestamp(self, symbol: str, is_fallback: bool):
        """æ›´æ–°åƒ¹æ ¼æ•¸æ“šæ™‚é–“æˆ³"""
        self.last_price_update_times[symbol] = {
            'timestamp': time.time(),
            'was_fallback': is_fallback
        }
    
    async def _get_cached_market_data(self, symbol: str) -> dict:
        """ç²å–ç·©å­˜çš„å¸‚å ´æ•¸æ“š"""
        try:
            # å¾åƒ¹æ ¼ç·©å­˜ç²å–æœ€æ–°æ•¸æ“š
            if (hasattr(self.phase1a_generator, 'price_buffer') and 
                symbol in self.phase1a_generator.price_buffer and
                self.phase1a_generator.price_buffer[symbol]):
                
                latest_entry = self.phase1a_generator.price_buffer[symbol][-1]
                
                # æª¢æŸ¥æ•¸æ“šæ˜¯å¦ä»ç„¶æ–°é®®ï¼ˆ5åˆ†é˜å…§ï¼‰
                if time.time() - latest_entry.get('timestamp', 0) < 300:
                    cached_data = {
                        'price': latest_entry['price'],
                        'close': latest_entry['price'],
                        'volume': latest_entry.get('volume', 0),
                        'high': latest_entry.get('high', latest_entry['price']),
                        'low': latest_entry.get('low', latest_entry['price']),
                        'source': 'cached_data',
                        'is_fallback': False
                    }
                    return cached_data
            
            return None
            
        except Exception as e:
            logger.debug(f"ç·©å­˜æ•¸æ“šç²å–éŒ¯èª¤: {e}")
            return None
    
    async def _cache_market_data(self, symbol: str, market_data: dict):
        """ç·©å­˜å¸‚å ´æ•¸æ“šåˆ°åƒ¹æ ¼ç·©å­˜ - ç”¢å“ç­‰ç´šé›™é‡åŒæ­¥ä¿éšœ"""
        try:
            if hasattr(self.phase1a_generator, 'price_buffer'):
                price_entry = {
                    'price': market_data.get('price', 0),
                    'volume': market_data.get('volume', 0),
                    'high': market_data.get('high', 0),
                    'low': market_data.get('low', 0),
                    'timestamp': time.time()
                }
                
                if symbol not in self.phase1a_generator.price_buffer:
                    self.phase1a_generator.price_buffer[symbol] = []
                
                self.phase1a_generator.price_buffer[symbol].append(price_entry)
                
                # é™åˆ¶ç·©å­˜å¤§å°
                max_buffer_size = 100
                if len(self.phase1a_generator.price_buffer[symbol]) > max_buffer_size:
                    self.phase1a_generator.price_buffer[symbol] = self.phase1a_generator.price_buffer[symbol][-max_buffer_size:]
                
                # ğŸ¯ ã€ç”¢å“ç­‰ç´šé›™é‡ä¿éšœã€‘ç¢ºä¿ intelligent_trigger_engine åŒæ­¥æ›´æ–°
                # é€™æ˜¯å•Ÿå‹•è…³æœ¬å±¤ç´šçš„å‚™ç”¨åŒæ­¥æ©Ÿåˆ¶ï¼Œèˆ‡ Phase1A å…§éƒ¨åŒæ­¥å½¢æˆé›™é‡ä¿éšœ
                try:
                    if (hasattr(self.phase1a_generator, 'intelligent_trigger_engine') and 
                        self.phase1a_generator.intelligent_trigger_engine):
                        
                        current_price = market_data.get('price', 0)
                        current_volume = market_data.get('volume', 0)
                        
                        await self.phase1a_generator.intelligent_trigger_engine.process_price_update(
                            symbol, current_price, current_volume
                        )
                        logger.debug(f"âœ… {symbol} å•Ÿå‹•è…³æœ¬å±¤ç´š intelligent_trigger_engine åŒæ­¥å®Œæˆ")
                except Exception as launcher_sync_e:
                    # å•Ÿå‹•è…³æœ¬å±¤ç´šåŒæ­¥å¤±æ•—ï¼Œè¨˜éŒ„ä½†ä¸å½±éŸ¿ä¸»æµç¨‹
                    logger.debug(f"âš ï¸ {symbol} å•Ÿå‹•è…³æœ¬å±¤ç´š intelligent_trigger_engine åŒæ­¥å¤±æ•—: {launcher_sync_e}")
                    
        except Exception as e:
            logger.debug(f"æ•¸æ“šç·©å­˜éŒ¯èª¤: {e}")
    
    async def _get_traditional_binance_data(self, symbol: str) -> dict:
        """å‚³çµ±å¹£å®‰APIæ•¸æ“šç²å–æ–¹æ³•ï¼ˆä½œç‚ºå›é€€ï¼‰"""
        try:
            import aiohttp
            
            # ç°¡åŒ–çš„å¹£å®‰APIèª¿ç”¨
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=10)) as session:
                url = f"https://api.binance.com/api/v3/ticker/24hr"
                params = {"symbol": symbol}
                
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        market_data = {
                            "close": float(data.get("lastPrice", 0)),
                            "price": float(data.get("lastPrice", 0)),
                            "volume": float(data.get("volume", 0)),
                            "high": float(data.get("highPrice", 0)),
                            "low": float(data.get("lowPrice", 0)),
                            "source": "traditional_binance_api",
                            "is_fallback": True
                        }
                        
                        logger.info(f"âœ… {symbol}: å‚³çµ±å¹£å®‰APIç²å–æˆåŠŸ - åƒ¹æ ¼: ${market_data['price']:.4f}")
                        return market_data
                    else:
                        logger.error(f"âŒ {symbol}: å¹£å®‰APIéŒ¯èª¤ {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"âŒ {symbol} å‚³çµ±å¹£å®‰APIéŒ¯èª¤: {e}")
            return None
    
    def _format_user_signal_display(self, symbol: str, signals: list, decisions: list = None) -> dict:
        """æ ¼å¼åŒ–ç”¨æˆ¶ä¿¡è™Ÿå±•ç¤º - ä½¿ç”¨ Phase1A çš„ format_for_display æ–¹æ³•ï¼Œåªè™•ç†Phase3æ•´åˆ"""
        if not signals:
            return None
        
        # å–æœ€é«˜å„ªå…ˆç´šä¿¡è™Ÿ
        best_signal = None
        best_priority = -1
        
        priority_map = {"CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1}
        
        for signal in signals:
            if hasattr(signal, 'tier'):
                tier_name = signal.tier.value if hasattr(signal.tier, 'value') else str(signal.tier)
                priority = priority_map.get(tier_name, 0)
                if priority > best_priority:
                    best_priority = priority
                    best_signal = signal
        
        if not best_signal:
            best_signal = signals[0]  # å¦‚æœæ²’æœ‰åˆ†å±¤ï¼Œå–ç¬¬ä¸€å€‹
        
        # ğŸ“Š Phase3 æ±ºç­–åˆ†æ - å•Ÿå‹•è…³æœ¬å”èª¿è·è²¬
        phase3_confidence = 0.0
        decision_action = None
        risk_check_failed = False
        
        if decisions and len(decisions) > 0:
            decision = decisions[0]
            
            # Phase3 ä¿¡å¿ƒåº¦è®€å–
            for confidence_attr in ['confidence', 'decision_confidence', 'certainty', 'probability']:
                if hasattr(decision, confidence_attr):
                    try:
                        phase3_confidence = float(getattr(decision, confidence_attr))
                        if phase3_confidence > 1.0:
                            phase3_confidence = phase3_confidence / 100.0
                        break
                    except (ValueError, TypeError):
                        continue
            
            # æª¢æŸ¥æ±ºç­–é¡å‹
            for decision_attr in ['decision', 'decision_type']:
                if hasattr(decision, decision_attr):
                    raw_decision = getattr(decision, decision_attr)
                    if hasattr(raw_decision, 'value'):
                        decision_action = raw_decision.value
                    else:
                        decision_action = str(raw_decision)
                    break
            
            # æª¢æŸ¥é¢¨éšªæª¢æŸ¥å¤±æ•—
            if phase3_confidence == 0.0 and decision_action and 'IGNORE' in decision_action:
                risk_check_failed = True
        
        # ğŸ¯ ä½¿ç”¨ Phase1A çš„ format_for_display æ–¹æ³•è™•ç†æ¥­å‹™é‚è¼¯
        try:
            if hasattr(best_signal, 'format_for_display'):
                signal_display_data = best_signal.format_for_display()
                logger.info(f"âœ… {symbol} ä½¿ç”¨ Phase1A format_for_display æ–¹æ³•")
            else:
                logger.error(f"âŒ {symbol} ä¿¡è™Ÿå°è±¡ç¼ºå°‘ format_for_display æ–¹æ³•")
                return None
            
            # å•Ÿå‹•è…³æœ¬è·è²¬ï¼šæ•´åˆ Phase3 ä¿¡å¿ƒåº¦
            base_confidence = signal_display_data.get('confidence', 0.5)
            
            if phase3_confidence > 0:
                final_confidence = phase3_confidence * 0.7 + base_confidence * 0.3
            elif risk_check_failed:
                final_confidence = base_confidence * 0.2
            else:
                final_confidence = base_confidence
            
            # æ›´æ–°æ•´åˆå¾Œçš„ä¿¡å¿ƒåº¦
            signal_display_data['confidence'] = final_confidence
            signal_display_data['phase3_confidence'] = phase3_confidence
            signal_display_data['risk_check_failed'] = risk_check_failed
            
            return signal_display_data
            
        except Exception as e:
            logger.error(f"âŒ {symbol} ä¿¡è™Ÿæ ¼å¼åŒ–å¤±æ•—: {e}")
            return None
    
    async def _display_user_signals(self, symbol: str, signals: list, decisions: list = None):
        """å‘ç”¨æˆ¶å±•ç¤ºä¿¡è™Ÿ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œä¸»è¦è·è²¬æ˜¯å”èª¿å±•ç¤º"""
        signal_display = self._format_user_signal_display(symbol, signals, decisions)
        
        if signal_display:
            logger.info("="*80)
            logger.info(f"ğŸ¯ ã€{symbol} äº¤æ˜“ä¿¡è™Ÿã€‘")
            logger.info(f"   ğŸ“ˆ æ“ä½œå»ºè­°: {signal_display['signal_type']}")
            logger.info(f"   ğŸ’ª ä¿¡å¿ƒåº¦: {signal_display['confidence']:.1%}")
            logger.info(f"   ğŸ† ä¿¡è™Ÿå±¤ç´š: {signal_display['tier']}")
            logger.info(f"   ğŸ’° å»ºè­°å€‰ä½: {signal_display['suggested_position_size']}")
            logger.info(f"   ğŸ’µ ç•¶å‰åƒ¹æ ¼: {signal_display['current_price']}")
            logger.info(f"   ğŸ“ˆ æ­¢ç›ˆåƒ¹æ ¼: {signal_display['take_profit']}")
            logger.info(f"   ğŸ“‰ æ­¢æåƒ¹æ ¼: {signal_display['stop_loss']}")
            logger.info(f"   â° å»ºè­°æŒå€‰: {signal_display['suggested_holding_hours']} å°æ™‚")
            
            # Phase3 æ±ºç­–ä¿¡æ¯å±•ç¤º (å•Ÿå‹•è…³æœ¬å”èª¿è·è²¬)
            if signal_display.get('phase3_confidence', 0) > 0:
                logger.info(f"   ğŸ¯ Phase3 æ±ºç­–ä¿¡å¿ƒåº¦: {signal_display['phase3_confidence']:.1%}")
            elif signal_display.get('risk_check_failed', False):
                logger.info(f"   ğŸš¨ Phase3 æ±ºç­–: ä¸ç¬¦åˆé–‹å€‰æ¢ä»¶ï¼Œè¶…éæŒå€‰é™åˆ¶")
            
            logger.info("="*80)
    
    async def start_monitoring(self):
        """å•Ÿå‹•ç›£æ§ç³»çµ±"""
        # å•Ÿå‹•çµ±ä¸€ç›£æ§ç³»çµ±
        if self.monitoring_manager:
            try:
                await self.monitoring_manager.start_monitoring()
                logger.info("âœ… çµ±ä¸€ç›£æ§ç³»çµ±å·²å•Ÿå‹•")
            except Exception as e:
                logger.error(f"âŒ ç›£æ§ç³»çµ±å•Ÿå‹•å¤±æ•—: {e}")
        
        # ğŸ§  å•Ÿå‹•å…§å­˜ç›£æ§
        try:
            memory_task = asyncio.create_task(self.memory_manager.memory_monitoring_loop())
            logger.info("âœ… å…§å­˜ç›£æ§ç³»çµ±å·²å•Ÿå‹•")
        except Exception as e:
            logger.error(f"âŒ å…§å­˜ç›£æ§å•Ÿå‹•å¤±æ•—: {e}")
    
    async def run_phase5_backtest(self):
        """åŸ·è¡Œ Phase5 å›æ¸¬ç”Ÿæˆæœ€æ–°åƒæ•¸"""
        logger.info("ğŸ¯ é–‹å§‹åŸ·è¡Œ Phase5 å›æ¸¬...")
        
        try:
            # ã€é‡è¦ä¿®å¾©ã€‘ä½¿ç”¨æ­£ç¢ºçš„ Phase5 å›æ¸¬ç­–ç•¥ä¾†ç”Ÿæˆæ–°åƒæ•¸
            logger.info("âš¡ åŸ·è¡Œ Phase5 åƒæ•¸ç”Ÿæˆå›æ¸¬...")
            
            # å°å…¥æ­£ç¢ºçš„ Phase5 å›æ¸¬ç­–ç•¥
            from backend.phase5_backtest_validation.phase5_enhanced_backtest_strategy import run_lean_backtest_analysis
            
            # ä½¿ç”¨å…§å»ºäº¤æ˜“å°é€²è¡Œå›æ¸¬
            trading_symbols = self.trading_symbols
            
            # åŸ·è¡Œ Lean å›æ¸¬åˆ†æä¸¦ç”Ÿæˆæ–°åƒæ•¸
            result = await run_lean_backtest_analysis(
                symbols=trading_symbols,
                lookback_days=7,  # å›æ¸¬7å¤©æ•¸æ“š (æ­£ç¢ºåƒæ•¸å)
                optimization_mode="standard"  # æ¨™æº–å„ªåŒ–æ¨¡å¼
            )
            
            if result and not result.get('error'):
                logger.info("âœ… Phase5 åƒæ•¸ç”Ÿæˆå›æ¸¬åŸ·è¡ŒæˆåŠŸ")
                
                # è¨˜éŒ„å›æ¸¬çµæœ
                summary = result.get('summary', {})
                avg_confidence = summary.get('avg_confidence', 0)
                avg_return = summary.get('avg_expected_return', 0)
                config_path = result.get('config_saved_path', '')
                
                logger.info(f"ğŸ“Š å›æ¸¬çµæœç¸½è¦½:")
                logger.info(f"   ğŸ¯ å¹³å‡ä¿¡å¿ƒåº¦: {avg_confidence:.2%}")
                logger.info(f"   ğŸ’° å¹³å‡æœŸæœ›æ”¶ç›Š: {avg_return:.2%}")
                logger.info(f"   ğŸ“ åƒæ•¸æª”æ¡ˆ: {config_path.split('/')[-1] if config_path else 'æœªç”Ÿæˆ'}")
                logger.info(f"   ğŸ”„ Phase1Aå°‡è¼‰å…¥æ–°åƒæ•¸: {result.get('next_phase1a_will_load', False)}")
                
                return True
            else:
                error_msg = result.get('error', 'æœªçŸ¥åŸå› ') if result else 'ç„¡å›æ¸¬çµæœ'
                logger.error(f"âŒ Phase5 åƒæ•¸ç”Ÿæˆå›æ¸¬åŸ·è¡Œå¤±æ•—: {error_msg}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Phase5 åƒæ•¸ç”Ÿæˆå›æ¸¬åŸ·è¡ŒéŒ¯èª¤: {e}")
            # ä½¿ç”¨èˆŠåƒæ•¸ç¹¼çºŒï¼Œä½†çµ¦å‡ºæ˜ç¢ºæç¤º
            backup_files = self._get_latest_phase5_backup_files()
            if backup_files:
                latest_file = max(backup_files, key=lambda x: x.stat().st_mtime)
                mtime = datetime.fromtimestamp(latest_file.stat().st_mtime)
                logger.warning(f"âš ï¸ Phase5 åŸ·è¡Œå¤±æ•—ï¼Œä½¿ç”¨èˆŠåƒæ•¸æ–‡ä»¶: {latest_file.name}")
                logger.warning(f"ğŸ“… æ–‡ä»¶æ—¥æœŸ: {mtime.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
            else:
                logger.error("âŒ ç„¡å¯ç”¨çš„ Phase5 åƒæ•¸æ–‡ä»¶")
            return False
    
    def _get_latest_phase5_backup_files(self):
        """ç²å–æœ€æ–°çš„ Phase5 å‚™ä»½æ–‡ä»¶åˆ—è¡¨"""
        try:
            from pathlib import Path
            backup_dir = Path(__file__).parent / "backend" / "phase5_backtest_validation" / "safety_backups" / "working"
            if backup_dir.exists():
                return list(backup_dir.glob("*.json"))
            return []
        except Exception as e:
            logger.error(f"âŒ ç²å– Phase5 å‚™ä»½æ–‡ä»¶å¤±æ•—: {e}")
            return []
    
    async def check_phase5_schedule(self):
        """æª¢æŸ¥æ˜¯å¦éœ€è¦åŸ·è¡Œå®šæ™‚ Phase5 å›æ¸¬"""
        if not self.phase5_enabled:
            return
        
        current_time = time.time()
        
        # 24å°æ™‚å®šæ™‚è§¸ç™¼ï¼Œä½†é¿é–‹Phase2åŸ·è¡Œæ™‚é–“
        if (self.phase5_last_run is None or 
            current_time - self.phase5_last_run >= self.phase5_interval_hours * 3600):
            
            if not self.phase5_running:
                # ğŸš¨ å”èª¿æ©Ÿåˆ¶ï¼šéŒ¯é–‹åŸ·è¡Œæ™‚é–“é¿å…è¡çª
                current_hour = datetime.now().hour
                if current_hour % 2 == 0:  # Phase2åœ¨å¶æ•¸å°æ™‚åŸ·è¡Œ
                    logger.info("â³ é¿é–‹Phase2åŸ·è¡Œæ™‚é–“ï¼Œå»¶é²1å°æ™‚åŸ·è¡ŒPhase5")
                    return
                
                logger.info("â° è§¸ç™¼å®šæ™‚ Phase5 å›æ¸¬...")
                self.phase5_running = True
                
                try:
                    success = await self.run_phase5_backtest()
                    if success:
                        self.phase5_last_run = current_time
                finally:
                    self.phase5_running = False
    
    async def run(self):
        """é‹è¡Œå®Œæ•´ç³»çµ±"""
        logger.info("ğŸš€ å•Ÿå‹• Trading X ç”Ÿç”¢ç’°å¢ƒç³»çµ± (Phase2 åƒæ•¸ç®¡ç†å¢å¼·ç‰ˆ)...")
        
        # ç¬¬ä¸€æ­¥ï¼šåˆå§‹åŒ–ç³»çµ±çµ„ä»¶
        logger.info("ğŸ”§ ç¬¬ä¸€æ­¥ï¼šåˆå§‹åŒ–ç³»çµ±çµ„ä»¶...")
        if not await self.initialize_systems():
            logger.error("âŒ ç³»çµ±åˆå§‹åŒ–å¤±æ•—ï¼Œé€€å‡º")
            return
        
        # ç¬¬äºŒæ­¥ï¼šåŸ·è¡Œ Phase5 å›æ¸¬ç”Ÿæˆæœ€æ–°åƒæ•¸ (åƒ…åœ¨ç³»çµ±åˆå§‹åŒ–æˆåŠŸå¾Œ)
        logger.info("ğŸ¯ ç¬¬äºŒæ­¥ï¼šåŸ·è¡Œ Phase5 å›æ¸¬åˆ†æç”Ÿæˆæ–°åƒæ•¸...")
        try:
            phase5_success = await self.run_phase5_backtest()
            if not phase5_success:
                logger.warning("âš ï¸ Phase5 åƒæ•¸ç”Ÿæˆå¤±æ•—ï¼Œä½†ç³»çµ±å°‡ç¹¼çºŒä½¿ç”¨ç¾æœ‰åƒæ•¸")
        except Exception as e:
            logger.error(f"âŒ Phase5 åƒæ•¸ç”Ÿæˆç•°å¸¸: {e}")
            logger.warning("âš ï¸ Phase5 åŸ·è¡Œç•°å¸¸ï¼Œç³»çµ±å°‡ç¹¼çºŒä½¿ç”¨ç¾æœ‰åƒæ•¸")
        
        # ç¬¬ä¸‰æ­¥ï¼šé‡æ–°è¼‰å…¥ Phase1A ä»¥ä½¿ç”¨æœ€æ–°åƒæ•¸
        logger.info("ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šé‡æ–°è¼‰å…¥ Phase1A é…ç½®...")
        try:
            if self.phase1a_generator and hasattr(self.phase1a_generator, 'reload_configuration'):
                self.phase1a_generator.reload_configuration()
                logger.info("âœ… Phase1A é…ç½®é‡æ–°è¼‰å…¥æˆåŠŸ")
            else:
                logger.debug("â„¹ï¸ Phase1A ç„¡éœ€æ‰‹å‹•é‡è¼‰é…ç½®")
        except Exception as e:
            logger.warning(f"âš ï¸ Phase1A é…ç½®é‡æ–°è¼‰å…¥å¤±æ•—: {e}")
        
        # ç¬¬å››æ­¥ï¼šå•Ÿå‹•ä¸»å¾ªç’°
        # åˆå§‹åŒ–æ­·å²æ•¸æ“š
        await self._initialize_historical_data()
        
        # ğŸ¯ ã€ç”¢å“ç­‰ç´šé©—è­‰ã€‘é©—è­‰æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶
        await self._verify_technical_indicator_sync_mechanism()
        
        logger.info("â–¶ï¸ ç¬¬å››æ­¥ï¼šå•Ÿå‹•ä¸»å¾ªç’°...")
        
        self.running = True
        
        try:
            # å•Ÿå‹•ç›£æ§ç³»çµ±
            await self.start_monitoring()
            
            # ä¸¦è¡Œé‹è¡Œä¿¡è™Ÿç”Ÿæˆ
            signal_task = asyncio.create_task(self.start_signal_generation_loop())
            
            # ç­‰å¾…ä»»å‹™å®Œæˆ
            await signal_task
            
        except KeyboardInterrupt:
            logger.info("ğŸ”„ æ¥æ”¶åˆ°åœæ­¢ä¿¡è™Ÿ...")
        except Exception as e:
            logger.error(f"âŒ ç³»çµ±é‹è¡ŒéŒ¯èª¤: {e}")
        finally:
            await self.shutdown()
    
    async def check_system_health(self):
        """æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ…‹"""
        current_time = time.time()
        
        # æª¢æŸ¥åš´é‡éŒ¯èª¤æ•¸é‡
        if self.system_health['critical_errors'] >= self.system_health['max_critical_errors']:
            logger.critical(f"ğŸš« ç³»çµ±å¥åº·æª¢æŸ¥å¤±æ•—ï¼šåš´é‡éŒ¯èª¤æ•¸ {self.system_health['critical_errors']} è¶…éé–¾å€¼ {self.system_health['max_critical_errors']}")
            logger.critical("ğŸ›‘ åŸºæ–¼ç”¢å“ç´šè¦æ±‚ï¼Œç³»çµ±å°‡åœæ­¢é‹è¡Œä»¥ä¿è­·æ•¸æ“šå®Œæ•´æ€§")
            await self.shutdown()
            return False
            
        # æª¢æŸ¥æ•¸æ“šè³ªé‡å¤±æ•—æ•¸é‡
        if self.system_health['data_quality_failures'] >= self.system_health['max_data_failures']:
            logger.critical(f"ğŸš« æ•¸æ“šè³ªé‡æª¢æŸ¥å¤±æ•—ï¼šå¤±æ•—æ•¸ {self.system_health['data_quality_failures']} è¶…éé–¾å€¼ {self.system_health['max_data_failures']}")
            logger.critical("ğŸ›‘ åŸºæ–¼ç”¨æˆ¶è¦æ±‚ï¼ˆä¸å‡†æ¨¡æ“¬æ•¸æ“šï¼‰ï¼Œç³»çµ±å°‡åœæ­¢é‹è¡Œ")
            await self.shutdown()
            return False
            
        self.system_health['last_health_check'] = current_time
        return True

    def record_critical_error(self, error_type: str, details: str):
        """è¨˜éŒ„åš´é‡éŒ¯èª¤"""
        self.system_health['critical_errors'] += 1
        logger.error(f"ğŸš¨ è¨˜éŒ„åš´é‡éŒ¯èª¤ ({self.system_health['critical_errors']}/{self.system_health['max_critical_errors']}): {error_type} - {details}")

    def record_data_quality_failure(self, symbol: str, reason: str):
        """è¨˜éŒ„æ•¸æ“šè³ªé‡å¤±æ•—"""
        self.system_health['data_quality_failures'] += 1
        logger.warning(f"ğŸ“Š è¨˜éŒ„æ•¸æ“šè³ªé‡å¤±æ•— ({self.system_health['data_quality_failures']}/{self.system_health['max_data_failures']}): {symbol} - {reason}")

    async def shutdown(self):
        """é—œé–‰ç³»çµ±"""
        logger.info("ğŸ”„ é—œé–‰ç³»çµ±ä¸­...")
        self.running = False
        
        # ä¿å­˜ Phase2 åƒæ•¸ç®¡ç†å™¨ç‹€æ…‹
        if self.phase2_parameter_manager:
            try:
                # å¯ä»¥åœ¨é€™è£¡ä¿å­˜å­¸ç¿’ç‹€æ…‹å’Œåƒæ•¸æ­·å²
                logger.info("ğŸ’¾ ä¿å­˜ Phase2 åƒæ•¸ç®¡ç†å™¨ç‹€æ…‹...")
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜ç‹€æ…‹å¤±æ•—: {e}")
        
        logger.info("âœ… ç³»çµ±å·²å®‰å…¨é—œé–‰")
    
    async def _perform_phase2_maintenance(self, current_time: float):
        """åŸ·è¡Œ Phase2 å„ªåŒ–çµ„ä»¶ç¶­è­·"""
        try:
            # 1. æ–‡ä»¶æ¸…ç†ç¶­è­·ï¼ˆæ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡ï¼‰
            if (self.file_cleanup_manager and 
                current_time - self.last_cleanup_time > self.cleanup_interval):
                
                logger.info("ğŸ§¹ åŸ·è¡Œå®šæœŸæ–‡ä»¶æ¸…ç†...")
                cleanup_results = await self.file_cleanup_manager.cleanup_all()
                
                # è¨˜éŒ„æ¸…ç†çµæœ
                total_cleaned = sum(result.get('files_cleaned', 0) for result in cleanup_results.values())
                total_size_freed = sum(result.get('space_freed_mb', 0) for result in cleanup_results.values())
                
                if total_cleaned > 0:
                    logger.info(f"âœ… æ–‡ä»¶æ¸…ç†å®Œæˆ: æ¸…ç† {total_cleaned} å€‹æ–‡ä»¶ï¼Œé‡‹æ”¾ {total_size_freed:.3f} MB")
                else:
                    logger.debug("â„¹ï¸ æ–‡ä»¶æ¸…ç†å®Œæˆ: ç„¡éœ€æ¸…ç†")
                
                self.last_cleanup_time = current_time
                
        except Exception as e:
            logger.error(f"âŒ Phase2 ç¶­è­·å¤±æ•—: {e}")
    
    async def _monitor_signals_with_learning_engine(self, signals, symbol: str, market_data: dict):
        """ä½¿ç”¨å­¸ç¿’å¼•æ“ç›£æ§ä¿¡è™Ÿ - æ”¯æ´å„ªå…ˆç´š3æ™‚é–“æ¡†æ¶æ„ŸçŸ¥"""
        try:
            # è™•ç†å–®å€‹æˆ–å¤šå€‹ä¿¡è™Ÿ
            signal_list = signals if isinstance(signals, list) else [signals]
            
            for signal in signal_list:
                # æº–å‚™åŸºç¤ä¿¡è™Ÿæ•¸æ“š
                base_signal_data = {
                    'signal_id': f"{symbol}_{int(time.time() * 1000)}",  # ä½¿ç”¨æ™‚é–“æˆ³ç”Ÿæˆå”¯ä¸€ID
                    'symbol': symbol,
                    'signal_strength': getattr(signal, 'signal_strength', getattr(signal, 'strength', 0.7)),
                    'signal_type': getattr(signal, 'signal_type', getattr(signal, 'direction', 'BUY')),
                    'tier': getattr(signal, 'tier', 'MEDIUM'),
                    'timestamp': datetime.now(),
                    'features': {
                        'market_data': market_data,
                        'signal_source': getattr(signal, 'signal_type', 'BASIC')
                    },
                    'market_conditions': {
                        'price': market_data.get('price', market_data.get('close', 0.0)),
                        'volume': market_data.get('volume', 0.0),
                        'volatility': market_data.get('volatility', 0.0)
                    },
                    'primary_timeframe': '5m'  # é»˜èªæ™‚é–“æ¡†æ¶
                }
                
                # === å„ªå…ˆç´š3ï¼šæ™‚é–“æ¡†æ¶æ„ŸçŸ¥è™•ç† ===
                if self.priority3_enabled and self.priority3_integration:
                    try:
                        # ä½¿ç”¨å„ªå…ˆç´š3æ•´åˆå¼•æ“è™•ç†ä¿¡è™Ÿ
                        enhanced_signal = await self.priority3_integration.process_signal_with_timeframes(
                            base_signal_data, market_data
                        )
                        
                        if enhanced_signal:
                            logger.debug(f"âœ… {symbol}: å„ªå…ˆç´š3å¢å¼·ä¿¡è™Ÿ - æœ€çµ‚æ¬Šé‡: {enhanced_signal.final_learning_weight:.3f}")
                            logger.debug(f"ğŸ” æ¬Šé‡åˆ†è§£: æ™‚é–“è¡°æ¸›={enhanced_signal.time_decay_weight:.3f}, "
                                       f"å¹£ç¨®åˆ†é¡={enhanced_signal.category_weight:.3f}, "
                                       f"æ™‚é–“æ¡†æ¶={enhanced_signal.cross_timeframe_weight:.3f}")
                        else:
                            logger.warning(f"âš ï¸ {symbol}: å„ªå…ˆç´š3è™•ç†å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤å­¸ç¿’")
                            # è¨˜éŒ„æ•¸æ“šè³ªé‡å¤±æ•—
                            self.record_data_quality_failure(symbol, "å„ªå…ˆç´š3å¤šæ™‚é–“æ¡†æ¶æ•¸æ“šç¼ºå¤±")
                            await self._fallback_learning_monitor(base_signal_data)
                            
                    except Exception as e:
                        logger.error(f"âŒ {symbol}: å„ªå…ˆç´š3è™•ç†éŒ¯èª¤: {e}")
                        # è¨˜éŒ„åš´é‡éŒ¯èª¤
                        self.record_critical_error("Priority3ProcessingError", f"{symbol}: {str(e)}")
                        await self._fallback_learning_monitor(base_signal_data)
                
                # === åŸºç¤å­¸ç¿’å¼•æ“ç›£æ§ï¼ˆå„ªå…ˆç´š1+2ï¼‰ ===
                elif self.learning_enabled and self.adaptive_learning_engine:
                    await self._fallback_learning_monitor(base_signal_data)
                
                else:
                    logger.debug(f"ğŸ“ {symbol}: å­¸ç¿’å¼•æ“æœªå•Ÿç”¨ï¼Œè·³éä¿¡è™Ÿç›£æ§")
                
        except Exception as e:
            logger.error(f"âŒ å­¸ç¿’å¼•æ“ä¿¡è™Ÿç›£æ§å¤±æ•—: {e}")
    
    async def _fallback_learning_monitor(self, signal_data: dict):
        """åŸºç¤å­¸ç¿’ç›£æ§ï¼ˆç•¶å„ªå…ˆç´š3ä¸å¯ç”¨æ™‚ï¼‰"""
        try:
            if self.learning_enabled and self.adaptive_learning_engine:
                # ç›£æ§ä¿¡è™Ÿè¡¨ç¾ï¼ˆæš«æ™‚ä¸æä¾›å¯¦éš›çµæœï¼Œè®“å­¸ç¿’å¼•æ“è¨˜éŒ„ï¼‰
                await self.adaptive_learning_engine.monitor_signal_performance(
                    signal_data, 
                    actual_outcome=None  # å¯¦éš›çµæœéœ€è¦å¾ŒçºŒè·Ÿè¹¤
                )
                logger.debug(f"ğŸ“Š åŸºç¤å­¸ç¿’: {signal_data['signal_id']}")
        except Exception as e:
            logger.error(f"âŒ åŸºç¤å­¸ç¿’ç›£æ§å¤±æ•—: {e}")
    
    async def _display_round_summary(self):
        """é¡¯ç¤ºæœ¬è¼ªçµ±è¨ˆç¸½çµ - åŒ…å«éšæ®µ4æ€§èƒ½ç›£æ§"""
        try:
            current_time = time.time()
            session_duration = (current_time - self.signal_stats['last_reset_time']) / 3600  # å°æ™‚
            
            logger.info("=" * 60)
            logger.info("ğŸ“Š ã€æœ¬è¼ªäº¤æ˜“ä¿¡è™Ÿçµ±è¨ˆç¸½çµã€‘")
            logger.info(f"â° æœƒè©±æ™‚é•·: {session_duration:.1f} å°æ™‚")
            logger.info(f"ğŸ¯ æœ¬è¼ªä¿¡è™Ÿæ•¸: {self.signal_stats['signals_per_session']}")
            logger.info(f"ğŸ“ˆ ç´¯ç©ç¸½ä¿¡è™Ÿ: {self.signal_stats['total_signals_generated']}")
            
            # å„äº¤æ˜“å°ä¿¡è™Ÿåˆ†å¸ƒ
            if self.signal_stats['signals_per_symbol']:
                logger.info("ğŸ“Š å„äº¤æ˜“å°ä¿¡è™Ÿåˆ†å¸ƒ:")
                for symbol, count in self.signal_stats['signals_per_symbol'].items():
                    logger.info(f"   â€¢ {symbol}: {count} å€‹ä¿¡è™Ÿ")
            
            # ğŸ¯ éšæ®µ4: å»é‡æ©Ÿåˆ¶æ€§èƒ½çµ±è¨ˆ
            await self._display_deduplication_performance()
            
            # ğŸ¯ éšæ®µ4: æ™ºèƒ½è§¸ç™¼æ€§èƒ½çµ±è¨ˆ
            await self._display_trigger_performance()
            
            # ğŸ¯ éšæ®µ4: ç³»çµ±å¥åº·ç‹€æ…‹
            await self._display_system_health_summary()
            
            logger.info("=" * 60)
            
            # é‡ç½®æœ¬è¼ªçµ±è¨ˆ
            self.signal_stats['signals_per_session'] = 0
            
        except Exception as e:
            logger.error(f"âŒ çµ±è¨ˆç¸½çµé¡¯ç¤ºå¤±æ•—: {e}")
    
    # ğŸ¯ ===== éšæ®µ4: æ€§èƒ½é©—è­‰èˆ‡ç›£æ§æ–¹æ³• =====
    
    async def _display_deduplication_performance(self):
        """é¡¯ç¤ºå»é‡æ©Ÿåˆ¶æ€§èƒ½çµ±è¨ˆ"""
        try:
            if not self.signal_deduplication_enabled:
                logger.info("ğŸš« ä¿¡è™Ÿå»é‡æ©Ÿåˆ¶: æœªå•Ÿç”¨")
                return
            
            logger.info("ğŸ¯ ã€ä¿¡è™Ÿå»é‡æ©Ÿåˆ¶æ€§èƒ½ã€‘")
            
            # çµ±è¨ˆæ¯å€‹äº¤æ˜“å°çš„ç·©å­˜å¤§å°
            total_cached_signals = 0
            active_symbols = 0
            
            for symbol, cache in self.signal_history_cache.items():
                cache_size = len(cache)
                if cache_size > 0:
                    active_symbols += 1
                    total_cached_signals += cache_size
                    logger.info(f"   â€¢ {symbol}: {cache_size} å€‹æ­·å²ä¿¡è™Ÿ")
            
            if active_symbols > 0:
                avg_cache_size = total_cached_signals / active_symbols
                logger.info(f"   ğŸ“Š æ´»èºäº¤æ˜“å°: {active_symbols} | å¹³å‡ç·©å­˜: {avg_cache_size:.1f} å€‹ä¿¡è™Ÿ")
                logger.info(f"   ğŸ”§ ç•¶å‰é–¾å€¼: {self.signal_similarity_threshold:.3f}")
                logger.info(f"   ğŸŒŠ æ³¢å‹•é©æ‡‰: {'å•Ÿç”¨' if self.volatility_adaptive_enabled else 'åœç”¨'}")
            else:
                logger.info("   ğŸ“Š å°šç„¡æ­·å²ä¿¡è™Ÿç·©å­˜")
                
        except Exception as e:
            logger.debug(f"å»é‡æ€§èƒ½çµ±è¨ˆéŒ¯èª¤: {e}")
    
    async def _display_trigger_performance(self):
        """é¡¯ç¤ºæ™ºèƒ½è§¸ç™¼æ€§èƒ½çµ±è¨ˆ"""
        try:
            if not self.intelligent_trigger_enabled:
                logger.info("ğŸš« æ™ºèƒ½è§¸ç™¼æ©Ÿåˆ¶: æœªå•Ÿç”¨")
                return
            
            logger.info("âš¡ ã€æ™ºèƒ½è§¸ç™¼æ©Ÿåˆ¶æ€§èƒ½ã€‘")
            
            if self.last_price_update_times:
                hybrid_count = 0
                fallback_count = 0
                current_time = time.time()
                
                for symbol, update_info in self.last_price_update_times.items():
                    is_fallback = update_info.get('was_fallback', False)
                    last_update = update_info['timestamp']
                    time_since = current_time - last_update
                    
                    if is_fallback:
                        fallback_count += 1
                        logger.info(f"   ğŸ”„ {symbol}: å¹£å®‰APIå›é€€ (ä¸Šæ¬¡æ›´æ–°: {time_since:.0f}så‰)")
                    else:
                        hybrid_count += 1
                        logger.info(f"   âš¡ {symbol}: æ™ºèƒ½æ··åˆç³»çµ± (ä¸Šæ¬¡æ›´æ–°: {time_since:.0f}så‰)")
                
                logger.info(f"   ğŸ“Š æ•¸æ“šæºåˆ†å¸ƒ: æ™ºèƒ½æ··åˆ {hybrid_count} | å¹£å®‰å›é€€ {fallback_count}")
                logger.info(f"   â±ï¸ è§¸ç™¼é–“éš”: æ™ºèƒ½æ··åˆ {self.price_update_threshold_seconds}s | å›é€€ {self.fallback_api_interval_seconds}s")
            else:
                logger.info("   ğŸ“Š å°šç„¡åƒ¹æ ¼æ›´æ–°è¨˜éŒ„")
                
        except Exception as e:
            logger.debug(f"è§¸ç™¼æ€§èƒ½çµ±è¨ˆéŒ¯èª¤: {e}")
    
    async def _display_system_health_summary(self):
        """é¡¯ç¤ºç³»çµ±å¥åº·ç‹€æ…‹ç¸½çµ"""
        try:
            logger.info("ğŸ¥ ã€ç³»çµ±å¥åº·ç‹€æ…‹ã€‘")
            logger.info(f"   ğŸš¨ åš´é‡éŒ¯èª¤: {self.system_health['critical_errors']}/{self.system_health['max_critical_errors']}")
            logger.info(f"   ğŸ“Š æ•¸æ“šè³ªé‡å¤±æ•—: {self.system_health['data_quality_failures']}/{self.system_health['max_data_failures']}")
            
            # ç³»çµ±å¥åº·åˆ†æ•¸
            health_score = self._calculate_system_health_score()
            health_status = "å„ªè‰¯" if health_score >= 0.8 else "è‰¯å¥½" if health_score >= 0.6 else "éœ€æ³¨æ„" if health_score >= 0.4 else "ç•°å¸¸"
            logger.info(f"   ğŸ’š ç³»çµ±å¥åº·åˆ†æ•¸: {health_score:.1%} ({health_status})")
            
            # å­¸ç¿’æ©Ÿåˆ¶ç‹€æ…‹ç¢ºèª
            learning_status = "æ­£å¸¸é‹è¡Œ" if (self.phase1a_generator and self.phase1a_generator.adaptive_mode) else "æœªå•Ÿç”¨"
            logger.info(f"   ğŸ§  å­¸ç¿’æ©Ÿåˆ¶: {learning_status}")
            
            # ğŸ¯ ã€ç”¢å“ç­‰ç´šç›£æ§ã€‘æŠ€è¡“æŒ‡æ¨™åŒæ­¥ç‹€æ…‹æª¢æŸ¥
            await self._display_technical_indicator_sync_status()
            
            # ç¢ºèªé–‰ç’°å…§æ©Ÿåˆ¶æœªå—å½±éŸ¿
            logger.info("   âœ… é–‰ç’°å…§æ©Ÿåˆ¶: å­¸ç¿’è¿½è¹¤æ­£å¸¸ | å›æ¸¬æ•¸æ“šå®Œæ•´ | åƒæ•¸ç”Ÿæˆæ­£å¸¸")
            
        except Exception as e:
            logger.debug(f"ç³»çµ±å¥åº·çµ±è¨ˆéŒ¯èª¤: {e}")
    
    async def _display_technical_indicator_sync_status(self):
        """é¡¯ç¤ºæŠ€è¡“æŒ‡æ¨™åŒæ­¥ç‹€æ…‹ - ç”¢å“ç­‰ç´šç›£æ§"""
        try:
            if not (hasattr(self.phase1a_generator, 'intelligent_trigger_engine') and 
                    self.phase1a_generator.intelligent_trigger_engine):
                logger.info("   ğŸ“Š æŠ€è¡“æŒ‡æ¨™åŒæ­¥: intelligent_trigger_engine æœªåˆå§‹åŒ–")
                return
            
            trigger_engine = self.phase1a_generator.intelligent_trigger_engine
            current_time = datetime.now()
            sync_status_summary = []
            
            # æª¢æŸ¥å„äº¤æ˜“å°çš„æŠ€è¡“æŒ‡æ¨™æ•¸æ“šæ–°é®®åº¦
            for symbol in self.trading_symbols:
                if (hasattr(trigger_engine, 'price_cache') and 
                    symbol in trigger_engine.price_cache and 
                    len(trigger_engine.price_cache[symbol]) > 0):
                    
                    latest_data = trigger_engine.price_cache[symbol][-1]
                    age_minutes = (current_time - latest_data.timestamp).total_seconds() / 60
                    
                    if age_minutes <= 3:
                        status = "ğŸŸ¢ æœ€æ–°"
                    elif age_minutes <= 10:
                        status = "ğŸŸ¡ è‰¯å¥½"
                    else:
                        status = "ğŸ”´ éæœŸ"
                    
                    sync_status_summary.append(f"{symbol}:{status}({age_minutes:.1f}m)")
                else:
                    sync_status_summary.append(f"{symbol}:ğŸ”´ ç„¡æ•¸æ“š")
            
            if sync_status_summary:
                logger.info(f"   ğŸ“Š æŠ€è¡“æŒ‡æ¨™åŒæ­¥ç‹€æ…‹: {' | '.join(sync_status_summary[:4])}")  # åªé¡¯ç¤ºå‰4å€‹äº¤æ˜“å°
                if len(sync_status_summary) > 4:
                    logger.info(f"   ğŸ“Š å…¶ä»–äº¤æ˜“å°: {' | '.join(sync_status_summary[4:])}")
                
                # çµ±è¨ˆæ•´é«”åŒæ­¥æ•ˆæœ
                fresh_count = sum(1 for s in sync_status_summary if "ğŸŸ¢" in s)
                good_count = sum(1 for s in sync_status_summary if "ğŸŸ¡" in s)
                stale_count = sum(1 for s in sync_status_summary if "ğŸ”´" in s)
                
                total_symbols = len(sync_status_summary)
                sync_efficiency = (fresh_count + good_count * 0.7) / total_symbols if total_symbols > 0 else 0
                
                logger.info(f"   âš¡ åŒæ­¥æ•ˆç‡: {sync_efficiency:.1%} (æœ€æ–°:{fresh_count} è‰¯å¥½:{good_count} éæœŸ:{stale_count})")
                
                if sync_efficiency >= 0.8:
                    logger.info("   âœ… æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶é‹è¡Œè‰¯å¥½")
                elif sync_efficiency >= 0.5:
                    logger.info("   âš ï¸ æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶éœ€è¦é—œæ³¨")
                else:
                    logger.info("   ğŸš¨ æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶éœ€è¦æª¢æŸ¥")
            else:
                logger.info("   ğŸ“Š æŠ€è¡“æŒ‡æ¨™åŒæ­¥: ç„¡ç›£æ§æ•¸æ“š")
                
        except Exception as e:
            logger.debug(f"æŠ€è¡“æŒ‡æ¨™åŒæ­¥ç‹€æ…‹æª¢æŸ¥éŒ¯èª¤: {e}")
            logger.info("   ğŸ“Š æŠ€è¡“æŒ‡æ¨™åŒæ­¥: ç›£æ§æª¢æŸ¥å¤±æ•—")
    
    async def _verify_technical_indicator_sync_mechanism(self):
        """é©—è­‰æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶ - ç”¢å“ç­‰ç´šå•Ÿå‹•é©—è­‰"""
        logger.info("ğŸ”§ é©—è­‰æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶...")
        
        try:
            if not (hasattr(self.phase1a_generator, 'intelligent_trigger_engine') and 
                    self.phase1a_generator.intelligent_trigger_engine):
                logger.warning("âš ï¸ intelligent_trigger_engine æœªåˆå§‹åŒ–ï¼Œè·³éåŒæ­¥æ©Ÿåˆ¶é©—è­‰")
                return
            
            trigger_engine = self.phase1a_generator.intelligent_trigger_engine
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åƒ¹æ ¼æ•¸æ“š
            symbols_with_data = []
            for symbol in self.trading_symbols[:3]:  # æª¢æŸ¥å‰3å€‹äº¤æ˜“å°
                if (hasattr(trigger_engine, 'price_cache') and 
                    symbol in trigger_engine.price_cache and 
                    len(trigger_engine.price_cache[symbol]) > 0):
                    symbols_with_data.append(symbol)
            
            if symbols_with_data:
                logger.info(f"âœ… æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶é©—è­‰é€šé: {len(symbols_with_data)} å€‹äº¤æ˜“å°æœ‰æ•¸æ“š")
                
                # é©—è­‰æ•¸æ“šæ–°é®®åº¦
                for symbol in symbols_with_data[:2]:  # é©—è­‰å‰2å€‹
                    latest_data = trigger_engine.price_cache[symbol][-1]
                    age_minutes = (datetime.now() - latest_data.timestamp).total_seconds() / 60
                    logger.info(f"   ğŸ“Š {symbol}: æ•¸æ“šå¹´é½¡ {age_minutes:.1f} åˆ†é˜")
                
                logger.info("ğŸ¯ æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶å·²å°±ç·’ï¼Œé æœŸå°‡æ¸›å°‘å¼·åˆ¶æ›´æ–°é »ç‡")
            else:
                logger.warning("âš ï¸ æš«ç„¡æŠ€è¡“æŒ‡æ¨™æ•¸æ“šï¼ŒåŒæ­¥æ©Ÿåˆ¶å°‡åœ¨æ•¸æ“šæµå…¥å¾Œç”Ÿæ•ˆ")
                
        except Exception as e:
            logger.warning(f"âš ï¸ æŠ€è¡“æŒ‡æ¨™åŒæ­¥æ©Ÿåˆ¶é©—è­‰å¤±æ•—: {e}")
            logger.info("ğŸ”„ ç³»çµ±å°‡ç¹¼çºŒé‹è¡Œï¼ŒåŒæ­¥æ©Ÿåˆ¶å°‡åœ¨é‹è¡Œéç¨‹ä¸­ç”Ÿæ•ˆ")
    
    def _calculate_system_health_score(self) -> float:
        """è¨ˆç®—ç³»çµ±å¥åº·åˆ†æ•¸"""
        try:
            # éŒ¯èª¤ç‡è©•åˆ†
            error_score = 1.0 - (self.system_health['critical_errors'] / max(1, self.system_health['max_critical_errors']))
            data_score = 1.0 - (self.system_health['data_quality_failures'] / max(1, self.system_health['max_data_failures']))
            
            # åŠ æ¬Šå¹³å‡
            health_score = (error_score * 0.6 + data_score * 0.4)
            return max(0.0, min(1.0, health_score))
            
        except Exception as e:
            logger.debug(f"å¥åº·åˆ†æ•¸è¨ˆç®—éŒ¯èª¤: {e}")
            return 0.5
    
    async def _validate_learning_integrity(self) -> bool:
        """éšæ®µ4: é©—è­‰å­¸ç¿’æ©Ÿåˆ¶å®Œæ•´æ€§"""
        try:
            if not (self.phase1a_generator and self.phase1a_generator.adaptive_mode):
                return True  # å­¸ç¿’æœªå•Ÿç”¨æ™‚è¦–ç‚ºæ­£å¸¸
            
            # æª¢æŸ¥å­¸ç¿’å¼•æ“æ˜¯å¦æ­£å¸¸é‹è¡Œ
            if hasattr(self.phase1a_generator.learning_core, 'get_learning_summary'):
                learning_summary = self.phase1a_generator.learning_core.get_learning_summary()
                
                # é©—è­‰é—œéµæŒ‡æ¨™
                performance_metrics = learning_summary.get('performance_metrics', {})
                total_signals = performance_metrics.get('total_signals_tracked', 0)
                
                # å¦‚æœé‹è¡Œä¸€æ®µæ™‚é–“å¾Œä»ç„¶æ²’æœ‰è¿½è¹¤åˆ°ä¿¡è™Ÿï¼Œå¯èƒ½æœ‰å•é¡Œ
                if time.time() - self.signal_stats['last_reset_time'] > 3600 and total_signals == 0:
                    logger.warning("âš ï¸ å­¸ç¿’å®Œæ•´æ€§æª¢æŸ¥: 1å°æ™‚å…§æœªè¿½è¹¤åˆ°ä»»ä½•å­¸ç¿’ä¿¡è™Ÿ")
                    return False
                    
                logger.debug(f"âœ… å­¸ç¿’å®Œæ•´æ€§æª¢æŸ¥: å·²è¿½è¹¤ {total_signals} å€‹ä¿¡è™Ÿ")
                return True
            
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ å­¸ç¿’å®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: {e}")
            return False
    
    async def _validate_backtest_data_integrity(self) -> bool:
        """éšæ®µ4: é©—è­‰å›æ¸¬æ•¸æ“šå®Œæ•´æ€§"""
        try:
            # æª¢æŸ¥åƒ¹æ ¼ç·©å­˜æ•¸æ“šæ˜¯å¦æ­£å¸¸
            if hasattr(self.phase1a_generator, 'price_buffer'):
                buffer_symbols = len(self.phase1a_generator.price_buffer)
                total_price_points = sum(len(buffer) for buffer in self.phase1a_generator.price_buffer.values())
                
                if buffer_symbols > 0 and total_price_points > 0:
                    avg_points = total_price_points / buffer_symbols
                    logger.debug(f"âœ… å›æ¸¬æ•¸æ“šå®Œæ•´æ€§: {buffer_symbols} å€‹äº¤æ˜“å°ï¼Œå¹³å‡ {avg_points:.1f} å€‹åƒ¹æ ¼é»")
                    return True
                else:
                    logger.warning("âš ï¸ å›æ¸¬æ•¸æ“šå®Œæ•´æ€§: åƒ¹æ ¼ç·©å­˜ç‚ºç©º")
                    return False
            
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ å›æ¸¬æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥å¤±æ•—: {e}")
            return False
        """é¡¯ç¤ºæœ¬è¼ªçµ±è¨ˆæ‘˜è¦"""
        try:
            current_time = time.time()
            runtime_minutes = (current_time - self.signal_stats['last_reset_time']) / 60
            
            logger.info("="*60)
            logger.info("ğŸ“Š æœ¬è¼ªä¿¡è™Ÿç”Ÿæˆçµ±è¨ˆ")
            logger.info(f"â±ï¸ é‹è¡Œæ™‚é–“: {runtime_minutes:.1f} åˆ†é˜")
            logger.info(f"ğŸ¯ æœ¬è¼ªç¸½ä¿¡è™Ÿ: {self.signal_stats['signals_per_session']}")
            logger.info(f"ğŸ“ˆ ç´¯ç©ç¸½ä¿¡è™Ÿ: {self.signal_stats['total_signals_generated']}")
            
            # é¡¯ç¤ºå„äº¤æ˜“å°çµ±è¨ˆ
            if self.signal_stats['signals_per_symbol']:
                logger.info("ğŸ“‹ å„äº¤æ˜“å°çµ±è¨ˆ:")
                for symbol, count in self.signal_stats['signals_per_symbol'].items():
                    logger.info(f"   {symbol}: {count} å€‹ä¿¡è™Ÿ")
            
            # é‡ç½®æœ¬è¼ªçµ±è¨ˆ
            self.signal_stats['signals_per_session'] = 0
            self.signal_stats['last_reset_time'] = current_time
            
            logger.info("="*60)
            
        except Exception as e:
            logger.error(f"âŒ çµ±è¨ˆé¡¯ç¤ºå¤±æ•—: {e}")

async def main():
    """ä¸»å…¥å£å‡½æ•¸"""
    print("ğŸš€ Trading X ç”Ÿç”¢ç’°å¢ƒå•Ÿå‹•å™¨ (Phase2 åƒæ•¸ç®¡ç†å¢å¼·ç‰ˆ)")
    print("="*60)
    
    # å‰µå»ºä¸¦é‹è¡Œç³»çµ±
    system = ProductionTradingSystemPhase2Enhanced()
    await system.run()

if __name__ == "__main__":
    asyncio.run(main())
