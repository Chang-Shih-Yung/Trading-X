"""
ğŸ¯ Trading X - çœŸå¯¦æ•¸æ“šä¿¡è™Ÿè³ªé‡æ§åˆ¶å¼•æ“
åŸºæ–¼ç¾æœ‰ Phase1ABC + Phase2+3 çœŸå¯¦æ•¸æ“šæºçš„ä¿¡è™Ÿå“è³ªç›£æ§ç³»çµ±

çœŸå¯¦æ•¸æ“šæºï¼š
- Phase1B: app.services.phase1b_volatility_adaptation
- Phase1C: app.services.phase1c_signal_standardization  
- Phase3: app.services.phase3_market_analyzer
- pandas-ta æŠ€è¡“æŒ‡æ¨™ç³»çµ±
"""

import asyncio
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import numpy as np
import json

# å°å…¥çœŸå¯¦ç³»çµ±æ¨¡çµ„
from app.services.phase1b_volatility_adaptation import (
    VolatilityAdaptiveEngine, 
    VolatilityMetrics, 
    SignalContinuityMetrics
)
from app.services.phase1c_signal_standardization import (
    SignalStandardizationEngine,
    StandardizedSignal,
    ExtremeSignalMetrics
)
from app.services.phase3_market_analyzer import (
    Phase3MarketAnalyzer,
    OrderBookData,
    FundingRateData,
    Phase3Analysis
)
from app.services.pandas_ta_indicators import TechnicalIndicatorEngine
from app.services.signal_scoring_engine import signal_scoring_engine
from binance_data_connector import binance_connector

logger = logging.getLogger(__name__)

class SignalPriority(Enum):
    """ä¿¡è™Ÿå„ªå…ˆç´šåˆ†é¡"""
    CRITICAL = "critical"        # é«˜è³ªé‡ç¢ºèªä¿¡è™Ÿ
    HIGH = "high"               # å¼·ä¿¡è™Ÿ
    MEDIUM = "medium"           # ä¸­ç­‰ä¿¡è™Ÿ
    LOW = "low"                 # å¼±ä¿¡è™Ÿ
    REJECTED = "rejected"       # è¢«æ‹’çµ•ä¿¡è™Ÿ

class DataIntegrityStatus(Enum):
    """æ•¸æ“šå®Œæ•´æ€§ç‹€æ…‹"""
    COMPLETE = "complete"       # æ•¸æ“šå®Œæ•´
    PARTIAL = "partial"         # æ•¸æ“šéƒ¨åˆ†ç¼ºå¤±
    INCOMPLETE = "incomplete"   # æ•¸æ“šä¸å®Œæ•´
    INVALID = "invalid"         # æ•¸æ“šç„¡æ•ˆ

@dataclass
class RealTimeDataSnapshot:
    """å³æ™‚æ•¸æ“šå¿«ç…§"""
    timestamp: datetime
    
    # Phase1B æ³¢å‹•é©æ‡‰æ•¸æ“š
    volatility_metrics: Optional[VolatilityMetrics]
    signal_continuity: Optional[SignalContinuityMetrics]
    
    # Phase1C æ¨™æº–åŒ–æ•¸æ“š
    standardized_signals: List[StandardizedSignal]
    extreme_signals: Optional[ExtremeSignalMetrics]
    
    # Phase3 å¸‚å ´æ·±åº¦æ•¸æ“š
    order_book_analysis: Optional[OrderBookData]
    funding_rate_data: Optional[FundingRateData]
    
    # pandas-ta æŠ€è¡“æŒ‡æ¨™
    technical_indicators: Dict[str, float]
    
    # æ•¸æ“šå®Œæ•´æ€§ç‹€æ…‹
    data_integrity: DataIntegrityStatus
    missing_components: List[str]

@dataclass 
class SignalCandidate:
    """ä¿¡è™Ÿå€™é¸è€… - ç¬¬ä¸€éšæ®µç¯©é¸"""
    signal_id: str
    source_type: str  # "phase1b", "phase1c", "phase3", "pandas_ta"
    raw_signal_strength: float
    confidence_score: float
    data_quality_score: float
    timestamp: datetime
    
    # ä¾†æºæ•¸æ“šåƒè€ƒ
    source_data: Dict[str, Any]
    integrity_check: bool
    
    # åˆæ­¥è©•ä¼°
    preliminary_priority: SignalPriority
    quality_flags: List[str]

@dataclass
class EPLDecision:
    """åŸ·è¡Œç­–ç•¥å±¤æ±ºå®š - ç¬¬äºŒéšæ®µæ±ºç­–"""
    decision_id: str
    original_candidate: SignalCandidate
    
    # EPL æ±ºç­–åƒæ•¸
    market_context_score: float      # å¸‚å ´ç’°å¢ƒè©•åˆ†
    risk_assessment_score: float     # é¢¨éšªè©•ä¼°è©•åˆ†
    timing_optimization_score: float # æ™‚æ©Ÿå„ªåŒ–è©•åˆ†
    portfolio_fit_score: float       # çµ„åˆé©é…è©•åˆ†
    
    # æœ€çµ‚æ±ºç­–
    final_priority: SignalPriority
    execution_confidence: float
    recommended_action: str
    risk_management_params: Dict[str, Any]
    
    # æ±ºç­–ç†ç”±
    decision_reasoning: List[str]
    data_support_level: str

class RealDataSignalQualityEngine:
    """åŸºæ–¼çœŸå¯¦æ•¸æ“šçš„ä¿¡è™Ÿè³ªé‡æ§åˆ¶å¼•æ“"""
    
    def __init__(self):
        # åˆå§‹åŒ–çœŸå¯¦ç³»çµ±çµ„ä»¶
        self.volatility_engine = VolatilityAdaptiveEngine()
        self.standardization_engine = SignalStandardizationEngine()
        self.phase3_analyzer = Phase3MarketAnalyzer()
        self.technical_engine = TechnicalIndicatorEngine()
        
        # è³ªé‡æ§åˆ¶åƒæ•¸
        self.min_data_completeness = 0.8  # æœ€ä½æ•¸æ“šå®Œæ•´æ€§è¦æ±‚
        self.signal_memory_size = 100      # ä¿¡è™Ÿè¨˜æ†¶é«”å¤§å°
        self.recent_signals = []           # è¿‘æœŸä¿¡è™Ÿè¨˜éŒ„
        
        # å»é‡å’Œå„ªå…ˆç´šè¨­å®š
        self.deduplication_window = timedelta(minutes=5)
        self.priority_weights = {
            SignalPriority.CRITICAL: 1.0,
            SignalPriority.HIGH: 0.8,
            SignalPriority.MEDIUM: 0.6,
            SignalPriority.LOW: 0.4,
            SignalPriority.REJECTED: 0.0
        }
        
    async def collect_real_time_data(self, symbol: str = "BTCUSDT") -> RealTimeDataSnapshot:
        """æ”¶é›†å³æ™‚çœŸå¯¦æ•¸æ“š"""
        timestamp = datetime.now()
        missing_components = []
        
        try:
            # 1. æ”¶é›† Phase1B æ³¢å‹•é©æ‡‰æ•¸æ“š
            volatility_metrics = None
            signal_continuity = None
            try:
                # é€™è£¡æ‡‰è©²å‘¼å«çœŸå¯¦çš„ Phase1B æ•¸æ“š
                price_data = await self._get_recent_price_data(symbol)
                volatility_metrics = self.volatility_engine.calculate_volatility_metrics(price_data)
                signal_continuity = self.volatility_engine.analyze_signal_continuity([])
            except Exception as e:
                logger.warning(f"Phase1B æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
                missing_components.append("phase1b_data")
            
            # 2. æ”¶é›† Phase1C æ¨™æº–åŒ–æ•¸æ“š
            standardized_signals = []
            extreme_signals = None
            try:
                # ä½¿ç”¨çœŸå¯¦çš„æ¨™æº–åŒ–å¼•æ“
                raw_signals = await self._collect_raw_signals(symbol)
                standardized_signals = await self.standardization_engine.standardize_signals(raw_signals)
                extreme_signals = await self.standardization_engine.detect_extreme_signals(standardized_signals)
            except Exception as e:
                logger.warning(f"Phase1C æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
                missing_components.append("phase1c_data")
            
            # 3. æ”¶é›† Phase3 å¸‚å ´æ·±åº¦æ•¸æ“š
            order_book_analysis = None
            funding_rate_data = None
            try:
                phase3_data = await self.phase3_analyzer.analyze_market_depth(symbol)
                if phase3_data:
                    order_book_analysis = phase3_data.order_book
                    funding_rate_data = phase3_data.funding_rate
            except Exception as e:
                logger.warning(f"Phase3 æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
                missing_components.append("phase3_data")
            
            # 4. æ”¶é›† pandas-ta æŠ€è¡“æŒ‡æ¨™ + å¹£å®‰å¯¦æ™‚æ•¸æ“šå¢å¼·
            technical_indicators = {}
            try:
                # ä¸¦è¡Œç²å–æŠ€è¡“æŒ‡æ¨™å’Œå¹£å®‰å¸‚å ´æ•¸æ“š
                async with binance_connector as connector:
                    market_data_task = connector.get_comprehensive_market_data(symbol)
                    technical_task = self.technical_engine.calculate_all_indicators(symbol)
                    
                    market_data, tech_indicators = await asyncio.gather(
                        market_data_task, technical_task, return_exceptions=True
                    )
                    
                    # è™•ç†æŠ€è¡“æŒ‡æ¨™
                    if not isinstance(tech_indicators, Exception):
                        technical_indicators.update(tech_indicators)
                    
                    # æ•´åˆå¹£å®‰å¯¦æ™‚æ•¸æ“šåˆ°æŠ€è¡“æŒ‡æ¨™
                    if not isinstance(market_data, Exception) and market_data:
                        # æ·»åŠ å¯¦æ™‚åƒ¹æ ¼ä¿¡æ¯
                        technical_indicators["current_price"] = market_data.get("current_price", 0)
                        
                        # æ·»åŠ 24å°æ™‚è®Šå‹•ä¿¡æ¯
                        ticker_24h = market_data.get("ticker_24h", {})
                        if ticker_24h:
                            technical_indicators["price_change_24h"] = float(ticker_24h.get("priceChangePercent", 0))
                            technical_indicators["volume_24h"] = float(ticker_24h.get("volume", 0))
                            technical_indicators["high_24h"] = float(ticker_24h.get("highPrice", 0))
                            technical_indicators["low_24h"] = float(ticker_24h.get("lowPrice", 0))
                        
                        # æ·»åŠ æ³¢å‹•æ€§æŒ‡æ¨™
                        volatility_metrics = market_data.get("volatility_metrics", {})
                        if volatility_metrics:
                            technical_indicators["volatility"] = volatility_metrics.get("current_volatility", 0)
                            technical_indicators["returns_std"] = volatility_metrics.get("returns_std", 0)
                        
                        # æ·»åŠ æˆäº¤é‡åˆ†æ
                        volume_analysis = market_data.get("volume_analysis", {})
                        if volume_analysis:
                            technical_indicators["volume_trend"] = volume_analysis.get("volume_trend", 0)
                            technical_indicators["volume_ratio"] = volume_analysis.get("volume_ratio", 1)
                        
                        # æ·»åŠ è³‡é‡‘è²»ç‡ï¼ˆæœŸè²¨æ•¸æ“šï¼‰
                        funding_rate = market_data.get("funding_rate", {})
                        if funding_rate:
                            technical_indicators["funding_rate"] = float(funding_rate.get("fundingRate", 0))
                        
                        # æ·»åŠ è¨‚å–®ç°¿å£“åŠ›
                        order_book = market_data.get("order_book", {})
                        if order_book and "bids" in order_book and "asks" in order_book:
                            bids = order_book["bids"][:5]
                            asks = order_book["asks"][:5]
                            bid_volume = sum(float(bid[1]) for bid in bids)
                            ask_volume = sum(float(ask[1]) for ask in asks)
                            
                            if bid_volume + ask_volume > 0:
                                technical_indicators["order_pressure"] = (bid_volume - ask_volume) / (bid_volume + ask_volume)
                                technical_indicators["total_book_volume"] = bid_volume + ask_volume
                        
                        logger.info(f"æˆåŠŸæ•´åˆå¹£å®‰å¯¦æ™‚æ•¸æ“šåˆ°æŠ€è¡“æŒ‡æ¨™ï¼Œç¸½è¨ˆ {len(technical_indicators)} å€‹æŒ‡æ¨™")
                    
            except Exception as e:
                logger.warning(f"pandas-ta + å¹£å®‰æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
                missing_components.append("technical_indicators")
            
            # åˆ¤æ–·æ•¸æ“šå®Œæ•´æ€§
            total_components = 4
            missing_count = len(missing_components)
            completeness_ratio = (total_components - missing_count) / total_components
            
            if completeness_ratio >= 0.9:
                data_integrity = DataIntegrityStatus.COMPLETE
            elif completeness_ratio >= 0.7:
                data_integrity = DataIntegrityStatus.PARTIAL
            elif completeness_ratio >= 0.5:
                data_integrity = DataIntegrityStatus.INCOMPLETE
            else:
                data_integrity = DataIntegrityStatus.INVALID
            
            return RealTimeDataSnapshot(
                timestamp=timestamp,
                volatility_metrics=volatility_metrics,
                signal_continuity=signal_continuity,
                standardized_signals=standardized_signals,
                extreme_signals=extreme_signals,
                order_book_analysis=order_book_analysis,
                funding_rate_data=funding_rate_data,
                technical_indicators=technical_indicators,
                data_integrity=data_integrity,
                missing_components=missing_components
            )
            
        except Exception as e:
            logger.error(f"å³æ™‚æ•¸æ“šæ”¶é›†å¤±æ•—: {e}")
            return RealTimeDataSnapshot(
                timestamp=timestamp,
                volatility_metrics=None,
                signal_continuity=None,
                standardized_signals=[],
                extreme_signals=None,
                order_book_analysis=None,
                funding_rate_data=None,
                technical_indicators={},
                data_integrity=DataIntegrityStatus.INVALID,
                missing_components=["all_components"]
            )
    
    async def stage1_signal_candidate_pool(self, data_snapshot: RealTimeDataSnapshot) -> List[SignalCandidate]:
        """ç¬¬ä¸€éšæ®µï¼šä¿¡è™Ÿå€™é¸è€…æ± ç”Ÿæˆ"""
        candidates = []
        
        # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
        if data_snapshot.data_integrity == DataIntegrityStatus.INVALID:
            logger.warning("æ•¸æ“šå®Œæ•´æ€§ç„¡æ•ˆï¼Œè·³éä¿¡è™Ÿç”Ÿæˆ")
            return candidates
        
        # 1. Phase1B æ³¢å‹•é©æ‡‰ä¿¡è™Ÿ
        if data_snapshot.volatility_metrics and data_snapshot.signal_continuity:
            candidate = self._create_phase1b_candidate(
                data_snapshot.volatility_metrics,
                data_snapshot.signal_continuity,
                data_snapshot.timestamp
            )
            if candidate:
                candidates.append(candidate)
        
        # 2. Phase1C æ¨™æº–åŒ–ä¿¡è™Ÿ
        for standardized_signal in data_snapshot.standardized_signals:
            candidate = self._create_phase1c_candidate(
                standardized_signal,
                data_snapshot.extreme_signals,
                data_snapshot.timestamp
            )
            if candidate:
                candidates.append(candidate)
        
        # 3. Phase3 å¸‚å ´æ·±åº¦ä¿¡è™Ÿ
        if data_snapshot.order_book_analysis and data_snapshot.funding_rate_data:
            candidate = self._create_phase3_candidate(
                data_snapshot.order_book_analysis,
                data_snapshot.funding_rate_data,
                data_snapshot.timestamp
            )
            if candidate:
                candidates.append(candidate)
        
        # 4. pandas-ta æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿ
        if data_snapshot.technical_indicators:
            tech_candidates = self._create_technical_candidates(
                data_snapshot.technical_indicators,
                data_snapshot.timestamp
            )
            candidates.extend(tech_candidates)
        
        # å»é‡è™•ç†
        candidates = self._deduplicate_candidates(candidates)
        
        logger.info(f"ç¬¬ä¸€éšæ®µç”Ÿæˆ {len(candidates)} å€‹ä¿¡è™Ÿå€™é¸è€…")
        return candidates
    
    async def stage2_epl_decision_layer(self, candidates: List[SignalCandidate], 
                                      market_context: Dict[str, Any]) -> List[EPLDecision]:
        """ç¬¬äºŒéšæ®µï¼šåŸ·è¡Œç­–ç•¥å±¤æ±ºç­–"""
        decisions = []
        
        for candidate in candidates:
            # å¸‚å ´ç’°å¢ƒè©•ä¼°
            market_score = self._evaluate_market_context(candidate, market_context)
            
            # é¢¨éšªè©•ä¼°
            risk_score = self._assess_signal_risk(candidate, market_context)
            
            # æ™‚æ©Ÿå„ªåŒ–è©•ä¼°
            timing_score = self._optimize_signal_timing(candidate, market_context)
            
            # çµ„åˆé©é…è©•ä¼°
            portfolio_score = self._evaluate_portfolio_fit(candidate, market_context)
            
            # ç¶œåˆæ±ºç­–è¨ˆç®—
            decision = self._make_epl_decision(
                candidate, market_score, risk_score, timing_score, portfolio_score
            )
            
            decisions.append(decision)
        
        # æŒ‰å„ªå…ˆç´šæ’åº
        decisions.sort(
            key=lambda d: (
                self.priority_weights[d.final_priority],
                d.execution_confidence
            ),
            reverse=True
        )
        
        logger.info(f"ç¬¬äºŒéšæ®µç”¢ç”Ÿ {len(decisions)} å€‹åŸ·è¡Œæ±ºç­–")
        return decisions
    
    def _create_phase1b_candidate(self, volatility: VolatilityMetrics, 
                                 continuity: SignalContinuityMetrics,
                                 timestamp: datetime) -> Optional[SignalCandidate]:
        """å‰µå»º Phase1B ä¿¡è™Ÿå€™é¸è€…"""
        try:
            # è¨ˆç®—ä¿¡è™Ÿå¼·åº¦ï¼ˆåŸºæ–¼æ³¢å‹•æ€§å’Œé€£çºŒæ€§ï¼‰
            signal_strength = (
                volatility.current_volatility * 0.3 +
                continuity.signal_persistence * 0.4 +
                continuity.consensus_strength * 0.3
            )
            
            # ä¿¡å¿ƒè©•åˆ†
            confidence = (
                volatility.regime_stability * 0.4 +
                continuity.temporal_consistency * 0.3 +
                continuity.cross_module_correlation * 0.3
            )
            
            # æ•¸æ“šè³ªé‡è©•åˆ†
            data_quality = min(1.0, (
                (1.0 if volatility.current_volatility > 0 else 0.0) +
                (1.0 if continuity.signal_persistence > 0 else 0.0) +
                (1.0 if continuity.consensus_strength > 0 else 0.0)
            ) / 3.0)
            
            # åˆæ­¥å„ªå…ˆç´šåˆ¤æ–·
            if signal_strength >= 0.8 and confidence >= 0.75:
                priority = SignalPriority.CRITICAL
            elif signal_strength >= 0.6 and confidence >= 0.6:
                priority = SignalPriority.HIGH
            elif signal_strength >= 0.4 and confidence >= 0.4:
                priority = SignalPriority.MEDIUM
            elif signal_strength >= 0.2:
                priority = SignalPriority.LOW
            else:
                priority = SignalPriority.REJECTED
            
            return SignalCandidate(
                signal_id=f"phase1b_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                source_type="phase1b",
                raw_signal_strength=signal_strength,
                confidence_score=confidence,
                data_quality_score=data_quality,
                timestamp=timestamp,
                source_data={
                    "volatility_metrics": asdict(volatility),
                    "continuity_metrics": asdict(continuity)
                },
                integrity_check=data_quality >= 0.7,
                preliminary_priority=priority,
                quality_flags=self._generate_quality_flags("phase1b", signal_strength, confidence)
            )
            
        except Exception as e:
            logger.error(f"Phase1B å€™é¸è€…å‰µå»ºå¤±æ•—: {e}")
            return None
    
    def _create_phase1c_candidate(self, signal: StandardizedSignal,
                                 extreme_metrics: Optional[ExtremeSignalMetrics],
                                 timestamp: datetime) -> Optional[SignalCandidate]:
        """å‰µå»º Phase1C ä¿¡è™Ÿå€™é¸è€…"""
        try:
            # ä½¿ç”¨æ¨™æº–åŒ–å¾Œçš„ä¿¡è™Ÿå¼·åº¦
            signal_strength = signal.standardized_value
            confidence = signal.quality_score
            
            # è€ƒæ…®æ¥µç«¯ä¿¡è™ŸåŠ æˆ
            if extreme_metrics and signal.is_extreme:
                signal_strength *= 1.2  # æ¥µç«¯ä¿¡è™ŸåŠ æˆ
                confidence *= 1.1
            
            # é™åˆ¶åœ¨ 0-1 ç¯„åœ
            signal_strength = min(1.0, max(0.0, signal_strength))
            confidence = min(1.0, max(0.0, confidence))
            
            # æ•¸æ“šè³ªé‡åŸºæ–¼ä¿¡è™Ÿè™•ç†å®Œæ•´æ€§
            data_quality = 0.9 if signal.standardized_value > 0 else 0.1
            
            # å„ªå…ˆç´šåˆ¤æ–·
            if signal_strength >= 0.85 and confidence >= 0.8:
                priority = SignalPriority.CRITICAL
            elif signal_strength >= 0.7 and confidence >= 0.65:
                priority = SignalPriority.HIGH
            elif signal_strength >= 0.5 and confidence >= 0.5:
                priority = SignalPriority.MEDIUM
            elif signal_strength >= 0.3:
                priority = SignalPriority.LOW
            else:
                priority = SignalPriority.REJECTED
            
            return SignalCandidate(
                signal_id=f"phase1c_{signal.signal_id}_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                source_type="phase1c",
                raw_signal_strength=signal_strength,
                confidence_score=confidence,
                data_quality_score=data_quality,
                timestamp=timestamp,
                source_data={
                    "standardized_signal": asdict(signal),
                    "extreme_metrics": asdict(extreme_metrics) if extreme_metrics else None
                },
                integrity_check=data_quality >= 0.7,
                preliminary_priority=priority,
                quality_flags=self._generate_quality_flags("phase1c", signal_strength, confidence)
            )
            
        except Exception as e:
            logger.error(f"Phase1C å€™é¸è€…å‰µå»ºå¤±æ•—: {e}")
            return None
    
    def _create_phase3_candidate(self, order_book: OrderBookData,
                                funding_rate: FundingRateData,
                                timestamp: datetime) -> Optional[SignalCandidate]:
        """å‰µå»º Phase3 ä¿¡è™Ÿå€™é¸è€…"""
        try:
            # åŸºæ–¼å¸‚å ´æ·±åº¦å’Œè³‡é‡‘è²»ç‡è¨ˆç®—ä¿¡è™Ÿå¼·åº¦
            pressure_strength = abs(order_book.pressure_ratio)  # å¸‚å ´å£“åŠ›å¼·åº¦
            funding_strength = abs(funding_rate.funding_rate) * 100  # è³‡é‡‘è²»ç‡å¼·åº¦
            
            # ç¶œåˆä¿¡è™Ÿå¼·åº¦
            signal_strength = min(1.0, (pressure_strength * 0.6 + funding_strength * 0.4))
            
            # ä¿¡å¿ƒè©•åˆ†åŸºæ–¼æ•¸æ“šå¯é æ€§
            spread_quality = 1.0 - min(1.0, order_book.bid_ask_spread / order_book.mid_price * 100)
            volume_quality = min(1.0, (order_book.total_bid_volume + order_book.total_ask_volume) / 1000000)
            confidence = (spread_quality * 0.5 + volume_quality * 0.5)
            
            # æ•¸æ“šè³ªé‡
            data_quality = 0.95 if order_book.mid_price > 0 and funding_rate.mark_price > 0 else 0.1
            
            # å„ªå…ˆç´šåˆ¤æ–·
            if signal_strength >= 0.8 and confidence >= 0.75:
                priority = SignalPriority.CRITICAL
            elif signal_strength >= 0.6 and confidence >= 0.6:
                priority = SignalPriority.HIGH
            elif signal_strength >= 0.4 and confidence >= 0.45:
                priority = SignalPriority.MEDIUM
            elif signal_strength >= 0.2:
                priority = SignalPriority.LOW
            else:
                priority = SignalPriority.REJECTED
            
            return SignalCandidate(
                signal_id=f"phase3_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                source_type="phase3",
                raw_signal_strength=signal_strength,
                confidence_score=confidence,
                data_quality_score=data_quality,
                timestamp=timestamp,
                source_data={
                    "order_book": asdict(order_book),
                    "funding_rate": asdict(funding_rate)
                },
                integrity_check=data_quality >= 0.7,
                preliminary_priority=priority,
                quality_flags=self._generate_quality_flags("phase3", signal_strength, confidence)
            )
            
        except Exception as e:
            logger.error(f"Phase3 å€™é¸è€…å‰µå»ºå¤±æ•—: {e}")
            return None
    
    def _create_technical_candidates(self, indicators: Dict[str, float],
                                   timestamp: datetime) -> List[SignalCandidate]:
        """å‰µå»º pandas-ta æŠ€è¡“æŒ‡æ¨™å€™é¸è€…"""
        candidates = []
        
        # ä¸»è¦æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿ
        key_indicators = {
            "RSI": indicators.get("RSI", 50),
            "MACD": indicators.get("MACD", 0),
            "BB_position": indicators.get("BB_position", 0.5),
            "volume_trend": indicators.get("volume_trend", 0)
        }
        
        for indicator_name, value in key_indicators.items():
            try:
                # æ ¹æ“šä¸åŒæŒ‡æ¨™è¨ˆç®—ä¿¡è™Ÿå¼·åº¦
                signal_strength = self._calculate_indicator_strength(indicator_name, value)
                confidence = 0.7  # æŠ€è¡“æŒ‡æ¨™çš„åŸºç¤ä¿¡å¿ƒåº¦
                data_quality = 0.8 if value != 0 else 0.2
                
                # å„ªå…ˆç´šåˆ¤æ–·
                if signal_strength >= 0.8:
                    priority = SignalPriority.HIGH
                elif signal_strength >= 0.6:
                    priority = SignalPriority.MEDIUM
                elif signal_strength >= 0.4:
                    priority = SignalPriority.LOW
                else:
                    priority = SignalPriority.REJECTED
                
                candidate = SignalCandidate(
                    signal_id=f"tech_{indicator_name}_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                    source_type="pandas_ta",
                    raw_signal_strength=signal_strength,
                    confidence_score=confidence,
                    data_quality_score=data_quality,
                    timestamp=timestamp,
                    source_data={
                        "indicator": indicator_name,
                        "value": value,
                        "all_indicators": indicators
                    },
                    integrity_check=data_quality >= 0.5,
                    preliminary_priority=priority,
                    quality_flags=self._generate_quality_flags("technical", signal_strength, confidence)
                )
                
                candidates.append(candidate)
                
            except Exception as e:
                logger.error(f"æŠ€è¡“æŒ‡æ¨™ {indicator_name} å€™é¸è€…å‰µå»ºå¤±æ•—: {e}")
                continue
        
        return candidates
    
    def _deduplicate_candidates(self, candidates: List[SignalCandidate]) -> List[SignalCandidate]:
        """å»é‡ä¿¡è™Ÿå€™é¸è€…"""
        # æŒ‰ä¾†æºé¡å‹å’Œæ™‚é–“æˆ³åˆ†çµ„å»é‡
        deduplicated = {}
        
        for candidate in candidates:
            # å‰µå»ºå»é‡éµå€¼
            dedup_key = f"{candidate.source_type}_{candidate.timestamp.strftime('%Y%m%d_%H%M')}"
            
            # ä¿ç•™ä¿¡è™Ÿå¼·åº¦æœ€é«˜çš„å€™é¸è€…
            if dedup_key not in deduplicated or \
               candidate.raw_signal_strength > deduplicated[dedup_key].raw_signal_strength:
                deduplicated[dedup_key] = candidate
        
        return list(deduplicated.values())
    
    def _evaluate_market_context(self, candidate: SignalCandidate, context: Dict[str, Any]) -> float:
        """è©•ä¼°å¸‚å ´ç’°å¢ƒ"""
        try:
            # å¸‚å ´è¶¨å‹¢è©•åˆ†
            trend_score = context.get("market_trend", 0.5)
            
            # æ³¢å‹•æ€§è©•åˆ†
            volatility_score = 1.0 - min(1.0, context.get("volatility", 0.5))
            
            # æµå‹•æ€§è©•åˆ†
            liquidity_score = context.get("liquidity", 0.7)
            
            # ç¶œåˆå¸‚å ´ç’°å¢ƒè©•åˆ†
            market_score = (trend_score * 0.4 + volatility_score * 0.3 + liquidity_score * 0.3)
            
            return min(1.0, max(0.0, market_score))
            
        except Exception as e:
            logger.error(f"å¸‚å ´ç’°å¢ƒè©•ä¼°å¤±æ•—: {e}")
            return 0.5
    
    def _assess_signal_risk(self, candidate: SignalCandidate, context: Dict[str, Any]) -> float:
        """è©•ä¼°ä¿¡è™Ÿé¢¨éšª"""
        try:
            # æ•¸æ“šè³ªé‡é¢¨éšª
            data_risk = 1.0 - candidate.data_quality_score
            
            # ä¿¡è™Ÿå¼·åº¦é¢¨éšªï¼ˆå¼·åº¦éä½æˆ–éé«˜éƒ½æœ‰é¢¨éšªï¼‰
            strength_risk = abs(candidate.raw_signal_strength - 0.7) / 0.7
            
            # å¸‚å ´ç’°å¢ƒé¢¨éšª
            market_risk = context.get("market_uncertainty", 0.3)
            
            # ç¶œåˆé¢¨éšªè©•åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
            total_risk = (data_risk * 0.4 + strength_risk * 0.3 + market_risk * 0.3)
            
            # è½‰æ›ç‚ºé¢¨éšªè©•åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
            risk_score = 1.0 - min(1.0, total_risk)
            
            return max(0.0, risk_score)
            
        except Exception as e:
            logger.error(f"é¢¨éšªè©•ä¼°å¤±æ•—: {e}")
            return 0.5
    
    def _optimize_signal_timing(self, candidate: SignalCandidate, context: Dict[str, Any]) -> float:
        """å„ªåŒ–ä¿¡è™Ÿæ™‚æ©Ÿ"""
        try:
            # å¸‚å ´é–‹æ”¾æ™‚é–“è©•åˆ†
            current_hour = candidate.timestamp.hour
            market_hours_score = 1.0 if 9 <= current_hour <= 21 else 0.7
            
            # ä¿¡è™Ÿæ–°é®®åº¦è©•åˆ†
            age_minutes = (datetime.now() - candidate.timestamp).total_seconds() / 60
            freshness_score = max(0.1, 1.0 - age_minutes / 60)  # 1å°æ™‚å…§æœ‰æ•ˆ
            
            # å¸‚å ´æ´»èºåº¦è©•åˆ†
            activity_score = context.get("market_activity", 0.7)
            
            # ç¶œåˆæ™‚æ©Ÿè©•åˆ†
            timing_score = (market_hours_score * 0.3 + freshness_score * 0.4 + activity_score * 0.3)
            
            return min(1.0, max(0.0, timing_score))
            
        except Exception as e:
            logger.error(f"æ™‚æ©Ÿå„ªåŒ–å¤±æ•—: {e}")
            return 0.6
    
    def _evaluate_portfolio_fit(self, candidate: SignalCandidate, context: Dict[str, Any]) -> float:
        """è©•ä¼°çµ„åˆé©é…åº¦"""
        try:
            # ä¿¡è™Ÿé¡å‹å¤šæ¨£æ€§è©•åˆ†
            recent_types = [s.source_type for s in self.recent_signals[-10:]]
            diversity_score = 1.0 - (recent_types.count(candidate.source_type) / max(1, len(recent_types)))
            
            # å„ªå…ˆç´šå¹³è¡¡è©•åˆ†
            recent_priorities = [s.preliminary_priority for s in self.recent_signals[-10:]]
            balance_score = 0.8 if candidate.preliminary_priority not in recent_priorities[-3:] else 0.5
            
            # çµ„åˆé©é…è©•åˆ†
            portfolio_score = (diversity_score * 0.6 + balance_score * 0.4)
            
            return min(1.0, max(0.0, portfolio_score))
            
        except Exception as e:
            logger.error(f"çµ„åˆé©é…è©•ä¼°å¤±æ•—: {e}")
            return 0.7
    
    def _make_epl_decision(self, candidate: SignalCandidate, market_score: float,
                          risk_score: float, timing_score: float, 
                          portfolio_score: float) -> EPLDecision:
        """é€²è¡Œ EPL æœ€çµ‚æ±ºç­–"""
        
        # ç¶œåˆåŸ·è¡Œä¿¡å¿ƒåº¦è¨ˆç®—
        execution_confidence = (
            candidate.confidence_score * 0.25 +
            market_score * 0.25 +
            risk_score * 0.25 +
            timing_score * 0.15 +
            portfolio_score * 0.1
        )
        
        # æœ€çµ‚å„ªå…ˆç´šæ±ºç­–
        if execution_confidence >= 0.85 and candidate.preliminary_priority in [SignalPriority.CRITICAL, SignalPriority.HIGH]:
            final_priority = SignalPriority.CRITICAL
            recommended_action = "EXECUTE_IMMEDIATELY"
        elif execution_confidence >= 0.7 and candidate.preliminary_priority != SignalPriority.REJECTED:
            final_priority = SignalPriority.HIGH
            recommended_action = "EXECUTE_WITH_CAUTION"
        elif execution_confidence >= 0.5:
            final_priority = SignalPriority.MEDIUM
            recommended_action = "MONITOR_AND_PREPARE"
        elif execution_confidence >= 0.3:
            final_priority = SignalPriority.LOW
            recommended_action = "LOW_PRIORITY_WATCH"
        else:
            final_priority = SignalPriority.REJECTED
            recommended_action = "REJECT_SIGNAL"
        
        # é¢¨éšªç®¡ç†åƒæ•¸
        risk_params = {
            "stop_loss_ratio": max(0.01, 0.05 * (1 - risk_score)),
            "take_profit_ratio": min(0.1, 0.03 * execution_confidence),
            "position_size_ratio": min(0.2, 0.1 * execution_confidence),
            "max_holding_time": int(60 * execution_confidence)  # åˆ†é˜
        }
        
        # æ±ºç­–ç†ç”±
        reasoning = [
            f"åŸ·è¡Œä¿¡å¿ƒåº¦: {execution_confidence:.3f}",
            f"å¸‚å ´ç’°å¢ƒè©•åˆ†: {market_score:.3f}",
            f"é¢¨éšªè©•ä¼°è©•åˆ†: {risk_score:.3f}",
            f"æ™‚æ©Ÿå„ªåŒ–è©•åˆ†: {timing_score:.3f}",
            f"çµ„åˆé©é…è©•åˆ†: {portfolio_score:.3f}"
        ]
        
        # æ•¸æ“šæ”¯æ’æ°´å¹³
        data_support = "STRONG" if candidate.data_quality_score >= 0.8 else \
                      "MODERATE" if candidate.data_quality_score >= 0.6 else "WEAK"
        
        return EPLDecision(
            decision_id=f"epl_{candidate.signal_id}",
            original_candidate=candidate,
            market_context_score=market_score,
            risk_assessment_score=risk_score,
            timing_optimization_score=timing_score,
            portfolio_fit_score=portfolio_score,
            final_priority=final_priority,
            execution_confidence=execution_confidence,
            recommended_action=recommended_action,
            risk_management_params=risk_params,
            decision_reasoning=reasoning,
            data_support_level=data_support
        )
    
    def _generate_quality_flags(self, source_type: str, strength: float, confidence: float) -> List[str]:
        """ç”Ÿæˆè³ªé‡æ¨™è¨˜"""
        flags = []
        
        if strength < 0.3:
            flags.append("WEAK_SIGNAL")
        elif strength > 0.9:
            flags.append("EXTREME_SIGNAL")
        
        if confidence < 0.4:
            flags.append("LOW_CONFIDENCE")
        elif confidence > 0.85:
            flags.append("HIGH_CONFIDENCE")
        
        if source_type == "phase1b" and strength > 0.7:
            flags.append("VOLATILITY_CONFIRMED")
        elif source_type == "phase1c" and strength > 0.8:
            flags.append("STANDARDIZED_STRONG")
        elif source_type == "phase3" and strength > 0.6:
            flags.append("MARKET_DEPTH_CONFIRMED")
        
        return flags
    
    def _calculate_indicator_strength(self, indicator: str, value: float) -> float:
        """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™å¼·åº¦"""
        try:
            if indicator == "RSI":
                if value <= 20 or value >= 80:
                    return 0.9  # æ¥µç«¯å€åŸŸ
                elif value <= 30 or value >= 70:
                    return 0.7  # è¶…è²·è¶…è³£
                else:
                    return 0.3  # ä¸­æ€§å€åŸŸ
            
            elif indicator == "MACD":
                return min(1.0, abs(value) * 10)  # MACD çµ•å°å€¼è¶Šå¤§ä¿¡è™Ÿè¶Šå¼·
            
            elif indicator == "BB_position":
                return abs(value - 0.5) * 2  # é›¢ä¸­è»¸è¶Šé ä¿¡è™Ÿè¶Šå¼·
            
            elif indicator == "volume_trend":
                return min(1.0, abs(value))
            
            else:
                return min(1.0, abs(value))
                
        except Exception as e:
            logger.error(f"æŒ‡æ¨™å¼·åº¦è¨ˆç®—å¤±æ•— {indicator}: {e}")
            return 0.0
    
    async def _get_recent_price_data(self, symbol: str) -> List[float]:
        """ç²å–è¿‘æœŸåƒ¹æ ¼æ•¸æ“š - åƒ…ä½¿ç”¨çœŸå¯¦å¹£å®‰API"""
        try:
            async with binance_connector as connector:
                # ç²å–æœ€è¿‘100å€‹1åˆ†é˜Kç·šæ•¸æ“š
                price_series = await connector.calculate_price_series(symbol, 100)
                
                if price_series and len(price_series) >= 5:
                    logger.info(f"æˆåŠŸç²å– {symbol} çœŸå¯¦åƒ¹æ ¼æ•¸æ“š: {len(price_series)} å€‹æ•¸æ“šé»")
                    return price_series
                else:
                    logger.error(f"åƒ¹æ ¼æ•¸æ“šä¸è¶³æˆ–ç²å–å¤±æ•—: {len(price_series) if price_series else 0}")
                    raise Exception("çœŸå¯¦åƒ¹æ ¼æ•¸æ“šç²å–å¤±æ•—")
                        
        except Exception as e:
            logger.error(f"çœŸå¯¦åƒ¹æ ¼æ•¸æ“šç²å–å¤±æ•—: {e}")
            raise Exception(f"ç„¡æ³•ç²å– {symbol} çš„çœŸå¯¦åƒ¹æ ¼æ•¸æ“š: {e}")
    
    async def _collect_raw_signals(self, symbol: str) -> List[Dict[str, Any]]:
        """æ”¶é›†åŸå§‹ä¿¡è™Ÿ - åƒ…ä½¿ç”¨çœŸå¯¦å¹£å®‰å¸‚å ´æ•¸æ“š"""
        try:
            async with binance_connector as connector:
                # ç²å–ç¶œåˆå¸‚å ´æ•¸æ“š
                market_data = await connector.get_comprehensive_market_data(symbol)
                
                if not market_data or market_data.get("data_completeness", 0) < 0.5:
                    logger.error("å¸‚å ´æ•¸æ“šä¸å®Œæ•´æˆ–ç²å–å¤±æ•—")
                    raise Exception("çœŸå¯¦å¸‚å ´æ•¸æ“šç²å–å¤±æ•—")
                
                signals = []
                
                # 1. åŸºæ–¼24å°æ™‚åƒ¹æ ¼è®Šå‹•çš„è¶¨å‹¢ä¿¡è™Ÿ
                ticker_24h = market_data.get("ticker_24h", {})
                if ticker_24h:
                    price_change_pct = float(ticker_24h.get("priceChangePercent", 0))
                    trend_strength = min(1.0, abs(price_change_pct) / 5.0)  # 5%è®Šå‹•ç‚ºæ»¿å¼·åº¦
                    trend_confidence = min(1.0, float(ticker_24h.get("volume", 0)) / 10000)  # æˆäº¤é‡ä¿¡å¿ƒåº¦
                    
                    signals.append({
                        "module": "trend_24h",
                        "value": trend_strength * (1 if price_change_pct > 0 else -1),
                        "confidence": max(0.6, trend_confidence),
                        "source_data": {
                            "price_change_pct": price_change_pct,
                            "volume": ticker_24h.get("volume", 0)
                        }
                    })
                
                # 2. åŸºæ–¼æ³¢å‹•æ€§çš„å‹•é‡ä¿¡è™Ÿ
                volatility_metrics = market_data.get("volatility_metrics", {})
                if volatility_metrics:
                    volatility = volatility_metrics.get("current_volatility", 0)
                    momentum_strength = min(1.0, volatility * 20)  # æ³¢å‹•æ€§è½‰æ›ç‚ºå‹•é‡å¼·åº¦
                    momentum_confidence = 0.8 if volatility > 0.005 else 0.6
                    
                    signals.append({
                        "module": "momentum_volatility",
                        "value": momentum_strength,
                        "confidence": momentum_confidence,
                        "source_data": volatility_metrics
                    })
                
                # 3. åŸºæ–¼è¨‚å–®ç°¿çš„å£“åŠ›ä¿¡è™Ÿ
                order_book = market_data.get("order_book", {})
                if order_book and "bids" in order_book and "asks" in order_book:
                    bids = order_book["bids"][:5]  # å‰5æª”è²·å–®
                    asks = order_book["asks"][:5]  # å‰5æª”è³£å–®
                    
                    bid_volume = sum(float(bid[1]) for bid in bids)
                    ask_volume = sum(float(ask[1]) for ask in asks)
                    
                    if bid_volume + ask_volume > 0:
                        pressure_ratio = (bid_volume - ask_volume) / (bid_volume + ask_volume)
                        pressure_strength = abs(pressure_ratio)
                        pressure_confidence = min(1.0, (bid_volume + ask_volume) / 50)
                        
                        signals.append({
                            "module": "order_pressure",
                            "value": pressure_strength * (1 if pressure_ratio > 0 else -1),
                            "confidence": max(0.7, pressure_confidence),
                            "source_data": {
                                "bid_volume": bid_volume,
                                "ask_volume": ask_volume,
                                "pressure_ratio": pressure_ratio
                            }
                        })
                
                # 4. åŸºæ–¼è³‡é‡‘è²»ç‡çš„æœŸè²¨ä¿¡è™Ÿ
                funding_rate = market_data.get("funding_rate", {})
                if funding_rate and "fundingRate" in funding_rate:
                    funding_value = float(funding_rate["fundingRate"])
                    funding_strength = min(1.0, abs(funding_value) * 2000)  # è³‡é‡‘è²»ç‡ä¿¡è™Ÿå¼·åº¦
                    funding_confidence = 0.9  # è³‡é‡‘è²»ç‡æ•¸æ“šé€šå¸¸å¾ˆå¯é 
                    
                    signals.append({
                        "module": "funding_rate",
                        "value": funding_strength * (1 if funding_value > 0 else -1),
                        "confidence": funding_confidence,
                        "source_data": funding_rate
                    })
                
                # 5. åŸºæ–¼æˆäº¤é‡è¶¨å‹¢çš„ä¿¡è™Ÿ
                volume_analysis = market_data.get("volume_analysis", {})
                if volume_analysis:
                    volume_trend = volume_analysis.get("volume_trend", 0)
                    volume_strength = min(1.0, abs(volume_trend) * 2)
                    volume_confidence = 0.8
                    
                    signals.append({
                        "module": "volume_trend",
                        "value": volume_strength * (1 if volume_trend > 0 else -1),
                        "confidence": volume_confidence,
                        "source_data": volume_analysis
                    })
                
                if not signals:
                    logger.error("ç„¡æ³•å¾çœŸå¯¦å¸‚å ´æ•¸æ“šç”Ÿæˆæœ‰æ•ˆä¿¡è™Ÿ")
                    raise Exception("ä¿¡è™Ÿç”Ÿæˆå¤±æ•—")
                
                logger.info(f"æˆåŠŸæ”¶é›† {len(signals)} å€‹åŸºæ–¼çœŸå¯¦å¸‚å ´æ•¸æ“šçš„ä¿¡è™Ÿ")
                return signals
                    
        except Exception as e:
            logger.error(f"çœŸå¯¦ä¿¡è™Ÿæ”¶é›†å¤±æ•—: {e}")
            raise Exception(f"ç„¡æ³•æ”¶é›† {symbol} çš„çœŸå¯¦ä¿¡è™Ÿæ•¸æ“š: {e}")

# å…¨å±€å¯¦ä¾‹
real_data_engine = RealDataSignalQualityEngine()
