"""
ğŸ¯ Trading X - æ¸¬è©¦åŸ·è¡Œå™¨
çµ±ä¸€ç®¡ç†å’ŒåŸ·è¡Œæ‰€æœ‰æ¸¬è©¦è…³æœ¬
"""

import unittest
import asyncio
import sys
import os
from typing import List, Dict, Any
from datetime import datetime
import importlib.util

class TestRunner:
    """æ¸¬è©¦é‹è¡Œå™¨"""
    
    def __init__(self, base_path: str):
        self.base_path = base_path
        self.test_results = {}
        self.categories = ["unit", "integration", "flow", "performance"]
    
    def discover_tests(self, category: str) -> List[str]:
        """ç™¼ç¾æ¸¬è©¦æ–‡ä»¶"""
        category_path = os.path.join(self.base_path, "tests", category)
        test_files = []
        
        if os.path.exists(category_path):
            for file in os.listdir(category_path):
                if file.startswith("test_") and file.endswith(".py"):
                    test_files.append(os.path.join(category_path, file))
        
        return test_files
    
    def run_category_tests(self, category: str, verbose: bool = True) -> Dict[str, Any]:
        """é‹è¡Œç‰¹å®šé¡åˆ¥çš„æ¸¬è©¦"""
        print(f"\nğŸ§ª é–‹å§‹åŸ·è¡Œ {category.upper()} æ¸¬è©¦...")
        print("=" * 60)
        
        test_files = self.discover_tests(category)
        category_results = {
            "category": category,
            "total_files": len(test_files),
            "test_results": [],
            "summary": {"passed": 0, "failed": 0, "errors": 0}
        }
        
        for test_file in test_files:
            print(f"\nğŸ“„ åŸ·è¡Œæ¸¬è©¦æ–‡ä»¶: {os.path.basename(test_file)}")
            result = self._run_single_test_file(test_file, verbose)
            category_results["test_results"].append(result)
            
            # æ›´æ–°æ‘˜è¦
            if result["success"]:
                category_results["summary"]["passed"] += 1
            else:
                category_results["summary"]["failed"] += 1
                if result.get("has_errors", False):
                    category_results["summary"]["errors"] += 1
        
        self._print_category_summary(category_results)
        return category_results
    
    def _run_single_test_file(self, test_file: str, verbose: bool) -> Dict[str, Any]:
        """é‹è¡Œå–®å€‹æ¸¬è©¦æ–‡ä»¶"""
        try:
            # å‹•æ…‹è¼‰å…¥æ¸¬è©¦æ¨¡çµ„
            spec = importlib.util.spec_from_file_location("test_module", test_file)
            test_module = importlib.util.module_from_spec(spec)
            
            # æ·»åŠ åˆ° sys.modules ä»¥æ”¯æŒç›¸å°å°å…¥
            sys.modules["test_module"] = test_module
            spec.loader.exec_module(test_module)
            
            # å‰µå»ºæ¸¬è©¦å¥—ä»¶
            loader = unittest.TestLoader()
            suite = loader.loadTestsFromModule(test_module)
            
            # é‹è¡Œæ¸¬è©¦
            runner = unittest.TextTestRunner(
                verbosity=2 if verbose else 1,
                stream=sys.stdout
            )
            
            result = runner.run(suite)
            
            return {
                "file": os.path.basename(test_file),
                "tests_run": result.testsRun,
                "failures": len(result.failures),
                "errors": len(result.errors),
                "success": result.wasSuccessful(),
                "has_errors": len(result.errors) > 0
            }
            
        except Exception as e:
            print(f"âŒ åŸ·è¡Œæ¸¬è©¦æ–‡ä»¶ {os.path.basename(test_file)} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return {
                "file": os.path.basename(test_file),
                "tests_run": 0,
                "failures": 0,
                "errors": 1,
                "success": False,
                "has_errors": True,
                "error_message": str(e)
            }
    
    def _print_category_summary(self, results: Dict[str, Any]):
        """æ‰“å°é¡åˆ¥æ‘˜è¦"""
        print(f"\nğŸ“Š {results['category'].upper()} æ¸¬è©¦æ‘˜è¦:")
        print(f"   æ¸¬è©¦æ–‡ä»¶æ•¸é‡: {results['total_files']}")
        print(f"   é€šéæ–‡ä»¶: {results['summary']['passed']}")
        print(f"   å¤±æ•—æ–‡ä»¶: {results['summary']['failed']}")
        print(f"   éŒ¯èª¤æ–‡ä»¶: {results['summary']['errors']}")
        
        # è©³ç´°çµæœ
        for test_result in results["test_results"]:
            status = "âœ…" if test_result["success"] else "âŒ"
            print(f"   {status} {test_result['file']}: {test_result['tests_run']} tests")
    
    def run_all_tests(self, include_performance: bool = False) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("\nğŸš€ Trading X å®Œæ•´æ¸¬è©¦å¥—ä»¶")
        print("=" * 60)
        print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        categories_to_run = ["unit", "integration", "flow"]
        if include_performance:
            categories_to_run.append("performance")
        
        all_results = {
            "start_time": datetime.now().isoformat(),
            "categories": {},
            "overall_summary": {"total_passed": 0, "total_failed": 0, "total_errors": 0}
        }
        
        for category in categories_to_run:
            category_result = self.run_category_tests(category)
            all_results["categories"][category] = category_result
            
            # æ›´æ–°ç¸½é«”æ‘˜è¦
            all_results["overall_summary"]["total_passed"] += category_result["summary"]["passed"]
            all_results["overall_summary"]["total_failed"] += category_result["summary"]["failed"]
            all_results["overall_summary"]["total_errors"] += category_result["summary"]["errors"]
        
        all_results["end_time"] = datetime.now().isoformat()
        self._print_overall_summary(all_results)
        
        return all_results
    
    def _print_overall_summary(self, results: Dict[str, Any]):
        """æ‰“å°ç¸½é«”æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ¯ Trading X æ¸¬è©¦ç¸½é«”æ‘˜è¦")
        print("=" * 60)
        
        summary = results["overall_summary"]
        total_files = summary["total_passed"] + summary["total_failed"]
        
        print(f"ç¸½æ¸¬è©¦æ–‡ä»¶: {total_files}")
        print(f"âœ… é€šé: {summary['total_passed']}")
        print(f"âŒ å¤±æ•—: {summary['total_failed']}")
        print(f"âš ï¸  éŒ¯èª¤: {summary['total_errors']}")
        
        success_rate = (summary["total_passed"] / total_files * 100) if total_files > 0 else 0
        print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
        
        print(f"\nå®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # çµ¦å‡ºå»ºè­°
        if summary["total_failed"] == 0 and summary["total_errors"] == 0:
            print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼ç³»çµ±ç‹€æ…‹è‰¯å¥½ã€‚")
        else:
            print(f"\nâš ï¸  ç™¼ç¾ {summary['total_failed']} å€‹å¤±æ•—å’Œ {summary['total_errors']} å€‹éŒ¯èª¤ã€‚")
            print("å»ºè­°æª¢æŸ¥å¤±æ•—çš„æ¸¬è©¦ä¸¦ä¿®å¾©ç›¸é—œå•é¡Œã€‚")
    
    def run_quick_test(self) -> Dict[str, Any]:
        """å¿«é€Ÿæ¸¬è©¦ï¼ˆåªé‹è¡Œæ ¸å¿ƒæ¸¬è©¦ï¼‰"""
        print("\nâš¡ Trading X å¿«é€Ÿæ¸¬è©¦æ¨¡å¼")
        print("=" * 60)
        
        # åªé‹è¡Œå–®å…ƒæ¸¬è©¦å’Œæ•´åˆæ¸¬è©¦
        quick_results = {
            "mode": "quick",
            "start_time": datetime.now().isoformat(),
            "categories": {}
        }
        
        for category in ["unit", "integration"]:
            quick_results["categories"][category] = self.run_category_tests(category)
        
        quick_results["end_time"] = datetime.now().isoformat()
        return quick_results

def main():
    """ä¸»å‡½æ•¸"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    base_path = os.path.dirname(current_dir)  # å›åˆ° X ç›®éŒ„
    
    runner = TestRunner(base_path)
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == "quick":
            results = runner.run_quick_test()
        elif mode == "performance":
            results = runner.run_category_tests("performance")
        elif mode in ["unit", "integration", "flow"]:
            results = runner.run_category_tests(mode)
        elif mode == "all":
            include_perf = "--include-performance" in sys.argv
            results = runner.run_all_tests(include_performance=include_perf)
        else:
            print("âŒ æœªçŸ¥çš„æ¸¬è©¦æ¨¡å¼ã€‚å¯ç”¨æ¨¡å¼: quick, unit, integration, flow, performance, all")
            return
    else:
        # é»˜èªé‹è¡Œå¿«é€Ÿæ¸¬è©¦
        results = runner.run_quick_test()
    
    # ä¿å­˜çµæœåˆ°æ–‡ä»¶
    import json
    result_file = os.path.join(base_path, "test_results.json")
    with open(result_file, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“„ æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: {result_file}")

if __name__ == "__main__":
    main()
