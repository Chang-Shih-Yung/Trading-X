"""
ğŸ¯ Trading X - æ€§èƒ½æ¸¬è©¦ï¼šç³»çµ±æ€§èƒ½åŸºæº–æ¸¬è©¦
æ¸¬è©¦ç³»çµ±åœ¨ä¸åŒè² è¼‰ä¸‹çš„æ€§èƒ½è¡¨ç¾
"""

import unittest
import asyncio
import time
import statistics
from datetime import datetime
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor
import json

class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ¨™æ”¶é›†å™¨"""
    
    def __init__(self):
        self.metrics = {
            "response_times": [],
            "throughput": 0,
            "error_rate": 0,
            "memory_usage": [],
            "concurrent_users": 0
        }
    
    def add_response_time(self, response_time: float):
        """æ·»åŠ éŸ¿æ‡‰æ™‚é–“"""
        self.metrics["response_times"].append(response_time)
    
    def calculate_statistics(self) -> Dict[str, Any]:
        """è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™"""
        response_times = self.metrics["response_times"]
        
        if not response_times:
            return self.metrics
        
        return {
            **self.metrics,
            "avg_response_time": statistics.mean(response_times),
            "median_response_time": statistics.median(response_times),
            "min_response_time": min(response_times),
            "max_response_time": max(response_times),
            "p95_response_time": self._percentile(response_times, 95),
            "p99_response_time": self._percentile(response_times, 99)
        }
    
    def _percentile(self, data: List[float], percentile: int) -> float:
        """è¨ˆç®—ç™¾åˆ†ä½æ•¸"""
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]

class MockHighPerformanceEngine:
    """æ¨¡æ“¬é«˜æ€§èƒ½è™•ç†å¼•æ“"""
    
    def __init__(self):
        self.processed_count = 0
        self.error_count = 0
        self.processing_delay = 0.01  # 10ms åŸºæº–å»¶é²
    
    async def process_signal(self, signal_data: Dict[str, Any]) -> Dict[str, Any]:
        """è™•ç†ä¿¡è™Ÿï¼ˆæ¨¡æ“¬è¨ˆç®—å¯†é›†æ“ä½œï¼‰"""
        start_time = time.time()
        
        try:
            # æ¨¡æ“¬æŠ€è¡“æŒ‡æ¨™è¨ˆç®—
            await asyncio.sleep(self.processing_delay)
            
            # æ¨¡æ“¬è¤‡é›œè¨ˆç®—
            result = {
                "signal_id": signal_data.get("id", "unknown"),
                "symbol": signal_data.get("symbol", "BTCUSDT"),
                "processed_at": datetime.now().isoformat(),
                "computation_result": sum(range(100)),  # ç°¡å–®è¨ˆç®—
                "status": "success"
            }
            
            self.processed_count += 1
            
        except Exception as e:
            self.error_count += 1
            result = {
                "signal_id": signal_data.get("id", "unknown"),
                "status": "error",
                "error": str(e)
            }
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        return {
            **result,
            "processing_time": processing_time
        }
    
    async def batch_process(self, signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹æ¬¡è™•ç†ä¿¡è™Ÿ"""
        tasks = [self.process_signal(signal) for signal in signals]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # è™•ç†ç•°å¸¸
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                self.error_count += 1
                processed_results.append({
                    "status": "error",
                    "error": str(result)
                })
            else:
                processed_results.append(result)
        
        return processed_results

class TestSystemPerformance(unittest.TestCase):
    """æ¸¬è©¦ç³»çµ±æ€§èƒ½"""
    
    def setUp(self):
        """è¨­ç½®æ€§èƒ½æ¸¬è©¦ç’°å¢ƒ"""
        self.engine = MockHighPerformanceEngine()
        self.metrics = PerformanceMetrics()
    
    def test_single_signal_latency(self):
        """æ¸¬è©¦å–®ä¿¡è™Ÿè™•ç†å»¶é²"""
        signal = {"id": "test_001", "symbol": "BTCUSDT", "data": "test_data"}
        
        async def run_latency_test():
            results = []
            
            # åŸ·è¡Œå¤šæ¬¡æ¸¬è©¦
            for i in range(100):
                start_time = time.time()
                result = await self.engine.process_signal(signal)
                end_time = time.time()
                
                response_time = end_time - start_time
                self.metrics.add_response_time(response_time)
                results.append(result)
            
            return results
        
        results = asyncio.run(run_latency_test())
        stats = self.metrics.calculate_statistics()
        
        # æ€§èƒ½æ–·è¨€
        self.assertEqual(len(results), 100)
        self.assertLess(stats["avg_response_time"], 0.1)  # å¹³å‡éŸ¿æ‡‰æ™‚é–“ < 100ms
        self.assertLess(stats["p95_response_time"], 0.2)  # 95%éŸ¿æ‡‰æ™‚é–“ < 200ms
        
        print(f"ğŸ“Š å–®ä¿¡è™Ÿè™•ç†æ€§èƒ½:")
        print(f"   å¹³å‡éŸ¿æ‡‰æ™‚é–“: {stats['avg_response_time']:.3f}s")
        print(f"   P95éŸ¿æ‡‰æ™‚é–“: {stats['p95_response_time']:.3f}s")
        print(f"   P99éŸ¿æ‡‰æ™‚é–“: {stats['p99_response_time']:.3f}s")
    
    def test_batch_processing_throughput(self):
        """æ¸¬è©¦æ‰¹æ¬¡è™•ç†ååé‡"""
        batch_sizes = [10, 50, 100, 500]
        
        async def run_throughput_test():
            throughput_results = {}
            
            for batch_size in batch_sizes:
                signals = [
                    {"id": f"batch_{i}", "symbol": "BTCUSDT", "data": f"data_{i}"}
                    for i in range(batch_size)
                ]
                
                start_time = time.time()
                results = await self.engine.batch_process(signals)
                end_time = time.time()
                
                processing_time = end_time - start_time
                throughput = batch_size / processing_time
                
                throughput_results[batch_size] = {
                    "processing_time": processing_time,
                    "throughput": throughput,
                    "success_count": sum(1 for r in results if r.get("status") == "success")
                }
                
                # æ€§èƒ½æ–·è¨€
                self.assertEqual(len(results), batch_size)
                self.assertGreater(throughput, 10)  # è‡³å°‘ 10 ä¿¡è™Ÿ/ç§’
            
            return throughput_results
        
        throughput_results = asyncio.run(run_throughput_test())
        
        print(f"ğŸ“Š æ‰¹æ¬¡è™•ç†ååé‡æ¸¬è©¦:")
        for batch_size, result in throughput_results.items():
            print(f"   æ‰¹æ¬¡å¤§å° {batch_size}: {result['throughput']:.1f} ä¿¡è™Ÿ/ç§’")
    
    def test_concurrent_processing_stress(self):
        """æ¸¬è©¦ä¸¦ç™¼è™•ç†å£“åŠ›"""
        concurrent_levels = [1, 5, 10, 20]
        
        async def run_stress_test():
            stress_results = {}
            
            for concurrent_level in concurrent_levels:
                signals = [
                    {"id": f"stress_{i}", "symbol": "BTCUSDT"}
                    for i in range(concurrent_level * 10)
                ]
                
                start_time = time.time()
                
                # åˆ†æ‰¹ä¸¦ç™¼è™•ç†
                batch_size = 10
                tasks = []
                for i in range(0, len(signals), batch_size):
                    batch = signals[i:i + batch_size]
                    task = self.engine.batch_process(batch)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks)
                end_time = time.time()
                
                # è¨ˆç®—çµæœ
                total_processed = sum(len(batch_result) for batch_result in results)
                processing_time = end_time - start_time
                throughput = total_processed / processing_time
                
                stress_results[concurrent_level] = {
                    "total_processed": total_processed,
                    "processing_time": processing_time,
                    "throughput": throughput,
                    "error_rate": self.engine.error_count / total_processed if total_processed > 0 else 0
                }
                
                # æ€§èƒ½æ–·è¨€
                self.assertGreater(throughput, 5)  # å£“åŠ›ä¸‹è‡³å°‘ 5 ä¿¡è™Ÿ/ç§’
                self.assertLess(stress_results[concurrent_level]["error_rate"], 0.1)  # éŒ¯èª¤ç‡ < 10%
            
            return stress_results
        
        stress_results = asyncio.run(run_stress_test())
        
        print(f"ğŸ“Š ä¸¦ç™¼å£“åŠ›æ¸¬è©¦:")
        for level, result in stress_results.items():
            print(f"   ä¸¦ç™¼ç´šåˆ¥ {level}: {result['throughput']:.1f} ä¿¡è™Ÿ/ç§’, éŒ¯èª¤ç‡: {result['error_rate']:.2%}")
    
    def test_memory_usage_monitoring(self):
        """æ¸¬è©¦è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        
        async def run_memory_test():
            memory_readings = []
            
            # åŸºæº–è¨˜æ†¶é«”
            baseline_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_readings.append(baseline_memory)
            
            # è™•ç†å¤§é‡æ•¸æ“š
            for batch_num in range(10):
                signals = [
                    {"id": f"mem_test_{i}", "symbol": "BTCUSDT", "large_data": "x" * 1000}
                    for i in range(100)
                ]
                
                await self.engine.batch_process(signals)
                
                current_memory = process.memory_info().rss / 1024 / 1024  # MB
                memory_readings.append(current_memory)
            
            return memory_readings
        
        memory_readings = asyncio.run(run_memory_test())
        
        memory_increase = max(memory_readings) - min(memory_readings)
        
        # è¨˜æ†¶é«”ä½¿ç”¨æ–·è¨€
        self.assertLess(memory_increase, 100)  # è¨˜æ†¶é«”å¢é•· < 100MB
        
        print(f"ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨æ¸¬è©¦:")
        print(f"   åŸºæº–è¨˜æ†¶é«”: {memory_readings[0]:.1f} MB")
        print(f"   æœ€å¤§è¨˜æ†¶é«”: {max(memory_readings):.1f} MB")
        print(f"   è¨˜æ†¶é«”å¢é•·: {memory_increase:.1f} MB")
    
    def test_sustained_load_endurance(self):
        """æ¸¬è©¦æŒçºŒè² è¼‰è€åŠ›"""
        async def run_endurance_test():
            start_time = time.time()
            test_duration = 10  # 10ç§’è€åŠ›æ¸¬è©¦
            
            total_processed = 0
            error_count = 0
            
            while time.time() - start_time < test_duration:
                signals = [
                    {"id": f"endurance_{i}", "symbol": "BTCUSDT"}
                    for i in range(20)
                ]
                
                try:
                    results = await self.engine.batch_process(signals)
                    total_processed += len(results)
                    error_count += sum(1 for r in results if r.get("status") == "error")
                except Exception as e:
                    error_count += len(signals)
                
                # çŸ­æš«ä¼‘æ¯é¿å…éè¼‰
                await asyncio.sleep(0.1)
            
            actual_duration = time.time() - start_time
            throughput = total_processed / actual_duration
            error_rate = error_count / total_processed if total_processed > 0 else 1
            
            return {
                "duration": actual_duration,
                "total_processed": total_processed,
                "throughput": throughput,
                "error_rate": error_rate
            }
        
        result = asyncio.run(run_endurance_test())
        
        # è€åŠ›æ¸¬è©¦æ–·è¨€
        self.assertGreater(result["throughput"], 50)  # æŒçºŒååé‡ > 50 ä¿¡è™Ÿ/ç§’
        self.assertLess(result["error_rate"], 0.05)   # éŒ¯èª¤ç‡ < 5%
        
        print(f"ğŸ“Š æŒçºŒè² è¼‰è€åŠ›æ¸¬è©¦ ({result['duration']:.1f}s):")
        print(f"   ç¸½è™•ç†æ•¸é‡: {result['total_processed']}")
        print(f"   æŒçºŒååé‡: {result['throughput']:.1f} ä¿¡è™Ÿ/ç§’")
        print(f"   éŒ¯èª¤ç‡: {result['error_rate']:.2%}")

if __name__ == "__main__":
    print("ğŸ§ª åŸ·è¡Œç³»çµ±æ€§èƒ½åŸºæº–æ¸¬è©¦...")
    print("âš ï¸  æ³¨æ„ï¼šæ€§èƒ½æ¸¬è©¦å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“")
    unittest.main(verbosity=2)
