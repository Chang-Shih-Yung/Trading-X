#!/usr/bin/env python3
"""
ğŸ”¬ è©³ç´°å¯¦æˆ°åˆ†æå·¥å…· - Phase1 çœŸå¯¦å•é¡Œæª¢æ¸¬
æª¢æ¸¬å¯¦éš›çš„æ•¸æ“šæµã€é‚è¼¯ä¸€è‡´æ€§å’Œå¯¦ç¾å®Œæ•´æ€§å•é¡Œ
"""

import os
import json
import ast
import re
from pathlib import Path
from typing import Dict, List, Any, Set
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DetailedPhase1AnalysisTool:
    """è©³ç´°Phase1åˆ†æå·¥å…·"""
    
    def __init__(self):
        self.base_path = Path("/Users/henrychang/Desktop/Trading-X/X/backend/phase1_signal_generation")
        self.issues = []
        self.warnings = []
        self.fixes_needed = []
        
        # æ ¸å¿ƒæµç¨‹çµ„ä»¶
        self.components = {
            "websocket_realtime_driver": "websocket_realtime_driver/websocket_realtime_driver.py",
            "phase1a_basic_signal_generation": "phase1a_basic_signal_generation/phase1a_basic_signal_generation.py",
            "indicator_dependency_graph": "indicator_dependency/indicator_dependency_graph.py",
            "phase1b_volatility_adaptation": "phase1b_volatility_adaptation/phase1b_volatility_adaptation.py",
            "phase1c_signal_standardization": "phase1c_signal_standardization/phase1c_signal_standardization.py",
            "unified_signal_candidate_pool": "unified_signal_pool/unified_signal_candidate_pool.py"
        }
        
        # æœŸæœ›çš„æ•¸æ“šæµæ¥å£
        self.expected_interfaces = {
            "websocket_realtime_driver": {
                "outputs": ["real_time_price", "volume", "market_depth", "kline_data"],
                "methods": ["start", "stop", "subscribe", "get_latest_data"]
            },
            "phase1a_basic_signal_generation": {
                "inputs": ["real_time_price", "volume", "market_depth"],
                "outputs": ["basic_signals", "standardized_basic_signals"],
                "methods": ["process_market_data", "generate_signals"]
            },
            "indicator_dependency_graph": {
                "inputs": ["standardized_basic_signals", "market_data"],
                "outputs": ["technical_indicators", "indicator_results"],
                "methods": ["calculate_indicators", "update_dependencies"]
            },
            "phase1b_volatility_adaptation": {
                "inputs": ["basic_signal_foundation", "technical_indicators"],
                "outputs": ["volatility_metrics", "adaptive_adjustments"],
                "methods": ["analyze_volatility", "adapt_signals"]
            },
            "phase1c_signal_standardization": {
                "inputs": ["preprocessed_signals", "adaptive_adjustments"],
                "outputs": ["standardized_signals", "quality_scores"],
                "methods": ["standardize_signals", "calculate_quality"]
            },
            "unified_signal_candidate_pool": {
                "inputs": ["standardized_signals", "quality_scores"],
                "outputs": ["epl_ready_signals", "ai_enhanced_signals"],
                "methods": ["aggregate_signals", "ai_learning", "prepare_epl"]
            }
        }
    
    def run_detailed_analysis(self) -> Dict[str, Any]:
        """åŸ·è¡Œè©³ç´°åˆ†æ"""
        logger.info("ğŸ”¬ é–‹å§‹è©³ç´°å¯¦æˆ°åˆ†æ...")
        
        # 1. æª¢æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        self._check_file_existence()
        
        # 2. åˆ†ææ•¸æ“šæµä¸€è‡´æ€§
        self._analyze_data_flow_consistency()
        
        # 3. æª¢æŸ¥æ–¹æ³•å¯¦ç¾å®Œæ•´æ€§
        self._check_method_implementations()
        
        # 4. é©—è­‰ç•°æ­¥å¯¦ç¾
        self._verify_async_implementations()
        
        # 5. æª¢æŸ¥å°å…¥ä¾è³´
        self._check_import_dependencies()
        
        # 6. åˆ†æé…ç½®ä¸€è‡´æ€§
        self._analyze_config_consistency()
        
        # 7. æª¢æŸ¥éŒ¯èª¤è™•ç†
        self._check_error_handling()
        
        return self._generate_detailed_report()
    
    def _check_file_existence(self):
        """æª¢æŸ¥æ–‡ä»¶å­˜åœ¨æ€§"""
        logger.info("ğŸ“ æª¢æŸ¥æ–‡ä»¶å­˜åœ¨æ€§...")
        
        missing_files = []
        for component, path in self.components.items():
            full_path = self.base_path / path
            if not full_path.exists():
                missing_files.append(f"{component}: {path}")
                self.issues.append(f"âŒ ç¼ºå¤±æ–‡ä»¶: {component} - {path}")
        
        if missing_files:
            self.issues.append(f"âŒ å…±æœ‰ {len(missing_files)} å€‹æ–‡ä»¶ç¼ºå¤±")
        else:
            logger.info("âœ… æ‰€æœ‰æ ¸å¿ƒæ–‡ä»¶éƒ½å­˜åœ¨")
    
    def _analyze_data_flow_consistency(self):
        """åˆ†ææ•¸æ“šæµä¸€è‡´æ€§"""
        logger.info("ğŸ”„ åˆ†ææ•¸æ“šæµä¸€è‡´æ€§...")
        
        for component, path in self.components.items():
            full_path = self.base_path / path
            if full_path.exists():
                self._check_component_data_flow(component, full_path)
    
    def _check_component_data_flow(self, component: str, file_path: Path):
        """æª¢æŸ¥çµ„ä»¶æ•¸æ“šæµ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            expected = self.expected_interfaces.get(component, {})
            
            # æª¢æŸ¥è¼¸å…¥æ•¸æ“šè™•ç†
            if 'inputs' in expected:
                for input_type in expected['inputs']:
                    if input_type not in content:
                        self.warnings.append(f"âš ï¸ {component}: æœªç™¼ç¾ {input_type} è¼¸å…¥è™•ç†")
            
            # æª¢æŸ¥è¼¸å‡ºæ•¸æ“šç”Ÿæˆ
            if 'outputs' in expected:
                for output_type in expected['outputs']:
                    if output_type not in content:
                        self.warnings.append(f"âš ï¸ {component}: æœªç™¼ç¾ {output_type} è¼¸å‡ºç”Ÿæˆ")
            
            # æª¢æŸ¥æ–¹æ³•å­˜åœ¨æ€§
            if 'methods' in expected:
                for method in expected['methods']:
                    method_pattern = f"(def|async def)\\s+{method}"
                    if not re.search(method_pattern, content):
                        self.issues.append(f"âŒ {component}: ç¼ºå¤±æ ¸å¿ƒæ–¹æ³• {method}")
            
        except Exception as e:
            self.issues.append(f"âŒ {component}: æ–‡ä»¶è®€å–å¤±æ•— - {str(e)}")
    
    def _check_method_implementations(self):
        """æª¢æŸ¥æ–¹æ³•å¯¦ç¾å®Œæ•´æ€§"""
        logger.info("âš™ï¸ æª¢æŸ¥æ–¹æ³•å¯¦ç¾å®Œæ•´æ€§...")
        
        for component, path in self.components.items():
            full_path = self.base_path / path
            if full_path.exists():
                self._analyze_component_methods(component, full_path)
    
    def _analyze_component_methods(self, component: str, file_path: Path):
        """åˆ†æçµ„ä»¶æ–¹æ³•"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£æAST
            tree = ast.parse(content)
            
            # æŸ¥æ‰¾é¡å’Œæ–¹æ³•
            classes = []
            methods = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    methods.append(node.name)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰ä¸»è¦é¡
            main_class_patterns = [
                f"Phase1A.*",
                f".*DependencyGraph",
                f"Phase1B.*",
                f"Phase1C.*",
                f".*SignalPool.*",
                f"UnifiedSignalCandidatePoolV3",
                f"WebSocket.*Driver"
            ]
            
            has_main_class = False
            for pattern in main_class_patterns:
                if any(re.match(pattern, cls) for cls in classes):
                    has_main_class = True
                    break
            
            if not has_main_class:
                self.issues.append(f"âŒ {component}: æœªç™¼ç¾ä¸»è¦è™•ç†é¡")
            
            # æª¢æŸ¥ç•°æ­¥æ–¹æ³•æ¯”ä¾‹
            async_methods = len([m for m in methods if content.find(f"async def {m}") != -1])
            total_methods = len(methods)
            
            if total_methods > 0:
                async_ratio = async_methods / total_methods
                if async_ratio < 0.3:  # è‡³å°‘30%æ‡‰è©²æ˜¯ç•°æ­¥æ–¹æ³•
                    self.warnings.append(f"âš ï¸ {component}: ç•°æ­¥æ–¹æ³•æ¯”ä¾‹éä½ ({async_ratio:.1%})")
            
        except SyntaxError as e:
            self.issues.append(f"âŒ {component}: èªæ³•éŒ¯èª¤ - {str(e)}")
        except Exception as e:
            self.issues.append(f"âŒ {component}: åˆ†æå¤±æ•— - {str(e)}")
    
    def _verify_async_implementations(self):
        """é©—è­‰ç•°æ­¥å¯¦ç¾"""
        logger.info("ğŸ”„ é©—è­‰ç•°æ­¥å¯¦ç¾...")
        
        for component, path in self.components.items():
            full_path = self.base_path / path
            if full_path.exists():
                self._check_async_patterns(component, full_path)
    
    def _check_async_patterns(self, component: str, file_path: Path):
        """æª¢æŸ¥ç•°æ­¥æ¨¡å¼"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æª¢æŸ¥ç•°æ­¥é—œéµå­—
            has_async_def = "async def" in content
            has_await = "await" in content
            has_asyncio = "asyncio" in content
            
            if not has_async_def:
                self.warnings.append(f"âš ï¸ {component}: æœªä½¿ç”¨ç•°æ­¥å‡½æ•¸")
            
            if has_async_def and not has_await:
                self.issues.append(f"âŒ {component}: æœ‰asyncå‡½æ•¸ä½†æœªä½¿ç”¨await")
            
            if not has_asyncio:
                self.warnings.append(f"âš ï¸ {component}: æœªå°å…¥asyncioæ¨¡çµ„")
            
            # æª¢æŸ¥å¸¸è¦‹çš„é˜»å¡å‘¼å«
            blocking_patterns = [
                r"time\.sleep\(",
                r"requests\.get\(",
                r"requests\.post\(",
                r"\.join\(\)"
            ]
            
            for pattern in blocking_patterns:
                if re.search(pattern, content):
                    self.warnings.append(f"âš ï¸ {component}: å¯èƒ½åŒ…å«é˜»å¡å‘¼å«: {pattern}")
            
        except Exception as e:
            self.issues.append(f"âŒ {component}: ç•°æ­¥åˆ†æå¤±æ•— - {str(e)}")
    
    def _check_import_dependencies(self):
        """æª¢æŸ¥å°å…¥ä¾è³´"""
        logger.info("ğŸ“¦ æª¢æŸ¥å°å…¥ä¾è³´...")
        
        for component, path in self.components.items():
            full_path = self.base_path / path
            if full_path.exists():
                self._analyze_imports(component, full_path)
    
    def _analyze_imports(self, component: str, file_path: Path):
        """åˆ†æå°å…¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æª¢æŸ¥å¿…è¦çš„å°å…¥
            required_imports = {
                "websocket_realtime_driver": ["asyncio", "websockets", "json"],
                "phase1a_basic_signal_generation": ["asyncio", "numpy", "pandas"],
                "indicator_dependency_graph": ["pandas", "numpy", "asyncio"],
                "phase1b_volatility_adaptation": ["asyncio", "numpy", "pandas"],
                "phase1c_signal_standardization": ["asyncio", "pandas", "numpy"],
                "unified_signal_candidate_pool": ["asyncio", "pandas", "numpy", "json"]
            }
            
            component_requirements = required_imports.get(component, [])
            
            for requirement in component_requirements:
                import_patterns = [
                    f"import {requirement}",
                    f"from {requirement} import",
                    f"import {requirement} as"
                ]
                
                if not any(pattern in content for pattern in import_patterns):
                    self.warnings.append(f"âš ï¸ {component}: å¯èƒ½ç¼ºå¤±å¿…è¦å°å…¥ {requirement}")
            
            # æª¢æŸ¥å¾ªç’°å°å…¥é¢¨éšª
            phase_imports = re.findall(r"from.*phase\d[abc]?.*import", content)
            if len(phase_imports) > 2:
                self.warnings.append(f"âš ï¸ {component}: å¯èƒ½å­˜åœ¨å¾ªç’°å°å…¥é¢¨éšª")
            
        except Exception as e:
            self.issues.append(f"âŒ {component}: å°å…¥åˆ†æå¤±æ•— - {str(e)}")
    
    def _analyze_config_consistency(self):
        """åˆ†æé…ç½®ä¸€è‡´æ€§"""
        logger.info("âš™ï¸ åˆ†æé…ç½®ä¸€è‡´æ€§...")
        
        for component in self.components.keys():
            json_files = [
                f"{component}/{component}.json",
                f"{component}/{component}_dependency.json"
            ]
            
            for json_file in json_files:
                json_path = self.base_path / json_file
                if json_path.exists():
                    self._check_json_config(component, json_path)
    
    def _check_json_config(self, component: str, json_path: Path):
        """æª¢æŸ¥JSONé…ç½®"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            # æª¢æŸ¥å¿…è¦çš„é…ç½®æ®µè½
            required_sections = [
                "dependencies",
                "performance_targets",
                "input_format",
                "output_format"
            ]
            
            for section in required_sections:
                if section not in config:
                    self.warnings.append(f"âš ï¸ {component}: JSONé…ç½®ç¼ºå¤± {section} æ®µè½")
            
            # æª¢æŸ¥å»¶é²ç›®æ¨™
            if "performance_targets" in config:
                targets = config["performance_targets"]
                if "latency" in targets or "processing_time" in targets:
                    # å»¶é²ç›®æ¨™å­˜åœ¨ï¼Œé€™æ˜¯å¥½çš„
                    pass
                else:
                    self.warnings.append(f"âš ï¸ {component}: ç¼ºå¤±å»¶é²æ€§èƒ½ç›®æ¨™")
            
        except json.JSONDecodeError as e:
            self.issues.append(f"âŒ {component}: JSONæ ¼å¼éŒ¯èª¤ - {str(e)}")
        except Exception as e:
            self.issues.append(f"âŒ {component}: é…ç½®åˆ†æå¤±æ•— - {str(e)}")
    
    def _check_error_handling(self):
        """æª¢æŸ¥éŒ¯èª¤è™•ç†"""
        logger.info("ğŸ›¡ï¸ æª¢æŸ¥éŒ¯èª¤è™•ç†...")
        
        for component, path in self.components.items():
            full_path = self.base_path / path
            if full_path.exists():
                self._analyze_error_handling(component, full_path)
    
    def _analyze_error_handling(self, component: str, file_path: Path):
        """åˆ†æéŒ¯èª¤è™•ç†"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æª¢æŸ¥try-exceptè¦†è“‹
            try_count = content.count("try:")
            except_count = content.count("except")
            
            if try_count == 0:
                self.issues.append(f"âŒ {component}: å®Œå…¨ç¼ºå¤±éŒ¯èª¤è™•ç†")
            elif try_count < 3:
                self.warnings.append(f"âš ï¸ {component}: éŒ¯èª¤è™•ç†è¦†è“‹å¯èƒ½ä¸è¶³")
            
            # æª¢æŸ¥è£¸except
            if "except:" in content:
                self.warnings.append(f"âš ï¸ {component}: ä½¿ç”¨è£¸exceptï¼Œæ‡‰è©²æŒ‡å®šç•°å¸¸é¡å‹")
            
            # æª¢æŸ¥æ—¥èªŒè¨˜éŒ„
            if "logger" not in content and "logging" not in content:
                self.warnings.append(f"âš ï¸ {component}: æœªä½¿ç”¨æ—¥èªŒè¨˜éŒ„")
            
        except Exception as e:
            self.issues.append(f"âŒ {component}: éŒ¯èª¤è™•ç†åˆ†æå¤±æ•— - {str(e)}")
    
    def _generate_detailed_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆè©³ç´°å ±å‘Š"""
        
        # è¨ˆç®—ç¸½é«”è©•åˆ†
        total_checks = len(self.issues) + len(self.warnings) + len(self.fixes_needed)
        critical_issues = len(self.issues)
        
        if total_checks == 0:
            score = 100
        else:
            # åš´é‡å•é¡Œ -20åˆ†ï¼Œè­¦å‘Š -5åˆ†ï¼Œéœ€è¦ä¿®å¾© -10åˆ†
            penalty = critical_issues * 20 + len(self.warnings) * 5 + len(self.fixes_needed) * 10
            score = max(0, 100 - penalty)
        
        report = {
            "overall_score": score,
            "critical_issues": self.issues,
            "warnings": self.warnings,
            "fixes_needed": self.fixes_needed,
            "components_analyzed": len(self.components),
            "analysis_timestamp": datetime.now().isoformat(),
            "recommendations": self._generate_recommendations()
        }
        
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¿®å¾©å»ºè­°"""
        recommendations = []
        
        if self.issues:
            recommendations.append("ğŸ”§ ç«‹å³ä¿®å¾©æ‰€æœ‰critical issuesä»¥ç¢ºä¿ç³»çµ±æ­£å¸¸é‹è¡Œ")
        
        if len(self.warnings) > 10:
            recommendations.append("âš ï¸ å¤§é‡warningséœ€è¦é—œæ³¨ï¼Œå»ºè­°åˆ†æ‰¹æ¬¡è§£æ±º")
        
        if self.fixes_needed:
            recommendations.append("ğŸ”¨ è™•ç†æ‰€æœ‰fixes_neededé …ç›®ä»¥æå‡ç³»çµ±å“è³ª")
        
        # åŸºæ–¼å…·é«”å•é¡Œé¡å‹çš„å»ºè­°
        import_issues = [w for w in self.warnings if "å°å…¥" in w or "import" in w]
        if import_issues:
            recommendations.append("ğŸ“¦ æª¢æŸ¥ä¸¦ä¿®å¾©å°å…¥ä¾è³´å•é¡Œ")
        
        async_issues = [w for w in self.warnings if "ç•°æ­¥" in w or "async" in w]
        if async_issues:
            recommendations.append("âš¡ æ”¹å–„ç•°æ­¥å¯¦ç¾ä»¥æå‡æ€§èƒ½")
        
        error_issues = [i for i in self.issues if "éŒ¯èª¤è™•ç†" in i]
        if error_issues:
            recommendations.append("ğŸ›¡ï¸ åŠ å¼·éŒ¯èª¤è™•ç†å’Œç•°å¸¸ç®¡ç†")
        
        return recommendations
    
    def print_detailed_report(self, report: Dict[str, Any]):
        """æ‰“å°è©³ç´°å ±å‘Š"""
        print("\n" + "="*80)
        print("ğŸ”¬ PHASE1 SIGNAL GENERATION - è©³ç´°å¯¦æˆ°åˆ†æå ±å‘Š")
        print("="*80)
        
        print(f"\nğŸ“Š ç¸½é«”è©•åˆ†: {report['overall_score']}/100")
        
        if report['critical_issues']:
            print(f"\nâŒ åš´é‡å•é¡Œ ({len(report['critical_issues'])} é …):")
            for issue in report['critical_issues'][:10]:  # é¡¯ç¤ºå‰10é …
                print(f"   {issue}")
            if len(report['critical_issues']) > 10:
                print(f"   ... é‚„æœ‰ {len(report['critical_issues']) - 10} é …")
        
        if report['warnings']:
            print(f"\nâš ï¸ è­¦å‘Šé …ç›® ({len(report['warnings'])} é …):")
            for warning in report['warnings'][:10]:  # é¡¯ç¤ºå‰10é …
                print(f"   {warning}")
            if len(report['warnings']) > 10:
                print(f"   ... é‚„æœ‰ {len(report['warnings']) - 10} é …")
        
        if report['fixes_needed']:
            print(f"\nğŸ”§ éœ€è¦ä¿®å¾© ({len(report['fixes_needed'])} é …):")
            for fix in report['fixes_needed'][:10]:
                print(f"   {fix}")
        
        if report['recommendations']:
            print(f"\nğŸ’¡ ä¿®å¾©å»ºè­°:")
            for rec in report['recommendations']:
                print(f"   {rec}")
        
        print(f"\nğŸ“ˆ åˆ†æçµ±è¨ˆ:")
        print(f"   åˆ†æçµ„ä»¶æ•¸: {report['components_analyzed']}")
        print(f"   åˆ†ææ™‚é–“: {report['analysis_timestamp']}")
        
        print("\n" + "="*80)

def main():
    """ä¸»å‡½æ•¸"""
    from datetime import datetime
    
    tool = DetailedPhase1AnalysisTool()
    report = tool.run_detailed_analysis()
    tool.print_detailed_report(report)
    
    return report

if __name__ == "__main__":
    main()
