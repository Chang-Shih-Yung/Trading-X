#!/usr/bin/env python3
"""
Signal Processing Statistics Pythonå¯¦ç¾é©—è­‰è…³æœ¬
é©—è­‰ signal_processing_statistics.py èˆ‡ JSON é…ç½®çš„åŒ¹é…åº¦
"""

import json
import ast
import inspect
from pathlib import Path
from typing import Dict, List, Any, Tuple

class SignalStatsPythonValidator:
    def __init__(self):
        self.base_path = Path("/Users/henrychang/Desktop/Trading-X")
        self.json_path = self.base_path / "X/backend/phase4_output_monitoring/2_signal_processing_statistics/signal_processing_statistics_config.json"
        self.py_path = self.base_path / "X/backend/phase4_output_monitoring/2_signal_processing_statistics/signal_processing_statistics.py"
        
    def load_json_config(self) -> Dict[str, Any]:
        """è¼‰å…¥JSONé…ç½®"""
        try:
            with open(self.json_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ ç„¡æ³•è¼‰å…¥JSONé…ç½®: {e}")
            return {}
    
    def analyze_python_implementation(self) -> Dict[str, Any]:
        """åˆ†æPythonå¯¦ç¾"""
        try:
            with open(self.py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            tree = ast.parse(content)
            
            classes = []
            methods = []
            functions = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, ast.FunctionDef):
                    methods.append(node.name)
                elif isinstance(node, ast.AsyncFunctionDef):
                    methods.append(node.name)
            
            return {
                "classes": classes,
                "methods": methods,
                "functions": functions,
                "line_count": len(content.split('\n'))
            }
        except Exception as e:
            print(f"âŒ ç„¡æ³•åˆ†æPythonå¯¦ç¾: {e}")
            return {}
    
    def validate_core_data_structures(self, py_analysis: Dict[str, Any]) -> Tuple[int, int]:
        """é©—è­‰æ ¸å¿ƒæ•¸æ“šçµæ§‹"""
        score = 0
        max_score = 25
        
        print("\nğŸ” é©—è­‰æ ¸å¿ƒæ•¸æ“šçµæ§‹:")
        print("-" * 40)
        
        required_classes = [
            "SignalMetrics",
            "StatisticalSummary", 
            "SignalProcessingStatistics"
        ]
        
        implemented_classes = py_analysis.get("classes", [])
        
        for cls in required_classes:
            if cls in implemented_classes:
                score += 8
                print(f"âœ… {cls} é¡å·²å®šç¾©")
            else:
                print(f"âŒ ç¼ºå°‘é¡: {cls}")
        
        # é¡å¤–åˆ†æ•¸çµ¦ä¸»é¡
        if "SignalProcessingStatistics" in implemented_classes:
            score += 1
            print("âœ… ä¸»è¦çµ±è¨ˆé¡å·²å¯¦ç¾")
        
        return score, max_score
    
    def validate_phase_integration_features(self, py_analysis: Dict[str, Any], config: Dict[str, Any]) -> Tuple[int, int]:
        """é©—è­‰Phaseæ•´åˆåŠŸèƒ½"""
        score = 0
        max_score = 30
        
        print("\nğŸ” é©—è­‰Phaseæ•´åˆåŠŸèƒ½:")
        print("-" * 40)
        
        methods = py_analysis.get("methods", [])
        
        # æª¢æŸ¥Phaseå»¶é²åˆ†ææ–¹æ³• (åŸºæ–¼JSONé…ç½®çš„phase_level_latency)
        phase_latency_methods = [
            "_calculate_statistical_summary",
            "_get_latency_by_priority",
            "_calculate_recent_trends"
        ]
        
        for method in phase_latency_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} å»¶é²åˆ†ææ–¹æ³•å·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘å»¶é²åˆ†ææ–¹æ³•: {method}")
        
        # æª¢æŸ¥ä¿¡è™Ÿä¾†æºåˆ†ææ–¹æ³• (åŸºæ–¼JSONçš„signals_by_source)
        source_analysis_methods = [
            "_get_performance_by_source",
            "_get_source_reliability"
        ]
        
        for method in source_analysis_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} ä¾†æºåˆ†ææ–¹æ³•å·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘ä¾†æºåˆ†ææ–¹æ³•: {method}")
        
        # æª¢æŸ¥å„ªå…ˆç´šåˆ†ææ–¹æ³• (åŸºæ–¼JSONçš„signals_by_priority)
        priority_analysis_methods = [
            "_get_success_rate_by_priority"
        ]
        
        for method in priority_analysis_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} å„ªå…ˆç´šåˆ†ææ–¹æ³•å·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘å„ªå…ˆç´šåˆ†ææ–¹æ³•: {method}")
        
        return score, max_score
    
    def validate_monitoring_architecture_implementation(self, py_analysis: Dict[str, Any], config: Dict[str, Any]) -> Tuple[int, int]:
        """é©—è­‰ç›£æ§æ¶æ§‹å¯¦ç¾"""
        score = 0
        max_score = 35
        
        print("\nğŸ” é©—è­‰ç›£æ§æ¶æ§‹å¯¦ç¾:")
        print("-" * 40)
        
        methods = py_analysis.get("methods", [])
        
        # æª¢æŸ¥å¯¦æ™‚çµ±è¨ˆæ–¹æ³• (å°æ‡‰JSONçš„real_time_statistics API)
        if "get_real_time_metrics" in methods:
            score += 10
            print("âœ… get_real_time_metrics å¯¦æ™‚çµ±è¨ˆæ–¹æ³•å·²å¯¦ç¾")
        else:
            print("âŒ ç¼ºå°‘å¯¦æ™‚çµ±è¨ˆæ–¹æ³•")
        
        # æª¢æŸ¥ç¶œåˆçµ±è¨ˆæ–¹æ³• (å°æ‡‰JSONçš„historical_analytics API)
        if "get_comprehensive_statistics" in methods:
            score += 10
            print("âœ… get_comprehensive_statistics ç¶œåˆçµ±è¨ˆæ–¹æ³•å·²å¯¦ç¾")
        else:
            print("âŒ ç¼ºå°‘ç¶œåˆçµ±è¨ˆæ–¹æ³•")
        
        # æª¢æŸ¥ä¿¡è™Ÿè¨˜éŒ„æ–¹æ³• (æ ¸å¿ƒåŠŸèƒ½)
        if "record_signal_metrics" in methods:
            score += 10
            print("âœ… record_signal_metrics ä¿¡è™Ÿè¨˜éŒ„æ–¹æ³•å·²å¯¦ç¾")
        else:
            print("âŒ ç¼ºå°‘ä¿¡è™Ÿè¨˜éŒ„æ–¹æ³•")
        
        # æª¢æŸ¥æ€§èƒ½åŸºæº–æ–¹æ³• (å°æ‡‰JSONçš„performance_metrics API)
        if "_calculate_performance_benchmarks" in methods:
            score += 5
            print("âœ… æ€§èƒ½åŸºæº–è¨ˆç®—æ–¹æ³•å·²å¯¦ç¾")
        else:
            print("âŒ ç¼ºå°‘æ€§èƒ½åŸºæº–æ–¹æ³•")
        
        return score, max_score
    
    def validate_json_compliance_features(self, py_analysis: Dict[str, Any], config: Dict[str, Any]) -> Tuple[int, int]:
        """é©—è­‰JSONåˆè¦åŠŸèƒ½"""
        score = 0
        max_score = 30
        
        print("\nğŸ” é©—è­‰JSONåˆè¦åŠŸèƒ½:")
        print("-" * 40)
        
        methods = py_analysis.get("methods", [])
        
        # æª¢æŸ¥æ™‚é–“æ¨¡å¼åˆ†æ (å°æ‡‰JSONçš„temporal_distribution)
        temporal_methods = [
            "_analyze_hourly_patterns",
            "_analyze_daily_patterns",
            "_identify_peak_windows"
        ]
        
        for method in temporal_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} æ™‚é–“æ¨¡å¼åˆ†æå·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘æ™‚é–“æ¨¡å¼åˆ†æ: {method}")
        
        # æª¢æŸ¥æ•¸æ“šæ›´æ–°æ–¹æ³• (å°æ‡‰JSONçš„data_retention_policy)
        data_management_methods = [
            "_update_distributions",
            "_update_time_window_stats",
            "_cleanup_old_data"
        ]
        
        for method in data_management_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} æ•¸æ“šç®¡ç†æ–¹æ³•å·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘æ•¸æ“šç®¡ç†æ–¹æ³•: {method}")
        
        return score, max_score
    
    def validate_statistical_analysis_completeness(self, py_analysis: Dict[str, Any]) -> Tuple[int, int]:
        """é©—è­‰çµ±è¨ˆåˆ†æå®Œæ•´æ€§"""
        score = 0
        max_score = 20
        
        print("\nğŸ” é©—è­‰çµ±è¨ˆåˆ†æå®Œæ•´æ€§:")
        print("-" * 40)
        
        methods = py_analysis.get("methods", [])
        
        # æª¢æŸ¥çµ±è¨ˆè¨ˆç®—æ–¹æ³•
        statistical_methods = [
            "_calculate_statistical_summary",
            "_get_empty_statistics"
        ]
        
        for method in statistical_methods:
            if method in methods:
                score += 5
                print(f"âœ… {method} çµ±è¨ˆè¨ˆç®—æ–¹æ³•å·²å¯¦ç¾")
            else:
                print(f"âŒ ç¼ºå°‘çµ±è¨ˆè¨ˆç®—æ–¹æ³•: {method}")
        
        # æª¢æŸ¥è¼”åŠ©æ–¹æ³•æ•¸é‡
        helper_methods = [m for m in methods if m.startswith("_")]
        if len(helper_methods) >= 15:
            score += 10
            print(f"âœ… è±å¯Œçš„è¼”åŠ©æ–¹æ³• ({len(helper_methods)} å€‹)")
        elif len(helper_methods) >= 10:
            score += 5
            print(f"âš ï¸ åŸºæœ¬çš„è¼”åŠ©æ–¹æ³• ({len(helper_methods)} å€‹)")
        else:
            print(f"âŒ è¼”åŠ©æ–¹æ³•ä¸è¶³ ({len(helper_methods)} å€‹)")
        
        return score, max_score
    
    def run_validation(self):
        """åŸ·è¡Œå®Œæ•´é©—è­‰"""
        print("ğŸš€ é–‹å§‹é©—è­‰ Signal Processing Statistics Pythonå¯¦ç¾...")
        print("=" * 60)
        
        # è¼‰å…¥é…ç½®å’Œåˆ†æä»£ç¢¼
        config = self.load_json_config()
        py_analysis = self.analyze_python_implementation()
        
        if not config or not py_analysis:
            print("âŒ ç„¡æ³•è¼‰å…¥å¿…è¦æ–‡ä»¶")
            return 0
        
        print(f"ğŸ“Š Pythonå¯¦ç¾çµ±è¨ˆ:")
        print(f"   - é¡å®šç¾©: {len(py_analysis.get('classes', []))}")
        print(f"   - æ–¹æ³•: {len(py_analysis.get('methods', []))}")
        print(f"   - å‡½æ•¸: {len(py_analysis.get('functions', []))}")
        print(f"   - ä»£ç¢¼è¡Œæ•¸: {py_analysis.get('line_count', 0)}")
        
        # åŸ·è¡Œå„é …é©—è­‰
        struct_score, struct_max = self.validate_core_data_structures(py_analysis)
        phase_score, phase_max = self.validate_phase_integration_features(py_analysis, config)
        arch_score, arch_max = self.validate_monitoring_architecture_implementation(py_analysis, config)
        json_score, json_max = self.validate_json_compliance_features(py_analysis, config)
        stats_score, stats_max = self.validate_statistical_analysis_completeness(py_analysis)
        
        # è¨ˆç®—ç¸½åˆ†
        total_score = struct_score + phase_score + arch_score + json_score + stats_score
        total_max = struct_max + phase_max + arch_max + json_max + stats_max
        percentage = (total_score / total_max) * 100
        
        print("\n" + "=" * 60)
        print("ğŸ“‹ é©—è­‰çµæœæ‘˜è¦:")
        print(f"   ğŸ—ï¸ æ ¸å¿ƒæ•¸æ“šçµæ§‹: {struct_score}/{struct_max}")
        print(f"   ğŸ”— Phaseæ•´åˆåŠŸèƒ½: {phase_score}/{phase_max}") 
        print(f"   ğŸ“Š ç›£æ§æ¶æ§‹å¯¦ç¾: {arch_score}/{arch_max}")
        print(f"   ğŸ“„ JSONåˆè¦åŠŸèƒ½: {json_score}/{json_max}")
        print(f"   ğŸ“ˆ çµ±è¨ˆåˆ†æå®Œæ•´æ€§: {stats_score}/{stats_max}")
        print("-" * 60)
        print(f"ğŸ¯ ç¸½é©—è­‰çµæœ: {total_score}/{total_max} ({percentage:.1f}%)")
        
        if percentage >= 95:
            print("ğŸ‰ å®Œç¾å¯¦ç¾ï¼Pythonä»£ç¢¼å®Œå…¨åŒ¹é…JSONé…ç½®")
        elif percentage >= 85:
            print("âœ… å¯¦ç¾è‰¯å¥½ï¼å»ºè­°é€²è¡Œç´°å¾®èª¿æ•´")
        elif percentage >= 70:
            print("âš ï¸ åŸºæœ¬å¯¦ç¾å®Œæˆï¼Œéœ€è¦è£œå……ç¼ºå¤±åŠŸèƒ½")
        else:
            print("âŒ å¯¦ç¾ä¸å®Œæ•´ï¼Œéœ€è¦é‡å¤§æ”¹é€²")
        
        return percentage

if __name__ == "__main__":
    validator = SignalStatsPythonValidator()
    result = validator.run_validation()
