#!/usr/bin/env python3
"""
ğŸ¯ Phase1 å¯¦æ™‚ä¿¡è™Ÿæµç«¯åˆ°ç«¯æ¸¬è©¦
å¾å¯¦æ™‚æ•¸æ“šæŠ“å– -> Phase1å…¨æµç¨‹ -> EPLé å‚™
"""

import asyncio
import time
import sys
import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import uuid

# æ·»åŠ è·¯å¾‘
current_dir = Path(__file__).parent
sys.path.extend([
    str(current_dir / "X" / "backend" / "phase1_signal_generation"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "websocket_realtime_driver"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "phase1a_basic_signal_generation"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "indicator_dependency"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "phase1b_volatility_adaptation"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "phase1c_signal_standardization"),
    str(current_dir / "X" / "backend" / "phase1_signal_generation" / "unified_signal_pool"),
])

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealTimeSignalFlowEngine:
    """å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦å¼•æ“"""
    
    def __init__(self):
        self.flow_metrics = {
            "total_processing_time": 0.0,
            "stage_times": {},
            "signals_generated": {},
            "final_epl_signals": 0,
            "success_rate": 0.0
        }
        
        # æ¨¡æ“¬ Phase1 å„æ¨¡çµ„
        self.modules = {}
        
    async def run_realtime_signal_flow_test(self, duration_seconds: int = 60):
        """é‹è¡Œå¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦"""
        logger.info(f"ğŸš€ é–‹å§‹ {duration_seconds} ç§’å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦")
        
        start_time = time.time()
        total_cycles = 0
        successful_cycles = 0
        
        while time.time() - start_time < duration_seconds:
            cycle_start = time.time()
            
            try:
                # åŸ·è¡Œä¸€å€‹å®Œæ•´çš„ä¿¡è™Ÿæµå‘¨æœŸ
                success = await self._execute_signal_flow_cycle()
                
                total_cycles += 1
                if success:
                    successful_cycles += 1
                
                # è¨ˆç®—å‘¨æœŸæ™‚é–“
                cycle_time = (time.time() - cycle_start) * 1000
                logger.info(f"ğŸ”„ å‘¨æœŸ {total_cycles}: {'âœ…' if success else 'âŒ'} è€—æ™‚ {cycle_time:.1f}ms")
                
                # æ§åˆ¶é »ç‡ï¼ˆæ¯2ç§’ä¸€å€‹å‘¨æœŸï¼‰
                await asyncio.sleep(2.0)
                
            except Exception as e:
                logger.error(f"âŒ å‘¨æœŸ {total_cycles + 1} åŸ·è¡Œå¤±æ•—: {e}")
                total_cycles += 1
        
        # è¨ˆç®—æœ€çµ‚æŒ‡æ¨™
        self.flow_metrics["success_rate"] = successful_cycles / total_cycles if total_cycles > 0 else 0
        self.flow_metrics["total_cycles"] = total_cycles
        self.flow_metrics["successful_cycles"] = successful_cycles
        
        # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
        await self._generate_flow_test_report()
        
        return self.flow_metrics["success_rate"] >= 0.8
    
    async def _execute_signal_flow_cycle(self) -> bool:
        """åŸ·è¡Œä¸€å€‹å®Œæ•´çš„ä¿¡è™Ÿæµå‘¨æœŸ"""
        try:
            flow_start = time.time()
            
            # ç¬¬1éšæ®µï¼šæ¨¡æ“¬å¯¦æ™‚æ•¸æ“šç²å– (WebSocket)
            stage_start = time.time()
            market_data = await self._stage_1_realtime_data_acquisition()
            self.flow_metrics["stage_times"]["data_acquisition"] = (time.time() - stage_start) * 1000
            
            if not market_data:
                return False
            
            # ç¬¬2éšæ®µï¼šPhase1A åŸºç¤ä¿¡è™Ÿç”Ÿæˆ
            stage_start = time.time()
            phase1a_signals = await self._stage_2_phase1a_signal_generation(market_data)
            self.flow_metrics["stage_times"]["phase1a_generation"] = (time.time() - stage_start) * 1000
            
            # ç¬¬3éšæ®µï¼šæŒ‡æ¨™ä¾è³´è¨ˆç®—
            stage_start = time.time()
            indicator_signals = await self._stage_3_indicator_calculation(market_data)
            self.flow_metrics["stage_times"]["indicator_calculation"] = (time.time() - stage_start) * 1000
            
            # ç¬¬4éšæ®µï¼šPhase1B æ³¢å‹•æ€§é©æ‡‰
            stage_start = time.time()
            phase1b_signals = await self._stage_4_phase1b_adaptation(phase1a_signals + indicator_signals, market_data)
            self.flow_metrics["stage_times"]["phase1b_adaptation"] = (time.time() - stage_start) * 1000
            
            # ç¬¬5éšæ®µï¼šPhase1C ä¿¡è™Ÿæ¨™æº–åŒ–
            stage_start = time.time()
            phase1c_signals = await self._stage_5_phase1c_standardization(phase1b_signals)
            self.flow_metrics["stage_times"]["phase1c_standardization"] = (time.time() - stage_start) * 1000
            
            # ç¬¬6éšæ®µï¼šçµ±ä¸€ä¿¡è™Ÿæ± èšåˆ
            stage_start = time.time()
            unified_signals = await self._stage_6_unified_pool_aggregation({
                'phase1a': phase1a_signals,
                'indicators': indicator_signals,
                'phase1b': phase1b_signals,
                'phase1c': phase1c_signals
            })
            self.flow_metrics["stage_times"]["unified_aggregation"] = (time.time() - stage_start) * 1000
            
            # ç¬¬7éšæ®µï¼šEPL é è™•ç†æº–å‚™
            stage_start = time.time()
            epl_ready_signals = await self._stage_7_epl_preprocessing(unified_signals)
            self.flow_metrics["stage_times"]["epl_preprocessing"] = (time.time() - stage_start) * 1000
            
            # è¨˜éŒ„ç¸½é«”æŒ‡æ¨™
            self.flow_metrics["total_processing_time"] = (time.time() - flow_start) * 1000
            self.flow_metrics["signals_generated"]["phase1a"] = len(phase1a_signals)
            self.flow_metrics["signals_generated"]["indicators"] = len(indicator_signals)
            self.flow_metrics["signals_generated"]["phase1b"] = len(phase1b_signals)
            self.flow_metrics["signals_generated"]["phase1c"] = len(phase1c_signals)
            self.flow_metrics["signals_generated"]["unified"] = len(unified_signals)
            self.flow_metrics["final_epl_signals"] = len(epl_ready_signals)
            
            logger.info(f"âœ… å®Œæ•´ä¿¡è™Ÿæµ: {len(epl_ready_signals)} å€‹ EPL ä¿¡è™Ÿï¼Œç¸½è€—æ™‚ {self.flow_metrics['total_processing_time']:.1f}ms")
            
            return len(epl_ready_signals) > 0
            
        except Exception as e:
            logger.error(f"âŒ ä¿¡è™Ÿæµå‘¨æœŸåŸ·è¡Œå¤±æ•—: {e}")
            return False
    
    async def _stage_1_realtime_data_acquisition(self) -> Dict[str, Any]:
        """ç¬¬1éšæ®µï¼šå¯¦æ™‚æ•¸æ“šç²å–"""
        try:
            # æ¨¡æ“¬å¯¦æ™‚å¸‚å ´æ•¸æ“š
            import random
            
            base_price = 45000.0
            price_change = random.uniform(-0.02, 0.02)  # Â±2% åƒ¹æ ¼è®ŠåŒ–
            current_price = base_price * (1 + price_change)
            
            volume_multiplier = random.uniform(0.5, 3.0)  # 0.5x-3x æˆäº¤é‡è®ŠåŒ–
            base_volume = 1000.0
            current_volume = base_volume * volume_multiplier
            
            # ç”Ÿæˆ Kç·šæ•¸æ“šï¼ˆæœ€è¿‘100æ ¹ï¼‰
            klines = []
            for i in range(100):
                timestamp = int((time.time() - (100 - i) * 60) * 1000)  # æ¯åˆ†é˜ä¸€æ ¹Kç·š
                open_price = base_price + random.uniform(-100, 100)
                high_price = open_price + random.uniform(0, 50)
                low_price = open_price - random.uniform(0, 50)
                close_price = open_price + random.uniform(-25, 25)
                volume = base_volume * random.uniform(0.8, 1.2)
                
                klines.append([
                    timestamp,  # é–‹ç›¤æ™‚é–“
                    str(open_price),  # é–‹ç›¤åƒ¹
                    str(high_price),  # æœ€é«˜åƒ¹
                    str(low_price),  # æœ€ä½åƒ¹
                    str(close_price),  # æ”¶ç›¤åƒ¹
                    str(volume),  # æˆäº¤é‡
                    timestamp + 60000,  # æ”¶ç›¤æ™‚é–“
                    str(volume * close_price),  # æˆäº¤é¡
                    100,  # æˆäº¤ç­†æ•¸
                    str(volume * 0.6),  # ä¸»å‹•è²·å…¥æˆäº¤é‡
                    str(volume * close_price * 0.6),  # ä¸»å‹•è²·å…¥æˆäº¤é¡
                    "0"  # å¿½ç•¥å­—æ®µ
                ])
            
            # ç”Ÿæˆè¨‚å–®ç°¿æ•¸æ“š
            orderbook = {
                "bids": [[str(current_price - i), str(random.uniform(10, 100))] for i in range(1, 6)],
                "asks": [[str(current_price + i), str(random.uniform(10, 100))] for i in range(1, 6)]
            }
            
            market_data = {
                "symbol": "BTCUSDT",
                "price": current_price,
                "volume": current_volume,
                "timestamp": datetime.now(),
                "klines": klines,
                "orderbook": orderbook,
                "bid": current_price - 0.5,
                "ask": current_price + 0.5,
                "price_change_pct": price_change * 100,
                "volume_ratio": volume_multiplier,
                "data_completeness": 1.0
            }
            
            logger.debug(f"ğŸ“Š å¸‚å ´æ•¸æ“š: BTC ${current_price:.1f} ({price_change*100:+.2f}%), æˆäº¤é‡ {volume_multiplier:.1f}x")
            
            return market_data
            
        except Exception as e:
            logger.error(f"âŒ å¯¦æ™‚æ•¸æ“šç²å–å¤±æ•—: {e}")
            return {}
    
    async def _stage_2_phase1a_signal_generation(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç¬¬2éšæ®µï¼šPhase1A åŸºç¤ä¿¡è™Ÿç”Ÿæˆ"""
        try:
            signals = []
            
            # åƒ¹æ ¼çªç ´æª¢æ¸¬
            price_change = market_data.get("price_change_pct", 0)
            if abs(price_change) > 1.0:  # 1% åƒ¹æ ¼è®ŠåŒ–é–¾å€¼
                signals.append({
                    "signal_id": f"phase1a_price_{uuid.uuid4().hex[:8]}",
                    "signal_type": "PRICE_BREAKOUT",
                    "signal_strength": min(1.0, abs(price_change) / 5.0),  # 5% è®ŠåŒ– = æ»¿å¼·åº¦
                    "confidence_score": 0.75 + min(0.2, abs(price_change) / 10.0),
                    "signal_source": "phase1a",
                    "timestamp": datetime.now(),
                    "metadata": {
                        "price_change_pct": price_change,
                        "trigger_threshold": 1.0
                    }
                })
            
            # æˆäº¤é‡æ¿€å¢æª¢æ¸¬
            volume_ratio = market_data.get("volume_ratio", 1.0)
            if volume_ratio > 1.5:  # 1.5x æˆäº¤é‡é–¾å€¼
                signals.append({
                    "signal_id": f"phase1a_volume_{uuid.uuid4().hex[:8]}",
                    "signal_type": "VOLUME_SURGE",
                    "signal_strength": min(1.0, (volume_ratio - 1.0) / 2.0),  # 3x æˆäº¤é‡ = æ»¿å¼·åº¦
                    "confidence_score": 0.7 + min(0.25, (volume_ratio - 1.0) / 4.0),
                    "signal_source": "phase1a",
                    "timestamp": datetime.now(),
                    "metadata": {
                        "volume_ratio": volume_ratio,
                        "trigger_threshold": 1.5
                    }
                })
            
            # å‹•é‡è½‰æ›æª¢æ¸¬ï¼ˆç°¡åŒ–ï¼‰
            if abs(price_change) > 0.5 and volume_ratio > 1.2:
                signals.append({
                    "signal_id": f"phase1a_momentum_{uuid.uuid4().hex[:8]}",
                    "signal_type": "MOMENTUM_SHIFT", 
                    "signal_strength": min(1.0, (abs(price_change) + volume_ratio) / 4.0),
                    "confidence_score": 0.65 + min(0.3, (abs(price_change) + volume_ratio) / 6.0),
                    "signal_source": "phase1a",
                    "timestamp": datetime.now(),
                    "metadata": {
                        "price_momentum": price_change,
                        "volume_momentum": volume_ratio
                    }
                })
            
            logger.debug(f"ğŸ“ˆ Phase1A: ç”Ÿæˆ {len(signals)} å€‹åŸºç¤ä¿¡è™Ÿ")
            return signals
            
        except Exception as e:
            logger.error(f"âŒ Phase1A ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
            return []
    
    async def _stage_3_indicator_calculation(self, market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç¬¬3éšæ®µï¼šæŠ€è¡“æŒ‡æ¨™è¨ˆç®—"""
        try:
            signals = []
            klines = market_data.get("klines", [])
            
            if len(klines) >= 20:
                # ç²å–æ”¶ç›¤åƒ¹æ•¸æ“š
                prices = [float(k[4]) for k in klines[-20:]]  # æœ€è¿‘20å€‹æ”¶ç›¤åƒ¹
                
                # ç°¡åŒ– RSI è¨ˆç®—
                if len(prices) >= 14:
                    gains = [max(0, prices[i] - prices[i-1]) for i in range(1, len(prices))]
                    losses = [max(0, prices[i-1] - prices[i]) for i in range(1, len(prices))]
                    
                    if gains and losses:
                        avg_gain = sum(gains[-14:]) / 14
                        avg_loss = sum(losses[-14:]) / 14
                        
                        if avg_loss > 0:
                            rs = avg_gain / avg_loss
                            rsi = 100 - (100 / (1 + rs))
                            
                            # RSI ä¿¡è™Ÿåˆ¤æ–·
                            if rsi > 70 or rsi < 30:
                                signals.append({
                                    "signal_id": f"indicator_rsi_{uuid.uuid4().hex[:8]}",
                                    "signal_type": "RSI_signals",
                                    "signal_strength": min(1.0, abs(rsi - 50) / 50),
                                    "confidence_score": 0.7 + min(0.25, abs(rsi - 50) / 100),
                                    "signal_source": "indicator_graph",
                                    "timestamp": datetime.now(),
                                    "metadata": {
                                        "rsi_value": rsi,
                                        "condition": "oversold" if rsi < 30 else "overbought"
                                    }
                                })
                
                # ç°¡åŒ– MACD è¨ˆç®—
                if len(prices) >= 26:
                    ema_12 = sum(prices[-12:]) / 12
                    ema_26 = sum(prices[-26:]) / 26
                    macd = ema_12 - ema_26
                    current_price = prices[-1]
                    
                    # MACD ä¿¡è™Ÿåˆ¤æ–·
                    macd_ratio = abs(macd) / current_price
                    if macd_ratio > 0.001:  # 0.1% é–¾å€¼
                        signals.append({
                            "signal_id": f"indicator_macd_{uuid.uuid4().hex[:8]}",
                            "signal_type": "MACD_signals",
                            "signal_strength": min(1.0, macd_ratio * 500),  # æ”¾å¤§ä¿‚æ•¸
                            "confidence_score": 0.65 + min(0.3, macd_ratio * 1000),
                            "signal_source": "indicator_graph",
                            "timestamp": datetime.now(),
                            "metadata": {
                                "macd_value": macd,
                                "macd_ratio": macd_ratio,
                                "direction": "bullish" if macd > 0 else "bearish"
                            }
                        })
                
                # å¸ƒæ—å¸¶è¨ˆç®—
                if len(prices) >= 20:
                    sma_20 = sum(prices) / len(prices)
                    variance = sum((p - sma_20) ** 2 for p in prices) / len(prices)
                    std_dev = variance ** 0.5
                    
                    upper_band = sma_20 + (2 * std_dev)
                    lower_band = sma_20 - (2 * std_dev)
                    current_price = prices[-1]
                    
                    # å¸ƒæ—å¸¶çªç ´ä¿¡è™Ÿ
                    if current_price > upper_band or current_price < lower_band:
                        band_penetration = abs(current_price - sma_20) / std_dev / 2
                        signals.append({
                            "signal_id": f"indicator_bb_{uuid.uuid4().hex[:8]}",
                            "signal_type": "BB_signals",
                            "signal_strength": min(1.0, band_penetration),
                            "confidence_score": 0.72 + min(0.25, band_penetration * 0.5),
                            "signal_source": "indicator_graph",
                            "timestamp": datetime.now(),
                            "metadata": {
                                "bb_position": "upper" if current_price > upper_band else "lower",
                                "penetration_ratio": band_penetration,
                                "sma_20": sma_20
                            }
                        })
            
            logger.debug(f"ğŸ“Š æŒ‡æ¨™è¨ˆç®—: ç”Ÿæˆ {len(signals)} å€‹æŠ€è¡“æŒ‡æ¨™ä¿¡è™Ÿ")
            return signals
            
        except Exception as e:
            logger.error(f"âŒ æŠ€è¡“æŒ‡æ¨™è¨ˆç®—å¤±æ•—: {e}")
            return []
    
    async def _stage_4_phase1b_adaptation(self, input_signals: List[Dict[str, Any]], market_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç¬¬4éšæ®µï¼šPhase1B æ³¢å‹•æ€§é©æ‡‰"""
        try:
            adapted_signals = []
            
            # è¨ˆç®—å¸‚å ´æ³¢å‹•æ€§
            klines = market_data.get("klines", [])
            if len(klines) >= 10:
                recent_prices = [float(k[4]) for k in klines[-10:]]
                price_changes = [(recent_prices[i] - recent_prices[i-1]) / recent_prices[i-1] 
                               for i in range(1, len(recent_prices))]
                volatility = (sum(pc ** 2 for pc in price_changes) / len(price_changes)) ** 0.5
            else:
                volatility = 0.01  # é»˜èªæ³¢å‹•æ€§
            
            # å°æ¯å€‹è¼¸å…¥ä¿¡è™Ÿé€²è¡Œæ³¢å‹•æ€§é©æ‡‰
            for signal in input_signals:
                adapted_signal = signal.copy()
                
                # æ³¢å‹•æ€§èª¿æ•´
                if volatility > 0.02:  # é«˜æ³¢å‹•æ€§å¸‚å ´
                    # æå‡ä¿¡è™Ÿå¼·åº¦å’Œä¿¡å¿ƒåº¦
                    adapted_signal["signal_strength"] = min(1.0, signal["signal_strength"] * 1.2)
                    adapted_signal["confidence_score"] = min(1.0, signal["confidence_score"] * 1.1)
                    adapted_signal["volatility_regime"] = "high"
                elif volatility < 0.005:  # ä½æ³¢å‹•æ€§å¸‚å ´
                    # é™ä½ä¿¡è™Ÿå¼·åº¦
                    adapted_signal["signal_strength"] = signal["signal_strength"] * 0.8
                    adapted_signal["confidence_score"] = signal["confidence_score"] * 0.9
                    adapted_signal["volatility_regime"] = "low"
                else:
                    adapted_signal["volatility_regime"] = "normal"
                
                # æ·»åŠ  Phase1B ç‰¹æœ‰çš„å­—æ®µ
                adapted_signal.update({
                    "stability_score": 1.0 - volatility * 10,  # æ³¢å‹•æ€§è¶Šé«˜ï¼Œç©©å®šæ€§è¶Šä½
                    "volatility_value": volatility,
                    "adaptation_applied": True,
                    "processing_stage": "phase1b"
                })
                
                adapted_signals.append(adapted_signal)
            
            # æ·»åŠ  Phase1B ç‰¹æœ‰çš„æ³¢å‹•æ€§ä¿¡è™Ÿ
            if volatility > 0.025:  # æ¥µé«˜æ³¢å‹•æ€§
                adapted_signals.append({
                    "signal_id": f"phase1b_volatility_{uuid.uuid4().hex[:8]}",
                    "signal_type": "VOLATILITY_BREAKOUT",
                    "signal_strength": min(1.0, volatility * 20),
                    "confidence_score": 0.8,
                    "signal_source": "phase1b",
                    "timestamp": datetime.now(),
                    "stability_score": 1.0 - volatility * 10,
                    "volatility_value": volatility,
                    "metadata": {
                        "volatility_threshold": 0.025,
                        "market_regime": "extreme_volatility"
                    }
                })
            
            logger.debug(f"ğŸŒŠ Phase1B: {len(input_signals)} -> {len(adapted_signals)} ä¿¡è™Ÿï¼Œæ³¢å‹•æ€§ {volatility:.4f}")
            return adapted_signals
            
        except Exception as e:
            logger.error(f"âŒ Phase1B æ³¢å‹•æ€§é©æ‡‰å¤±æ•—: {e}")
            return input_signals
    
    async def _stage_5_phase1c_standardization(self, input_signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç¬¬5éšæ®µï¼šPhase1C ä¿¡è™Ÿæ¨™æº–åŒ–"""
        try:
            standardized_signals = []
            
            for signal in input_signals:
                standardized_signal = signal.copy()
                
                # æ¨™æº–åŒ–ä¿¡è™Ÿå¼·åº¦åˆ° 0.0-1.0
                original_strength = signal.get("signal_strength", 0.5)
                normalized_strength = max(0.0, min(1.0, original_strength))
                
                # æ¨™æº–åŒ–ä¿¡å¿ƒåº¦åˆ° 0.0-1.0
                original_confidence = signal.get("confidence_score", 0.5)
                normalized_confidence = max(0.0, min(1.0, original_confidence))
                
                # è¨ˆç®—ç¶œåˆå“è³ªåˆ†æ•¸
                quality_score = (normalized_strength * 0.6 + normalized_confidence * 0.4)
                
                # åˆ†å±¤åˆ†é…
                if quality_score >= 0.8:
                    tier = "tier_1_critical"
                    execution_priority = 1
                elif quality_score >= 0.6:
                    tier = "tier_2_important" 
                    execution_priority = 2
                else:
                    tier = "tier_3_normal"
                    execution_priority = 3
                
                # æ›´æ–°æ¨™æº–åŒ–å­—æ®µ
                standardized_signal.update({
                    "signal_strength": normalized_strength,
                    "confidence_score": normalized_confidence,
                    "quality_score": quality_score,
                    "tier_assignment": tier,
                    "execution_priority": execution_priority,
                    "processing_stage": "phase1c",
                    "standardization_applied": True,
                    "risk_assessment": 1.0 - normalized_confidence,
                    "position_sizing": normalized_confidence * 0.1,  # æœ€å¤§10%å€‰ä½
                    "metadata": {
                        **signal.get("metadata", {}),
                        "original_strength": original_strength,
                        "original_confidence": original_confidence,
                        "standardization_timestamp": datetime.now().isoformat()
                    }
                })
                
                standardized_signals.append(standardized_signal)
            
            # æŒ‰å“è³ªåˆ†æ•¸æ’åº
            standardized_signals.sort(key=lambda x: x["quality_score"], reverse=True)
            
            logger.debug(f"ğŸ“ Phase1C: æ¨™æº–åŒ– {len(standardized_signals)} å€‹ä¿¡è™Ÿ")
            return standardized_signals
            
        except Exception as e:
            logger.error(f"âŒ Phase1C ä¿¡è™Ÿæ¨™æº–åŒ–å¤±æ•—: {e}")
            return input_signals
    
    async def _stage_6_unified_pool_aggregation(self, signals_by_source: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """ç¬¬6éšæ®µï¼šçµ±ä¸€ä¿¡è™Ÿæ± èšåˆ"""
        try:
            all_signals = []
            
            # åˆä½µæ‰€æœ‰ä¿¡è™Ÿæºçš„ä¿¡è™Ÿ
            for source, signals in signals_by_source.items():
                for signal in signals:
                    signal["aggregation_source"] = source
                    all_signals.append(signal)
            
            # å»é‡è™•ç†ï¼ˆåŸºæ–¼ä¿¡è™Ÿé¡å‹å’Œæ™‚é–“çª—å£ï¼‰
            deduplicated_signals = []
            for signal in all_signals:
                is_duplicate = False
                signal_type = signal.get("signal_type", "")
                signal_time = signal.get("timestamp", datetime.now())
                
                for existing in deduplicated_signals:
                    if (existing.get("signal_type") == signal_type and
                        abs((signal_time - existing.get("timestamp", datetime.now())).total_seconds()) < 30):
                        # ä¿ç•™å“è³ªæ›´é«˜çš„ä¿¡è™Ÿ
                        if signal.get("quality_score", 0) > existing.get("quality_score", 0):
                            deduplicated_signals.remove(existing)
                            break
                        else:
                            is_duplicate = True
                            break
                
                if not is_duplicate:
                    deduplicated_signals.append(signal)
            
            # å“è³ªéæ¿¾ï¼ˆæœ€ä½å“è³ªåˆ†æ•¸ 0.5ï¼‰
            quality_filtered = [s for s in deduplicated_signals if s.get("quality_score", 0) >= 0.5]
            
            # æ•¸é‡é™åˆ¶ï¼ˆæœ€å¤šä¿ç•™å‰10å€‹æœ€é«˜å“è³ªä¿¡è™Ÿï¼‰
            final_signals = sorted(quality_filtered, key=lambda x: x.get("quality_score", 0), reverse=True)[:10]
            
            # æ·»åŠ èšåˆå…ƒæ•¸æ“š
            for i, signal in enumerate(final_signals):
                signal.update({
                    "pool_ranking": i + 1,
                    "aggregation_timestamp": datetime.now(),
                    "processing_stage": "unified_pool",
                    "final_candidate": True
                })
            
            logger.debug(f"ğŸ¯ çµ±ä¸€æ± : {sum(len(signals) for signals in signals_by_source.values())} -> {len(final_signals)} å€‹å€™é¸ä¿¡è™Ÿ")
            return final_signals
            
        except Exception as e:
            logger.error(f"âŒ çµ±ä¸€ä¿¡è™Ÿæ± èšåˆå¤±æ•—: {e}")
            return []
    
    async def _stage_7_epl_preprocessing(self, unified_signals: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ç¬¬7éšæ®µï¼šEPL é è™•ç†æº–å‚™"""
        try:
            epl_ready_signals = []
            
            for signal in unified_signals:
                # EPL é€šéæ¦‚ç‡é æ¸¬ï¼ˆç°¡åŒ–æ¨¡å‹ï¼‰
                quality_score = signal.get("quality_score", 0.5)
                confidence = signal.get("confidence_score", 0.5)
                strength = signal.get("signal_strength", 0.5)
                
                # ç¶œåˆè©•åˆ†æ±ºå®š EPL é€šéæ¦‚ç‡
                epl_prediction = (quality_score * 0.4 + confidence * 0.3 + strength * 0.3)
                
                # åªä¿ç•™ EPL é æ¸¬é€šéæ¦‚ç‡ > 0.6 çš„ä¿¡è™Ÿ
                if epl_prediction > 0.6:
                    epl_signal = signal.copy()
                    epl_signal.update({
                        "epl_prediction": epl_prediction,
                        "epl_ready": True,
                        "processing_stage": "epl_preprocessing",
                        "stop_loss_suggestion": 0.02,  # 2% æ­¢æ
                        "take_profit_levels": [0.02, 0.04, 0.06],  # å¤šå±¤æ­¢ç›ˆ
                        "position_sizing": min(0.1, confidence * 0.15),  # å‹•æ…‹å€‰ä½
                        "execution_conditions": ["market_open", "sufficient_liquidity"],
                        "contraindications": ["extreme_volatility"] if signal.get("volatility_value", 0) > 0.03 else [],
                        "epl_preprocessing_timestamp": datetime.now(),
                        "ready_for_phase2": True
                    })
                    
                    epl_ready_signals.append(epl_signal)
            
            # æœ€çµ‚æ’åºï¼šæŒ‰ EPL é æ¸¬æ¦‚ç‡é™åº
            epl_ready_signals.sort(key=lambda x: x["epl_prediction"], reverse=True)
            
            logger.info(f"ğŸ¯ EPL é è™•ç†: {len(unified_signals)} -> {len(epl_ready_signals)} å€‹æº–å‚™å°±ç·’ä¿¡è™Ÿ")
            
            return epl_ready_signals
            
        except Exception as e:
            logger.error(f"âŒ EPL é è™•ç†å¤±æ•—: {e}")
            return []
    
    async def _generate_flow_test_report(self):
        """ç”Ÿæˆæµç¨‹æ¸¬è©¦å ±å‘Š"""
        total_time = self.flow_metrics.get("total_processing_time", 0)
        success_rate = self.flow_metrics.get("success_rate", 0)
        
        report = f"""
ğŸ¯ Phase1 å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦å ±å‘Š
{'='*50}

ğŸ“Š ç¸½é«”æŒ‡æ¨™:
- ç¸½å‘¨æœŸæ•¸: {self.flow_metrics.get('total_cycles', 0)}
- æˆåŠŸå‘¨æœŸ: {self.flow_metrics.get('successful_cycles', 0)}
- æˆåŠŸç‡: {success_rate:.1%}
- å¹³å‡è™•ç†æ™‚é–“: {total_time:.1f}ms

â±ï¸ éšæ®µè€—æ™‚:
- æ•¸æ“šç²å–: {self.flow_metrics['stage_times'].get('data_acquisition', 0):.1f}ms
- Phase1A ç”Ÿæˆ: {self.flow_metrics['stage_times'].get('phase1a_generation', 0):.1f}ms
- æŒ‡æ¨™è¨ˆç®—: {self.flow_metrics['stage_times'].get('indicator_calculation', 0):.1f}ms
- Phase1B é©æ‡‰: {self.flow_metrics['stage_times'].get('phase1b_adaptation', 0):.1f}ms
- Phase1C æ¨™æº–åŒ–: {self.flow_metrics['stage_times'].get('phase1c_standardization', 0):.1f}ms
- çµ±ä¸€æ± èšåˆ: {self.flow_metrics['stage_times'].get('unified_aggregation', 0):.1f}ms
- EPL é è™•ç†: {self.flow_metrics['stage_times'].get('epl_preprocessing', 0):.1f}ms

ğŸ¯ ä¿¡è™Ÿç”Ÿæˆ:
- Phase1A: {self.flow_metrics['signals_generated'].get('phase1a', 0)} å€‹
- æŠ€è¡“æŒ‡æ¨™: {self.flow_metrics['signals_generated'].get('indicators', 0)} å€‹
- Phase1B: {self.flow_metrics['signals_generated'].get('phase1b', 0)} å€‹
- Phase1C: {self.flow_metrics['signals_generated'].get('phase1c', 0)} å€‹
- çµ±ä¸€æ± : {self.flow_metrics['signals_generated'].get('unified', 0)} å€‹
- æœ€çµ‚ EPL: {self.flow_metrics.get('final_epl_signals', 0)} å€‹

ğŸ† è©•ç´š: {'A+' if success_rate >= 0.95 else 'A' if success_rate >= 0.9 else 'B+' if success_rate >= 0.85 else 'B' if success_rate >= 0.8 else 'C' if success_rate >= 0.7 else 'D'}
        """
        
        print(report)
        
        # ä¿å­˜è©³ç´°æŒ‡æ¨™åˆ°æ–‡ä»¶
        with open("realtime_signal_flow_report.json", "w", encoding="utf-8") as f:
            json.dump(self.flow_metrics, f, indent=2, default=str, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸç‡: {success_rate:.1%}")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    try:
        engine = RealTimeSignalFlowEngine()
        
        # é‹è¡Œ60ç§’çš„å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦
        success = await engine.run_realtime_signal_flow_test(duration_seconds=60)
        
        if success:
            logger.info("ğŸ‰ å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦é€šéï¼")
        else:
            logger.warning("âš ï¸ å¯¦æ™‚ä¿¡è™Ÿæµæ¸¬è©¦éœ€è¦æ”¹é€²")
            
        return success
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    asyncio.run(main())
