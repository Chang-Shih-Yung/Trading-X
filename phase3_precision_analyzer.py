#!/usr/bin/env python3
"""
ğŸ” Phase3 Market Analyzer ç²¾ç¢ºæ·±åº¦åˆ†æå·¥å…·
é©—è­‰ phase3_market_analyzer.py èˆ‡ phase3_market_analyzer_CORE_FLOW.json çš„å®Œæ•´åŒ¹é…åº¦
"""

import json
import ast
import re
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass

@dataclass
class AnalysisResult:
    category: str
    item: str
    status: str  # PASS, FAIL, PARTIAL
    details: str
    score: float  # 0.0 - 1.0

class Phase3PrecisionAnalyzer:
    """Phase3 å¸‚å ´åˆ†æå™¨ç²¾ç¢ºåˆ†æå·¥å…·"""
    
    def __init__(self):
        self.analysis_results: List[AnalysisResult] = []
        self.total_score = 0.0
        self.max_score = 0.0
        
    def analyze_complete_implementation(self, py_file: str, json_file: str) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´çš„å¯¦ç¾åˆ†æ"""
        print("ğŸ” é–‹å§‹ Phase3 Market Analyzer ç²¾ç¢ºæ·±åº¦åˆ†æ...")
        
        # è¼‰å…¥æ–‡ä»¶
        py_content = self._load_file(py_file)
        json_spec = self._load_json(json_file)
        
        if not py_content or not json_spec:
            print("âŒ æ–‡ä»¶è¼‰å…¥å¤±æ•—")
            return {}
        
        # 1. 7å±¤æ¶æ§‹å®Œæ•´æ€§æª¢æŸ¥
        self._verify_7_layer_architecture(py_content, json_spec)
        
        # 2. æ•¸æ“šæµè®Šæ•¸é€£çºŒæ€§æª¢æŸ¥
        self._verify_data_flow_continuity(py_content, json_spec)
        
        # 3. Layeræ“ä½œæ–¹æ³•å®Œæ•´æ€§æª¢æŸ¥
        self._verify_layer_operations(py_content, json_spec)
        
        # 4. æ€§èƒ½å„ªåŒ–æ©Ÿåˆ¶æª¢æŸ¥
        self._verify_performance_optimizations(py_content, json_spec)
        
        # 5. ä¿¡è™Ÿé¡å‹èˆ‡å¼·åº¦æª¢æŸ¥
        self._verify_signal_types_and_strength(py_content, json_spec)
        
        # 6. Phase1Cæ•´åˆæª¢æŸ¥
        self._verify_phase1c_integration(py_content, json_spec)
        
        # 7. äº‹ä»¶é©…å‹•èˆ‡é©æ‡‰æ€§æª¢æŸ¥
        self._verify_event_driven_adaptive(py_content, json_spec)
        
        # 8. æ•…éšœæ¢å¾©æ©Ÿåˆ¶æª¢æŸ¥
        self._verify_failover_mechanisms(py_content, json_spec)
        
        # è¨ˆç®—ç¸½åˆ†
        return self._generate_comprehensive_report()
    
    def _verify_7_layer_architecture(self, py_content: str, json_spec: Dict):
        """é©—è­‰7å±¤æ¶æ§‹å®Œæ•´æ€§"""
        print("\nğŸ—ï¸ é©—è­‰7å±¤æ¶æ§‹å®Œæ•´æ€§...")
        
        # JSONè¦ç¯„ä¸­çš„å±¤ç´š
        required_layers = {
            "layer_0": "Phase1C æ™‚é–“æˆ³åŒæ­¥æ•´åˆå±¤",
            "layer_1a": "é«˜é »æ•¸æ“šæµè™•ç†å±¤", 
            "layer_1b": "ä½é »æ•¸æ“šæ”¶é›†å±¤",
            "layer_2": "OrderBook æ·±åº¦åˆ†æå±¤",
            "layer_3": "å¸‚å ´æƒ…ç·’èˆ‡è³‡é‡‘æµå‘åˆ†æå±¤",
            "layer_4": "å¸‚å ´å¾®çµæ§‹ä¿¡è™Ÿç”Ÿæˆå±¤",
            "layer_5": "é«˜éšåˆ†æèˆ‡é æ¸¬ä¿¡è™Ÿå±¤"
        }
        
        # æª¢æŸ¥æ¯å±¤çš„å¯¦ç¾
        for layer_key, layer_name in required_layers.items():
            layer_method = f"_layer_{layer_key.replace('layer_', '')}"
            
            if re.search(rf"def {layer_method}|async def {layer_method}", py_content):
                self._add_result("7å±¤æ¶æ§‹", f"{layer_key} ({layer_name})", "PASS", 
                               "Layeræ–¹æ³•å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("7å±¤æ¶æ§‹", f"{layer_key} ({layer_name})", "FAIL", 
                               "Layeræ–¹æ³•æœªå¯¦ç¾", 0.0)
        
        # æª¢æŸ¥ä¸»è™•ç†æµç¨‹
        if "process_market_data" in py_content:
            self._add_result("7å±¤æ¶æ§‹", "ä¸»è™•ç†æµç¨‹", "PASS", "ä¸»è™•ç†æ–¹æ³•å­˜åœ¨", 1.0)
        else:
            self._add_result("7å±¤æ¶æ§‹", "ä¸»è™•ç†æµç¨‹", "FAIL", "ä¸»è™•ç†æ–¹æ³•ç¼ºå¤±", 0.0)
    
    def _verify_data_flow_continuity(self, py_content: str, json_spec: Dict):
        """é©—è­‰æ•¸æ“šæµè®Šæ•¸é€£çºŒæ€§"""
        print("\nğŸ“Š é©—è­‰æ•¸æ“šæµè®Šæ•¸é€£çºŒæ€§...")
        
        # JSONè¦ç¯„ä¸­çš„é—œéµæ•¸æ“šæµè®Šæ•¸
        data_flow_variables = {
            "layer_0": [
                "synchronized_phase3_timestamp_reference"
            ],
            "layer_1a": [
                "real_time_orderbook_websocket",
                "tick_by_tick_trade_data", 
                "adaptive_50ms_to_200ms",
                "incremental_volume_profile"
            ],
            "layer_1b": [
                "funding_rate_8_hours",
                "open_interest_30_seconds",
                "market_regime_daily"
            ],
            "layer_2": [
                "bid_ask_imbalance",
                "order_flow_intensity",
                "market_depth_analysis",
                "sliding_window_analysis"
            ],
            "layer_3": [
                "funding_sentiment_score",
                "oi_momentum_signal",
                "volume_sentiment_indicators"
            ],
            "layer_4": [
                "liquidity_shock_signal",
                "institutional_flow_signal", 
                "sentiment_divergence_signal",
                "liquidity_regime_change_signal"
            ],
            "layer_5": [
                "price_impact_prediction",
                "liquidity_forecast",
                "market_stress_indicator"
            ]
        }
        
        # æª¢æŸ¥è®Šæ•¸åœ¨ä»£ç¢¼ä¸­çš„ä½¿ç”¨
        for layer, variables in data_flow_variables.items():
            for var in variables:
                if var in py_content:
                    self._add_result("æ•¸æ“šæµé€£çºŒæ€§", f"{layer}.{var}", "PASS", 
                                   "è®Šæ•¸å·²ä½¿ç”¨", 1.0)
                else:
                    self._add_result("æ•¸æ“šæµé€£çºŒæ€§", f"{layer}.{var}", "FAIL", 
                                   "è®Šæ•¸æœªä½¿ç”¨", 0.0)
    
    def _verify_layer_operations(self, py_content: str, json_spec: Dict):
        """é©—è­‰Layeræ“ä½œæ–¹æ³•å®Œæ•´æ€§"""
        print("\nğŸ”§ é©—è­‰Layeræ“ä½œæ–¹æ³•å®Œæ•´æ€§...")
        
        # é—œéµæ“ä½œæ–¹æ³•
        required_operations = {
            "layer_1a": [
                "_process_orderbook_stream",
                "_process_tick_data",
                "_detect_large_orders"
            ],
            "layer_1b": [
                "_collect_funding_rate",
                "_monitor_open_interest",
                "_analyze_market_regime"
            ],
            "layer_2": [
                "_calculate_bid_ask_imbalance",
                "_analyze_order_flow_intensity",
                "_analyze_market_depth"
            ],
            "layer_3": [
                "_analyze_funding_sentiment",
                "_calculate_oi_momentum",
                "_analyze_volume_sentiment"
            ],
            "layer_4": [
                "_detect_liquidity_shock",
                "_detect_institutional_flow",
                "_detect_sentiment_divergence",
                "_detect_liquidity_regime_change"
            ],
            "layer_5": [
                "_predict_price_impact",
                "_forecast_liquidity",
                "_calculate_market_stress"
            ]
        }
        
        for layer, operations in required_operations.items():
            for operation in operations:
                if f"def {operation}" in py_content or f"async def {operation}" in py_content:
                    self._add_result("Layeræ“ä½œæ–¹æ³•", f"{layer}.{operation}", "PASS", 
                                   "æ“ä½œæ–¹æ³•å·²å¯¦ç¾", 1.0)
                else:
                    self._add_result("Layeræ“ä½œæ–¹æ³•", f"{layer}.{operation}", "FAIL", 
                                   "æ“ä½œæ–¹æ³•æœªå¯¦ç¾", 0.0)
    
    def _verify_performance_optimizations(self, py_content: str, json_spec: Dict):
        """é©—è­‰æ€§èƒ½å„ªåŒ–æ©Ÿåˆ¶"""
        print("\nâš¡ é©—è­‰æ€§èƒ½å„ªåŒ–æ©Ÿåˆ¶...")
        
        # JSONè¦ç¯„è¦æ±‚çš„å„ªåŒ–æ©Ÿåˆ¶
        optimization_features = [
            "DoubleBuffer",  # é›™ç·©è¡
            "RingBuffer",   # ç’°ç‹€ç·©è¡
            "AdaptivePerformanceController",  # é©æ‡‰æ€§èƒ½æ§åˆ¶
            "EventDrivenProcessor",  # äº‹ä»¶é©…å‹•è™•ç†
            "adaptive_50ms_to_200ms",  # é©æ‡‰æ€§æ¡æ¨£
            "incremental_volume_profile",  # å¢é‡è¨ˆç®—
            "sliding_window_analysis"  # æ»‘å‹•çª—å£
        ]
        
        for feature in optimization_features:
            if feature in py_content:
                self._add_result("æ€§èƒ½å„ªåŒ–", feature, "PASS", "å„ªåŒ–æ©Ÿåˆ¶å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("æ€§èƒ½å„ªåŒ–", feature, "FAIL", "å„ªåŒ–æ©Ÿåˆ¶æœªå¯¦ç¾", 0.0)
        
        # æª¢æŸ¥æ™‚é–“ç›®æ¨™
        time_targets = [
            "35ms",  # ç¸½è™•ç†æ™‚é–“
            "30ms",  # Tier1é«˜æ³¢å‹•ç›®æ¨™
            "50ms",  # Tier1æ­£å¸¸ç›®æ¨™
            "9ms",   # Layer1Aç›®æ¨™
            "6ms"    # Layer1Bç›®æ¨™
        ]
        
        for target in time_targets:
            if target in py_content:
                self._add_result("æ€§èƒ½ç›®æ¨™", target, "PASS", "æ™‚é–“ç›®æ¨™å·²è¨­å®š", 1.0)
            else:
                self._add_result("æ€§èƒ½ç›®æ¨™", target, "FAIL", "æ™‚é–“ç›®æ¨™æœªè¨­å®š", 0.0)
    
    def _verify_signal_types_and_strength(self, py_content: str, json_spec: Dict):
        """é©—è­‰ä¿¡è™Ÿé¡å‹èˆ‡å¼·åº¦"""
        print("\nğŸ¯ é©—è­‰ä¿¡è™Ÿé¡å‹èˆ‡å¼·åº¦...")
        
        # JSONè¦ç¯„ä¸­çš„ä¿¡è™Ÿé¡å‹
        signal_types = {
            "LIQUIDITY_SHOCK": {
                "strength": "0.8-1.0",
                "tier": "tier_1_critical"
            },
            "INSTITUTIONAL_FLOW": {
                "strength": "0.7-0.9", 
                "tier": "tier_1_critical"
            },
            "SENTIMENT_DIVERGENCE": {
                "strength": "0.72-1.0",
                "tier": "tier_2_important"
            },
            "LIQUIDITY_REGIME_CHANGE": {
                "strength": "0.75-1.0",
                "tier": "tier_3_monitoring"
            }
        }
        
        for signal_type, specs in signal_types.items():
            if signal_type in py_content:
                self._add_result("ä¿¡è™Ÿé¡å‹", signal_type, "PASS", "ä¿¡è™Ÿé¡å‹å·²å®šç¾©", 1.0)
            else:
                self._add_result("ä¿¡è™Ÿé¡å‹", signal_type, "FAIL", "ä¿¡è™Ÿé¡å‹æœªå®šç¾©", 0.0)
            
            # æª¢æŸ¥tieråˆ†é…
            if specs["tier"] in py_content:
                self._add_result("ä¿¡è™Ÿå±¤ç´š", f"{signal_type}.{specs['tier']}", "PASS", 
                               "Tieråˆ†é…æ­£ç¢º", 1.0)
            else:
                self._add_result("ä¿¡è™Ÿå±¤ç´š", f"{signal_type}.{specs['tier']}", "FAIL", 
                               "Tieråˆ†é…ç¼ºå¤±", 0.0)
    
    def _verify_phase1c_integration(self, py_content: str, json_spec: Dict):
        """é©—è­‰Phase1Cæ•´åˆ"""
        print("\nğŸ”— é©—è­‰Phase1Cæ•´åˆ...")
        
        # Phase1Cæ•´åˆè¦æ±‚
        integration_features = [
            "phase1c_signal_standardization",
            "layer_0_cross_module_sync",
            "Phase1C",
            "unified_signal_candidate_pool",
            "200ms",  # åŒæ­¥å®¹éŒ¯
            "signal_strength",  # 0.0-1.0æ¨™æº–
            "tier_assignment"
        ]
        
        for feature in integration_features:
            if feature in py_content:
                self._add_result("Phase1Cæ•´åˆ", feature, "PASS", "æ•´åˆç‰¹æ€§å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("Phase1Cæ•´åˆ", feature, "FAIL", "æ•´åˆç‰¹æ€§ç¼ºå¤±", 0.0)
        
        # æª¢æŸ¥æ¨™æº–åŒ–ä¿¡è™Ÿæ ¼å¼
        if "MarketMicrostructureSignal" in py_content:
            self._add_result("Phase1Cæ•´åˆ", "æ¨™æº–åŒ–ä¿¡è™Ÿæ ¼å¼", "PASS", 
                           "ä¿¡è™Ÿæ ¼å¼å·²æ¨™æº–åŒ–", 1.0)
        else:
            self._add_result("Phase1Cæ•´åˆ", "æ¨™æº–åŒ–ä¿¡è™Ÿæ ¼å¼", "FAIL", 
                           "ä¿¡è™Ÿæ ¼å¼æœªæ¨™æº–åŒ–", 0.0)
    
    def _verify_event_driven_adaptive(self, py_content: str, json_spec: Dict):
        """é©—è­‰äº‹ä»¶é©…å‹•èˆ‡é©æ‡‰æ€§"""
        print("\nğŸ¯ é©—è­‰äº‹ä»¶é©…å‹•èˆ‡é©æ‡‰æ€§...")
        
        # äº‹ä»¶é©…å‹•ç‰¹æ€§
        event_driven_features = [
            "should_trigger_liquidity_shock_analysis",
            "large_order_volume_multiplier",
            "spread_widening_multiplier",
            "depth_decrease_threshold",
            "market_stress_level",
            "processing_mode"
        ]
        
        for feature in event_driven_features:
            if feature in py_content:
                self._add_result("äº‹ä»¶é©…å‹•", feature, "PASS", "äº‹ä»¶é©…å‹•ç‰¹æ€§å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("äº‹ä»¶é©…å‹•", feature, "FAIL", "äº‹ä»¶é©…å‹•ç‰¹æ€§ç¼ºå¤±", 0.0)
        
        # é©æ‡‰æ€§ç‰¹æ€§
        adaptive_features = [
            "high_volatility",
            "low_volatility", 
            "normal",
            "update_market_stress",
            "get_processing_frequency_ms",
            "dynamic_weight_adaptation"
        ]
        
        for feature in adaptive_features:
            if feature in py_content:
                self._add_result("é©æ‡‰æ€§æ©Ÿåˆ¶", feature, "PASS", "é©æ‡‰æ€§ç‰¹æ€§å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("é©æ‡‰æ€§æ©Ÿåˆ¶", feature, "FAIL", "é©æ‡‰æ€§ç‰¹æ€§ç¼ºå¤±", 0.0)
    
    def _verify_failover_mechanisms(self, py_content: str, json_spec: Dict):
        """é©—è­‰æ•…éšœæ¢å¾©æ©Ÿåˆ¶"""
        print("\nğŸ›¡ï¸ é©—è­‰æ•…éšœæ¢å¾©æ©Ÿåˆ¶...")
        
        # æ•…éšœæ¢å¾©ç‰¹æ€§
        failover_features = [
            "binance",
            "okx",
            "bybit",
            "å¤‡æ´",
            "å‚™æ´",
            "fallback",
            "5s",  # åˆ‡æ›æ™‚é–“
            "health_check",
            "api_availability"
        ]
        
        for feature in failover_features:
            if feature.lower() in py_content.lower():
                self._add_result("æ•…éšœæ¢å¾©", feature, "PASS", "æ•…éšœæ¢å¾©ç‰¹æ€§å·²å¯¦ç¾", 1.0)
            else:
                self._add_result("æ•…éšœæ¢å¾©", feature, "FAIL", "æ•…éšœæ¢å¾©ç‰¹æ€§ç¼ºå¤±", 0.0)
    
    def _add_result(self, category: str, item: str, status: str, details: str, score: float):
        """æ·»åŠ åˆ†æçµæœ"""
        result = AnalysisResult(category, item, status, details, score)
        self.analysis_results.append(result)
        self.total_score += score
        self.max_score += 1.0
    
    def _generate_comprehensive_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç¶œåˆå ±å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç¶œåˆåˆ†æå ±å‘Š...")
        
        # æŒ‰é¡åˆ¥çµ±è¨ˆ
        category_stats = {}
        for result in self.analysis_results:
            if result.category not in category_stats:
                category_stats[result.category] = {"pass": 0, "fail": 0, "partial": 0, "total": 0, "score": 0}
            
            category_stats[result.category][result.status.lower()] += 1
            category_stats[result.category]["total"] += 1
            category_stats[result.category]["score"] += result.score
        
        # è¨ˆç®—é¡åˆ¥åˆ†æ•¸
        for category, stats in category_stats.items():
            if stats["total"] > 0:
                stats["percentage"] = (stats["score"] / stats["total"]) * 100
        
        overall_percentage = (self.total_score / self.max_score) * 100 if self.max_score > 0 else 0
        
        # åˆ¤å®šæœ€çµ‚ç‹€æ…‹
        if overall_percentage >= 95:
            final_status = "âœ… EXCELLENT - æ¥è¿‘å®Œç¾åŒ¹é…"
        elif overall_percentage >= 85:
            final_status = "ğŸŸ¢ GOOD - å¤§éƒ¨åˆ†ç‰¹æ€§å·²å¯¦ç¾"
        elif overall_percentage >= 70:
            final_status = "ğŸŸ¡ PARTIAL - éœ€è¦é‡è¦æ”¹é€²"
        else:
            final_status = "ğŸ”´ POOR - éœ€è¦é‡å¤§é‡æ§‹"
        
        report = {
            "overall_score": overall_percentage,
            "final_status": final_status,
            "category_breakdown": category_stats,
            "critical_missing": self._get_critical_missing(),
            "architecture_gaps": self._get_architecture_gaps(),
            "performance_issues": self._get_performance_issues(),
            "recommendations": self._get_recommendations(overall_percentage)
        }
        
        return report
    
    def _get_critical_missing(self) -> List[str]:
        """ç²å–é—œéµç¼ºå¤±é …ç›®"""
        missing = []
        critical_categories = ["7å±¤æ¶æ§‹", "æ•¸æ“šæµé€£çºŒæ€§", "Layeræ“ä½œæ–¹æ³•"]
        
        for result in self.analysis_results:
            if result.category in critical_categories and result.status == "FAIL":
                missing.append(f"{result.category}: {result.item}")
        
        return missing
    
    def _get_architecture_gaps(self) -> List[str]:
        """ç²å–æ¶æ§‹å·®è·"""
        gaps = []
        
        for result in self.analysis_results:
            if result.category in ["7å±¤æ¶æ§‹", "Phase1Cæ•´åˆ"] and result.status == "FAIL":
                gaps.append(f"{result.item}: {result.details}")
        
        return gaps
    
    def _get_performance_issues(self) -> List[str]:
        """ç²å–æ€§èƒ½å•é¡Œ"""
        issues = []
        
        for result in self.analysis_results:
            if result.category in ["æ€§èƒ½å„ªåŒ–", "æ€§èƒ½ç›®æ¨™"] and result.status == "FAIL":
                issues.append(f"{result.item}: {result.details}")
        
        return issues
    
    def _get_recommendations(self, score: float) -> List[str]:
        """ç²å–æ”¹é€²å»ºè­°"""
        recommendations = []
        
        if score < 95:
            recommendations.append("å¯¦ç¾æ‰€æœ‰å¤±æ•—çš„åˆ†æé …ç›®")
        
        if score < 85:
            recommendations.append("é‡é»é—œæ³¨7å±¤æ¶æ§‹å®Œæ•´æ€§å’Œæ•¸æ“šæµé€£çºŒæ€§")
        
        if score < 70:
            recommendations.append("éœ€è¦é‡æ–°è¨­è¨ˆæ ¸å¿ƒæ¶æ§‹ä»¥ç¬¦åˆJSONè¦ç¯„")
        
        # å…·é«”å»ºè­°
        if score < 90:
            recommendations.append("å®Œå–„äº‹ä»¶é©…å‹•å’Œé©æ‡‰æ€§æ©Ÿåˆ¶")
            recommendations.append("å¯¦ç¾å®Œæ•´çš„æ€§èƒ½å„ªåŒ–ç‰¹æ€§")
            recommendations.append("ç¢ºä¿Phase1Cæ•´åˆçš„å®Œæ•´æ€§")
        
        return recommendations
    
    def _load_file(self, filepath: str) -> str:
        """è¼‰å…¥æ–‡ä»¶"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"è¼‰å…¥æ–‡ä»¶å¤±æ•— {filepath}: {e}")
            return ""
    
    def _load_json(self, filepath: str) -> Dict:
        """è¼‰å…¥JSONæ–‡ä»¶"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¼‰å…¥JSONå¤±æ•— {filepath}: {e}")
            return {}

def main():
    """ä¸»å‡½æ•¸"""
    analyzer = Phase3PrecisionAnalyzer()
    
    # æ–‡ä»¶è·¯å¾‘
    py_file = "X/backend/phase1_signal_generation/phase3_market_analyzer/phase3_market_analyzer.py"
    json_file = "X/backend/phase1_signal_generation/phase3_market_analyzer/phase3_market_analyzer_CORE_FLOW.json"
    
    # åŸ·è¡Œåˆ†æ
    report = analyzer.analyze_complete_implementation(py_file, json_file)
    
    # é¡¯ç¤ºçµæœ
    print("\n" + "="*80)
    print("ğŸ¯ PHASE3 MARKET ANALYZER ç²¾ç¢ºæ·±åº¦åˆ†æå ±å‘Š")
    print("="*80)
    print(f"ç¸½é«”åˆ†æ•¸: {report['overall_score']:.1f}%")
    print(f"æœ€çµ‚ç‹€æ…‹: {report['final_status']}")
    
    print("\nğŸ“Š é¡åˆ¥åˆ†æ:")
    for category, stats in report['category_breakdown'].items():
        print(f"  {category}: {stats['percentage']:.1f}% "
              f"(âœ…{stats['pass']} âŒ{stats['fail']})")
    
    if report['critical_missing']:
        print("\nğŸš¨ é—œéµç¼ºå¤±:")
        for missing in report['critical_missing'][:10]:  # é¡¯ç¤ºå‰10å€‹
            print(f"  â€¢ {missing}")
    
    if report['architecture_gaps']:
        print("\nğŸ—ï¸ æ¶æ§‹å·®è·:")
        for gap in report['architecture_gaps'][:5]:  # é¡¯ç¤ºå‰5å€‹
            print(f"  â€¢ {gap}")
    
    if report['performance_issues']:
        print("\nâš¡ æ€§èƒ½å•é¡Œ:")
        for issue in report['performance_issues'][:5]:  # é¡¯ç¤ºå‰5å€‹
            print(f"  â€¢ {issue}")
    
    if report['recommendations']:
        print("\nğŸ’¡ æ”¹é€²å»ºè­°:")
        for rec in report['recommendations']:
            print(f"  â€¢ {rec}")
    
    print("\n" + "="*80)
    
    return report

if __name__ == "__main__":
    main()
